<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Intellij IDEA 2021.2.3最新版免费激活教程（可激活至2099年，亲测有效）</title>
      <link href="/posts/2375004886/"/>
      <url>/posts/2375004886/</url>
      
        <content type="html"><![CDATA[<p>欢迎关注博主公众号【跟着Mic学架构】，专注于分享Java领域技术干活，回复关键字[面试资料]可以获得海量面试资料。</p><blockquote><p>申明，本教程Intellij IDEA 最新版破解、激活码均收集与网络，请勿商用，仅供个人学习使用，如有侵权，请联系作者删除。如条件允许，建议大家购买正版。</p></blockquote><blockquote><p>本教程更新于：2021年10月26号，后续如果存在不可用问题，博主会及时更新。</p></blockquote><p><strong>以下是博主免费激活之后的Licenses信息，激活到2099年，支持Windows和Macos。</strong></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261458608.jpg" alt="img"></p><h1 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h1><ol><li>本教程适用于Intellij IDEA 2021.2.3以下所有版本</li><li>本教程适用于JetBrains全系列产品，包括IDEA、Pycharm、WebStorm、PhpStorm、AppCode等</li><li>本教程适用于Windows/Mac/Linux，本文以Window下的版本为例进行演示，其他系统的操作方式完全相同。</li></ol><h1 id="安装IntelliJ-IDEA-2021-2-3最新版本"><a href="#安装IntelliJ-IDEA-2021-2-3最新版本" class="headerlink" title="安装IntelliJ IDEA 2021.2.3最新版本"></a>安装IntelliJ IDEA 2021.2.3最新版本</h1><h2 id="下载IntelliJ-IDEA"><a href="#下载IntelliJ-IDEA" class="headerlink" title="下载IntelliJ IDEA"></a>下载IntelliJ IDEA</h2><p>点击<a href="https://www.jetbrains.com/idea/download/#section=windows">https://www.jetbrains.com/idea/download/#section=windows</a>这个地址，下载IntelliJ IDEA 2021.2.3最新版本</p><blockquote><p>建议用迅雷下载，速度会更快哦！！！</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261504175.png" alt="image-20211026150246674"></p><h2 id="卸载老版本的IDEA（如果已经安装了IDEA）"><a href="#卸载老版本的IDEA（如果已经安装了IDEA）" class="headerlink" title="卸载老版本的IDEA（如果已经安装了IDEA）"></a>卸载老版本的IDEA（如果已经安装了IDEA）</h2><blockquote><p>如果电脑上已经安装了老版本的IDEA，需要先卸载赶紧，否则可能会出现问题</p></blockquote><h3 id="保存配置文件"><a href="#保存配置文件" class="headerlink" title="保存配置文件"></a>保存配置文件</h3><p>IntelliJ IDEA有一个配置文件夹，保留了你使用IntelliJ IDEA的一些默认配置信息，如果你已经修改过IntelliJ IDEA的配置，比如JDK环境、Maven环境、以及其他配置项目。</p><p>如果你希望新安装的IntelliJ IDEA，安装完成后能够保留这些配置，则需要先备份IntelliJ IDEA的配置目录，该目录默认的路径配置如下。</p><blockquote><p>这个文件是：IntelliJIDEA安装目录下 ${IntelliJIDEA_HOME}\bin\idea.properties</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">---------------------------------------------------------------------</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Uncomment this option <span class="keyword">if</span> you want to customize path to IDE config folder. Make sure you<span class="string">&#x27;re using forward slashes.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="string">---------------------------------------------------------------------</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="string"> idea.config.path=$&#123;user.home&#125;/.IntelliJIdea/config</span></span></span><br><span class="line"><span class="meta"></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="string">---------------------------------------------------------------------</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"><span class="string"> Uncomment this option if you want to customize path to IDE system folder. Make sure you&#x27;</span>re using forward slashes.</span></span><br><span class="line"><span class="meta">#</span><span class="bash">---------------------------------------------------------------------</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> idea.system.path=<span class="variable">$&#123;user.home&#125;</span>/.IntelliJIdea/system</span></span><br></pre></td></tr></table></figure><p>config和system是用来存储IntelliJ IDEA个性化配置的地方。提前把<code>.IntelliJIdea</code>这个文件件备份，后续新的版本安装完成后，可以直接导入这个配置项目</p><h3 id="开始卸载"><a href="#开始卸载" class="headerlink" title="开始卸载"></a>开始卸载</h3><p>没有安装IntelliJ IDEA的同学，可以省略这个步骤。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261532215.png" alt="image-20211026153227181"></p><h2 id="开始安装IntelliJ-IDEA-2021-2-3版本"><a href="#开始安装IntelliJ-IDEA-2021-2-3版本" class="headerlink" title="开始安装IntelliJ IDEA 2021.2.3版本"></a>开始安装IntelliJ IDEA 2021.2.3版本</h2><p>默认安装目录是<code>C:\Program Files\JetBrains\IntelliJ IDEA 2021.2.3</code>，这里我选择安装到其他磁盘</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261536577.png" alt="image-20211026153628542"></p><p>勾选创建桌面快捷方式，<code>Create Desktop Shortcut</code>，方便后续打开。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261539494.png" alt="image-20211026153910459"></p><p>点击<code>next</code>-&gt;<code>install</code>，进行安装，安装完成后，<code>Run IntelliJ IDEA</code>运行。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261540124.png" alt="image-20211026154054084"></p><h1 id="开始激活Intellij-IDEA"><a href="#开始激活Intellij-IDEA" class="headerlink" title="开始激活Intellij IDEA"></a>开始激活Intellij IDEA</h1><p>打开IntelliJ IDEA工具，首先会进入到<code>License Activation</code>激活页面，这个页面有两个选项</p><ol><li><code>Activate IntelliJ IDEA</code>， 通过密钥激活IDEA</li><li><code>Start trial</code>，免费体验IDEA，不过在新版本中需要注册帐号登录才能体验。</li></ol><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261544766.png" alt="image-20211026154421721"></p><blockquote><p>还有一个问题需要注意，有些同学点击<code>Log In to JetBrains Account...</code>这个按钮跳转到网页，网页无法打开。我就遇到了这个问题。</p><p>原因是，我们在host文件中增加了一些<code>account.jetbrains.com</code>相关的映射，所以大家需要去<code>C:/Windows/System32/Driver/etcs/host</code>文件中，把这些内容去掉就可以打开了</p></blockquote><blockquote><p>注册的流程这里就省略了，直接点击按钮后会弹出一个浏览器进入到IntelliJ IDEA官网，注册一个帐号并登录即可</p></blockquote><p>下图是对应登录成功后的界面，点击<code>Start Trial</code>开始免费试用。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261549810.png" alt="image-20211026154909766"></p><p>开始试用后，会进入待如下页面，<code>免费试用的时间是1个月</code></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261549572.png" alt="image-20211026154953537"></p><p>需要注意，有了登录帐号这个机制以后，对于这个帐号的试用期，是从注册登录的这一刻开始，这篇文章我写在10月26号，但是第一次登录是在10月23号，所以提示有效期是到11月23号。</p><p>所以，如果遇到帐号已经过期的情况下，可能不会出现这个界面，所以大家可以执行破解补丁中<code>reset_script</code>这个脚本来重置试用期时间。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261557317.png" alt="image-20211026155705290"></p><center style="color:red">破解补丁在文章末尾处下载</center><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">window系统： reset_jetbrains_eval_mac_linux.sh</span><br><span class="line">Linux/Mac系统： reset_jetbrains_eval_windows.vbs</span><br></pre></td></tr></table></figure><h1 id="清空IDEA以往的激活方式"><a href="#清空IDEA以往的激活方式" class="headerlink" title="清空IDEA以往的激活方式"></a>清空IDEA以往的激活方式</h1><p>之前用过IDEA的同学，可能已经用了其他破解补丁破解过，一般的方式也是通过Host代理、以及Jar文件替换的形式来实现，所以在使用这篇文章描述的方法来破解时，需要把原本激活的配置还原，比如Host文件的映射要去掉。</p><h1 id="配置破解补丁"><a href="#配置破解补丁" class="headerlink" title="配置破解补丁"></a>配置破解补丁</h1><p>进入到IDEA项目开发界面（<code>默认情况下，需要创建一个项目或者打开一个项目，才能进入到这个页面</code>）</p><p>点击如图所示的菜单： <code>Help - &gt; Edit Custom VM Options...</code>。 修改<code>idea64.exe.vmoptions</code>文件。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261609030.png" alt="image-20211026160900903"></p><p>点击按钮，会打开<code>idea64.exe.vmoptions</code>文件。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261612234.png" alt="image-20211026161250145"></p><p>在这个文件中，我们需要把破解补丁中的<code>FineAgent.jar</code>文件，配置到<code>idea64.exe.vmoptions</code>文件中。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261612155.png" alt="image-20211026161238120"></p><ol><li><p>先把这个jar包拷贝到一个固定目录下，我这里把它拷贝到了IDEA安装目录下<code>D:\software\IntelliJ IDEA 2021.2.3\FineAgent.jar</code>，大家可以根据自己实际的情况随意放置。</p></li><li><p>修改<code>idea64.exe.vmoptions</code>文件，增加如下配置</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">-javaagent:D:\software\IntelliJ IDEA 2021.2.3\FineAgent.jar</span><br></pre></td></tr></table></figure><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261618161.png" alt="image-20211026161856091"></p></li></ol><h1 id="重启IntelliJ-IDEA"><a href="#重启IntelliJ-IDEA" class="headerlink" title="重启IntelliJ IDEA"></a>重启IntelliJ IDEA</h1><p>修改完成后，重启IntelliJ IDEA工具。</p><p>重启后，又会重新进入到激活页面，这个时候，我们选择<code>Activate IntelliJ IDEA</code>。</p><p>然后License选择<code>Activation Code</code>。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261619884.png" alt="image-20211026161957845"></p><p>输入激活码，点击<code>Activate</code>按钮进行激活。</p><blockquote><p>激活码一定要在补丁配置之后才能使用，否则是激活不了的。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261621919.png" alt="image-20211026162135885"></p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261621194.png" alt="image-20211026162108148"></p><p>点击<code>Activate</code>按钮后，就能看到下面这个界面， 过期时间到2099年， 唉，终于可以在IDEA这个工具上实现终身编程的梦想。 </p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261626009.png" alt="image-20211026162630968"></p><h1 id="激活补丁下载"><a href="#激活补丁下载" class="headerlink" title="激活补丁下载"></a>激活补丁下载</h1><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261627765.png" alt="image-20211026162742723"></p><p>激活补丁，本来是分享在百度云盘，但是百度云盘同时访问的人数过多，很容易出现被封的情况。我这边做了多个网盘的分享，然后在公众号里面基于关键字随机回复，保证激活补丁的持续性。</p><p>需要下载的小伙伴，扫描下面的二维码，或者关注公众号： 跟着Mic学架构，回复关键字<code>idea</code>，即可免费获得激活码。</p><blockquote><p>后续激活码如果失效了，我会同步进行更新。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110261631009.png" alt="img"></p>]]></content>
      
      
      <categories>
          
          <category> Intellij IDEA </category>
          
      </categories>
      
      
        <tags>
            
            <tag> IDEA </tag>
            
            <tag> Intellij IDEA </tag>
            
            <tag> 破解 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>面试题系列：new String(&quot;abc&quot;)创建了几个对象</title>
      <link href="/posts/2257629016/"/>
      <url>/posts/2257629016/</url>
      
        <content type="html"><![CDATA[<h1 id="new-String-“abc”-创建了几个对象"><a href="#new-String-“abc”-创建了几个对象" class="headerlink" title="new String(“abc”)创建了几个对象"></a>new String(“abc”)创建了几个对象</h1><h1 id="面试官考察点猜想"><a href="#面试官考察点猜想" class="headerlink" title="面试官考察点猜想"></a>面试官考察点猜想</h1><p>这种问题，考察你对JVM的理解程度。涉及到常量池、对象内存分配等问题。</p><h1 id="涉及背景知识详解"><a href="#涉及背景知识详解" class="headerlink" title="涉及背景知识详解"></a>涉及背景知识详解</h1><p>在分析这个问题之前，我们先来了解一下JVM的组成，如图所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211025105901442.png" alt="image-20211025105901442"></p><p>在JVM1.8中，内存划分为堆、程序计数器、本地方发栈、方法区（元空间）、虚拟机栈。</p><h2 id="JVM知识点普及"><a href="#JVM知识点普及" class="headerlink" title="JVM知识点普及"></a>JVM知识点普及</h2><p>下面分别解释一下JVM运行时内存的功能。</p><h3 id="堆内存空间"><a href="#堆内存空间" class="headerlink" title="堆内存空间"></a>堆内存空间</h3><p>堆是 JVM 内存中最大的一块内存空间，该内存被所有线程共享，几乎所有对象和数组都被分配到了堆内存中。堆被划分为新生代和老年代，新生代又被进一步划分为 Eden 和 Survivor 区，最后 Survivor 由 From Survivor 和 To Survivor 组成。</p><p>但需要注意的是，这些区域的划分因不同的垃圾收集器而不同。大部分垃圾收集器都是基于分代收集理论设计的，就会采用这种分代模型。而一些新的垃圾收集器不采用分代设计，比如 G1 收集器就是把堆内存拆分为多个大小相等的 Region。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211025204342332.png" alt="image-20211025204342332"></p><h3 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h3><p>在 jdk8 之前，HotSopt 虚拟机的方法区又被称为永久代，由于永久代的设计容易导致内存溢出等问题，jdk8 之后就没有永久代了，取而代之的是元空间（MetaSpace）。元空间并没有处于堆内存上，而是直接占用的本地内存，因此元空间的最大大小受本地内存限制。</p><p>方法区与堆空间类似，是所有线程共享的。方法区主要是用来存放已被虚拟机加载的类型信息、常量、静态变量等数据。方法区是一个逻辑分区，包含元空间、运行时常量池、字符串常量池，元空间物理上使用的本地内存，运行时常量池和字符串常量池是在堆中开辟的一块特殊内存区域。这样做的好处之一是可以避免运行时动态生成的常量的复制迁移，可以直接使用堆中的引用。</p><blockquote><p>要注意的是，字符串常量池在JVM中只有一个，而运行时常量池是和类型数据绑定的，每个Class一个。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211025210852393.png" alt="image-20211025210852393"></p><ol><li>每个class的字节码文件中都有一个常量池，里面是编译后即知的该class会用到的<code>字面量</code>与<code>符号引用</code>，这就是<code>class文件常量池</code>。JVM加载class，会将其类信息，包括class文件常量池置于方法区中。</li><li>class类信息及其class文件常量池是字节码的二进制流，它代表的是一个类的静态存储结构，JVM加载类时，需要将其转换为方法区中的<code>java.lang.Class</code>类的对象实例；同时，会将class文件常量池中的内容导入<code>运行时常量池</code>。</li><li>运行时常量池中的常量对应的内容只是字面量，比如一个”字符串”，它还不是String对象；当Java程序在运行时执行到这个”字符串”字面量时，会去<code>字符串常量池</code>里找该字面量的对象引用是否存在，存在则直接返回该引用，不存在则在Java堆里创建该字面量对应的String对象，并将其引用置于字符串常量池中，然后返回该引用。</li><li>Java的基本数据类型中，除了两个浮点数类型，其他的基本数据类型都在各自内部实现了常量池，但都在[-128~127]这个范围内。</li></ol><h3 id="虚拟机栈"><a href="#虚拟机栈" class="headerlink" title="虚拟机栈"></a>虚拟机栈</h3><p>每当启动一个新的线程，虚拟机都会在虚拟机栈里为它分配一个线程栈，线程栈与线程同生共死。线程栈以栈帧为单位保存线程的运行状态，虚拟机只会对线程栈执行两种操作：以栈帧为单位的压栈或出栈。每个方法在执行的同时都会创建一个栈帧，每个方法从调用开始到结束，就对应着一个栈帧在线程栈中压栈和出栈的过程。方法可以通过两种方式结束，一种通过 return 正常返回，一种通过抛出异常而终止。方法返回后，虚拟机都会弹出当前栈帧然后释放掉。</p><p>当虚拟机调用一个Java方法时．它从对应类的类型信息中得到此方法的局部变量区和操作数栈的大小，并据此分配栈帧内存，然后压入Java栈中。</p><blockquote><p>栈帧由三部分组成：局部变量区、操作数栈、帧数据区。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211025213551522.png" alt="image-20211025213551522"></p><p><strong>1）局部变量区：</strong></p><ul><li>局部变量区是一个数组结构，主要存放对应方法的参数和局部变量。</li><li>如果是实例方法，局部变量表第一个参数是一个 reference 引用类型，存放的是当前对象本身 this。</li></ul><p><strong>2）操作数栈：</strong></p><ul><li>操作数栈也是一个数组结构，但并不是通过索引来访问的，而是栈的压栈和出栈操作。</li><li>操作数栈是虚拟机的工作区，大多数指令都要从这里弹出数据、执行运算、然后把结果压回操作数栈。</li></ul><p><strong>3）动态链接：</strong></p><ul><li><p>每个栈帧内部都包含一个指向当前方法所在类型的运行时常量池的引用，以便对当前方法的代码实现动态链接。</p></li><li><p>在class文件里面，一个方法若要调用其他方法，或者访问成员变量，则需要通过符号引用来表示，动态链接的作用就是将这些以符号引用所表示的方法转换为对实际方法的直接引用。</p></li></ul><p><strong>4）方法返回：</strong></p><ul><li>方法执行后，有两种方式退出该方法：正常调用完成，执行返回指令。异常调用完成，遇到未捕获异常，不会有方法返回值给调用者。</li></ul><h3 id="本地方法栈"><a href="#本地方法栈" class="headerlink" title="本地方法栈"></a>本地方法栈</h3><p>本地方法栈与虚拟机栈所发挥的作用是相似的，当线程调用Java方法时，会创建一个栈帧并压入虚拟机栈；而调用本地方法时，虚拟机会保持栈不变，不会压入新的栈帧，虚拟机只是简单的动态链接并直接调用指定的本地方法，使用的是某种本地方法栈。比如某个虚拟机实现的本地方法接口是使用C连接模型，那么它的本地方法栈就是C栈。</p><p>本地方法可以通过本地方法接口来访问虚拟机的运行时数据区，它可以做任何他想做的事情，本地方法不受虚拟机控制。</p><h3 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h3><p>每一个运行的线程都会有它的程序计数器（PC寄存器），与线程的生命周期一样。执行某个方法时，PC寄存器的内容总是下一条将被执行的地址，这个地址可以是一个本地指针，也可以是在方法字节码中相对于该方法起始指令的偏移量。如果该线程正在执行一个本地方法，那么此时PC寄存器的值是 undefined。</p><p>程序计数器是程序控制流的指示器，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。多线程环境下，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器，各条线程之间计数器互不影响，独立存储。</p><h2 id="代码在JVM内存中的体现"><a href="#代码在JVM内存中的体现" class="headerlink" title="代码在JVM内存中的体现"></a>代码在JVM内存中的体现</h2><p>当我们通过<code>Object o=new Object()</code>创建一个对象时，在JVM中会分配一块内存用来存储该对象的信息，实现原理如下图所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211025115151377.png" alt="image-20211025115151377"></p><p>在main方法中，创建了一个局部变量<code>o</code>，当main方法运行时，首先会把main方法压入到栈帧中，接着执行该方法的<code>Object o =new Object()</code>创建对象。</p><ol><li>在局部变量表中创建一个局部变量<code>o</code>。</li><li>在堆内存中分配一块内存地址，用来存储<code>object</code>对象。</li><li>变量<code>o</code>指向堆内存中的内存地址。</li></ol><p>我们再来看一个例子，声明一个Person对象，在该对象中存在一个常量<code>name</code>、以及一个成员变量<code>age</code>，当运行该类中的<code>main</code>方法时，此时JVM内存中的运行情况如下。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211025203956559.png" alt="image-20211025203956559"></p><blockquote><p>在这个例子中，看到了常量池的出现，看来，还有必要了解一下常量池的知识</p></blockquote><h2 id="JVM中的常量池"><a href="#JVM中的常量池" class="headerlink" title="JVM中的常量池"></a>JVM中的常量池</h2><p>在JVM中，常量池主要分为：<strong>Class文件常量池</strong>、<strong>运行时常量池</strong>，当然还有<strong>全局字符串常量池</strong>，以及<strong>基本类型包装类对象常量池</strong>。</p><p>常量池主要存放两大类常量：字面量和符号引用。</p><ul><li>字面量：字面量主要是文本字符串、final 常量值、类名和方法名的常量等。</li><li>符号引用：符号引用对java动态连接起着非常重要的作用。主要的符号引用有：类和接口的全限定名、字段的名称和描述符、方法的名称和描述符等。</li></ul><h3 id="Class文件常量池"><a href="#Class文件常量池" class="headerlink" title="Class文件常量池"></a>Class文件常量池</h3><p>class文件是一组以<strong>8位字节为单位的二进制数据流</strong>，在java代码的<strong>编译期间</strong>，我们编写的.java文件就被编译为.class文件格式的二进制数据存放在磁盘中，其中就包括<strong>class文件常量池</strong>。</p><p>为了更好的说明，我们通过下面这段代码为例进行讲解。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ConstantExample</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> value = <span class="number">1</span>;</span><br><span class="line">    <span class="keyword">public</span> String s = <span class="string">&quot;abc&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">static</span> <span class="keyword">int</span> f = <span class="number">0x101</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setValue</span><span class="params">(<span class="keyword">int</span> v)</span></span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> temp = <span class="number">3</span>;</span><br><span class="line">        <span class="keyword">this</span>.value = temp + v;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getValue</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这段代码被编译后，通过<code>javap -v</code>命令查看编译后的字节码。</p><p>从下面这个字节码信息中可以看到，执行这个命令之后我们得到了该class文件的版本号、常量池、已经编译后的字节码指令(处于篇幅原因这里省略)，下面我们会对照这个class文件来讲解：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">example/target/classes/HelloExample.class</span><br><span class="line">  Last modified <span class="number">2021</span>-<span class="number">10</span>-<span class="number">25</span>; size <span class="number">734</span> bytes</span><br><span class="line">  MD5 checksum fd06c1426f4fdef12aa109ee7f010a45</span><br><span class="line">  Compiled from <span class="string">&quot;HelloExample.java&quot;</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HelloExample</span></span></span><br><span class="line"><span class="class">  <span class="title">minor</span> <span class="title">version</span>: 0</span></span><br><span class="line"><span class="class">  <span class="title">major</span> <span class="title">version</span>: 52</span></span><br><span class="line"><span class="class">  <span class="title">flags</span>: <span class="title">ACC_PUBLIC</span>, <span class="title">ACC_SUPER</span></span></span><br><span class="line"><span class="class"><span class="title">Constant</span> <span class="title">pool</span>:</span></span><br><span class="line"><span class="class">   #1 </span>= Methodref          #<span class="number">6.</span>#<span class="number">32</span>         <span class="comment">// java/lang/Object.&quot;&lt;init&gt;&quot;:()V</span></span><br><span class="line">   #<span class="number">2</span> = Fieldref           #<span class="number">5.</span>#<span class="number">33</span>         <span class="comment">// HelloExample.value:I</span></span><br><span class="line">   #<span class="number">3</span> = String             #<span class="number">34</span>            <span class="comment">// abc</span></span><br><span class="line">   #<span class="number">4</span> = Fieldref           #<span class="number">5.</span>#<span class="number">35</span>         <span class="comment">// HelloExample.s:Ljava/lang/String;</span></span><br><span class="line">   #<span class="number">5</span> = Class              #<span class="number">36</span>            <span class="comment">// HelloExample</span></span><br><span class="line">   #<span class="number">6</span> = Class              #<span class="number">37</span>            <span class="comment">// java/lang/Object</span></span><br><span class="line">   #<span class="number">7</span> = Utf8               value</span><br><span class="line">   #<span class="number">8</span> = Utf8               I</span><br><span class="line">   #<span class="number">9</span> = Utf8               s</span><br><span class="line">  #<span class="number">10</span> = Utf8               Ljava/lang/String;</span><br><span class="line">  #<span class="number">11</span> = Utf8               f</span><br><span class="line">  #<span class="number">12</span> = Utf8               ConstantValue</span><br><span class="line">  #<span class="number">13</span> = Integer            <span class="number">257</span></span><br><span class="line">  #<span class="number">14</span> = Utf8               &lt;init&gt;</span><br><span class="line">  #<span class="number">15</span> = Utf8               ()V</span><br><span class="line">  #<span class="number">16</span> = Utf8               Code</span><br><span class="line">  #<span class="number">17</span> = Utf8               LineNumberTable</span><br><span class="line">  #<span class="number">18</span> = Utf8               LocalVariableTable</span><br><span class="line">  #<span class="number">19</span> = Utf8               <span class="keyword">this</span></span><br><span class="line">  #<span class="number">20</span> = Utf8               LHelloExample;</span><br><span class="line">  #<span class="number">21</span> = Utf8               getValue</span><br><span class="line">  #<span class="number">22</span> = Utf8               ()I</span><br><span class="line">  #<span class="number">23</span> = Utf8               setValue</span><br><span class="line">  #<span class="number">24</span> = Utf8               (I)V</span><br><span class="line">  #<span class="number">25</span> = Utf8               MethodParameters</span><br><span class="line">  #<span class="number">26</span> = Utf8               main</span><br><span class="line">  #<span class="number">27</span> = Utf8               ([Ljava/lang/String;)V</span><br><span class="line">  #<span class="number">28</span> = Utf8               args</span><br><span class="line">  #<span class="number">29</span> = Utf8               [Ljava/lang/String;</span><br><span class="line">  #<span class="number">30</span> = Utf8               SourceFile</span><br><span class="line">  #<span class="number">31</span> = Utf8               HelloExample.java</span><br><span class="line">  #<span class="number">32</span> = NameAndType        #<span class="number">14</span>:#<span class="number">15</span>        <span class="comment">// &quot;&lt;init&gt;&quot;:()V</span></span><br><span class="line">  #<span class="number">33</span> = NameAndType        #<span class="number">7</span>:#<span class="number">8</span>          <span class="comment">// value:I</span></span><br><span class="line">  #<span class="number">34</span> = Utf8               abc</span><br><span class="line">  #<span class="number">35</span> = NameAndType        #<span class="number">9</span>:#<span class="number">10</span>         <span class="comment">// s:Ljava/lang/String;</span></span><br><span class="line">  #<span class="number">36</span> = Utf8               HelloExample</span><br><span class="line">  #<span class="number">37</span> = Utf8               java/lang/Object</span><br><span class="line"></span><br></pre></td></tr></table></figure><h4 id="字面量"><a href="#字面量" class="headerlink" title="字面量"></a>字面量</h4><p><strong>字面量</strong>接近于java语言层面的常量概念，主要包括：</p><ul><li><p><strong>文本字符串</strong>，也就是我们经常声明的：<code>public String s = &quot;abc&quot;;</code>中的<code>&quot;abc&quot;</code></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">#<span class="number">3</span> = String             #<span class="number">34</span>            <span class="comment">// abc</span></span><br></pre></td></tr></table></figure></li><li><p><strong>用final修饰的</strong>成员变量，包括<strong>静态变量</strong>、<strong>实例变量</strong>和<strong>局部变量</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">#<span class="number">11</span> = Utf8               f</span><br><span class="line">#<span class="number">12</span> = Utf8               ConstantValue</span><br><span class="line">#<span class="number">13</span> = Integer            <span class="number">257</span></span><br></pre></td></tr></table></figure></li></ul><p>这里需要说明的一点，上面说的存在于常量池的字面量，指的是数据的<strong>值</strong>，也就是<code>abc</code>和<code>0x101(257)</code>,通过上面对常量池的观察可知这两个字面量是确实存在于常量池的。<br>而对于<strong>基本类型数据</strong>(甚至是方法中的局部变量)，也就是上面的<code>private int value = 1</code>;常量池中只保留了他的的<strong>字段描述符</strong><code>I</code>和<strong>字段的名称</strong><code>value</code>，他们的字面量不会存在于常量池：</p><h4 id="符号引用"><a href="#符号引用" class="headerlink" title="符号引用"></a>符号引用</h4><p><strong>符号引用</strong>主要设涉及编译原理方面的概念，包括下面三类常量:</p><ul><li><p><strong>类和接口</strong>的<strong>全限定名</strong>，也就是<code>Ljava/lang/String;</code>这样，将类名中原来的”.”替换为”/“得到的，主要用于在运行时解析得到类的直接引用.</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">#<span class="number">5</span> = Class              #<span class="number">36</span>            <span class="comment">// HelloExample</span></span><br><span class="line">#<span class="number">6</span> = Class              #<span class="number">37</span>            <span class="comment">// java/lang/Object</span></span><br></pre></td></tr></table></figure></li><li><p><strong>字段</strong>的<strong>名称</strong>和<strong>描述符</strong>，字段也就是类或者接口中声明的<strong>变量</strong>，包括<strong>类级别变量(static)<strong>和</strong>实例级的变量</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">#<span class="number">2</span> = Fieldref           #<span class="number">5.</span>#<span class="number">33</span>         <span class="comment">// HelloExample.value:I</span></span><br><span class="line">#<span class="number">7</span> = Utf8               value</span><br><span class="line">#<span class="number">8</span> = Utf8               I</span><br></pre></td></tr></table></figure></li></ul><h3 id="运行时常量"><a href="#运行时常量" class="headerlink" title="运行时常量"></a>运行时常量</h3><p>运行时常量池是方法区的一部分，所以也是<strong>全局共享</strong>的。我们知道，jvm在执行某个类的时候，必须经过<strong>加载、连接(验证,准备,解析)、初始化</strong>，在第一步的<strong>加载</strong>阶段，虚拟机需要完成下面3件事情：</p><ul><li>通过一个类的<strong>“全限定名”</strong>来获取此类的<strong>二进制字节流</strong></li><li>将这个字节流所代表的<strong>静态储存结构</strong>转化为方法区的<strong>运行时数据结构</strong></li><li>在内存中生成一个类代表这类的<strong>java.lang.Class对象</strong>，作为方法区这个类的各种数据访问的入口</li></ul><p>这里需要说明的一点是，<strong>类对象</strong>和普通的<strong>实例对象</strong>是不同的，类对象是在类加载的时候生成的，普通的实例对象一般是在调用new之后创建。</p><p>上面第二条，<strong>将class字节流代表的静态储存结构转化为方法区的运行时数据结构</strong>，其中就包含了class文件常量池进入运行时常量池的过程。这里需要强调一下，<strong>不同的类共用一个运行时常量池</strong>，同时在进入运行时常量池的过程中，多个class文件中常量池中相同的字符串只会存在一份在运行时常量池中，这也是一种优化。</p><p>运行时常量池的作用是存储 Java class文件常量池中的符号信息。运行时常量池 中保存着一些 class 文件中描述的符号引用，同时在类加载的<strong>“解析阶段”</strong>还会将这些<strong>符号引用</strong>所翻译出来的**直接引用(直接指向实例对象的指针)**存储在 运行时常量池 中。</p><p>运行时常量池相对于 class 常量池一大特征就是其具有<strong>动态性</strong>，Java 规范并不要求常量只能在运行时才产生，也就是说运行时常量池中的内容并不全部来自 class 常量池，class 常量池并非运行时常量池的唯一数据输入口；<strong>在运行时可以通过代码生成常量并将其放入运行时常量池中</strong>，这种特性被用的较多的是String.intern()（这个方法下面将会详细讲）。</p><h1 id="问题解答"><a href="#问题解答" class="headerlink" title="问题解答"></a>问题解答</h1><p>理解了上述JVM的背景知识之后，再回到最开始的问题.下面这段代码会创建几个对象？</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">String str=<span class="keyword">new</span> String(<span class="string">&quot;abc&quot;</span>);</span><br></pre></td></tr></table></figure><ol><li>首先，我们看到这个代码中有一个<code>new</code>关键字，我们知道<strong>new</strong>指令是创建一个类的实例对象并完成加载初始化的，因此这个字符串对象是在<strong>运行期</strong>才能确定的，创建的字符串对象是在<strong>堆内存上</strong>。</li><li>其次，在String的构造方法中传递了一个字符串<code>abc</code>，由于这里的<code>abc</code>是被<code>final</code>修饰的属性，所以它是一个字符串常量。在首次构建这个对象时，JVM拿字面量<code>&quot;abc&quot;</code>去字符串常量池试图获取其对应String对象的引用。于是在堆中创建了一个<code>&quot;abc&quot;</code>的String对象，并将其引用保存到字符串常量池中，然后返回；</li></ol><p>所以，这里正确的回答应该是： 如果<code>abc</code>这个字符串常量不存在，则创建两个对象，分别是<code>abc</code>这个字符串常量，以及<code>new String</code>这个实例对象。</p><p>如果<code>abc</code>这字符串常量存在，则只会创建一个对象。</p><h1 id="问题总结"><a href="#问题总结" class="headerlink" title="问题总结"></a>问题总结</h1><p>关于这道题，其实涉及到的知识点非常多，我并没有非常完整的把JVM的内容整体说完，因为JVM整个体系还是较为庞大的。</p><p>所以，建议大家平时如果有时间的情况下，可以系统化的学习一下JVM有关的内容，这块的面试问题还是比较多的。</p>]]></content>
      
      
      <categories>
          
          <category> 面试题系列 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> JVM面试题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>基于Apache Zookeeper手写实现动态配置中心（纯代码实践）</title>
      <link href="/posts/2642238054/"/>
      <url>/posts/2642238054/</url>
      
        <content type="html"><![CDATA[<p>相信大家都知道，每个项目中会有一些配置信息放在一个独立的properties文件中，比如application.properties。这个文件中会放一些常量的配置，比如数据库连接信息、线程池大小、限流参数。</p><p>在传统的开发模式下，这种方式很方便，一方面能够对配置进行统一管理，另一方面，我们在维护的时候很方便。</p><p>但是随着业务的发展以及架构的升级，在微服务架构中，服务的数量以及每个服务涉及到的配置会越来越多，并且对于配置管理的需求越来越高，比如要求实时性、独立性。</p><p>另外，在微服务架构下，会涉及到不同的环境下的配置管理、灰度发布、动态限流、动态降级等需求，包括对于配置内容的安全与权限，所以传统的配置维护方式很难达到需求。</p><p>因此，就产生了分布式配置中心。</p><ul><li>传统的配置方式不方便维护</li><li>配置内容的安全和访问权限，在传统的配置方式中很难实现</li><li>更新配置内容时，需要重启</li></ul><h1 id="配置中心的工作流程"><a href="#配置中心的工作流程" class="headerlink" title="配置中心的工作流程"></a>配置中心的工作流程</h1><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110241810704.png" alt="image-20200709192446173"></p><center>图11-1</center><h1 id="Spring-Boot的外部化配置"><a href="#Spring-Boot的外部化配置" class="headerlink" title="Spring Boot的外部化配置"></a>Spring Boot的外部化配置</h1><p>在这篇文章中，我们会Zookeeper集成到Spring Boot的外部化配置中，让用户无感知的使用配置中心上的数据作为数据源，所以我们需要先了解Spring Boot中的外部化配置。</p><p>Spring Boot的外部化配置是基于Environment来实现的，它表示Spring Boot应用运行时的环境信息，先来看基本使用</p><h2 id="Environment的使用"><a href="#Environment的使用" class="headerlink" title="Environment的使用"></a>Environment的使用</h2><ul><li><p>在spring boot应用中，修改aplication.properties配置</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">key</span>=<span class="string">value</span></span><br></pre></td></tr></table></figure></li><li><p>创建一个Controller进行测试</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EnvironementController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    Environment environment;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/env&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">env</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> environment.getProperty(<span class="string">&quot;key&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="Value注解使用"><a href="#Value注解使用" class="headerlink" title="@Value注解使用"></a>@Value注解使用</h2><p>在properties文件中定义的属性，除了可以通过environment的getProperty方法获取之外，spring还提供了@Value注解，</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EnvironementController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;env&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String env;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/env&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">env</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> env;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>spring容器在加载一个bean时，当发现这个Bean中有@Value注解时，那么它可以从Environment中将属性值进行注入，如果Environment中没有这个属性，则会报错。</p><h2 id="Environment设计猜想"><a href="#Environment设计猜想" class="headerlink" title="Environment设计猜想"></a>Environment设计猜想</h2><p>Spring Boot的外部化配置，不仅仅只是appliation.properties，包括命令行参数、系统属性、操作系统环境变量等，都可以作为Environment的数据来源。</p><ul><li>@Value(“${java.version}”) 获取System.getProperties ， 获取系统属性</li><li>配置command的jvm参数， <code>-Denvtest=command </code>，然后通过<code>@Value(&quot;$&#123;envtest&#125;&quot;)</code></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110241810629.png" alt="image-20210818164156459"></p><center>图11-2</center><ul><li>第一部分是属性定义，这个属性定义可以来自于很多地方，比如application.properties、或者系统环境变量等。 </li><li>然后根据约定的方式去指定路径或者指定范围去加载这些配置，保存到内存中。</li><li>最后，我们可以根据指定的key从缓存中去查找这个值。</li></ul><h1 id="扩展Environment"><a href="#扩展Environment" class="headerlink" title="扩展Environment"></a>扩展Environment</h1><p>我们可以自己扩展Environment中的数据源，代码如下;</p><blockquote><p>其中，EnvironmentPostProcessor：它可以在spring上下文构建之前可以设置一些系统配置。</p></blockquote><h2 id="CusEnvironmentPostProcessor"><a href="#CusEnvironmentPostProcessor" class="headerlink" title="CusEnvironmentPostProcessor"></a>CusEnvironmentPostProcessor</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CusEnvironmentPostProcessor</span> <span class="keyword">implements</span> <span class="title">EnvironmentPostProcessor</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Properties properties=<span class="keyword">new</span> Properties();</span><br><span class="line">    <span class="keyword">private</span> String propertiesFile=<span class="string">&quot;custom.properties&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">postProcessEnvironment</span><span class="params">(ConfigurableEnvironment environment, SpringApplication application)</span> </span>&#123;</span><br><span class="line">        Resource resource=<span class="keyword">new</span> ClassPathResource(propertiesFile);</span><br><span class="line">        environment.getPropertySources().addLast(loadProperties(resource));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> PropertySource&lt;?&gt; loadProperties(Resource resource)&#123;</span><br><span class="line">        <span class="keyword">if</span>(!resource.exists())&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">&quot;file:&#123;&quot;</span>+resource+<span class="string">&quot;&#125; not exist&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            properties.load(resource.getInputStream());</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> PropertiesPropertySource(resource.getFilename(),properties);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(e);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="custom-properties"><a href="#custom-properties" class="headerlink" title="custom.properties"></a>custom.properties</h2><p>在classpath目录下创建custom.properties文件</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">name</span>=<span class="string">mic</span></span><br><span class="line"><span class="attr">age</span>=<span class="string">18</span></span><br></pre></td></tr></table></figure><h2 id="spring-factories"><a href="#spring-factories" class="headerlink" title="spring.factories"></a>spring.factories</h2><p>在META-INF目录下创建spring.factories文件，因为EnvironmentPostProcessor的扩展实现是基于SPI机制完成的。</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">org.springframework.boot.env.EnvironmentPostProcessor</span>=<span class="string">\</span></span><br><span class="line"><span class="string">  com.example.springbootzookeeper.CusEnvironmentPostProcessor</span></span><br></pre></td></tr></table></figure><h2 id="TestController"><a href="#TestController" class="headerlink" title="TestController"></a>TestController</h2><p>创建测试类，演示自定义配置加载的功能。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;name&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">public</span> String val;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">say</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> val;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>通过上面的例子我们发现，在Environment中，我们可以通过指定PropertySources来增加Environment外部化配置信息，使得在Spring Boot运行期间自由访问到这些配置。</p><p>那么我们要实现动态配置中心，无非就是要在启动的时候，从远程服务器上获取到数据保存到PropertySource中，并且添加到Environment。</p><p>下面我们就开始来实现这个过程。</p><h1 id="Zookeeper实现配置中心"><a href="#Zookeeper实现配置中心" class="headerlink" title="Zookeeper实现配置中心"></a>Zookeeper实现配置中心</h1><p>在本小节中，主要基于Spring的Environment扩展实现自己的动态配置中心，代码结构如图11-3所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110241810639.png" alt="image-20210805232800966"></p><center>图11-3</center><h2 id="自定义配置中心的相关说明"><a href="#自定义配置中心的相关说明" class="headerlink" title="自定义配置中心的相关说明"></a>自定义配置中心的相关说明</h2><p>在本次案例中，我们并没有完全使用EnvironmentPostProcessor这个扩展点，而是基于SpringFactoriesLoader自定义了一个扩展点，主要目的是让大家知道EnvironmentPostProcessor扩展点的工作原理，以及我们以后自己也可以定义扩展点。</p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>以下是所有代码的实现过程，按照下面这个步骤去开发即可完成动态配置中心。</p><h3 id="ZookeeperApplicationContextInitializer"><a href="#ZookeeperApplicationContextInitializer" class="headerlink" title="ZookeeperApplicationContextInitializer"></a>ZookeeperApplicationContextInitializer</h3><p>ApplicationContextInitializer扩展，它是在ConfigurableApplicationContext通过调用refresh函数来初始化Spring容器之前会进行回调的一个扩展方法，我们可以在这个扩展中实现Environment的扩展。</p><p>所以这个类的主要作用就是在ApplicationContext完成refresh之前，扩展Environment，增加外部化配置注入。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ZookeeperApplicationContextInitializer</span> <span class="keyword">implements</span> <span class="title">ApplicationContextInitializer</span>&lt;<span class="title">ConfigurableApplicationContext</span>&gt;</span>&#123;</span><br><span class="line">    <span class="comment">//PropertySourceLocator接口支持扩展自定义配置加载到spring Environment中。</span></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> List&lt;PropertySourceLocator&gt; propertySourceLocators;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ZookeeperApplicationContextInitializer</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">//基于SPI机制加载所有的外部化属性扩展点</span></span><br><span class="line">        ClassLoader classLoader=ClassUtils.getDefaultClassLoader();</span><br><span class="line">        <span class="comment">//这部分的代码是SPI机制</span></span><br><span class="line">        propertySourceLocators=<span class="keyword">new</span> ArrayList&lt;&gt;(SpringFactoriesLoader.loadFactories(PropertySourceLocator.class,classLoader));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initialize</span><span class="params">(ConfigurableApplicationContext applicationContext)</span> </span>&#123;</span><br><span class="line">        <span class="comment">//获取运行的环境上下文</span></span><br><span class="line">        ConfigurableEnvironment environment=applicationContext.getEnvironment();</span><br><span class="line">        <span class="comment">//MutablePropertySources它包含了一个CopyOnWriteArrayList集合，用来包含多个PropertySource。</span></span><br><span class="line">        MutablePropertySources mutablePropertySources = environment.getPropertySources();</span><br><span class="line">        <span class="keyword">for</span> (PropertySourceLocator locator : <span class="keyword">this</span>.propertySourceLocators) &#123;</span><br><span class="line">            <span class="comment">//回调所有实现PropertySourceLocator接口实例的locate方法，收集所有扩展属性配置保存到Environment中</span></span><br><span class="line">            Collection&lt;PropertySource&lt;?&gt;&gt; source = locator.locateCollection(environment,applicationContext);</span><br><span class="line">            <span class="keyword">if</span> (source == <span class="keyword">null</span> || source.size() == <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//把PropertySource属性源添加到environment中。</span></span><br><span class="line">            <span class="keyword">for</span> (PropertySource&lt;?&gt; p : source) &#123;</span><br><span class="line">                <span class="comment">//addFirst或者Last决定了配置的优先级</span></span><br><span class="line">                mutablePropertySources.addFirst(p);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>创建classpath:/META-INF/spring.factories</strong></p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">org.springframework.context.ApplicationContextInitializer</span>=<span class="string">\</span></span><br><span class="line"><span class="string">  com.gupaoedu.example.zookeepercuratordemo.config.ZookeeperApplicationContextInitializer</span></span><br></pre></td></tr></table></figure><h3 id="PropertySourceLocator"><a href="#PropertySourceLocator" class="headerlink" title="PropertySourceLocator"></a>PropertySourceLocator</h3><p>PropertySourceLocator接口支持扩展自定义配置加载到spring Environment中。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">PropertySourceLocator</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    PropertySource&lt;?&gt; locate(Environment environment,ConfigurableApplicationContext applicationContext);</span><br><span class="line"><span class="comment">//Environment表示环境变量信息</span></span><br><span class="line">    <span class="comment">//applicationContext表示应用上下文</span></span><br><span class="line">    <span class="keyword">default</span> Collection&lt;PropertySource&lt;?&gt;&gt; locateCollection(Environment environment, ConfigurableApplicationContext applicationContext) &#123;</span><br><span class="line">        <span class="keyword">return</span> locateCollection(<span class="keyword">this</span>, environment,applicationContext);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> Collection&lt;PropertySource&lt;?&gt;&gt; locateCollection(PropertySourceLocator locator,</span><br><span class="line">                                                          Environment environment,ConfigurableApplicationContext applicationContext) &#123;</span><br><span class="line">        PropertySource&lt;?&gt; propertySource = locator.locate(environment,applicationContext);</span><br><span class="line">        <span class="keyword">if</span> (propertySource == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">return</span> Collections.emptyList();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> Arrays.asList(propertySource);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ZookeeperPropertySourceLocator"><a href="#ZookeeperPropertySourceLocator" class="headerlink" title="ZookeeperPropertySourceLocator"></a>ZookeeperPropertySourceLocator</h3><p>ZookeeperPropertySourceLocator用来实现基于Zookeeper属性配置的扩展点，它会访问zookeeper获取远程服务器数据。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ZookeeperPropertySourceLocator</span> <span class="keyword">implements</span> <span class="title">PropertySourceLocator</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> CuratorFramework curatorFramework;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String DATA_NODE=<span class="string">&quot;/data&quot;</span>;  <span class="comment">//仅仅为了演示，所以写死目标数据节点</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ZookeeperPropertySourceLocator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        curatorFramework= CuratorFrameworkFactory.builder()</span><br><span class="line">                .connectString(<span class="string">&quot;192.168.221.128:2181&quot;</span>)</span><br><span class="line">                .sessionTimeoutMs(<span class="number">20000</span>).connectionTimeoutMs(<span class="number">20000</span>)</span><br><span class="line">                .retryPolicy(<span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>,<span class="number">3</span>))</span><br><span class="line">                .namespace(<span class="string">&quot;config&quot;</span>).build();</span><br><span class="line">        curatorFramework.start();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> PropertySource&lt;?&gt; locate(Environment environment, ConfigurableApplicationContext applicationContext) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;开始加载远程配置到Environment中&quot;</span>);</span><br><span class="line">        CompositePropertySource composite = <span class="keyword">new</span> CompositePropertySource(<span class="string">&quot;configService&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Map&lt;String,Object&gt; dataMap=getRemoteEnvironment();</span><br><span class="line">            <span class="comment">//基于Map结构的属性源</span></span><br><span class="line">            MapPropertySource mapPropertySource=<span class="keyword">new</span> MapPropertySource(<span class="string">&quot;configService&quot;</span>,dataMap);</span><br><span class="line">            composite.addPropertySource(mapPropertySource);</span><br><span class="line">            addListener(environment,applicationContext);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> composite;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> Map&lt;String,Object&gt; <span class="title">getRemoteEnvironment</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        String data=<span class="keyword">new</span> String(curatorFramework.getData().forPath(DATA_NODE));</span><br><span class="line">        <span class="comment">//暂时支持json格式</span></span><br><span class="line">        ObjectMapper objectMapper=<span class="keyword">new</span> ObjectMapper();</span><br><span class="line">        Map&lt;String,Object&gt; map=objectMapper.readValue(data, Map.class);</span><br><span class="line">        <span class="keyword">return</span> map;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//添加节点变更事件</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addListener</span><span class="params">(Environment environment, ConfigurableApplicationContext applicationContext)</span></span>&#123;</span><br><span class="line">        NodeDataCuratorCacheListener curatorCacheListener=<span class="keyword">new</span> NodeDataCuratorCacheListener(environment,applicationContext);</span><br><span class="line">        CuratorCache curatorCache=CuratorCache.build(curatorFramework,DATA_NODE,CuratorCache.Options.SINGLE_NODE_CACHE);</span><br><span class="line">        CuratorCacheListener listener=CuratorCacheListener</span><br><span class="line">                .builder()</span><br><span class="line">                .forChanges(curatorCacheListener).build();</span><br><span class="line">        curatorCache.listenable().addListener(listener);</span><br><span class="line">        curatorCache.start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>配置扩展点： classpath:/META-INF/spring.factories</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">com.gupaoedu.example.zookeepercuratordemo.config.PropertySourceLocator</span>=<span class="string">\</span></span><br><span class="line"><span class="string">  com.gupaoedu.example.zookeepercuratordemo.config.ZookeeperPropertySourceLocator</span></span><br></pre></td></tr></table></figure><h2 id="配置动态变更逻辑"><a href="#配置动态变更逻辑" class="headerlink" title="配置动态变更逻辑"></a>配置动态变更逻辑</h2><h3 id="NodeDataCuratorCacheListener"><a href="#NodeDataCuratorCacheListener" class="headerlink" title="NodeDataCuratorCacheListener"></a>NodeDataCuratorCacheListener</h3><p>NodeDataCuratorCacheListener用来实现持久化订阅机制，当目标节点数据发生变更时，需要收到变更并且应用。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NodeDataCuratorCacheListener</span> <span class="keyword">implements</span> <span class="title">CuratorCacheListenerBuilder</span>.<span class="title">ChangeListener</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Environment environment;</span><br><span class="line">    <span class="keyword">private</span> ConfigurableApplicationContext applicationContext;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NodeDataCuratorCacheListener</span><span class="params">(Environment environment, ConfigurableApplicationContext applicationContext)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.environment = environment;</span><br><span class="line">        <span class="keyword">this</span>.applicationContext=applicationContext;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">event</span><span class="params">(ChildData oldNode, ChildData node)</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;数据发生变更&quot;</span>);</span><br><span class="line">        String resultData=<span class="keyword">new</span> String(node.getData());</span><br><span class="line">        ObjectMapper objectMapper=<span class="keyword">new</span> ObjectMapper();</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Map&lt;String,Object&gt; map=objectMapper.readValue(resultData, Map.class);</span><br><span class="line">            ConfigurableEnvironment cfe=(ConfigurableEnvironment)environment;</span><br><span class="line">            MapPropertySource mapPropertySource=<span class="keyword">new</span> MapPropertySource(<span class="string">&quot;configService&quot;</span>,map);</span><br><span class="line">            cfe.getPropertySources().replace(<span class="string">&quot;configService&quot;</span>,mapPropertySource);</span><br><span class="line">            <span class="comment">//发布事件，用来更新@Value注解对应的值（事件机制可以分两步演示）</span></span><br><span class="line">            applicationContext.publishEvent(<span class="keyword">new</span> EnvironmentChangeEvent(<span class="keyword">this</span>));</span><br><span class="line">            System.out.println(<span class="string">&quot;数据更新完成&quot;</span>);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (JsonProcessingException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="EnvironmentChangeEvent"><a href="#EnvironmentChangeEvent" class="headerlink" title="EnvironmentChangeEvent"></a>EnvironmentChangeEvent</h3><p>定义一个环境变量变更事件。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">EnvironmentChangeEvent</span> <span class="keyword">extends</span> <span class="title">ApplicationEvent</span> </span>&#123;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">EnvironmentChangeEvent</span><span class="params">(Object source)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">super</span>(source);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ConfigurationPropertiesRebinder"><a href="#ConfigurationPropertiesRebinder" class="headerlink" title="ConfigurationPropertiesRebinder"></a>ConfigurationPropertiesRebinder</h3><p>ConfigurationPropertiesRebinder接收事件，并重新绑定@Value注解的数据，使得数据能够动态改变</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigurationPropertiesRebinder</span> <span class="keyword">implements</span> <span class="title">ApplicationListener</span>&lt;<span class="title">EnvironmentChangeEvent</span>&gt; </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ConfigurationPropertiesBeans beans;</span><br><span class="line">    <span class="keyword">private</span> Environment environment;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">ConfigurationPropertiesRebinder</span><span class="params">(ConfigurationPropertiesBeans beans,Environment environment)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.beans = beans;</span><br><span class="line">        <span class="keyword">this</span>.environment=environment;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">onApplicationEvent</span><span class="params">(EnvironmentChangeEvent event)</span> </span>&#123;</span><br><span class="line">        rebind();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">rebind</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.beans.getFieldMapper().forEach((k,v)-&gt;&#123;</span><br><span class="line">            v.forEach(f-&gt;f.resetValue(environment));</span><br><span class="line">        &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="ConfigurationPropertiesBeans"><a href="#ConfigurationPropertiesBeans" class="headerlink" title="ConfigurationPropertiesBeans"></a>ConfigurationPropertiesBeans</h3><p>ConfigurationPropertiesBeans实现了BeanPostPorocessor接口，该接口我们也叫后置处理器，作用是在Bean对象在实例化和依赖注入完毕后，在显示调用初始化方法的前后添加我们自己的逻辑。注意是Bean实例化完毕后及依赖注入完成后触发的。</p><p>我们可以在这个后置处理器的回调方法中，扫描指定注解的bean，收集这些属性，用来触发事件变更。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigurationPropertiesBeans</span> <span class="keyword">implements</span> <span class="title">BeanPostProcessor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Map&lt;String,List&lt;FieldPair&gt;&gt; fieldMapper=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Object <span class="title">postProcessBeforeInitialization</span><span class="params">(Object bean, String beanName)</span></span></span><br><span class="line"><span class="function">        <span class="keyword">throws</span> BeansException </span>&#123;</span><br><span class="line">        Class clz=bean.getClass();</span><br><span class="line">        <span class="keyword">if</span>(clz.isAnnotationPresent(RefreshScope.class))&#123; <span class="comment">//如果某个bean声明了RefreshScope注解，说明需要进行动态更新</span></span><br><span class="line">            <span class="keyword">for</span>(Field field:clz.getDeclaredFields())&#123;</span><br><span class="line">                Value value=field.getAnnotation(Value.class);</span><br><span class="line">                List&lt;String&gt; keyList=getPropertyKey(value.value(),<span class="number">0</span>);</span><br><span class="line">                <span class="keyword">for</span>(String key:keyList)&#123;</span><br><span class="line">                    <span class="comment">//使用List&lt;FieldPair&gt;存储的目的是，如果在多个bean中存在相同的key，则全部进行替换</span></span><br><span class="line">                    fieldMapper.computeIfAbsent(key,(k)-&gt;<span class="keyword">new</span> ArrayList()).add(<span class="keyword">new</span> FieldPair(bean,field,value.value()));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> bean;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//获取key信息，也就是$&#123;value&#125;中解析出value这个属性</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> List&lt;String&gt; <span class="title">getPropertyKey</span><span class="params">(String value,<span class="keyword">int</span> begin)</span></span>&#123;</span><br><span class="line">        <span class="keyword">int</span> start=value.indexOf(<span class="string">&quot;$&#123;&quot;</span>,begin)+<span class="number">2</span>;</span><br><span class="line">        <span class="keyword">if</span>(start&lt;<span class="number">2</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> middle=value.indexOf(<span class="string">&quot;:&quot;</span>,start);</span><br><span class="line">        <span class="keyword">int</span> end=value.indexOf(<span class="string">&quot;&#125;&quot;</span>,start);</span><br><span class="line">        String key;</span><br><span class="line">        <span class="keyword">if</span>(middle&gt;<span class="number">0</span>&amp;&amp;middle&lt;end)&#123;</span><br><span class="line">            key=value.substring(start,middle);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            key=value.substring(start,end);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//如果是这种用法，就需要递归，@Value(&quot;$&#123;swagger2.host:127.0.0.1:$&#123;server.port:8080&#125;&#125;&quot;)</span></span><br><span class="line">        List&lt;String&gt; keys=getPropertyKey(value,end);</span><br><span class="line">        keys.add(key);</span><br><span class="line">        <span class="keyword">return</span> keys;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> Map&lt;String, List&lt;FieldPair&gt;&gt; getFieldMapper() &#123;</span><br><span class="line">        <span class="keyword">return</span> fieldMapper;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="RefreshScope"><a href="#RefreshScope" class="headerlink" title="RefreshScope"></a>RefreshScope</h3><p>定义注解来实现指定需要动态刷新类的识别。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;)</span></span><br><span class="line"><span class="meta">@Retention(RetentionPolicy.RUNTIME)</span></span><br><span class="line"><span class="meta">@Documented</span></span><br><span class="line"><span class="keyword">public</span> <span class="meta">@interface</span> RefreshScope &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="FieldPair"><a href="#FieldPair" class="headerlink" title="FieldPair"></a>FieldPair</h3><p>这个类中主要通过PropertyPlaceholderHelper将字符串里的占位符内容，用我们配置的properties里的替换。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">FieldPair</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> PropertyPlaceholderHelper propertyPlaceholderHelper=<span class="keyword">new</span> PropertyPlaceholderHelper(<span class="string">&quot;$&#123;&quot;</span>,<span class="string">&quot;&#125;&quot;</span>,<span class="string">&quot;:&quot;</span>,<span class="keyword">true</span>);</span><br><span class="line">    <span class="keyword">private</span> Object bean;</span><br><span class="line">    <span class="keyword">private</span> Field field;</span><br><span class="line">    <span class="keyword">private</span> String value;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">FieldPair</span><span class="params">(Object bean, Field field, String value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.bean = bean;</span><br><span class="line">        <span class="keyword">this</span>.field = field;</span><br><span class="line">        <span class="keyword">this</span>.value = value;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">resetValue</span><span class="params">(Environment environment)</span></span>&#123;</span><br><span class="line">        <span class="keyword">boolean</span> access=field.isAccessible();</span><br><span class="line">        <span class="keyword">if</span>(!access)&#123;</span><br><span class="line">            field.setAccessible(<span class="keyword">true</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//从新从environment中将占位符替换为新的值</span></span><br><span class="line">        String resetValue=propertyPlaceholderHelper.replacePlaceholders(value,((ConfigurableEnvironment) environment)::getProperty);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">           <span class="comment">//通过反射更新</span></span><br><span class="line">            field.set(bean,resetValue);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IllegalAccessException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="访问测试ConfigController"><a href="#访问测试ConfigController" class="headerlink" title="访问测试ConfigController"></a>访问测试ConfigController</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RefreshScope</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;name&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;job&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String job;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">get</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name+<span class="string">&quot;:&quot;</span>+job;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="基于自定义PropertySourceLocator扩展"><a href="#基于自定义PropertySourceLocator扩展" class="headerlink" title="基于自定义PropertySourceLocator扩展"></a>基于自定义PropertySourceLocator扩展</h1><p>由于在上述代码中，我们创建了一个PropertySourceLocator接口，并且在整个配置加载过程中，我们都是基于PropertySourceLocator扩展点来进行加载的，所以也就是意味着除了上述使用的Zookeeper作为远程配置装载以外，我们还可以通过扩展PropertySourceLocator来实现其他的扩展，具体实现如下</p><h2 id="CustomPropertySourceLocator"><a href="#CustomPropertySourceLocator" class="headerlink" title="CustomPropertySourceLocator"></a>CustomPropertySourceLocator</h2><p>创建一个MapPropertySource作为Environment的属性源。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomPropertySourceLocator</span> <span class="keyword">implements</span> <span class="title">PropertySourceLocator</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> PropertySource&lt;?&gt; locate(Environment environment, ConfigurableApplicationContext applicationContext) &#123;</span><br><span class="line">        Map&lt;String, Object&gt; source = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        source.put(<span class="string">&quot;age&quot;</span>,<span class="string">&quot;18&quot;</span>);</span><br><span class="line">        MapPropertySource propertiesPropertySource = <span class="keyword">new</span> MapPropertySource(<span class="string">&quot;configCenter&quot;</span>,source);</span><br><span class="line">        <span class="keyword">return</span> propertiesPropertySource;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="spring-factories-1"><a href="#spring-factories-1" class="headerlink" title="spring.factories"></a>spring.factories</h2><p>由于CustomPropertySourceLocator是自定义扩展点，所以我们需要在spring.factories文件中定义它的扩展实现，修改如下</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">com.gupaoedu.example.zookeepercuratordemo.config.PropertySourceLocator</span>=<span class="string">\</span></span><br><span class="line"><span class="string">  com.gupaoedu.example.zookeepercuratordemo.config.ZookeeperPropertySourceLocator,\</span></span><br><span class="line"><span class="string">  com.gupaoedu.example.zookeepercuratordemo.config.CustomPropertySourceLocator</span></span><br></pre></td></tr></table></figure><h2 id="ConfigController"><a href="#ConfigController" class="headerlink" title="ConfigController"></a>ConfigController</h2><p>接下来，我们通过下面的代码进行测试，从结果可以看到，我们自己定义的propertySource被加载到Environment中了。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RefreshScope</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ConfigController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;name&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String name;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;job&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String job;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Value(&quot;$&#123;age&#125;&quot;)</span></span><br><span class="line">    <span class="keyword">private</span> String age;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">get</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> name+<span class="string">&quot;:&quot;</span>+job+<span class="string">&quot;:&quot;</span>+age;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Zookeeper </category>
          
          <category> 配置中心 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Spring Boot </tag>
            
            <tag> Zookeeper </tag>
            
            <tag> 配置中心 </tag>
            
            <tag> 手写系列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Apache Zookeeper客户端Curator使用及权限模式详解</title>
      <link href="/posts/3223606942/"/>
      <url>/posts/3223606942/</url>
      
        <content type="html"><![CDATA[<p>这篇文章是让大家了解Zookeeper基于Java客户端Curator的基本操作，以及如何使用Zookeeper解决实际问题。</p><h1 id="Zookeeper基于Java访问"><a href="#Zookeeper基于Java访问" class="headerlink" title="Zookeeper基于Java访问"></a>Zookeeper基于Java访问</h1><p>针对zookeeper，比较常用的Java客户端有zkclient、curator。由于Curator对于zookeeper的抽象层次比较高，简化了zookeeper客户端的开发量。使得curator逐步被广泛应用。</p><ol><li><p>封装zookeeper client与zookeeper server之间的连接处理</p></li><li><p>提供了一套fluent风格的操作api</p></li><li><p>提供zookeeper各种应用场景（共享锁、leader选举）的抽象封装</p></li></ol><h2 id="依赖jar包"><a href="#依赖jar包" class="headerlink" title="依赖jar包"></a>依赖jar包</h2><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.curator<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>curator-framework<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="建立连接"><a href="#建立连接" class="headerlink" title="建立连接"></a>建立连接</h2><p>curator提供了两种操作方式来进行操作，一种是Fluent风格，另外一种就是普通的方法调用风格</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CuratorMain</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        CuratorFramework curatorFramework=</span><br><span class="line">                CuratorFrameworkFactory.newClient(<span class="string">&quot;192.168.221.128:2181&quot;</span>,<span class="number">5000</span>,<span class="number">20000</span>,</span><br><span class="line">                        <span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>,<span class="number">3</span>));</span><br><span class="line">        curatorFramework.start();</span><br><span class="line">        curatorFramework.blockUntilConnected();</span><br><span class="line">        System.out.println(<span class="string">&quot;zookeeper starter success&quot;</span>);</span><br><span class="line">        String data=<span class="keyword">new</span> String(curatorFramework.getData().forPath(<span class="string">&quot;/pr&quot;</span>));</span><br><span class="line">        System.out.println(<span class="string">&quot;输出结果：&quot;</span>+data);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>重试策略：</strong>Curator内部实现的几种重试策略: </p><ul><li>ExponentialBackoffRetry:重试指定的次数, 且每一次重试之间停顿的时间逐渐增加，<strong>时间间隔 = baseSleepTimeMs * Math.max(1, random.nextInt(1 &lt;&lt; (retryCount + 1)))</strong></li><li>RetryNTimes:指定最大重试次数的重试策略</li><li>RetryOneTime:仅重试一次</li><li>RetryUntilElapsed:一直重试直到达到规定的时间</li></ul><p><strong>namespace:</strong> 值得注意的是session会话含有隔离命名空间，即客户端对Zookeeper上数据节点的任何操作都是相对/curator目录进行的，这有利于实现不同的Zookeeper的业务之间的隔离</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    CuratorFramework curatorFramework=CuratorFrameworkFactory.builder()</span><br><span class="line">        .connectString(<span class="string">&quot;192.168.221.128:2181&quot;</span>)</span><br><span class="line">        .sessionTimeoutMs(<span class="number">5000</span>).connectionTimeoutMs(<span class="number">20000</span>)</span><br><span class="line">        .retryPolicy(<span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>,<span class="number">3</span>))</span><br><span class="line">        .namespace(<span class="string">&quot;curator&quot;</span>).build();</span><br><span class="line">    curatorFramework.start();</span><br><span class="line">    String data=<span class="keyword">new</span> String(curatorFramework.getData().forPath(<span class="string">&quot;/pr&quot;</span>));</span><br><span class="line">    System.out.println(<span class="string">&quot;输出结果：&quot;</span>+data);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="节点的增删改查"><a href="#节点的增删改查" class="headerlink" title="节点的增删改查"></a>节点的增删改查</h2><p>下面代码演示了Curator访问Zookeeper实现数据的增删改查功能。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CuratorMain</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> CuratorFramework curatorFramework;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CuratorMain</span><span class="params">()</span></span>&#123;</span><br><span class="line">        curatorFramework=CuratorFrameworkFactory.builder()</span><br><span class="line">            .connectString(<span class="string">&quot;192.168.221.128:2181&quot;</span>)</span><br><span class="line">            .sessionTimeoutMs(<span class="number">5000</span>).connectionTimeoutMs(<span class="number">20000</span>)</span><br><span class="line">            .retryPolicy(<span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>,<span class="number">3</span>))</span><br><span class="line">            .namespace(<span class="string">&quot;curator&quot;</span>).build();</span><br><span class="line">        curatorFramework.start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">nodeCRUD</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;开始创建节点&quot;</span>);</span><br><span class="line">        String node=curatorFramework.create().creatingParentsIfNeeded().withMode(CreateMode.PERSISTENT).forPath(<span class="string">&quot;/node&quot;</span>);</span><br><span class="line">        System.out.println(<span class="string">&quot;节点创建成功：&quot;</span>+node);</span><br><span class="line">        Stat stat=<span class="keyword">new</span> Stat(); <span class="comment">//存储节点信息</span></span><br><span class="line">        curatorFramework.getData().storingStatIn(stat).forPath(node);</span><br><span class="line">        System.out.println(<span class="string">&quot;查询节点：&quot;</span>+node+<span class="string">&quot;信息，stat:&quot;</span>+stat.toString());</span><br><span class="line">        stat=curatorFramework.setData().withVersion(stat.getVersion()).forPath(node,<span class="string">&quot;Hello World&quot;</span>.getBytes());</span><br><span class="line">        String result=<span class="keyword">new</span> String(curatorFramework.getData().forPath(node));</span><br><span class="line">        System.out.println(<span class="string">&quot;修改节点后的数据信息：&quot;</span>+result);</span><br><span class="line">        System.out.println(<span class="string">&quot;开始删除节点&quot;</span>);</span><br><span class="line">        curatorFramework.delete().forPath(node);</span><br><span class="line">        Stat exist=curatorFramework.checkExists().forPath(node);</span><br><span class="line">        <span class="keyword">if</span>(exist==<span class="keyword">null</span>)&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;节点删除成功&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        CuratorMain curatorMain=<span class="keyword">new</span> CuratorMain();</span><br><span class="line">        curatorMain.nodeCRUD();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="异步请求"><a href="#异步请求" class="headerlink" title="异步请求"></a>异步请求</h2><p>所谓异步请求，就是客户端发起请求后，由一个异步线程去执行，当收到服务端的返回结果后，再通过回调方法进行通知。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">asyncCrud</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    CountDownLatch countDownLatch=<span class="keyword">new</span> CountDownLatch(<span class="number">2</span>);</span><br><span class="line">    ExecutorService executorService= Executors.newFixedThreadPool(<span class="number">2</span>);</span><br><span class="line">    System.out.println(<span class="string">&quot;开始节点创建&quot;</span>);</span><br><span class="line">    String node=curatorFramework.create().withMode(CreateMode.PERSISTENT).inBackground((session,event)-&gt;&#123;</span><br><span class="line">        System.out.println(Thread.currentThread().getName()+<span class="string">&quot;：执行创建节点-&gt;&quot;</span>+event.getPath());</span><br><span class="line">        countDownLatch.countDown();</span><br><span class="line">    &#125;,executorService).forPath(<span class="string">&quot;/async-node&quot;</span>);</span><br><span class="line">    System.out.println(<span class="string">&quot;异步等待节点创建,此时节点创建状态，node:&quot;</span>+node);</span><br><span class="line">    curatorFramework.delete().inBackground((session,event)-&gt;&#123;</span><br><span class="line">        System.out.println(Thread.currentThread().getName()+<span class="string">&quot;：执行删除节点-&gt;&quot;</span>+event.getPath());</span><br><span class="line">        countDownLatch.countDown();</span><br><span class="line">    &#125;,executorService).forPath(<span class="string">&quot;/async-node&quot;</span>);</span><br><span class="line">    System.out.println(<span class="string">&quot;等待异步执行结束&quot;</span>);</span><br><span class="line">    countDownLatch.await();</span><br><span class="line">    executorService.shutdown();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Zookeeper权限控制"><a href="#Zookeeper权限控制" class="headerlink" title="Zookeeper权限控制"></a>Zookeeper权限控制</h1><p>Zookeeper作为一个分布式协调框架，内部存储了一些分布式系统运行时的状态的数据，比如master选举、比如分布式锁。对这些数据的操作会直接影响到分布式系统的运行状态。因此，为了保证zookeeper中的数据的安全性，避免误操作带来的影响。Zookeeper提供了一套ACL权限控制机制来保证数据的安全。</p><p>ACL权限控制，使用：<code>scheme:id:perm</code>来标识。</p><ul><li>Scheme（权限模式），标识授权策略</li><li>ID（授权对象）</li><li>Permission：授予的权限</li></ul><p>ZooKeeper的权限控制是基于每个znode节点的，需要对每个节点设置权限，每个znode支持设置多种权限控制方案和多个权限，子节点不会继承父节点的权限，客户端无权访问某节点，但可能可以访问它的子节点。</p><h2 id="Scheme权限模式"><a href="#Scheme权限模式" class="headerlink" title="Scheme权限模式"></a>Scheme权限模式</h2><p>Zookeeper提供以下权限模式，所谓权限模式，就是使用什么样的方式来进行授权。</p><ul><li><strong>world：</strong>默认方式，相当于全部都能访问。</li><li><strong>auth</strong>：代表已经认证通过的用户(cli中可以通过addauth digest user:pwd 来添加当前上下文中的授权用户)</li><li><strong>digest</strong>：即用户名:密码这种方式认证，这也是业务系统中最常用的。用 <em>username:password</em> 字符串来产生一个MD5串，然后该串被用来作为ACL ID。认证是通过明文发送<em>username:password</em> 来进行的，当用在ACL时，表达式为<em>username:base64</em> ，base64是password的SHA1摘要的编码。</li><li><strong>ip</strong>：通过ip地址来做权限控制，比如 ip:192.168.1.1 表示权限控制都是针对这个ip地址的。也可以针对网段 ip:192.168.1.1/24，此时addr中的有效位与客户端addr中的有效位进行比对。</li></ul><h2 id="ID授权对象"><a href="#ID授权对象" class="headerlink" title="ID授权对象"></a>ID授权对象</h2><p>指权限赋予的用户或一个指定的实体，不同的权限模式下，授权对象不同</p><p> <img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110241451473.png" alt="img"></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Id ipId1 = <span class="keyword">new</span> Id(<span class="string">&quot;ip&quot;</span>, <span class="string">&quot;192.168.190.1&quot;</span>);</span><br><span class="line">Id ANYONE_ID_UNSAFE = <span class="keyword">new</span> Id(<span class="string">&quot;world&quot;</span>, <span class="string">&quot;anyone&quot;</span>);</span><br></pre></td></tr></table></figure><h2 id="Permission权限类型"><a href="#Permission权限类型" class="headerlink" title="Permission权限类型"></a>Permission权限类型</h2><p> 指通过权限检查后可以被允许的操作，create /delete /read/write/admin</p><ul><li><p>Create 允许对子节点Create 操作</p></li><li><p>Read 允许对本节点GetChildren 和GetData 操作</p></li><li><p>Write 允许对本节点SetData 操作</p></li><li><p>Delete 允许对子节点Delete 操作</p></li><li><p>Admin 允许对本节点setAcl 操作</p></li></ul><p>权限模式(Schema)和授权对象主要用来确认权限验证过程中使用的验证策略： <strong>比如ip地址、digest:username:password</strong>，匹配到验证策略并验证成功后，再根据权限操作类型来决定当前客户端的访问权限。</p><h2 id="在控制台上实现权限操作"><a href="#在控制台上实现权限操作" class="headerlink" title="在控制台上实现权限操作"></a>在控制台上实现权限操作</h2><p>在Zookeeper中提供了ACL相关的命令如下。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">getAcl        getAcl &lt;path&gt;     读取ACL权限</span><br><span class="line">setAcl        setAcl &lt;path&gt; &lt;acl&gt;     设置ACL权限</span><br><span class="line">addauth      addauth &lt;scheme&gt; &lt;auth&gt;     添加认证用户</span><br></pre></td></tr></table></figure><h3 id="word方式"><a href="#word方式" class="headerlink" title="word方式"></a>word方式</h3><p>创建一个节点后默认就是world模式</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 2] create /auth</span><br><span class="line">Created /auth</span><br><span class="line">[zk: localhost:2181(CONNECTED) 3] getAcl /auth </span><br><span class="line">&#x27;world,&#x27;anyone</span><br><span class="line">: cdrwa</span><br><span class="line">[zk: localhost:2181(CONNECTED) 4] create /world</span><br><span class="line">Created /world</span><br><span class="line">[zk: localhost:2181(CONNECTED) 5] getAcl /world</span><br><span class="line">&#x27;world,&#x27;anyone</span><br><span class="line">: cdrwa</span><br><span class="line">[zk: localhost:2181(CONNECTED) 6] setAcl /world:anyone:acd</span><br><span class="line">setAcl [-s] [-v version] [-R] path acl</span><br><span class="line">[zk: localhost:2181(CONNECTED) 7] setAcl /world world:anyone:acd</span><br><span class="line">[zk: localhost:2181(CONNECTED) 8] getAcl /world</span><br><span class="line">&#x27;world,&#x27;anyone</span><br><span class="line">: cda</span><br></pre></td></tr></table></figure><blockquote><p>其中， cdrwa，分别对应 create . delete   read  write admin</p></blockquote><h3 id="IP模式"><a href="#IP模式" class="headerlink" title="IP模式"></a>IP模式</h3><p>在ip模式中，首先连接到zkServer的命令需要使用如下方式</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./zkCli.sh -server 192.168.221.128:2181</span><br></pre></td></tr></table></figure><p>接着按照IP的方式操作如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: 192.168.221.128:2181(CONNECTED) 3] create /ip-model</span><br><span class="line">Created /ip-model</span><br><span class="line">[zk: 192.168.221.128:2181(CONNECTED) 4] setAcl /ip-model ip:127.0.0.1:cdrwa,ip:192.168.221.128/131:cdrwa</span><br><span class="line">Acl is not valid : /ip-model</span><br><span class="line">[zk: 192.168.221.128:2181(CONNECTED) 5] setAcl /ip-model ip:127.0.0.1:cdrwa,ip:192.168.221.128:cdrwa</span><br><span class="line">[zk: 192.168.221.128:2181(CONNECTED) 6] getAcl /ip-model</span><br><span class="line">&#x27;ip,&#x27;127.0.0.1</span><br><span class="line">: cdrwa</span><br><span class="line">&#x27;ip,&#x27;192.168.221.128</span><br><span class="line">: cdrwa</span><br></pre></td></tr></table></figure><h3 id="Auth模式"><a href="#Auth模式" class="headerlink" title="Auth模式"></a>Auth模式</h3><p>auth模式的操作如下。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: 192.168.221.128:2181(CONNECTED) 7] create /auth</span><br><span class="line">Created /auth</span><br><span class="line">[zk: 192.168.221.128:2181(CONNECTED) 8] addauth digest mic:mic  # 增加授权用户，明文用户名和密码，zk会对密码加密</span><br><span class="line">[zk: 192.168.221.128:2181(CONNECTED) 9] setAcl /auth auth:mic:cdrwa  # 授予权限</span><br><span class="line">[zk: 192.168.221.128:2181(CONNECTED) 11] getAcl /auth</span><br><span class="line">&#x27;digest,&#x27;mic:xUsfnPBF9eNvHVWZx/TZt9ioxBA=</span><br><span class="line">: cdrwa</span><br><span class="line">[zk: 192.168.221.128:2181(CONNECTED) 12] </span><br></pre></td></tr></table></figure><p>当我们退出当前的会话后，再次连接，执行如下操作，会提示没有权限</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 1] get /auth </span><br><span class="line">Insufficient permission : /auth</span><br></pre></td></tr></table></figure><p>这时候，我们需要重新授权。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 2] addauth digest mic:mic</span><br><span class="line">[zk: localhost:2181(CONNECTED) 3] get /auth</span><br><span class="line">null</span><br><span class="line">[zk: localhost:2181(CONNECTED) 4] </span><br></pre></td></tr></table></figure><h3 id="Digest"><a href="#Digest" class="headerlink" title="Digest"></a>Digest</h3><p>使用语法，会发现使用方式和Auth模式相同。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">setAcl /digest digest:用户名:密码:权限</span><br></pre></td></tr></table></figure><p>但是有一个不一样的点，密码需要用加密后的，否则无法被识别。</p><p><strong>密码： 用户名和密码加密后的字符串。</strong></p><p>使用下面程序生成密码</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    String up=<span class="string">&quot;mic:mic&quot;</span>;</span><br><span class="line">    <span class="keyword">byte</span>[] digest=MessageDigest.getInstance(<span class="string">&quot;SHA1&quot;</span>).digest(up.getBytes());</span><br><span class="line">    String encodeString=Base64.getEncoder().encodeToString(digest);</span><br><span class="line">    System.out.println(encodeString);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>得到：<strong>xUsfnPBF9eNvHVWZx/TZt9ioxBA=</strong></p><p>再回到client上进行如下操作</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 10] create /digest</span><br><span class="line">Created /digest</span><br><span class="line">[zk: localhost:2181(CONNECTED) 11] setAcl /digest digest:mic:xUsfnPBF9eNvHVWZx/TZt9ioxBA=:cdrwa</span><br><span class="line">[zk: localhost:2181(CONNECTED) 12] getAcl /digest</span><br><span class="line">&#x27;digest,&#x27;mic:xUsfnPBF9eNvHVWZx/TZt9ioxBA=</span><br><span class="line">: cdrwa</span><br></pre></td></tr></table></figure><p>当退出当前会话后，需要再次授权才能访问**/digest**节点</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[zk: localhost:2181(CONNECTED) 1] get /digest </span><br><span class="line">Insufficient permission : /digest</span><br><span class="line">[zk: localhost:2181(CONNECTED) 2] addauth digest mic:mic</span><br><span class="line">[zk: localhost:2181(CONNECTED) 3] get /digest</span><br><span class="line">null</span><br></pre></td></tr></table></figure><h2 id="Curator演示ACL的使用"><a href="#Curator演示ACL的使用" class="headerlink" title="Curator演示ACL的使用"></a>Curator演示ACL的使用</h2><p>接下来我们使用Curator简单演示一下ACL权限的访问操作。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CuratorMain</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> CuratorFramework curatorFramework;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CuratorMain</span><span class="params">()</span></span>&#123;</span><br><span class="line">        curatorFramework=CuratorFrameworkFactory.builder()</span><br><span class="line">            .connectString(<span class="string">&quot;192.168.221.128:2181&quot;</span>)</span><br><span class="line">            .sessionTimeoutMs(<span class="number">5000</span>).connectionTimeoutMs(<span class="number">20000</span>)</span><br><span class="line">            .retryPolicy(<span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>,<span class="number">3</span>))</span><br><span class="line">            .namespace(<span class="string">&quot;curator&quot;</span>).build();</span><br><span class="line">        curatorFramework.start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">aclExample</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Id id=<span class="keyword">new</span> Id(<span class="string">&quot;digest&quot;</span>, DigestAuthenticationProvider.generateDigest(<span class="string">&quot;mic:mic&quot;</span>));</span><br><span class="line">        List&lt;ACL&gt; acls=<span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        acls.add(<span class="keyword">new</span> ACL(ZooDefs.Perms.ALL,id));</span><br><span class="line">        String node=curatorFramework.create().creatingParentsIfNeeded()</span><br><span class="line">            .withMode(CreateMode.PERSISTENT)</span><br><span class="line">            .withACL(acls,<span class="keyword">false</span>).forPath(<span class="string">&quot;/auth&quot;</span>,<span class="string">&quot;Hello&quot;</span>.getBytes());</span><br><span class="line">        System.out.println(<span class="string">&quot;成功创建带权限的节点:&quot;</span>+node);</span><br><span class="line">        String data=<span class="keyword">new</span> String(curatorFramework.getData().forPath(node));</span><br><span class="line">        System.out.println(<span class="string">&quot;获取数据结果：&quot;</span>+data);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        CuratorMain curatorMain=<span class="keyword">new</span> CuratorMain();</span><br><span class="line">        curatorMain.aclExample();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码执行后会报错</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">Exception in thread &quot;main&quot; org.apache.zookeeper.KeeperException$NoAuthException: KeeperErrorCode = NoAuth for /curator/auth</span><br></pre></td></tr></table></figure><p>修改后代码如下。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CuratorMain</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> CuratorFramework curatorFramework;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CuratorMain</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        curatorFramework=CuratorFrameworkFactory.builder()</span><br><span class="line">            .connectString(<span class="string">&quot;192.168.221.128:2181&quot;</span>)</span><br><span class="line">            .sessionTimeoutMs(<span class="number">20000</span>).connectionTimeoutMs(<span class="number">20000</span>)</span><br><span class="line">            .retryPolicy(<span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>,<span class="number">3</span>))</span><br><span class="line">            .authorization(<span class="string">&quot;digest&quot;</span>,<span class="string">&quot;mic:mic&quot;</span>.getBytes()) <span class="comment">//在连接时增加授权，即可访问</span></span><br><span class="line">            .namespace(<span class="string">&quot;curator&quot;</span>).build();</span><br><span class="line">        curatorFramework.start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">aclExample</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Id id=<span class="keyword">new</span> Id(<span class="string">&quot;digest&quot;</span>, DigestAuthenticationProvider.generateDigest(<span class="string">&quot;mic:mic&quot;</span>));</span><br><span class="line">        List&lt;ACL&gt; acls=<span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">        acls.add(<span class="keyword">new</span> ACL(ZooDefs.Perms.ALL,id));</span><br><span class="line">        String node=curatorFramework.create().creatingParentsIfNeeded()</span><br><span class="line">            .withMode(CreateMode.PERSISTENT)</span><br><span class="line">            .withACL(acls,<span class="keyword">false</span>).forPath(<span class="string">&quot;/auth&quot;</span>,<span class="string">&quot;Hello&quot;</span>.getBytes());</span><br><span class="line">        System.out.println(<span class="string">&quot;成功创建带权限的节点:&quot;</span>+node);</span><br><span class="line">        String data=<span class="keyword">new</span> String(curatorFramework.getData().forPath(node));</span><br><span class="line">        System.out.println(<span class="string">&quot;获取数据结果：&quot;</span>+data);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        CuratorMain curatorMain=<span class="keyword">new</span> CuratorMain();</span><br><span class="line">        curatorMain.aclExample();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="事件监听机制详解"><a href="#事件监听机制详解" class="headerlink" title="事件监听机制详解"></a>事件监听机制详解</h1><p>在上一节课中，我们了解了Zookeeper中的事件监听机制，基于事件监听，应用程序可以订阅指定节点的变更事件来完成响应的逻辑，这个特性可以让zookeeper实现分布式锁、注册中心、配置中心等功能。</p><p>在Zookeeper客户端中，提供了一下以下事件类型</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">enum</span> <span class="title">EventType</span> </span>&#123;</span><br><span class="line">   <span class="comment">//当zookeeper客户端的连接状态发生变更时，即KeeperState.Expired、KeeperState.Disconnected、KeeperState.SyncConnected、KeeperState.AuthFailed状态</span></span><br><span class="line">    None(-<span class="number">1</span>),         </span><br><span class="line">   <span class="comment">//当node-x这个节点被创建时，该事件被触发</span></span><br><span class="line">    NodeCreated(<span class="number">1</span>),</span><br><span class="line">   <span class="comment">//当node-x这个节点被删除时，该事件被触发。 </span></span><br><span class="line">    NodeDeleted(<span class="number">2</span>),</span><br><span class="line">   <span class="comment">//当node-x这个节点的数据发生变更时，该事件被触发</span></span><br><span class="line">    NodeDataChanged(<span class="number">3</span>),</span><br><span class="line">   <span class="comment">//当node-x这个节点的直接子节点被创建、被删除、子节点数据发生变更时，该事件被触发。</span></span><br><span class="line">    NodeChildrenChanged(<span class="number">4</span>),</span><br><span class="line">   <span class="comment">//当node-x这个节点的订阅事件被移除时</span></span><br><span class="line">    DataWatchRemoved(<span class="number">5</span>),</span><br><span class="line">   <span class="comment">//当node-x这个节点的直接子节点的事件被移除时</span></span><br><span class="line">    ChildWatchRemoved(<span class="number">6</span>),</span><br><span class="line">   <span class="comment">//当值就订阅被移除时</span></span><br><span class="line">    PersistentWatchRemoved(<span class="number">7</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在zookeeper3.6版本之前，Curator提供了三种Watcher来监听节点的变化。</p><ul><li><strong>PathChildCache</strong>：监视一个路径下子结点的创建、删除、更新。</li><li><strong>NodeCache</strong>：监视当前结点的创建、更新、删除，并将结点的数据缓存在本地。</li><li><strong>TreeCache</strong>：PathChildCache和NodeCache的“合体”，监视路径下的创建、更新、删除事件，并缓存路径下所有孩子结点的数据。</li></ul><p>但是在zookeeper3.6版本之后，只提供了一个CuratorCache来实现时间订阅。当然，如果要使用事件订阅功能，我们需要引入下面的jar包。</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.curator<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>curator-recipes<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.2.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h2 id="普通事件订阅"><a href="#普通事件订阅" class="headerlink" title="普通事件订阅"></a>普通事件订阅</h2><p>普通的事件订阅，就是使用如getData、exists等命令添加的CuratorWatcher机制。这种方式触发的事件，只会响应一次。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CuratorWatchMain</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> CuratorFramework curatorFramework;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CuratorWatchMain</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        curatorFramework=CuratorFrameworkFactory.builder()</span><br><span class="line">            .connectString(<span class="string">&quot;192.168.221.128:2181&quot;</span>)</span><br><span class="line">            .sessionTimeoutMs(<span class="number">20000</span>).connectionTimeoutMs(<span class="number">20000</span>)</span><br><span class="line">            .retryPolicy(<span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>,<span class="number">3</span>))</span><br><span class="line">            .namespace(<span class="string">&quot;curator&quot;</span>).build();</span><br><span class="line">        curatorFramework.start();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">normalWatcher</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        CuratorWatcher watcher=<span class="keyword">new</span> CuratorWatcher() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent watchedEvent)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;监听事件：&quot;</span>+watchedEvent.toString());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        String node=curatorFramework.create().forPath(<span class="string">&quot;/listener&quot;</span>,<span class="string">&quot;I&#x27;Listener&quot;</span>.getBytes());</span><br><span class="line">        <span class="comment">//设置对当前节点的修改和删除事件</span></span><br><span class="line">        String data=<span class="keyword">new</span> String(curatorFramework.getData().usingWatcher(watcher).forPath(node));</span><br><span class="line">        System.out.println(node+<span class="string">&quot;节点对应的value：&quot;</span>+data);</span><br><span class="line">        <span class="comment">//第一次更新</span></span><br><span class="line">        curatorFramework.setData().forPath(node,<span class="string">&quot;change listener&quot;</span>.getBytes());</span><br><span class="line">        <span class="comment">//第二次更新</span></span><br><span class="line">        curatorFramework.setData().forPath(node,<span class="string">&quot;change listener&quot;</span>.getBytes());</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        CuratorWatchMain curatorMain=<span class="keyword">new</span> CuratorWatchMain();</span><br><span class="line">        curatorMain.normalWatcher();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果希望事件监听是持久化的，则改造代码如下</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">normalWatcher</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    CuratorWatcher watcher=<span class="keyword">new</span> CuratorWatcher() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent watchedEvent)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;监听事件：&quot;</span>+watchedEvent.toString());</span><br><span class="line">            curatorFramework.checkExists().usingWatcher(<span class="keyword">this</span>).forPath(<span class="string">&quot;/listener&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;;</span><br><span class="line">    String node=curatorFramework.create().forPath(<span class="string">&quot;/listener&quot;</span>,<span class="string">&quot;I&#x27;Listener&quot;</span>.getBytes());</span><br><span class="line">    <span class="comment">//设置对当前节点的修改和删除事件</span></span><br><span class="line">    String data=<span class="keyword">new</span> String(curatorFramework.getData().usingWatcher(watcher).forPath(node));</span><br><span class="line">    System.out.println(node+<span class="string">&quot;节点对应的value：&quot;</span>+data);</span><br><span class="line">    <span class="comment">//第一次更新</span></span><br><span class="line">    curatorFramework.setData().forPath(node,<span class="string">&quot;change listener&quot;</span>.getBytes());</span><br><span class="line">    Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">    <span class="comment">//第二次更新</span></span><br><span class="line">    curatorFramework.setData().forPath(node,<span class="string">&quot;change listener&quot;</span>.getBytes());</span><br><span class="line">    System.in.read();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="CuratorCache-API说明"><a href="#CuratorCache-API说明" class="headerlink" title="CuratorCache API说明"></a>CuratorCache API说明</h2><p>在Curator包中，提供了另外一个可以持续订阅的API，CuratorCacheListener</p><p>CuratorCacheListener是基于CuratorCache缓存实现的监听器，CuratorCache对Zookeeper事件监听进行了封装，能够自动处理反复注册监听，在使用CuratorListener时，首选需要构建CuratorCache缓存实例，具体定义如下。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">CuratorCache.build(CuratorFramework client, String path, Options... options)</span><br><span class="line"></span><br><span class="line">Parameters:</span><br><span class="line">client - the client     <span class="comment">//客户端连接</span></span><br><span class="line">path - path to watch    <span class="comment">//需要订阅事件的节点</span></span><br><span class="line">options - empty or one or more options    </span><br></pre></td></tr></table></figure><p>options有三个选项：</p><p><strong>CuratorCache.Options.SINGLE_NODE_CACHE</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">Options</span></span></span><br><span class="line"><span class="class"></span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Normally the entire tree of nodes starting at the given node are cached. This option</span></span><br><span class="line"><span class="comment">    * causes only the given node to be cached (i.e. a single node cache)</span></span><br><span class="line"><span class="comment">    单节点缓存</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    SINGLE_NODE_CACHE,</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Decompress data via &#123;<span class="doctag">@link</span> org.apache.curator.framework.api.GetDataBuilder#decompressed()&#125;</span></span><br><span class="line"><span class="comment">    对数据进行压缩</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    COMPRESSED_DATA,</span><br><span class="line">    </span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">    * Normally, when the cache is closed via &#123;<span class="doctag">@link</span> CuratorCache#close()&#125;, the storage is cleared</span></span><br><span class="line"><span class="comment">    * via &#123;<span class="doctag">@link</span> CuratorCacheStorage#clear()&#125;. This option prevents the storage from being cleared.</span></span><br><span class="line"><span class="comment">    关闭后不清理缓存</span></span><br><span class="line"><span class="comment">    */</span></span><br><span class="line">    DO_NOT_CLEAR_ON_CLOSE</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="CuratorCache实现事件订阅"><a href="#CuratorCache实现事件订阅" class="headerlink" title="CuratorCache实现事件订阅"></a>CuratorCache实现事件订阅</h2><p>代码实现如下。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CuratorWatchMain</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> CuratorFramework curatorFramework;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CuratorWatchMain</span><span class="params">()</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        curatorFramework=CuratorFrameworkFactory.builder()</span><br><span class="line">            .connectString(<span class="string">&quot;192.168.221.128:2181&quot;</span>)</span><br><span class="line">            .sessionTimeoutMs(<span class="number">20000</span>).connectionTimeoutMs(<span class="number">20000</span>)</span><br><span class="line">            .retryPolicy(<span class="keyword">new</span> ExponentialBackoffRetry(<span class="number">1000</span>,<span class="number">3</span>))</span><br><span class="line">            .authorization(<span class="string">&quot;digest&quot;</span>,<span class="string">&quot;mic:mic&quot;</span>.getBytes())</span><br><span class="line">            .namespace(<span class="string">&quot;curator&quot;</span>).build();</span><br><span class="line">        curatorFramework.start();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">normalWatcher</span><span class="params">()</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        CuratorWatcher watcher=<span class="keyword">new</span> CuratorWatcher() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(WatchedEvent watchedEvent)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;监听事件：&quot;</span>+watchedEvent.toString());</span><br><span class="line">                curatorFramework.checkExists().usingWatcher(<span class="keyword">this</span>).forPath(<span class="string">&quot;/listener&quot;</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        String node=curatorFramework.create().forPath(<span class="string">&quot;/listener&quot;</span>,<span class="string">&quot;I&#x27;Listener&quot;</span>.getBytes());</span><br><span class="line">        <span class="comment">//设置对当前节点的修改和删除事件</span></span><br><span class="line">        String data=<span class="keyword">new</span> String(curatorFramework.getData().usingWatcher(watcher).forPath(node));</span><br><span class="line">        System.out.println(node+<span class="string">&quot;节点对应的value：&quot;</span>+data);</span><br><span class="line">        <span class="comment">//第一次更新</span></span><br><span class="line">        curatorFramework.setData().forPath(node,<span class="string">&quot;change listener&quot;</span>.getBytes());</span><br><span class="line">        Thread.sleep(<span class="number">3000</span>);</span><br><span class="line">        <span class="comment">//第二次更新</span></span><br><span class="line">        curatorFramework.setData().forPath(node,<span class="string">&quot;change listener&quot;</span>.getBytes());</span><br><span class="line">        System.in.read();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addListenerWithNodeCache</span><span class="params">(String node)</span></span>&#123;</span><br><span class="line">        CuratorCache curatorCache=CuratorCache.build(curatorFramework,node,CuratorCache.Options.SINGLE_NODE_CACHE);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * type表示事件类型，NODE_CREATE,NODE_CHANGE,NODE_DELETE</span></span><br><span class="line"><span class="comment">         * forAll: 表示对所有事件的监听</span></span><br><span class="line"><span class="comment">         * forDeletes: 删除节点事件</span></span><br><span class="line"><span class="comment">         * forChange:  节点更新事件监听</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        CuratorCacheListener listener=CuratorCacheListener</span><br><span class="line">            .builder()</span><br><span class="line">            .forAll((type, oldNode, newNode)-&gt;&#123;</span><br><span class="line">                System.out.println(<span class="string">&quot;事件类型：&quot;</span>+type+<span class="string">&quot;\n\r原节点：&quot;</span>+oldNode+<span class="string">&quot;\n\r新节点&quot;</span>+newNode);</span><br><span class="line">            &#125;).forInitialized(()-&gt;&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;初始化&quot;</span>);</span><br><span class="line">        &#125;).build();</span><br><span class="line">        curatorCache.listenable().addListener(listener);</span><br><span class="line">        curatorCache.start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">operation</span><span class="params">(String node)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        curatorFramework.create().forPath(node);</span><br><span class="line">        curatorFramework.setData().forPath(node,<span class="string">&quot;Hello&quot;</span>.getBytes());</span><br><span class="line">        curatorFramework.delete().forPath(node);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        CuratorWatchMain curatorMain=<span class="keyword">new</span> CuratorWatchMain();</span><br><span class="line">        String node=<span class="string">&quot;/node&quot;</span>;</span><br><span class="line">        curatorMain.addListenerWithNodeCache(node);</span><br><span class="line">        curatorMain.operation(node);</span><br><span class="line">        System.in.read();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Zookeeper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
            <tag> Apache Zookeeper </tag>
            
            <tag> Curator </tag>
            
            <tag> 权限模式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>如果你还不知道Apache Zookeeper？你凭什么拿大厂Offer！！</title>
      <link href="/posts/250607254/"/>
      <url>/posts/250607254/</url>
      
        <content type="html"><![CDATA[<p>很多同学或多或少都用到了Zookeeper，并知道它能实现两个功能</p><ul><li>配置中心，实现表分片规则的统一配置管理</li><li>注册中心，实现sharding-proxy节点的服务地址注册</li></ul><p>那么Zookeeper到底是什么？以及为什么能实现这样的功能？接下来我们就来了解一下Zookeeper。</p><h1 id="Zookeeper的前世今生"><a href="#Zookeeper的前世今生" class="headerlink" title="Zookeeper的前世今生"></a>Zookeeper的前世今生</h1><p>Apache ZooKeeper是一个高可靠的分布式协调中间件。它是Google Chubby的一个开源实现，那么它主要是解决什么问题的呢？那就得先了解Google Chubby</p><p>Google Chubby是谷歌的一个用来解决分布式一致性问题的组件，同时，也是粗粒度的分布式锁服务。</p><h1 id="分布式一致性问题"><a href="#分布式一致性问题" class="headerlink" title="分布式一致性问题"></a>分布式一致性问题</h1><p>什么是分布式一致性问题呢？简单来说，就是在一个分布式系统中，有多个节点，每个节点都会提出一个请求，但是在所有节点中只能确定一个请求被通过。而这个通过是需要所有节点达成一致的结果，所以所谓的一致性就是在提出的所有请求中能够选出最终一个确定请求。并且这个请求选出来以后，所有的节点都要知道。</p><p>这个就是典型的拜占庭将军问题</p><p>拜占庭将军问题说的是：拜占庭帝国军队的将军们必须通过投票达成一致来决定是否对某一个国家发起进攻。但是这些将军在地里位置上是分开的，并且在将军中存在叛徒。叛徒可以通过任意行动来达到自己的目标：</p><ol><li><p>欺骗某些将军采取进攻行动</p></li><li><p>促使一个不是所有将军都统一的决定，比如将军们本意是不希望进攻，但是叛徒可以促成进攻行动</p></li><li><p>迷惑将军使得他们无法做出决定</p></li></ol><p>如果叛徒达到了任意一个目标，那么这次行动必然失败。只有完全达成一致那么这次进攻才可能胜利</p><p>拜占庭问题的本质是，由于网络通信存在不可靠的问题，也就是可能存在消息丢失，或者网络延迟。如何在这样的背景下对某一个请求达成一致。</p><p>为了解决这个问题，很多人提出了各种协议，比如大名鼎鼎的Paxos； 也就是说在不可信的网络环境中，按照paxos这个协议就能够针对某个提议达成一致。</p><p><strong>所以：分布式一致性的本质，就是在分布式系统中，多个节点就某一个提议如何达成一致</strong></p><blockquote><p>这个和Google Chubby有什么关系呢</p></blockquote><p>在Google有一个GFS(google file system)，他们有一个需求就是要从多个gfs server中选出一个master server。这个就是典型的一致性问题，5个分布在不同节点的server，需要确定一个master server，而他们要达成的一致性目标是：确定某一个节点为master，并且所有节点要同意。</p><p>而GFS就是使用chubby来解决这个问题的。</p><p>实现原理是：所有的server通过Chubby提供的通信协议到Chubby server上创建同一个文件，当然，最终只有一个server能够获准创建这个文件，这个server就成为了master，它会在这个文件中写入自己 的地址，这样其它的server通过读取这个文件就能知道被选出的master的地址。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202049938.png" alt="image-20200901150615438"></p><center>图9-3</center><h1 id="分布式锁服务"><a href="#分布式锁服务" class="headerlink" title="分布式锁服务"></a>分布式锁服务</h1><p>从另外一个层面来看，Chubby提供了一种粗粒度的分布式锁服务，chubby是通过创建文件的形式来提供锁的功能，server向chubby中创建文件其实就表示加锁操作，创建文件成功表示抢占到了锁。</p><p>由于Chubby没有开源，所以雅虎公司基于chubby的思想，开发了一个类似的分布式协调组件Zookeeper，后来捐赠给了Apache。</p><p>所以，大家一定要了解，zookeeper并不是作为注册中心而设计，他是作为分布式锁的一种设计，而注册中心只是他能够实现的一种功能而已。</p><h1 id="Zookeeper的安装和部署"><a href="#Zookeeper的安装和部署" class="headerlink" title="Zookeeper的安装和部署"></a>Zookeeper的安装和部署</h1><h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>zookeeper有两种运行模式：集群模式和单击模式。</p><p>下载zookeeper安装包：<a href="https://mirrors.bfsu.edu.cn/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz">https://mirrors.bfsu.edu.cn/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz</a></p><p>下载完成，通过tar -zxvf解压</p><p>常用命令</p><ol><li>启动ZK服务:      </li></ol><p>  bin/zkServer.sh start</p><ol start="2"><li>查看ZK服务状态: </li></ol><p>  bin/zkServer.sh status</p><ol start="3"><li>停止ZK服务:    </li></ol><p>  bin/zkServer.sh stop</p><ol start="4"><li>重启ZK服务:    </li></ol><p>  bin/zkServer.sh restart</p><ol start="5"><li>连接服务器</li></ol><p>  zkCli.sh -timeout 0 -r -server ip:port</p><h2 id="单机环境安装"><a href="#单机环境安装" class="headerlink" title="单机环境安装"></a>单机环境安装</h2><p>一般情况下，在开发测试环境，没有这么多资源的情况下，而且也不需要特别好的稳定性的前提下，我们可以使用单机部署；</p><p>初次使用zookeeper，需要将conf目录下的zoo_sample.cfg文件copy一份重命名为zoo.cfg</p><p>修改dataDir目录，dataDir表示日志文件存放的路径（关于zoo.cfg的其他配置信息后面会讲）</p><h2 id="集群环境安装（后续再讲）"><a href="#集群环境安装（后续再讲）" class="headerlink" title="集群环境安装（后续再讲）"></a>集群环境安装（后续再讲）</h2><p>在zookeeper集群中，各个节点总共有三种角色，分别是：leader，follower，observer</p><p>集群模式我们采用模拟3台机器来搭建zookeeper集群。分别复制安装包到三台机器上并解压，同时copy一份zoo.cfg。</p><ol><li><p>修改配置文件</p><ol><li>修改端口</li><li>server.1=IP1:2888:3888 【2888：访问zookeeper的端口；3888：重新选举leader的端口】</li><li>server.2=IP2.2888:3888</li><li>server.3=IP3.2888:2888</li></ol></li><li><p>server.A=B：C：D：其 中</p><ol><li>A 是一个数字，表示这个是第几号服务器；</li><li>B 是这个服务器的 ip地址；</li><li>C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；</li><li>D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号。</li><li>在集群模式下，集群中每台机器都需要感知到整个集群是由哪几台机器组成的，在配置文件中，按照格式server.id=host:port:port，每一行代表一个机器配置。id: 指的是server ID,用来标识该机器在集群中的机器序号</li></ol></li><li><p>新建datadir目录，设置myid</p><p>在每台zookeeper机器上，我们都需要在数据目录(dataDir)下创建一个myid文件，该文件只有一行内容，对应每台机器的Server ID数字；比如server.1的myid文件内容就是1。【必须确保每个服务器的myid文件中的数字不同，并且和自己所在机器的zoo.cfg中server.id的id值一致，id的范围是1~255】</p></li><li><p>启动zookeeper</p></li></ol><h1 id="Zookeeper的数据模型"><a href="#Zookeeper的数据模型" class="headerlink" title="Zookeeper的数据模型"></a>Zookeeper的数据模型</h1><p>如果我们把zookeeper当成是一个内存数据库的话，那么crud就是对zookeeper内存数据库进行一个数据的增删改查操作，那zookeeper的数据结构是什么样的呢？如图9-4所示，zookeeper的视图结构和标准的文件系统非常类似，每一个节点称之为ZNode， 是zookeeper的最小单元。每个znode上都可以保存数据以及挂载子节点，构成一个层次化的树形结构</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202049555.png" alt="image-20210802143509845"></p><center>图9-4</center><h2 id="节点类型"><a href="#节点类型" class="headerlink" title="节点类型"></a>节点类型</h2><p>Zookeeper中包含4种类型的节点，分别说明如下。</p><h3 id="持久化节点"><a href="#持久化节点" class="headerlink" title="持久化节点"></a>持久化节点</h3><p>持久化节点可以细分为两种节点，分别是：</p><ul><li><p><strong>PERSISTENT</strong>：持久化，不会随客户端的断开而自动删除,默认类型，如图9-5所示</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202049219.png" alt="image-20210802151200309"></p><center>图9-5</center></li><li><p><strong>PERSISTENT_SEQUENTIAL</strong>：带序号的持久化，znode的名字将被附加一个单调递增的数字，如图9-6所示</p></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202049610.png" alt="image-20210802151234839"></p><center>图9-5  <h3 id="临时节点"><a href="#临时节点" class="headerlink" title="临时节点"></a>临时节点</h3><ul><li><p><strong>EPHEMERAL</strong>：临时节点，当客户端断开时自动删除，如图9-6所示，如果该Client创建了/Server1和/Server2这两个节点，当Client的session断开后，这两个节点会被Zookeeper自动删除。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202049947.png" alt="image-20210802151732541"></p><center>图9-6</li><li><p><strong>EPHEMERAL_SEQUENTIAL</strong>：带序号的临时节点，znode的名字将被附加一个单调递增的数字，如图9-7所示</p></li></ul><p><strong>注意，临时节点不能存在子节点</strong></p><p>  <img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202049440.png" alt="image-20210802151821941"></p>  <center>图9-7<h3 id="Container节点"><a href="#Container节点" class="headerlink" title="Container节点"></a>Container节点</h3><p><strong>CONTAINER</strong>：container节点是一个特殊用途的节点，它是为Leader、Lock等操作而设计的节点类型，它的作用是： 当容器节点的最后一个子节点被删除后，容器节点将会被标注并且在一段时间后删除。</p><p>由于容器节点存在这个特性，所以当我们在容器节点下创建一个子节点时，需要捕获KeeperException.NoNodeException异常，如果捕获到这个异常，就需要重新创建容器节点。</p><h3 id="TTL节点"><a href="#TTL节点" class="headerlink" title="TTL节点"></a>TTL节点</h3><p>如果某个节点设置为TTL节点类型，那么这个节点在指定TTL时间（单位为毫秒）段内没有修改并且没有子节点时，该节点会在一段时间后被删除。</p><ul><li><strong>PERSISTENT_WITH_TTL</strong>：zookeeper的扩展类型，如果znode在给定的TTL内没有被修改，它将在没有子节点时被删除。要想使用该类型，必须在zookeeper的bin/zkService.sh中的启动zookeeper的java环境中设置环境变量zookeeper.extendedTypesEnabled=true（具体做法在下边），否则KeeperErrorCode = Unimplemented for /**。</li></ul><blockquote><p>设置zookeeper.extendedTypesEnabled=true </p></blockquote><p>打开zookeeper bin/zkServer.sh(win是zkService.cmd),修改启动zookeeper的命令,加上**-Dzookeeper.extendedTypesEnabled=true**,也就是设置java的一个环境变量。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">nohup &quot;$JAVA&quot; $ZOO_DATADIR_AUTOCREATE &quot;-Dzookeeper.log.dir=$&#123;ZOO_LOG_DIR&#125;&quot; \</span><br><span class="line">    &quot;-Dzookeeper.log.file=$&#123;ZOO_LOG_FILE&#125;&quot; &quot;-Dzookeeper.extendedTypesEnabled=true&quot; &quot;-Dzookeeper.root.logger=$&#123;ZOO_LOG4J_PROP&#125;&quot; \</span><br><span class="line">    -XX:+HeapDumpOnOutOfMemoryError -XX:OnOutOfMemoryError=&#x27;kill -9 %p&#x27; \</span><br><span class="line">    -cp &quot;$CLASSPATH&quot; $JVMFLAGS $ZOOMAIN &quot;$ZOOCFG&quot; &gt; &quot;$_ZOO_DAEMON_OUT&quot; 2&gt;&amp;1 &lt; /dev/null &amp;</span><br><span class="line">                                                                                       </span><br></pre></td></tr></table></figure><ul><li><strong>PERSISTENT_SEQUENTIAL_WITH_TTL</strong>：同上，是不过是带序号的</li></ul><h1 id="Zookeeper的操作命令"><a href="#Zookeeper的操作命令" class="headerlink" title="Zookeeper的操作命令"></a>Zookeeper的操作命令</h1><h2 id="创建节点"><a href="#创建节点" class="headerlink" title="创建节点"></a>创建节点</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">create [-s] [-e] [-c] [-t ttl] path [data] [acl]</span><br></pre></td></tr></table></figure><p>**[-s]**：sequential 序列化的，即可以重复创建，在路径后面加上序列号</p><p>**[-e]**：ephemeral 临时的，断开连接后自动失效</p><p><strong>[-c]</strong> ：表示container node（容器节点），</p><p>**[-t ttl]**：表示TTL Nodes（带超时时间的节点）</p><p>**[acl]**：是针对这个节点创建一个权限的，如果创建权限了，则拥有权限的才可以访问</p><h2 id="删除节点"><a href="#删除节点" class="headerlink" title="删除节点"></a>删除节点</h2><p>删除节点，-v表示版本号，实现乐观锁机制</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">delete [-v version] path</span><br></pre></td></tr></table></figure><h2 id="更新节点"><a href="#更新节点" class="headerlink" title="更新节点"></a>更新节点</h2><p>给节点赋值 -s返回节点状态</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set [-s] [-v version] path data</span><br></pre></td></tr></table></figure><h2 id="查询节点信息"><a href="#查询节点信息" class="headerlink" title="查询节点信息"></a>查询节点信息</h2><p>获取指定节点的值</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get [-s] [-w] path</span><br></pre></td></tr></table></figure><h1 id="节点状态信息stat"><a href="#节点状态信息stat" class="headerlink" title="节点状态信息stat"></a>节点状态信息stat</h1><p>节点除了存储数据内容以外，还存储了数据节点本身的一些状态信息，通过get命令可以获得状态信息的详细内容，如图9-8所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202050200.jpg" alt="img"></p><center>图9-8<h2 id="版本-保证分布式数据原子性"><a href="#版本-保证分布式数据原子性" class="headerlink" title="版本-保证分布式数据原子性"></a>版本-保证分布式数据原子性</h2><p>zookeeper为数据节点引入了版本的概念，每个数据节点都有三类版本信息，对数据节点任何更新操作都会引起版本号的变化</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202050613.png" alt="img"></p><center>图9-9<p>版本有点和我们经常使用的乐观锁类似。这里有两个概念说一下，一个是乐观锁，一个是悲观锁</p><p>悲观锁：是数据库中一种非常典型且非常严格的并发控制策略。假如一个事务A正在对数据进行处理，那么在整个处理过程中，都会将数据处于锁定状态，在这期间其他事务无法对数据进行更新操作。</p><p>乐观锁：乐观锁和悲观锁正好想法，它假定多个事务在处理过程中不会彼此影响，因此在事务处理过程中不需要进行加锁处理，如果多个事务对同一数据做更改，那么在更新请求提交之前，每个事务都会首先检查当前事务读取数据后，是否有其他事务对数据进行了修改。如果有修改，则回滚事务</p><p>再回到zookeeper，version属性就是用来实现乐观锁机制的“写入校验”</p><h1 id="Watcher监听节点事件变化"><a href="#Watcher监听节点事件变化" class="headerlink" title="Watcher监听节点事件变化"></a>Watcher监听节点事件变化</h1><p>zookeeper提供了分布式数据的发布/订阅功能，zookeeper允许客户端向服务端注册一个watcher监听，当服务端的一些指定事件触发了watcher，那么服务端就会向客户端发送一个事件通知。zookeeper提供以下几种命令来对指定节点设置监听。</p><ul><li>get [-s] [-w] path：监听指定path节点的修改和删除事件。同样该事件也是一次性触发。</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get -w /node</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在其他窗口执行下面命令，会触发相关事件</span></span><br><span class="line">set /node 123</span><br><span class="line">delete /node</span><br></pre></td></tr></table></figure><ul><li>ls [-s] [-w] [-R] path   ： 监控指定path的子节点的添加和删除事件。</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ls -w /node</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在其他窗口执行下面命令，会触发相关事件</span></span><br><span class="line">create /node/node1</span><br><span class="line">delete /node/node1</span><br></pre></td></tr></table></figure><blockquote><p>注意： 当前命令设置的监听是一次性的，就是说一旦触发了一次事件监听，后续的事件都不会响应。当然我们可以通过重复订阅来解决</p></blockquote><ul><li><p>stat [-w] path：作用和get完全相同。</p></li><li><p>addWatch [-m mode] path # optional mode is one of [PERSISTENT, PERSISTENT_RECURSIVE] - default is PERSISTENT_RECURSIVE</p><p>addWatch的作用是针对指定节点添加事件监听，支持两种模式</p><ul><li>PERSISTENT，持久化订阅，针对当前节点的修改和删除事件，以及当前节点的子节点的删除和新增事件。</li><li>PERSISTENT_RECURSIVE，持久化递归订阅，在PERSISTENT的基础上，增加了子节点修改的事件触发，以及子节点的子节点的数据变化都会触发相关事件（满足递归订阅特性）</li></ul></li></ul><h1 id="Session会话机制"><a href="#Session会话机制" class="headerlink" title="Session会话机制"></a>Session会话机制</h1><p>如图9-10所示，表示Zookeeper的session会话状态机制。</p><ul><li>首先，客户端向Zookeeper Server发起连接请求，此时状态为CONNECTING</li><li>当连接建立好之后，Session状态转化为CONNECTED，此时可以进行数据的IO操作。</li><li>如果Client和Server的连接出现丢失，则Client又会变成CONNECTING状态</li><li>如果会话过期或者主动关闭连接时，此时连接状态为CLOSE</li><li>如果是身份验证失败，直接结束</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202050706.jpg" alt="State transitions"></p><center>图9-10<h1 id="Zookeeper的应用场景"><a href="#Zookeeper的应用场景" class="headerlink" title="Zookeeper的应用场景"></a>Zookeeper的应用场景</h1><h2 id="配置中心"><a href="#配置中心" class="headerlink" title="配置中心"></a>配置中心</h2><p>程序总是需要配置的，如果程序分散部署在多台机器上，要逐个改变配置就变得困难。好吧，现在把这些配置全部放到zookeeper上去，保存在 Zookeeper 的某个目录节点中，然后所有相关应用程序对这个目录节点进行监听，一旦配置信息发生变化，每个应用程序就会收到 Zookeeper 的通知，然后从 Zookeeper 获取新的配置信息应用到系统中就好。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202050321.png" alt="image-20210802214801468"></p><center>图9-11<h2 id="服务注册中心"><a href="#服务注册中心" class="headerlink" title="服务注册中心"></a>服务注册中心</h2><p>如图9-12所示，Zookeeper可以用来实现服务注册中心，简单来说就是管理目标服务端的地址，客户端调用目标服务端之前，从zookeeper上获得地址进行访问。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202050741.png" alt="image-20210802214840063"></p><center>图9-12</center><h2 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h2><p>利用临时有序节点实现分布式锁，如图9-13所示，每个App节点要抢占分布式锁，可以先去Zookeeper上创建一个临时有序节点，节点最小的表示该客户端获得了锁，其他没获得锁的客户端先等待，直到获得锁的客户端删除了该节点或者断开会话连接。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202050425.png" alt="image-20210802214934703"></p><center>图9-13</center>]]></content>
      
      
      <categories>
          
          <category> Zookeeper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Zookeeper </tag>
            
            <tag> 分布式协调 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ShardingSphere基于Zookeeper实现分布式治理</title>
      <link href="/posts/432870994/"/>
      <url>/posts/432870994/</url>
      
        <content type="html"><![CDATA[<p>随着数据规模的不断膨胀，使用多节点集群的分布式方式逐渐成为趋势。在这种情况下，如何高效、自动化管理集群节点，实现不同节点的协同工作，配置一致性，状态一致性，高可用性，可观测性等，就成为一个重要的挑战。</p><p>集群管理的复杂性体现在，一方面我们需要把所有的节点，不管是底层数据库节点，还是中间件或者业务系统节点的状态都统一管理起来，并且能实时探测到最新的配置变动情况，进一步为集群的调控和调度提供依据。</p><p>另一方面，不同节点之间的统一协调，分库分表策略以及规则同步，也需要我们能够设计一套在分布式情况下，进行全局事件通知机制以及独占性操作的分布式协调锁机制。在这方面，ShardingJDBC采用了Zookeeper/Etcd来实现配置的同步，状态变更通知，以及分布式锁来控制排他操作。</p><h1 id="ShardingJDBC分布式治理"><a href="#ShardingJDBC分布式治理" class="headerlink" title="ShardingJDBC分布式治理"></a>ShardingJDBC分布式治理</h1><p>ShardingJDBC集成了Zookeeper/Etcd，用来实现ShardingJDBC的分布式治理，下面我们先通过一个应用程序来演示一下实现原理。</p><h2 id="安装Zookeeper"><a href="#安装Zookeeper" class="headerlink" title="安装Zookeeper"></a>安装Zookeeper</h2><ul><li><p>通过这个地址下载Zookeeper</p><p><a href="https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz">https://mirrors.tuna.tsinghua.edu.cn/apache/zookeeper/zookeeper-3.6.3/apache-zookeeper-3.6.3-bin.tar.gz</a></p></li><li><p>常用操作命令</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash">启动ZK服务:</span>      </span><br><span class="line">bin/zkServer.sh start</span><br><span class="line"><span class="meta">#</span><span class="bash">查看ZK服务状态:</span> </span><br><span class="line">bin/zkServer.sh status</span><br><span class="line"><span class="meta">#</span><span class="bash">停止ZK服务:</span>    </span><br><span class="line">bin/zkServer.sh stop</span><br><span class="line"><span class="meta">#</span><span class="bash">重启ZK服务:</span>    </span><br><span class="line">bin/zkServer.sh restart</span><br><span class="line"><span class="meta">#</span><span class="bash">连接服务器</span></span><br><span class="line">zkCli.sh -timeout 0 -r -server ip:port</span><br></pre></td></tr></table></figure></li><li><p>单机安装</p><p>初次使用zookeeper，需要将conf目录下的zoo_sample.cfg文件copy一份重命名为zoo.cfg</p><p>修改dataDir目录，dataDir表示日志文件存放的路径（关于zoo.cfg的其他配置信息后面会讲）</p></li></ul><h2 id="Sharding-JDBC集成Zookeeper"><a href="#Sharding-JDBC集成Zookeeper" class="headerlink" title="Sharding-JDBC集成Zookeeper"></a>Sharding-JDBC集成Zookeeper</h2><p>本阶段演示的项目代码：sharding-jdbc-split-zookeeper，项目结构如图9-1所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110241710242.png" alt="image-20210729212359651"></p><center>图9-1 项目结构</center><h3 id="添加jar包依赖"><a href="#添加jar包依赖" class="headerlink" title="添加jar包依赖"></a>添加jar包依赖</h3><p>引入jar包依赖(只需要依赖下面两个包即可)</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.shardingsphere<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>shardingsphere-governance-repository-zookeeper-curator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.0.0-alpha<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.shardingsphere<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>shardingsphere-jdbc-governance-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.0.0-alpha<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.shardingsphere<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>shardingsphere-test<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>其他基础jar包（所有项目都是基于spring boot集成mybatis拷贝的）</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-generator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.alibaba<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>fastjson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.72<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.commons<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-lang3<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.9<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.18.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="添加配置文件"><a href="#添加配置文件" class="headerlink" title="添加配置文件"></a>添加配置文件</h3><p>增加基础的分库分表配置-application.properties</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">spring.shardingsphere.datasource.names</span>=<span class="string">ds-0,ds-1</span></span><br><span class="line"><span class="meta">spring.shardingsphere.datasource.common.type</span>=<span class="string">com.zaxxer.hikari.HikariDataSource</span></span><br><span class="line"><span class="meta">spring.shardingsphere.datasource.common.driver-class-name</span>=<span class="string">com.mysql.jdbc.Driver</span></span><br><span class="line"></span><br><span class="line"><span class="meta">spring.shardingsphere.datasource.ds-0.username</span>=<span class="string">root</span></span><br><span class="line"><span class="meta">spring.shardingsphere.datasource.ds-0.password</span>=<span class="string">123456</span></span><br><span class="line"><span class="meta">spring.shardingsphere.datasource.ds-0.jdbc-url</span>=<span class="string">jdbc:mysql://192.168.221.128:3306/shard01?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class="line"></span><br><span class="line"><span class="meta">spring.shardingsphere.datasource.ds-1.username</span>=<span class="string">root</span></span><br><span class="line"><span class="meta">spring.shardingsphere.datasource.ds-1.password</span>=<span class="string">123456</span></span><br><span class="line"><span class="meta">spring.shardingsphere.datasource.ds-1.jdbc-url</span>=<span class="string">jdbc:mysql://192.168.221.128:3306/shard02?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8</span></span><br><span class="line"></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.default-database-strategy.standard.sharding-column</span>=<span class="string">user_id</span></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.default-database-strategy.standard.sharding-algorithm-name</span>=<span class="string">database-inline</span></span><br><span class="line"></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.tables.t_order.actual-data-nodes</span>=<span class="string">ds-$-&gt;&#123;0..1&#125;.t_order_$-&gt;&#123;0..1&#125;</span></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.tables.t_order.table-strategy.standard.sharding-column</span>=<span class="string">order_id</span></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.tables.t_order.table-strategy.standard.sharding-algorithm-name</span>=<span class="string">t-order-inline</span></span><br><span class="line"></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.tables.t_order.key-generate-strategy.column</span>=<span class="string">order_id</span></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.tables.t_order.key-generate-strategy.key-generator-name</span>=<span class="string">snowflake</span></span><br><span class="line"></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.sharding-algorithms.database-inline.type</span>=<span class="string">INLINE</span></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.sharding-algorithms.database-inline.props.algorithm-expression</span>=<span class="string">ds-$-&gt;&#123;user_id % 2&#125;</span></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-inline.type</span>=<span class="string">INLINE</span></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-inline.props.algorithm-expression</span>=<span class="string">t_order_$-&gt;&#123;order_id % 2&#125;</span></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-item-inline.type</span>=<span class="string">INLINE</span></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-item-inline.props.algorithm-expression</span>=<span class="string">t_order_item_$-&gt;&#123;order_id % 2&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.key-generators.snowflake.type</span>=<span class="string">SNOWFLAKE</span></span><br><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.key-generators.snowflake.props.worker-id</span>=<span class="string">123</span></span><br></pre></td></tr></table></figure><h3 id="增加Zookeeper配置"><a href="#增加Zookeeper配置" class="headerlink" title="增加Zookeeper配置"></a>增加Zookeeper配置</h3><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 治理名称(在zookeeper上的节点名称)</span></span><br><span class="line"><span class="meta">spring.shardingsphere.governance.name</span>=<span class="string">sharding-jdbc-split-zookeeper</span></span><br><span class="line"><span class="comment"># 本地配置是否覆盖配置中心配置。如果可覆盖，每次启动都以本地配置为准.</span></span><br><span class="line"><span class="meta">spring.shardingsphere.governance.overwrite</span>=<span class="string">true</span></span><br><span class="line"><span class="comment"></span></span><br><span class="line"><span class="comment"># Zookeeper/etcd</span></span><br><span class="line"><span class="meta">spring.shardingsphere.governance.registry-center.type</span>=<span class="string">ZooKeeper</span></span><br><span class="line"><span class="meta">spring.shardingsphere.governance.registry-center.server-lists</span>=<span class="string">192.168.221.131:2181</span></span><br><span class="line"><span class="comment"># 之所以加下面两个参数，是因为默认的链接超时时间是1500毫秒，由于时间较短导致启动时很容易超时，导致连接失败</span></span><br><span class="line"><span class="comment"># 重试次数</span></span><br><span class="line"><span class="meta">spring.shardingsphere.governance.registry-center.props.maxRetries</span>=<span class="string">4</span></span><br><span class="line"><span class="comment"># 重试间隔时间</span></span><br><span class="line"><span class="meta">spring.shardingsphere.governance.registry-center.props.retryIntervalMilliseconds</span>=<span class="string">6000</span></span><br></pre></td></tr></table></figure><h3 id="启动项目进行测试"><a href="#启动项目进行测试" class="headerlink" title="启动项目进行测试"></a>启动项目进行测试</h3><p>启动过程中看到如下日志，表示配置zookeeper成功，启动的时候会先把本地配置保存到zookeeper中，后续我们可以在zookeeper中修改相关配置，然后同步通知给到相关的应用节点。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">2021-07-29 21:31:25.007  INFO 112916 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.io.tmpdir=C:\Users\mayn\AppData\Local\Temp\</span><br><span class="line">2021-07-29 21:31:25.007  INFO 112916 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:java.compiler=&lt;NA&gt;</span><br><span class="line">2021-07-29 21:31:25.007  INFO 112916 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.name=Windows 10</span><br><span class="line">2021-07-29 21:31:25.007  INFO 112916 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.arch=amd64</span><br><span class="line">2021-07-29 21:31:25.007  INFO 112916 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.version=10.0</span><br><span class="line">2021-07-29 21:31:25.007  INFO 112916 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:user.name=mayn</span><br><span class="line">2021-07-29 21:31:25.007  INFO 112916 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:user.home=C:\Users\mayn</span><br><span class="line">2021-07-29 21:31:25.007  INFO 112916 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:user.dir=E:\教研-课件\vip课程\第五轮\03 高并发组件\09 ShardingSphere基于Zookeeper实现分布式治理\sharding-jdbc-readwrite-zookeeper</span><br><span class="line">2021-07-29 21:31:25.007  INFO 112916 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.memory.free=482MB</span><br><span class="line">2021-07-29 21:31:25.007  INFO 112916 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.memory.max=7264MB</span><br><span class="line">2021-07-29 21:31:25.007  INFO 112916 --- [           main] org.apache.zookeeper.ZooKeeper           : Client environment:os.memory.total=501MB</span><br><span class="line">2021-07-29 21:31:25.009  INFO 112916 --- [           main] org.apache.zookeeper.ZooKeeper           : Initiating client connection, connectString=192.168.221.131:2181 sessionTimeout=60000 watcher=org.apache.curator.ConnectionState@68e2d03e</span><br><span class="line">2021-07-29 21:31:25.012  INFO 112916 --- [           main] org.apache.zookeeper.common.X509Util     : Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation</span><br><span class="line">2021-07-29 21:31:25.020  INFO 112916 --- [           main] org.apache.zookeeper.ClientCnxnSocket    : jute.maxbuffer value is 1048575 Bytes</span><br><span class="line">2021-07-29 21:31:25.023  INFO 112916 --- [           main] org.apache.zookeeper.ClientCnxn          : zookeeper.request.timeout value is 0. feature enabled=false</span><br><span class="line">2021-07-29 21:31:25.030  INFO 112916 --- [           main] o.a.c.f.imps.CuratorFrameworkImpl        : Default schema</span><br></pre></td></tr></table></figure><p>接着访问如下接口进行测试。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/t-order&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TOrderController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    ITOrderService orderService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        orderService.initEnvironment();</span><br><span class="line">        orderService.processSuccess();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="配置中心的数据结构说明"><a href="#配置中心的数据结构说明" class="headerlink" title="配置中心的数据结构说明"></a>配置中心的数据结构说明</h2><p>注册中心的数据结构如下</p><p>namespace： 就是spring.shardingsphere.governance.name</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">namespace</span><br><span class="line">├──users                                     # 权限配置</span><br><span class="line">├──props                                     # 属性配置</span><br><span class="line">├──schemas                                   # Schema 配置</span><br><span class="line">├      ├──$&#123;schema_1&#125;                        # Schema 名称1</span><br><span class="line">├      ├      ├──datasource                  # 数据源配置</span><br><span class="line">├      ├      ├──rule                        # 规则配置</span><br><span class="line">├      ├      ├──table                       # 表结构配置</span><br><span class="line">├      ├──$&#123;schema_2&#125;                        # Schema 名称2</span><br><span class="line">├      ├      ├──datasource                  # 数据源配置</span><br><span class="line">├      ├      ├──rule                        # 规则配置</span><br><span class="line">├      ├      ├──table                       # 表结构配置</span><br></pre></td></tr></table></figure><h3 id="rules全局配置规则"><a href="#rules全局配置规则" class="headerlink" title="rules全局配置规则"></a>rules全局配置规则</h3><p>可包括访问 ShardingSphere-Proxy 用户名和密码的权限配置</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="bullet">-</span> <span class="type">!AUTHORITYusers:</span>  <span class="bullet">-</span> <span class="string">root@%:root</span>  <span class="bullet">-</span> <span class="string">sharding@127.0.0.1:shardingprovider:</span>  <span class="attr">type:</span> <span class="string">NATIVE</span></span><br></pre></td></tr></table></figure><h3 id="props属性配置"><a href="#props属性配置" class="headerlink" title="props属性配置"></a>props属性配置</h3><p>ShardingSphere相关属性配置</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">executor-size: 20sql-show:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><h3 id="schemas-schemeName-dataSources"><a href="#schemas-schemeName-dataSources" class="headerlink" title="/schemas/${schemeName}/dataSources"></a>/schemas/${schemeName}/dataSources</h3><p>多个数据库连接池的集合，不同数据库连接池属性自适配（例如：DBCP，C3P0，Druid, HikariCP）。</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">ds_0:   dataSourceClassName: com.zaxxer.hikari.HikariDataSource  props:    url:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/demo_ds_0?serverTimezone=UTC&amp;useSSL=false</span>    <span class="attr">password: null    maxPoolSize: 50    connectionTimeoutMilliseconds: 30000    idleTimeoutMilliseconds: 60000    minPoolSize: 1    username: root    maxLifetimeMilliseconds: 1800000ds_1:   dataSourceClassName: com.zaxxer.hikari.HikariDataSource  props:    url:</span> <span class="string">jdbc:mysql://127.0.0.1:3306/demo_ds_1?serverTimezone=UTC&amp;useSSL=false</span>    <span class="attr">password: null    maxPoolSize: 50    connectionTimeoutMilliseconds: 30000    idleTimeoutMilliseconds: 60000    minPoolSize: 1    username: root    maxLifetimeMilliseconds:</span> <span class="number">1800000</span></span><br></pre></td></tr></table></figure><h3 id="schemas-schemeName-rule"><a href="#schemas-schemeName-rule" class="headerlink" title="/schemas/${schemeName}/rule"></a>/schemas/${schemeName}/rule</h3><p>规则配置，可包括数据分片、读写分离等配置规则</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">rules:-</span> <span class="type">!SHARDING</span>  <span class="attr">defaultDatabaseStrategy:    standard:      shardingAlgorithmName: database-inline      shardingColumn: user_id  keyGenerators:    snowflake:      props:        worker-id:</span> <span class="string">&#x27;123&#x27;</span>      <span class="attr">type: SNOWFLAKE  shardingAlgorithms:    t-order-inline:      props:        algorithm-expression:</span> <span class="string">t_order_$-&gt;&#123;order_id</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span>      <span class="attr">type: INLINE    database-inline:      props:        algorithm-expression:</span> <span class="string">ds-$-&gt;&#123;user_id</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span>      <span class="attr">type: INLINE    t-order-item-inline:      props:        algorithm-expression:</span> <span class="string">t_order_item_$-&gt;&#123;order_id</span> <span class="string">%</span> <span class="number">2</span><span class="string">&#125;</span>      <span class="attr">type: INLINE  tables:    t_order:      actualDataNodes:</span> <span class="string">ds-$-&gt;&#123;0..1&#125;.t_order_$-&gt;&#123;0..1&#125;</span>      <span class="attr">keyGenerateStrategy:        column: order_id        keyGeneratorName: snowflake      logicTable: t_order      tableStrategy:        standard:          shardingAlgorithmName: t-order-inline          shardingColumn:</span> <span class="string">order_id</span></span><br></pre></td></tr></table></figure><h3 id="schemas-schemeName-table"><a href="#schemas-schemeName-table" class="headerlink" title="/schemas/${schemeName}/table"></a>/schemas/${schemeName}/table</h3><p>表结构配置，暂时不支持动态修改</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">configuredSchemaMetaData:  tables:    t_order:      columns:        order_id:          caseSensitive: false          dataType: 0          generated: true          name: order_id          primaryKey: true        user_id:          caseSensitive: false          dataType: 0          generated: false          name: user_id          primaryKey: false        address_id:          caseSensitive: false          dataType: 0          generated: false          name: address_id          primaryKey: false        status:          caseSensitive: false          dataType: 0          generated: false          name: status          primaryKey: falseunconfiguredSchemaMetaDataMap:  ds-0:</span>  <span class="bullet">-</span> <span class="string">t_order_complex</span>  <span class="bullet">-</span> <span class="string">t_order_interval</span>  <span class="bullet">-</span> <span class="string">t_order_item_complex</span></span><br></pre></td></tr></table></figure><h2 id="动态生效"><a href="#动态生效" class="headerlink" title="动态生效"></a>动态生效</h2><p><strong>除了table相关的配置无法动态更改之外</strong>，其他配置在zookeeper上修改之后，在不重启应用节点时，都会同步到相关服务节点。</p><p>比如，我们修改图9-2所示的红色部分的位置，把<code>t_order_$-&gt;&#123;0..1&#125;</code>修改成<code>t_order_$-&gt;&#123;0..4&#125;</code>，这样就会生成4个分片，并且取模规则也做相应更改。</p><p>然后点击保存后，在不重启应用节点时，重新发起接口测试请求，就可以看到修改成功后的结果。</p><p><a href="http://localhost:8080/swagger-ui.html">http://localhost:8080/swagger-ui.html</a></p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110241710256.png" alt="image-20210729215100735" style="zoom:87%;" /><center>图9-2 zookeeper配置中心</center><h2 id="注册中心节点"><a href="#注册中心节点" class="headerlink" title="注册中心节点"></a>注册中心节点</h2><p>在zookeeper服务器上，还存在以下节点信息。</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="string">namespace</span>   <span class="string">├──states</span>   <span class="string">├</span>    <span class="string">├──proxynodes</span>   <span class="string">├</span>    <span class="string">├</span>     <span class="string">├──$&#123;your_instance_ip_a&#125;@$&#123;your_instance_pid_x&#125;@$&#123;UUID&#125;</span>   <span class="string">├</span>    <span class="string">├</span>     <span class="string">├──$&#123;your_instance_ip_b&#125;@$&#123;your_instance_pid_y&#125;@$&#123;UUID&#125;</span>   <span class="string">├</span>    <span class="string">├</span>     <span class="string">├──....</span>   <span class="string">├</span>    <span class="string">├──datanodes</span>   <span class="string">├</span>    <span class="string">├</span>     <span class="string">├──$&#123;schema_1&#125;</span>   <span class="string">├</span>    <span class="string">├</span>     <span class="string">├</span>      <span class="string">├──$&#123;ds_0&#125;</span>   <span class="string">├</span>    <span class="string">├</span>     <span class="string">├</span>      <span class="string">├──$&#123;ds_1&#125;</span>   <span class="string">├</span>    <span class="string">├</span>     <span class="string">├──$&#123;schema_2&#125;</span>   <span class="string">├</span>    <span class="string">├</span>     <span class="string">├</span>      <span class="string">├──$&#123;ds_0&#125;</span>   <span class="string">├</span>    <span class="string">├</span>     <span class="string">├</span>      <span class="string">├──$&#123;ds_1&#125;</span>   <span class="string">├</span>    <span class="string">├</span>     <span class="string">├──....</span></span><br></pre></td></tr></table></figure><p>这个是注册中心节点，用来保存shardingsphere-proxy中间件的服务器实例信息、以及实例运行情况。</p><p>运行实例标识由运行服务器的 IP 地址和 PID 构成。</p><p>运行实例标识均为临时节点，当实例上线时注册，下线时自动清理。 注册中心监控这些节点的变化来治理运行中实例对数据库的访问等。</p><p><strong>由于注册中心会在后续的内容中讲，所以这里暂时不展开。</strong></p><h2 id="分布式治理总结"><a href="#分布式治理总结" class="headerlink" title="分布式治理总结"></a>分布式治理总结</h2><p>引入zookeeper这样一个角色，可以协助ShardingJDBC完成以下功能</p><ul><li><strong>配置集中化</strong>：越来越多的运行时实例，使得散落的配置难于管理，配置不同步导致的问题十分严重。将配置集中于配置中心，可以更加有效进行管理。</li><li><strong>配置动态化</strong>：配置修改后的分发，是配置中心可以提供的另一个重要能力。它可支持数据源和规则的动态切换。</li><li>存放运行时的动态/临时状态数据，比如可用的 ShardingSphere 的实例，需要禁用或熔断的数据源等。</li><li>提供熔断数据库访问程序对数据库的访问和禁用从库的访问的编排治理能力。治理模块仍然有大量未完成的功能（比如流控等）。</li></ul><p>到目前为止，ShardingSphere中Sharding-JDBC部分的内容就到这里结束了，另外一个组件Sharding-Proxy就没有展开了，因为它相当于实现了数据库层面的代理，也就是说，不需要开发者在应用程序中配置数据库分库分表的规则，而是直接把Sharding-Proxy当作数据库源连接，Sharding-Proxy相当于Mysql数据库的代理，当请求发送到Sharding-Proxy之后，在Sharding-Proxy上会配置相关的分片规则，然后根据分片规则进行相关处理。</p>]]></content>
      
      
      <categories>
          
          <category> ShardingSphere </category>
          
          <category> 分库分表 </category>
          
          <category> Zookeeper </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 分库分表 </tag>
            
            <tag> ShardingSphere </tag>
            
            <tag> Zookeeper </tag>
            
            <tag> 配置中心 </tag>
            
            <tag> 分布式治理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>分库分表利器之Sharding Sphere（深度好文，看过的人都说好）</title>
      <link href="/posts/1378559791/"/>
      <url>/posts/1378559791/</url>
      
        <content type="html"><![CDATA[<p><code>Sharding-JDBC</code> 最早是当当网内部使用的一款分库分表框架，到2017年的时候才开始对外开源，这几年在大量社区贡献者的不断迭代下，功能也逐渐完善，现已更名为 <code>ShardingSphere</code>，2020年4⽉16⽇正式成为 <code>Apache</code> 软件基⾦会的顶级项⽬。</p><p>随着版本的不断更迭 <code>ShardingSphere</code> 的核心功能也变得多元化起来。如图7-1，ShardingSphere生态包含三款开源分布式数据库中间件解决方案，Sharding-JDBC、Sharding-Proxy、Sharding-Sidecar。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033545.png" alt="image-20210716164452547"></p><center>图7-1</center><p>Apache ShardingSphere 5.x 版本开始致力于提供可插拔架构，项目的功能组件能够灵活的以可插拔的方式进行扩展。 目前，数据分片、读写分离、数据加密、影子库压测等功能，以及对 MySQL、PostgreSQL、SQLServer、Oracle 等 SQL 与协议的支持，均通过插件的方式织入项目。 开发者能够像使用积木一样定制属于自己的独特系统。Apache ShardingSphere 目前已提供数十个 SPI 作为系统的扩展点，而且仍在不断增加中。</p><p>如图7-2，是Sharding-Sphere的整体架构。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033017.png"></p><center>图7-2</center><h2 id="Sharding-JDBC"><a href="#Sharding-JDBC" class="headerlink" title="Sharding-JDBC"></a>Sharding-JDBC</h2><p>Sharding-JDBC是比较常用的一个组件，它定位的是一个增强版的JDBC驱动，简单来说就是在应用端来完成数据库分库分表相关的路由和分片操作，也是我们本阶段重点去分析的组件。</p><p>我们在项目内引入Sharding-JDBC的依赖，我们的业务代码在操作数据库的时候，就会通过Sharding-JDBC的代码连接到数据库。也就是分库分表的一些核心动作，比如SQL解析，路由，执行，结果处理，都是由它来完成的，它工作在客户端。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033427.png"></p><center>图7-3</center><h2 id="Sharding-Proxy"><a href="#Sharding-Proxy" class="headerlink" title="Sharding-Proxy"></a>Sharding-Proxy</h2><p>Sharding-Proxy有点类似于Mycat，它是提供了数据库层面的代理，什么意思呢？简单来说，以前我们的应用是直连数据库，引入了Sharding-Proxy之后，我们的应用是直连Sharding-Proxy，然后Sharding-Proxy通过处理之后再转发到mysql中。</p><p>这种方式的好处在于，用户不需要感知到分库分表的存在，相当于正常访问mysql。目前Sharding-Proxy支持Mysql和PostgreSQL两种数据库协议，如图7-4所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033785.png"></p><center>图7-4</center><h2 id="Sharding-Sidecar（TODO）"><a href="#Sharding-Sidecar（TODO）" class="headerlink" title="Sharding-Sidecar（TODO）"></a>Sharding-Sidecar（TODO）</h2><p>看到Sidecar，大家应该就能想到服务网格架构，它主要定位于 Kubernetes 的云原生数据库代理，以 Sidecar 的形式代理所有对数据库的访问。目前Sharding-Sidecar还处于开发阶段未发布。</p><h1 id="Sharding-JDBC-1"><a href="#Sharding-JDBC-1" class="headerlink" title="Sharding-JDBC"></a>Sharding-JDBC</h1><p>Sharding-JDBC是对原有JDBC驱动的增强，在分库分表的场景中，为应用提供了如图7-5所示的功能。</p><p><img src="http://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/27872_BDAA13805A1849549BFF9B61D689D2F6" alt="file"></p><center>图7-5</center><ul><li></li></ul><h2 id="Sharding-JDBC的整体架构"><a href="#Sharding-JDBC的整体架构" class="headerlink" title="Sharding-JDBC的整体架构"></a>Sharding-JDBC的整体架构</h2><p>如图7-6所示，Java应用程序通过Sharding-JDBC驱动访问数据库，而在Sharding-JDBC中，它会根据相关配置完成分库分表路由、分布式事务等功能，所以我们可以认为它是对JDBC驱动的增强。</p><p>Registry Center表示注册中心，用来实现集中化分片配置规则管理、动态配置、以及数据源等信息。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033009.png"></p><center>图7-6</center><h2 id="Sharding-JDBC的基本使用"><a href="#Sharding-JDBC的基本使用" class="headerlink" title="Sharding-JDBC的基本使用"></a>Sharding-JDBC的基本使用</h2><p>为了让大家更好的理解Shading-JDBC，我们通过一个案例来简单认识一下Sharding-JDBC。‘</p><blockquote><p><a href="https://shardingsphere.apache.org/document/current/cn/quick-start/shardingsphere-jdbc-quick-start/">https://shardingsphere.apache.org/document/current/cn/quick-start/shardingsphere-jdbc-quick-start/</a></p></blockquote><p>为了更直观的理解Sharding-JDBC，下面通过一个原生的案例进行演示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033494.png" alt="image-20210717164207374"></p><center>图7-7</center><p>图7-8表示整体项目结构。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033784.png" alt="image-20210717170042801"></p><h3 id="引入Maven依赖"><a href="#引入Maven依赖" class="headerlink" title="引入Maven依赖"></a>引入Maven依赖</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.shardingsphere<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>shardingsphere-jdbc-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.0.0-alpha<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.zaxxer<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>HikariCP<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="Order"><a href="#Order" class="headerlink" title="Order"></a>Order</h3><p>定义Order表的实体对象。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Order</span> <span class="keyword">implements</span> <span class="title">Serializable</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">661434701950670670L</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> orderId;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> userId;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> addressId;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String status;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="OrderReporitoryImpl"><a href="#OrderReporitoryImpl" class="headerlink" title="OrderReporitoryImpl"></a>OrderReporitoryImpl</h3><p>定义数据库操作层</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">OrderRepository</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">createTableIfNotExists</span><span class="params">()</span> <span class="keyword">throws</span> SQLException</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function">Long <span class="title">insert</span><span class="params">(<span class="keyword">final</span> Order order)</span> <span class="keyword">throws</span> SQLException</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderRepositoryImpl</span> <span class="keyword">implements</span> <span class="title">OrderRepository</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> DataSource dataSource;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">OrderRepositoryImpl</span><span class="params">(<span class="keyword">final</span> DataSource dataSource)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.dataSource = dataSource;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createTableIfNotExists</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;CREATE TABLE IF NOT EXISTS t_order (order_id BIGINT NOT NULL AUTO_INCREMENT, user_id INT NOT NULL, address_id BIGINT NOT NULL, status VARCHAR(50), PRIMARY KEY (order_id))&quot;</span>;</span><br><span class="line">        <span class="keyword">try</span> (Connection connection = dataSource.getConnection();</span><br><span class="line">             Statement statement = connection.createStatement()) &#123;</span><br><span class="line">            statement.executeUpdate(sql);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Long <span class="title">insert</span><span class="params">(<span class="keyword">final</span> Order order)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        String sql = <span class="string">&quot;INSERT INTO t_order (user_id, address_id, status) VALUES (?, ?, ?)&quot;</span>;</span><br><span class="line">        <span class="keyword">try</span> (Connection connection = dataSource.getConnection();</span><br><span class="line">             PreparedStatement preparedStatement = connection.prepareStatement(sql, Statement.RETURN_GENERATED_KEYS)) &#123;</span><br><span class="line">            preparedStatement.setInt(<span class="number">1</span>, order.getUserId());</span><br><span class="line">            preparedStatement.setLong(<span class="number">2</span>, order.getAddressId());</span><br><span class="line">            preparedStatement.setString(<span class="number">3</span>, order.getStatus());</span><br><span class="line">            preparedStatement.executeUpdate();</span><br><span class="line">            <span class="keyword">try</span> (ResultSet resultSet = preparedStatement.getGeneratedKeys()) &#123;</span><br><span class="line">                <span class="keyword">if</span> (resultSet.next()) &#123;</span><br><span class="line">                    order.setOrderId(resultSet.getLong(<span class="number">1</span>));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> order.getOrderId();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="OrderServiceImpl"><a href="#OrderServiceImpl" class="headerlink" title="OrderServiceImpl"></a>OrderServiceImpl</h3><p>定义数据库访问层</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ExampleService</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 初始化表结构</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> SQLException SQL exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">initEnvironment</span><span class="params">()</span> <span class="keyword">throws</span> SQLException</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 执行成功</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@throws</span> SQLException SQL exception</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">void</span> <span class="title">processSuccess</span><span class="params">()</span> <span class="keyword">throws</span> SQLException</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">OrderServiceImpl</span> <span class="keyword">implements</span> <span class="title">ExampleService</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> OrderRepository orderRepository;</span><br><span class="line">    Random random=<span class="keyword">new</span> Random();</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">OrderServiceImpl</span><span class="params">(<span class="keyword">final</span> DataSource dataSource)</span> </span>&#123;</span><br><span class="line">        orderRepository=<span class="keyword">new</span> OrderRepositoryImpl(dataSource);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initEnvironment</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        orderRepository.createTableIfNotExists();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processSuccess</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;-------------- Process Success Begin ---------------&quot;</span>);</span><br><span class="line">        List&lt;Long&gt; orderIds = insertData();</span><br><span class="line">        System.out.println(<span class="string">&quot;-------------- Process Success Finish --------------&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> List&lt;Long&gt; <span class="title">insertData</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;---------------------------- Insert Data ----------------------------&quot;</span>);</span><br><span class="line">        List&lt;Long&gt; result = <span class="keyword">new</span> ArrayList&lt;&gt;(<span class="number">10</span>);</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">10</span>; i++) &#123;</span><br><span class="line">            Order order = insertOrder(i);</span><br><span class="line">            result.add(order.getOrderId());</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> Order <span class="title">insertOrder</span><span class="params">(<span class="keyword">final</span> <span class="keyword">int</span> i)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        Order order = <span class="keyword">new</span> Order();</span><br><span class="line">        order.setUserId(random.nextInt(<span class="number">10000</span>));</span><br><span class="line">        order.setAddressId(i);</span><br><span class="line">        order.setStatus(<span class="string">&quot;INSERT_TEST&quot;</span>);</span><br><span class="line">        orderRepository.insert(order);</span><br><span class="line">        <span class="keyword">return</span> order;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="DataSourceUtil"><a href="#DataSourceUtil" class="headerlink" title="DataSourceUtil"></a>DataSourceUtil</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DataSourceUtil</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String HOST = <span class="string">&quot;192.168.221.128&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> PORT = <span class="number">3306</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String USER_NAME = <span class="string">&quot;root&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String PASSWORD = <span class="string">&quot;123456&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> DataSource <span class="title">createDataSource</span><span class="params">(<span class="keyword">final</span> String dataSourceName)</span> </span>&#123;</span><br><span class="line">        HikariDataSource result = <span class="keyword">new</span> HikariDataSource();</span><br><span class="line">        result.setDriverClassName(<span class="string">&quot;com.mysql.jdbc.Driver&quot;</span>);</span><br><span class="line">        result.setJdbcUrl(String.format(<span class="string">&quot;jdbc:mysql://%s:%s/%s?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8&quot;</span>, HOST, PORT, dataSourceName));</span><br><span class="line">        result.setUsername(USER_NAME);</span><br><span class="line">        result.setPassword(PASSWORD);</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Sharding-JDBC分片规则配置"><a href="#Sharding-JDBC分片规则配置" class="headerlink" title="Sharding-JDBC分片规则配置"></a>Sharding-JDBC分片规则配置</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ShardingDatabasesAndTableConfiguration</span> </span>&#123;</span><br><span class="line">    <span class="comment">//创建两个数据源</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Map&lt;String,DataSource&gt; <span class="title">createDataSourceMap</span><span class="params">()</span></span>&#123;</span><br><span class="line">        Map&lt;String, DataSource&gt; dataSourceMap=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        dataSourceMap.put(<span class="string">&quot;ds0&quot;</span>,DataSourceUtil.createDataSource(<span class="string">&quot;shard01&quot;</span>));</span><br><span class="line">        dataSourceMap.put(<span class="string">&quot;ds1&quot;</span>,DataSourceUtil.createDataSource(<span class="string">&quot;shard02&quot;</span>));</span><br><span class="line">        <span class="keyword">return</span> dataSourceMap;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> ShardingRuleConfiguration <span class="title">createShardingRuleConfiguration</span><span class="params">()</span></span>&#123;</span><br><span class="line">        ShardingRuleConfiguration configuration=<span class="keyword">new</span> ShardingRuleConfiguration();</span><br><span class="line">        configuration.getTables().add(getOrderTableRuleConfiguration());</span><br><span class="line"><span class="comment">//        configuration.getBindingTableGroups().add(&quot;t_order,t_order_item&quot;);</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 设置数据库的分片规则</span></span><br><span class="line"><span class="comment">         * inline表示行表达式分片算法，它使用groovy的表达式，支持单分片键，比如 t_user_$-&gt;&#123;uid%8&#125; 表示t_user表根据u_id%8分成8张表</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        configuration.setDefaultDatabaseShardingStrategy(</span><br><span class="line">                <span class="keyword">new</span> StandardShardingStrategyConfiguration(<span class="string">&quot;user_id&quot;</span>,<span class="string">&quot;inline&quot;</span>));</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 设置表的分片规则</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        configuration.setDefaultTableShardingStrategy(<span class="keyword">new</span> StandardShardingStrategyConfiguration(<span class="string">&quot;order_id&quot;</span>,<span class="string">&quot;order_inline&quot;</span>));</span><br><span class="line">        Properties props=<span class="keyword">new</span> Properties();</span><br><span class="line">        props.setProperty(<span class="string">&quot;algorithm-expression&quot;</span>,<span class="string">&quot;ds$&#123;user_id%2&#125;&quot;</span>); <span class="comment">//表示根据user_id取模得到目标表</span></span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 定义具体的分片规则算法，用于提供分库分表的算法规则</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        configuration.getShardingAlgorithms().put(<span class="string">&quot;inline&quot;</span>,<span class="keyword">new</span> ShardingSphereAlgorithmConfiguration(<span class="string">&quot;INLINE&quot;</span>,props));</span><br><span class="line">        Properties properties=<span class="keyword">new</span> Properties();</span><br><span class="line">        properties.setProperty(<span class="string">&quot;algorithm-expression&quot;</span>,<span class="string">&quot;t_order_$&#123;order_id%2&#125;&quot;</span>);</span><br><span class="line">        configuration.getShardingAlgorithms().put(<span class="string">&quot;order_inline&quot;</span>,<span class="keyword">new</span> ShardingSphereAlgorithmConfiguration(<span class="string">&quot;INLINE&quot;</span>,properties));</span><br><span class="line">        configuration.getKeyGenerators().put(<span class="string">&quot;snowflake&quot;</span>,<span class="keyword">new</span> ShardingSphereAlgorithmConfiguration(<span class="string">&quot;SNOWFLAKE&quot;</span>,getProperties()));</span><br><span class="line">        <span class="keyword">return</span> configuration;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> Properties <span class="title">getProperties</span><span class="params">()</span></span>&#123;</span><br><span class="line">        Properties properties=<span class="keyword">new</span> Properties();</span><br><span class="line">        properties.setProperty(<span class="string">&quot;worker-id&quot;</span>,<span class="string">&quot;123&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> properties;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//创建订单表的分片规则</span></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> ShardingTableRuleConfiguration <span class="title">getOrderTableRuleConfiguration</span><span class="params">()</span></span>&#123;</span><br><span class="line">        ShardingTableRuleConfiguration tableRule=<span class="keyword">new</span> ShardingTableRuleConfiguration(<span class="string">&quot;t_order&quot;</span>,<span class="string">&quot;ds$&#123;0..1&#125;.t_order_$&#123;0..1&#125;&quot;</span>);</span><br><span class="line">        tableRule.setKeyGenerateStrategy(<span class="keyword">new</span> KeyGenerateStrategyConfiguration(<span class="string">&quot;order_id&quot;</span>,<span class="string">&quot;snowflake&quot;</span>));</span><br><span class="line">        <span class="keyword">return</span> tableRule;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> DataSource <span class="title">getDataSource</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> ShardingSphereDataSourceFactory.createDataSource(createDataSourceMap(), Collections.singleton(createShardingRuleConfiguration()),<span class="keyword">new</span> Properties());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Main方法测试"><a href="#Main方法测试" class="headerlink" title="Main方法测试"></a>Main方法测试</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ExampleMain</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> SQLException </span>&#123;</span><br><span class="line">        DataSource dataSource=ShardingDatabasesAndTableConfiguration.getDataSource();</span><br><span class="line">        ExampleService exampleService=<span class="keyword">new</span> OrderServiceImpl(dataSource);</span><br><span class="line">        exampleService.initEnvironment();</span><br><span class="line">        exampleService.processSuccess();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Sharding-JDBC使用总结"><a href="#Sharding-JDBC使用总结" class="headerlink" title="Sharding-JDBC使用总结"></a>Sharding-JDBC使用总结</h2><p>从上述的案例来看，Sharding-JDBC相当于通过配置化的方式帮我们提供了分片规则的配置，但是基于原生的使用方式，配置起来比较复杂，我们可以直接集成到Spring-Boot中，使用起来会比较简洁。</p><h2 id="Spring-Boot集成Sharding-JDBC分片实战"><a href="#Spring-Boot集成Sharding-JDBC分片实战" class="headerlink" title="Spring Boot集成Sharding-JDBC分片实战"></a>Spring Boot集成Sharding-JDBC分片实战</h2><p>下面给大家演示一下在springboot应用中集成mybatis的情况下，如何实现分库分表的配置。</p><blockquote><p>项目代码参考： sharding-jdbc-spring-boot-example，项目结构如图7-8所示。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033606.png" alt="image-20210719150821495"></p><center>图7-8</center><p>其中，MybatisPlusGeneratorConfig，用来生成t_order表的dal、service、controller代码，由于代码是基于mybatis-plus生成，这里就不做过多描述了</p><h3 id="引入pom依赖"><a href="#引入pom依赖" class="headerlink" title="引入pom依赖"></a>引入pom依赖</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependencies</span>&gt;</span>    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span>        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-web<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span>        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>mysql<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mysql-connector-java<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>        <span class="tag">&lt;<span class="name">scope</span>&gt;</span>runtime<span class="tag">&lt;/<span class="name">scope</span>&gt;</span>    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span>        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span>    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span>        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.baomidou<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>mybatis-plus-generator<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span>    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span>        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.projectlombok<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lombok<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>        <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.18.12<span class="tag">&lt;/<span class="name">version</span>&gt;</span>    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span>        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.shardingsphere<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>shardingsphere-jdbc-core-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>        <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.0.0-alpha<span class="tag">&lt;/<span class="name">version</span>&gt;</span>    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span>    <span class="tag">&lt;<span class="name">dependency</span>&gt;</span>        <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.zaxxer<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>        <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>HikariCP<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>        <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.4.2<span class="tag">&lt;/<span class="name">version</span>&gt;</span>    <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span><span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></span><br></pre></td></tr></table></figure><h3 id="application-properties配置"><a href="#application-properties配置" class="headerlink" title="application.properties配置"></a>application.properties配置</h3><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment">#配置数据源名称spring.shardingsphere.datasource.names=ds-0,ds-1spring.shardingsphere.datasource.common.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.common.driver-class-name=com.mysql.jdbc.Driver# 分别配置多个数据源的详细信息spring.shardingsphere.datasource.ds-0.username=rootspring.shardingsphere.datasource.ds-0.password=123456spring.shardingsphere.datasource.ds-0.jdbc-url=jdbc:mysql://192.168.221.128:3306/shard01?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.datasource.ds-1.username=rootspring.shardingsphere.datasource.ds-1.password=123456spring.shardingsphere.datasource.ds-1.jdbc-url=jdbc:mysql://192.168.221.128:3306/shard02?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8# 配置数据库的分库策略，其中database-inline会在后面声明spring.shardingsphere.rules.sharding.default-database-strategy.standard.sharding-column=user_idspring.shardingsphere.rules.sharding.default-database-strategy.standard.sharding-algorithm-name=database-inline# 配置t_order表的分表策略，其中t-order-inline会在后面声明# 行表达式标识符可以使用 $&#123;...&#125; 或 $-&gt;&#123;...&#125;，但前者与 Spring 本身的属性文件占位符冲突，因此在 Spring 环境中使用行表达式标识符建议使用 $-&gt;&#123;...&#125;spring.shardingsphere.rules.sharding.tables.t_order.actual-data-nodes=ds-$-&gt;&#123;0..1&#125;.t_order_$-&gt;&#123;0..1&#125;spring.shardingsphere.rules.sharding.tables.t_order.table-strategy.standard.sharding-column=order_idspring.shardingsphere.rules.sharding.tables.t_order.table-strategy.standard.sharding-algorithm-name=t-order-inline# 配置order_id采用雪花算法生成全局id策略spring.shardingsphere.rules.sharding.tables.t_order.key-generate-strategy.column=order_idspring.shardingsphere.rules.sharding.tables.t_order.key-generate-strategy.key-generator-name=snowflake# 配置具体的分库分表规则spring.shardingsphere.rules.sharding.sharding-algorithms.database-inline.type=INLINEspring.shardingsphere.rules.sharding.sharding-algorithms.database-inline.props.algorithm-expression=ds-$-&gt;&#123;user_id % 2&#125;spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-inline.type=INLINEspring.shardingsphere.rules.sharding.sharding-algorithms.t-order-inline.props.algorithm-expression=t_order_$-&gt;&#123;order_id % 2&#125;spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-item-inline.type=INLINEspring.shardingsphere.rules.sharding.sharding-algorithms.t-order-item-inline.props.algorithm-expression=t_order_item_$-&gt;&#123;order_id % 2&#125;# 配置雪花算法spring.shardingsphere.rules.sharding.key-generators.snowflake.type=SNOWFLAKEspring.shardingsphere.rules.sharding.key-generators.snowflake.props.worker-id=123</span></span><br></pre></td></tr></table></figure><h3 id="增加逻辑代码"><a href="#增加逻辑代码" class="headerlink" title="增加逻辑代码"></a>增加逻辑代码</h3><p><strong>TOrderMapper</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Update(&quot;CREATE TABLE IF NOT EXISTS t_order (order_id BIGINT AUTO_INCREMENT, user_id INT NOT NULL, address_id BIGINT NOT NULL, status VARCHAR(50), PRIMARY KEY (order_id))&quot;)</span><span class="function"><span class="keyword">void</span> <span class="title">createTableIfNotExists</span><span class="params">()</span></span>;</span><br></pre></td></tr></table></figure><p><strong>TOrderServiceImpl</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Servicepublic</span> <span class="class"><span class="keyword">class</span> <span class="title">TOrderServiceImpl</span> <span class="keyword">extends</span> <span class="title">ServiceImpl</span>&lt;<span class="title">TOrderMapper</span>, <span class="title">TOrder</span>&gt; <span class="keyword">implements</span> <span class="title">ITOrderService</span> </span>&#123;    <span class="meta">@Autowired</span>    TOrderMapper orderMapper;    Random random=<span class="keyword">new</span> Random();    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">initEnvironment</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;        orderMapper.createTableIfNotExists();    &#125;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">processSuccess</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;        System.out.println(<span class="string">&quot;-------------- Process Success Begin ---------------&quot;</span>);        List&lt;Long&gt; orderIds = insertData();        System.out.println(<span class="string">&quot;-------------- Process Success Finish --------------&quot;</span>);    &#125;    <span class="function"><span class="keyword">private</span> List&lt;Long&gt; <span class="title">insertData</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;        System.out.println(<span class="string">&quot;---------------------------- Insert Data ----------------------------&quot;</span>);        List&lt;Long&gt; result = <span class="keyword">new</span> ArrayList&lt;&gt;(<span class="number">10</span>);        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">1</span>; i &lt;= <span class="number">10</span>; i++) &#123;            TOrder order = <span class="keyword">new</span> TOrder();            order.setUserId(random.nextInt(<span class="number">10000</span>));            order.setAddressId(i);            order.setStatus(<span class="string">&quot;INSERT_TEST&quot;</span>);            orderMapper.insert(order);            result.add(order.getOrderId());        &#125;        <span class="keyword">return</span> result;    &#125;&#125;</span><br></pre></td></tr></table></figure><h3 id="TOrderController"><a href="#TOrderController" class="headerlink" title="TOrderController"></a>TOrderController</h3><p>提供测试接口。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span><span class="meta">@RequestMapping(&quot;/t-order&quot;)</span><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TOrderController</span> </span>&#123;    <span class="meta">@Autowired</span>    ITOrderService orderService;    <span class="meta">@GetMapping</span>    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> <span class="keyword">throws</span> SQLException </span>&#123;        orderService.initEnvironment();        orderService.processSuccess();    &#125;&#125;</span><br></pre></td></tr></table></figure><h1 id="Sharding-JDBC的相关概念说明"><a href="#Sharding-JDBC的相关概念说明" class="headerlink" title="Sharding-JDBC的相关概念说明"></a>Sharding-JDBC的相关概念说明</h1><p>前面我们通过两种方式演示了Sharding-JDBC的分库分表功能的用法，其实，从这个层面来说，Sharding-JDBC相当于增强了JDBC驱动的功能，使得开发者只需要通过配置就可以轻松完成分库分表功能的实现。</p><p>在Sharding-JDBC中，有一些表的概念，需要给大家普及一下，逻辑表、真实表、分片键、数据节点、动态表、广播表、绑定表。</p><h2 id="逻辑表"><a href="#逻辑表" class="headerlink" title="逻辑表"></a>逻辑表</h2><p>逻辑表可以理解为数据库中的视图，是一张虚拟表。可以映射到一张物理表，也可以由多张物理表组成，这些物理表可以来自于不同的数据源。对于mysql, Hbase和ES，要组成一张逻辑表，只需要他们有相同含义的key即可。这个key在mysql中是主键，Hbase中是生成rowkey用的值，是ES中的key。</p><p>在前面的分库分表规则配置中，就有用到t_order这个逻辑表的定义，当我们针对t_order表操作时，会根据分片规则映射到实际的物理表进行相关事务操作，如图7-9所示，逻辑表会在SQL解析和路由时被替换成真实的表名。</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.tables.t_order.actual-data-nodes</span>=<span class="string">ds-$-&gt;&#123;0..1&#125;.t_order_$-&gt;&#123;0..1&#125;</span></span><br></pre></td></tr></table></figure><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033362.jpg" alt="img"></p><center>图7-9</center><h2 id="广播表"><a href="#广播表" class="headerlink" title="广播表"></a>广播表</h2><p>广播表也叫全局表，也就是它会存在于多个库中冗余，避免跨库查询问题。</p><p>比如省份、字典等一些基础数据，为了避免分库分表后关联表查询这些基础数据存在跨库问题，所以可以把这些数据同步给每一个数据库节点，这个就叫广播表，如图7-10所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033482.jpg" alt="img"></p><center>图7-10</center><p>在Sharding-JDBC中，配置方式如下</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 广播表, 其主节点是ds0spring.shardingsphere.sharding.broadcast-tables=t_configspring.shardingsphere.sharding.tables.t_config.actual-data-nodes=ds$-&gt;&#123;0&#125;.t_config</span></span><br></pre></td></tr></table></figure><h2 id="绑定表"><a href="#绑定表" class="headerlink" title="绑定表"></a>绑定表</h2><p>我们有些表的数据是存在逻辑的主外键关系的，比如订单表order_info，存的是汇总的商品数，商品金额；订单明细表order_detail，是每个商品的价格，个数等等。或者叫做从属关系，父表和子表的关系。他们之间会经常有关联查询的操作，如果父表的数据和子表的数据分别存储在不同的数据库，跨库关联查询也比较麻烦。所以我们能不能把父表和数据和从属于父表的数据落到一个节点上呢？</p><p>比如order_id=1001的数据在node1，它所有的明细数据也放到node1；order_id=1002的数据在node2，它所有的明细数据都放到node2，这样在关联查询的时候依然是在一个数据库，如图7-11所示</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033009.jpg" alt="img"></p><center>图7-11</center><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 绑定表规则，多组绑定规则使用数组形式配置spring.shardingsphere.rules.sharding.binding-tables=t_order,t_order_item</span></span><br></pre></td></tr></table></figure><p>如果存在多个绑定表规则，可以用数组的方式声明</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.binding-tables[0]</span>= <span class="string"># 绑定表规则列表spring.shardingsphere.rules.sharding.binding-tables[1]= # 绑定表规则列表spring.shardingsphere.rules.sharding.binding-tables[x]= # 绑定表规则列表</span></span><br></pre></td></tr></table></figure><h1 id="Sharding-JDBC中的分片策略"><a href="#Sharding-JDBC中的分片策略" class="headerlink" title="Sharding-JDBC中的分片策略"></a>Sharding-JDBC中的分片策略</h1><p>Sharding-JDBC内置了很多常用的分片策略，这些算法主要针对两个维度</p><ul><li>数据源分片</li><li>数据表分片</li></ul><p>Sharding-JDBC的分片策略包含了分片键和分片算法；</p><ul><li>分片键，用于分片的数据库字段，是将数据库(表)水平拆分的关键字段。例：将订单表中的订单主键的尾数取模分片，则订单主键为分片字段。 SQL中如果无分片字段，将执行全路由，性能较差。 除了对单分片字段的支持，ShardingSphere也支持根据多个字段进行分片。</li><li>分片算法，就是用来实现分片的计算规则。</li></ul><p>Sharding-JDBC提供内置了多种分片算法，包含四种类型分别是</p><ul><li>自动分片算法</li><li>标准分片算法</li><li>复合分片算法</li><li>Hinit分片算法</li></ul><h2 id="自动分片算法"><a href="#自动分片算法" class="headerlink" title="自动分片算法"></a>自动分片算法</h2><p>自动分片算法，就是根据我们配置的算法表达式完成数据的自动分发功能，在Sharding-JDBC中提供了五种自动分片算法</p><ul><li>取模分片算法</li><li>哈希取模分片算法</li><li>基于分片容量的范围分片算法</li><li>基于分片边界的范围分片算法</li><li>自动时间段分片算法</li></ul><h3 id="取模分片算法"><a href="#取模分片算法" class="headerlink" title="取模分片算法"></a>取模分片算法</h3><p>最基础的取模算法，它会根据分片字段的值和sharding-count进行取模运算，得到一个结果。</p><blockquote><p>ModShardingAlgorithm</p></blockquote><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># database-mod是自定义字符串名字spring.shardingsphere.rules.sharding.default-database-strategy.standard.sharding-algorithm-name=database-mod# MOD表示取模算法类型spring.shardingsphere.rules.sharding.sharding-algorithms.database-mod.type=MOD# 表示分片数量spring.shardingsphere.rules.sharding.sharding-algorithms.database-mod.props.sharding-count=2  </span></span><br></pre></td></tr></table></figure><h3 id="哈希取模分片算法"><a href="#哈希取模分片算法" class="headerlink" title="哈希取模分片算法"></a>哈希取模分片算法</h3><p>和取模算法相同，唯一的区别是针对分片键得到哈希值之后再取模</p><blockquote><p>HashModShardingAlgorithm</p></blockquote><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># database-mod是自定义字符串名字spring.shardingsphere.rules.sharding.default-database-strategy.standard.sharding-algorithm-name=database-hash-modspring.shardingsphere.rules.sharding.sharding-algorithms.database-hash-mod.type=HASH_MODspring.shardingsphere.rules.sharding.sharding-algorithms.database-hash-mod.props.sharding-count=2</span></span><br></pre></td></tr></table></figure><h3 id="分片容量范围"><a href="#分片容量范围" class="headerlink" title="分片容量范围"></a>分片容量范围</h3><p>分片容量范围，简单理解就是按照某个字段的数值范围进行分片，比如存在下面这样一个需求，怎么配置呢？</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(0~199)保存到表0[200~399]保存到表1[400~599)保存到表2</span><br></pre></td></tr></table></figure><blockquote><p>参考7.2.3章节中的方式，构建一个t_order_colume_range表，使用mybatis-plus生成相关代码，如图7-12所示</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033546.png" alt="image-20210720174801870"></p><center>图7-12</center><p>添加如下配置，通过<code>spring.profiles.active=volumn-range</code>来激活不同的配置信息。</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">server.port</span>=<span class="string">8080spring.mvc.view.prefix=classpath:/templates/spring.mvc.view.suffix=.htmlspring.shardingsphere.datasource.names=ds-0spring.shardingsphere.datasource.common.type=com.zaxxer.hikari.HikariDataSourcespring.shardingsphere.datasource.common.driver-class-name=com.mysql.jdbc.Driverspring.shardingsphere.datasource.ds-0.username=rootspring.shardingsphere.datasource.ds-0.password=123456spring.shardingsphere.datasource.ds-0.jdbc-url=jdbc:mysql://192.168.221.128:3306/shard01?serverTimezone=UTC&amp;useSSL=false&amp;useUnicode=true&amp;characterEncoding=UTF-8spring.shardingsphere.rules.sharding.tables.t_order_volume_range.actual-data-nodes=ds-0.t_order_volume_range_$-&gt;&#123;0..2&#125;spring.shardingsphere.rules.sharding.tables.t_order_volume_range.table-strategy.standard.sharding-column=user_idspring.shardingsphere.rules.sharding.tables.t_order_volume_range.table-strategy.standard.sharding-algorithm-name=t-order-volume-rangespring.shardingsphere.rules.sharding.tables.t_order_volume_range.key-generate-strategy.column=order_idspring.shardingsphere.rules.sharding.tables.t_order_volume_range.key-generate-strategy.key-generator-name=snowflakespring.shardingsphere.rules.sharding.sharding-algorithms.t-order-volume-range.type=VOLUME_RANGE#最小的范围，0-200spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-volume-range.props.range-lower=200#最大的范围，600 ，如果超过600，会报错spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-volume-range.props.range-upper=600# 表示每张表的容量为200spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-volume-range.props.sharding-volume=200spring.shardingsphere.rules.sharding.key-generators.snowflake.type=SNOWFLAKEspring.shardingsphere.rules.sharding.key-generators.snowflake.props.worker-id=123</span></span><br></pre></td></tr></table></figure><h3 id="基于分片边界的范围分片算法"><a href="#基于分片边界的范围分片算法" class="headerlink" title="基于分片边界的范围分片算法"></a>基于分片边界的范围分片算法</h3><p>前面讲的分片容量范围分片，是一个均衡的分片方法，如果存在不均衡的场景，比如下面这种情况</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(0~1000)保存到表0[1000~20000]保存到表1[20000~300000)保存到表2[300000~无穷大)保存到表3</span><br></pre></td></tr></table></figure><p>我们就可以用到基于分片边界的范围分片算法来完成，配置方法如下</p><blockquote><p>BoundaryBasedRangeShardingAlgorithm</p></blockquote><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># BOUNDARY_RANGE 表示分片算法类型spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-boundary-range.type=BOUNDARY_RANGE# 分片的范围边界，多个范围边界以逗号分隔spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-boundary-range.props.sharding-ranges=1000,20000,300000</span></span><br></pre></td></tr></table></figure><h3 id="自动时间段分片算法"><a href="#自动时间段分片算法" class="headerlink" title="自动时间段分片算法"></a>自动时间段分片算法</h3><blockquote><p>IntervalShardingAlgorithm</p></blockquote><p>根据时间段进行分片，如果想实现如下功能</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(1970-01-01 23:59:59 ~ 2020-01-01 23:59:59) 表0[2020-01-01 23:59:59 ~ 2021-01-01 23:59:59) 表1[2021-01-01 23:59:59 ~ 2021-02-01 23:59:59) 表2[2022-01-01 23:59:59 ~ 2024-01-01 23:59:59) 表3</span><br></pre></td></tr></table></figure><p>配置方法如下，表示从2010-01-01到2021-01-01这个时间区间内的数据，按照每一年划分一个表</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.tables.t_order_volume_range.actual-data-nodes</span>=<span class="string">ds-0.t_order_volume_range_$-&gt;&#123;0..2&#125;spring.shardingsphere.rules.sharding.tables.t_order_volume_range.table-strategy.standard.sharding-column=create_datespring.shardingsphere.rules.sharding.tables.t_order_volume_range.table-strategy.standard.sharding-algorithm-name=t-order-auto-intervalspring.shardingsphere.rules.sharding.tables.t_order_volume_range.key-generate-strategy.column=order_idspring.shardingsphere.rules.sharding.tables.t_order_volume_range.key-generate-strategy.key-generator-name=snowflakespring.shardingsphere.rules.sharding.sharding-algorithms.t-order-auto-interval.type=AUTO_INTERVAL# 分片的起始时间范围，时间戳格式：yyyy-MM-dd HH:mm:ssspring.shardingsphere.rules.sharding.sharding-algorithms.t-order-auto-interval.props.datetime-lower=2010-01-01 23:59:59# 分片的结束时间范围，时间戳格式：yyyy-MM-dd HH:mm:ssspring.shardingsphere.rules.sharding.sharding-algorithms.t-order-auto-interval.props.datetime-upper=2021-01-01 23:59:59# 单一分片所能承载的最大时间，单位：秒，下面的数字表示1年spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-auto-interval.props.sharding-seconds=&#x27;31536000&#x27;</span></span><br></pre></td></tr></table></figure><p>需要注意，如果是基于时间段来分片，那么在查询的时候不能使用函数查询，否则会导致全路由。</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">select</span> <span class="operator">*</span> <span class="keyword">from</span> t_order <span class="keyword">where</span> to_date(<span class="keyword">create</span>,<span class="string">&#x27;yyyy-mm-dd&#x27;</span>)<span class="operator">=</span><span class="string">&#x27;&#x27;</span></span><br></pre></td></tr></table></figure><h2 id="标准分片算法"><a href="#标准分片算法" class="headerlink" title="标准分片算法"></a>标准分片算法</h2><p>标准分片策略（<code>StandardShardingStrategy</code>），它只支持对单个分片健（字段）为依据的分库分表，Sharding-JDBC提供了两种算法实现</p><h3 id="行表达式分片算法"><a href="#行表达式分片算法" class="headerlink" title="行表达式分片算法"></a>行表达式分片算法</h3><blockquote><p>类型：INLINE</p></blockquote><p>使用 Groovy 的表达式，提供对 SQL 语句中的 <code>=</code> 和 <code>IN</code> 的分片操作支持，只支持单分片键。 对于简单的分片算法，可以通过简单的配置使用，从而避免繁琐的 Java 代码开发，如: <code>t_user_$-&gt;&#123;u_id % 8&#125;</code> 表示 <code>t_user</code> 表根据 <code>u_id</code> 模 8，而分成 8 张表，表名称为 <code>t_user_0</code> 到 <code>t_user_7</code></p><p><strong>配置方法如下。</strong></p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.sharding-algorithms.database-inline.type</span>=<span class="string">INLINEspring.shardingsphere.rules.sharding.sharding-algorithms.database-inline.props.algorithm-expression=ds-$-&gt;&#123;user_id % 2&#125;spring.shardingsphere.rules.sharding.sharding-algorithms.t-order-inline.type=INLINEspring.shardingsphere.rules.sharding.sharding-algorithms.t-order-inline.props.algorithm-expression=t_order_$-&gt;&#123;order_id % 2&#125;</span></span><br></pre></td></tr></table></figure><h3 id="时间范围分片算法"><a href="#时间范围分片算法" class="headerlink" title="时间范围分片算法"></a>时间范围分片算法</h3><p>和前面自动分片算法的自动时间段分片算法类似。</p><p>类型：INTERVAL</p><p>可配置属性：</p><table><thead><tr><th align="left"><em>属性名称</em></th><th align="left"><em>数据类型</em></th><th align="left"><em>说明</em></th><th align="left"><em>默认值</em></th></tr></thead><tbody><tr><td align="left">datetime-pattern</td><td align="left">String</td><td align="left">分片键的时间戳格式，必须遵循 Java DateTimeFormatter 的格式。例如：yyyy-MM-dd HH:mm:ss</td><td align="left">-</td></tr><tr><td align="left">datetime-lower</td><td align="left">String</td><td align="left">时间分片下界值，格式与 <code>datetime-pattern</code> 定义的时间戳格式一致</td><td align="left">-</td></tr><tr><td align="left">datetime-upper (?)</td><td align="left">String</td><td align="left">时间分片上界值，格式与 <code>datetime-pattern</code> 定义的时间戳格式一致</td><td align="left">当前时间</td></tr><tr><td align="left">sharding-suffix-pattern</td><td align="left">String</td><td align="left">分片数据源或真实表的后缀格式，必须遵循 Java DateTimeFormatter 的格式，必须和 <code>datetime-interval-unit</code> 保持一致。例如：yyyyMM</td><td align="left">-</td></tr><tr><td align="left">datetime-interval-amount (?)</td><td align="left">int</td><td align="left">分片键时间间隔，超过该时间间隔将进入下一分片</td><td align="left">1</td></tr><tr><td align="left">datetime-interval-unit (?)</td><td align="left">String</td><td align="left">分片键时间间隔单位，必须遵循 Java ChronoUnit 的枚举值。例如：MONTHS</td><td align="left"></td></tr></tbody></table><h2 id="复合分片算法"><a href="#复合分片算法" class="headerlink" title="复合分片算法"></a>复合分片算法</h2><p><strong>使用场景</strong>：SQL 语句中有<code>&gt;</code>，<code>&gt;=</code>, <code>&lt;=</code>，<code>&lt;</code>，<code>=</code>，<code>IN</code> 和 <code>BETWEEN AND</code> 等操作符，不同的是复合分片策略支持对多个分片健操作。</p><p>Sharding-JDBC内置了一种复合分片算法的实现。</p><blockquote><p>类型： COMPLEX_INLINE，实现类：ComplexInlineShardingAlgorithm </p></blockquote><table><thead><tr><th align="left"><em>属性名称</em></th><th align="left"><em>数据类型</em></th><th align="left"><em>说明</em></th><th align="left"><em>默认值</em></th></tr></thead><tbody><tr><td align="left">sharding-columns (?)</td><td align="left">String</td><td align="left">分片列名称，多个列用逗号分隔。如不配置无法则不能校验</td><td align="left">-</td></tr><tr><td align="left">algorithm-expression</td><td align="left">String</td><td align="left">分片算法的行表达式</td><td align="left">-</td></tr><tr><td align="left">allow-range-query-with-inline-sharding (?)</td><td align="left">boolean</td><td align="left">是否允许范围查询。注意：范围查询会无视分片策略，进行全路由</td><td align="left"></td></tr></tbody></table><blockquote><p>目前版本还未发布（在github仓库中已经提供了实现），如果要实现符合分片算法，需要自己手动实现。</p></blockquote><h2 id="自定义分片算法"><a href="#自定义分片算法" class="headerlink" title="自定义分片算法"></a>自定义分片算法</h2><p>除了默认提供了分片算法之外，我们可以根据实际需求自定义分片算法，Sharding-JDBC同样提供了几种类型的扩展实现</p><ul><li>标准分片算法</li><li>复合分片算法</li><li>Hinit分片策略</li><li>不分片策略</li></ul><p>分片策略的接口定义如下，它有四个子类，分别对应上面四种分片策略，我们可以通过继承不同的分片策略完成自定义分片策略的扩展。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">ShardingStrategy</span> </span>&#123;    <span class="function">Collection&lt;String&gt; <span class="title">getShardingColumns</span><span class="params">()</span></span>;    <span class="function">ShardingAlgorithm <span class="title">getShardingAlgorithm</span><span class="params">()</span></span>;    <span class="function">Collection&lt;String&gt; <span class="title">doSharding</span><span class="params">(Collection&lt;String&gt; var1, Collection&lt;ShardingConditionValue&gt; var2, ConfigurationProperties var3)</span></span>;&#125;</span><br></pre></td></tr></table></figure><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033704.png" alt="image-20210722160919076"></p><center>图7-13</center><h3 id="自定义标准分片算法"><a href="#自定义标准分片算法" class="headerlink" title="自定义标准分片算法"></a>自定义标准分片算法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">StandardModTableShardAlgorithm</span> <span class="keyword">implements</span> <span class="title">StandardShardingAlgorithm</span>&lt;<span class="title">Long</span>&gt; </span>&#123;    <span class="keyword">private</span> Properties props=<span class="keyword">new</span> Properties();    <span class="comment">/**     * 用于处理=和IN的分片。     * <span class="doctag">@param</span> collection 表示目标分片的集合     * <span class="doctag">@param</span> preciseShardingValue 逻辑表相关信息     * <span class="doctag">@return</span>     */</span>    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> String <span class="title">doSharding</span><span class="params">(Collection&lt;String&gt; collection, PreciseShardingValue&lt;Long&gt; preciseShardingValue)</span> </span>&#123;        <span class="keyword">for</span>(String name:collection)&#123;            <span class="comment">//根据order_id的值进行取模，得到一个目标值            if(name.endsWith(String.valueOf(preciseShardingValue.getValue()%4)))&#123;                return name;            &#125;        &#125;        throw new UnsupportedOperationException();    &#125;    /**     * 用于处理BETWEEN AND分片，如果不配置RangeShardingAlgorithm，SQL中的BETWEEN AND将按照全库路由处理     * @param collection     * @param rangeShardingValue     * @return     */    @Override    public Collection&lt;String&gt; doSharding(Collection&lt;String&gt; collection, RangeShardingValue&lt;Long&gt; rangeShardingValue) &#123;        Collection&lt;String&gt; result=new LinkedHashSet&lt;&gt;(collection.size());        for(Long i=rangeShardingValue.getValueRange().lowerEndpoint();i&lt;=rangeShardingValue.getValueRange().upperEndpoint();i++)&#123;            for(String name:collection)&#123;                if(name.endsWith(String.valueOf(i%4)))&#123;                    result.add(name);                &#125;            &#125;        &#125;        return result;    &#125;    /**     * 初始化对象的时候调用的方法     */    @Override    public void init() &#123;    &#125;    /**     * 对应分片算法（sharding-algorithms）的类型     * @return     */    @Override    public String getType() &#123;        return &quot;STANDARD_MOD&quot;;    &#125;    @Override    public Properties getProps() &#123;        return this.props;    &#125;    /**     * 获取分片相关属性     * @param properties     */    @Override    public void setProps(Properties properties) &#123;        this.props=properties;    &#125;&#125;</span></span><br></pre></td></tr></table></figure><h3 id="通过SPI机制进行扩展"><a href="#通过SPI机制进行扩展" class="headerlink" title="通过SPI机制进行扩展"></a>通过SPI机制进行扩展</h3><ul><li><p>在resource目录下创建META-INF/service/org.apache.shardingsphere.sharding.spi.ShardingAlgorithm文件</p></li><li><p>把自定义标准分片算法的全路径写如到上述文件中</p></li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">com.gupao.sharding.example.StandardModTableShardAlgorithm</span><br></pre></td></tr></table></figure><h3 id="增加application-custom-standard-properties文件"><a href="#增加application-custom-standard-properties文件" class="headerlink" title="增加application-custom-standard.properties文件"></a>增加application-custom-standard.properties文件</h3><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">spring.shardingsphere.rules.sharding.tables.t_order_standard.actual-data-nodes</span>=<span class="string">ds-0.t_order_standard_$-&gt;&#123;0..3&#125;spring.shardingsphere.rules.sharding.tables.t_order_standard.table-strategy.standard.sharding-column=order_idspring.shardingsphere.rules.sharding.tables.t_order_standard.table-strategy.standard.sharding-algorithm-name=standard-modspring.shardingsphere.rules.sharding.tables.t_order_standard.key-generate-strategy.column=order_idspring.shardingsphere.rules.sharding.tables.t_order_standard.key-generate-strategy.key-generator-name=snowflakespring.shardingsphere.rules.sharding.sharding-algorithms.standard-mod.type=STANDARD_MODspring.shardingsphere.rules.sharding.sharding-algorithms.standard-mod.props.algorithm-class-name=com.gupao.sharding.example.StandardModTableShardAlgorithm</span></span><br></pre></td></tr></table></figure><p>其中，STANDARD_MOD是我们自定义的取模分片算法的类型。</p><h3 id="表以及代码生成"><a href="#表以及代码生成" class="headerlink" title="表以及代码生成"></a>表以及代码生成</h3><p>把t_order表复制一张t_order_standard，通过mybatis-plus生成业务代码。</p><p>代码工程详见： <strong>sharding-jdbc-springboot-example</strong></p><h1 id="关于Java中的SPI机制"><a href="#关于Java中的SPI机制" class="headerlink" title="关于Java中的SPI机制"></a>关于Java中的SPI机制</h1><p>SPI 的全名为 Service Provider Interface，它的核心思想是中间件中定义标准，然后使用者可以在这个标准上实现自定义扩展，举个比较常见的例子，就是JDBC驱动。 Java官方只提供了JDBC驱动的接口</p><p><strong>java.sql.Driver</strong></p><p>然后各大数据库厂商，如Mysql、Oracle都会基于这个接口定义不同数据库的连接实现，然后使用java语言的开发者不需要关心不同数据库的具体配置，只需要集成相关的依赖包以及配置相关驱动，Java程序就能自动匹配到相关的实现完成数据库连接。</p><p>这种思想在很多地方都有使用，比如Spring中的SpringFactoriesLoader、Dubbo中的SPI思想、Sentinel中的SPI思想等等。很多中间件中使用的SPI都不是Java原生的SPI，而是基于这种思想优化过后的，后续我们会再讲到。</p><p>下面来看一下SPI如何使用</p><h2 id="SPI的使用规则"><a href="#SPI的使用规则" class="headerlink" title="SPI的使用规则"></a>SPI的使用规则</h2><p>SPI的使用如图7-14所示，必须遵循以下约定。</p><p>1、在工程的META-INF/services/目录下，以接口的全限定名作为文件名，文件内容为实现接口的服务类；</p><p>2、使用ServiceLoader动态加载META-INF/services下的实现类；</p><p>3、接口的实现类需含无参构造函数；（因为类默认包含无参构造函数，如果我们没有重载构造函数所以此处可忽略）</p><p>![img](E:\教研-课件\vip课程\第五轮\03 高并发架构设计之存储篇（Mic老师）\07 ShardingSphere分库分表应用实战\07 ShardingSphere分库分表应用实战.assets\20180329110040213)</p><center>图7-14</center><h2 id="SPI的使用实战"><a href="#SPI的使用实战" class="headerlink" title="SPI的使用实战"></a>SPI的使用实战</h2><p>首先创建一个普通的maven项目，目录结构如下。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110202033895.png" alt="image-20210722222355032"></p><center>图7-15</center><h3 id="Parser"><a href="#Parser" class="headerlink" title="Parser"></a>Parser</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">interface</span> <span class="title">Parser</span> </span>&#123;     <span class="comment">//解析文件方法    String parse(File file) throws Exception;    //文件类型    String getType();&#125;</span></span><br></pre></td></tr></table></figure><p>定义如下两个实现类</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JsonParser</span> <span class="keyword">implements</span> <span class="title">Parser</span> </span>&#123;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> String <span class="title">parse</span><span class="params">(File file)</span> <span class="keyword">throws</span> Exception </span>&#123;        <span class="keyword">return</span> <span class="string">&quot;我是Json格式解析&quot;</span>;    &#125;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> String <span class="title">getType</span><span class="params">()</span> </span>&#123;        <span class="keyword">return</span> ParserConstant.JSON_PARSER;    &#125;&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">XmlParser</span> <span class="keyword">implements</span> <span class="title">Parser</span> </span>&#123;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> String <span class="title">parse</span><span class="params">(File file)</span> <span class="keyword">throws</span> Exception </span>&#123;        <span class="keyword">return</span> <span class="string">&quot;我是XML格式解析&quot;</span>;    &#125;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> String <span class="title">getType</span><span class="params">()</span> </span>&#123;        <span class="keyword">return</span> ParserConstant.XML_PARSER;    &#125;&#125;</span><br></pre></td></tr></table></figure><h3 id="ParserConstant"><a href="#ParserConstant" class="headerlink" title="ParserConstant"></a>ParserConstant</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ParserConstant</span> </span>&#123;    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">static</span> String XML_PARSER=<span class="string">&quot;xml&quot;</span>;    <span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">static</span> String JSON_PARSER=<span class="string">&quot;json&quot;</span>;&#125;</span><br></pre></td></tr></table></figure><h3 id="ParserManager"><a href="#ParserManager" class="headerlink" title="ParserManager"></a>ParserManager</h3><p>定义一个解析管理器</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ParserManager</span> </span>&#123;    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> ConcurrentHashMap&lt;String,Parser&gt; registeredParsers = <span class="keyword">new</span> ConcurrentHashMap&lt;&gt;();    <span class="keyword">static</span>&#123;        loadInitialParser();  <span class="comment">//加载扩展实现        initDefaultStrategy();  //加载默认实现    &#125;    private static void loadInitialParser()&#123;        ServiceLoader&lt;Parser&gt; parserServiceLoader=ServiceLoader.load(Parser.class);        Iterator&lt;Parser&gt; iterator=parserServiceLoader.iterator();        while(iterator.hasNext())&#123;            Parser parser=iterator.next();            registeredParsers.put(parser.getType(),parser);        &#125;    &#125;    private static void initDefaultStrategy()&#123;        Parser jsonParser=new JsonParser();        Parser xmlParser=new XmlParser();        registeredParsers.put(jsonParser.getType(),jsonParser);        registeredParsers.put(xmlParser.getType(),xmlParser);    &#125;    public static Parser getParser(String key)&#123;        return registeredParsers.get(key);    &#125;&#125;</span></span><br></pre></td></tr></table></figure><p>把上述项目打包 maven install到本地。</p><h2 id="其他项目依赖Parser"><a href="#其他项目依赖Parser" class="headerlink" title="其他项目依赖Parser"></a>其他项目依赖Parser</h2><p>上述项目打包之后安装到本地，在其他项目中，依赖上述项目</p><p>演示项目是： sharding-jdbc-springboot-example</p><ul><li>依赖pom</li></ul><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.example<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>file-parse-processor<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><ul><li>定义扩展实现</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TxtParser</span> <span class="keyword">implements</span> <span class="title">Parser</span> </span>&#123;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> String <span class="title">parse</span><span class="params">(File file)</span> <span class="keyword">throws</span> Exception </span>&#123;        <span class="keyword">return</span> <span class="string">&quot;txt文件解析结果&quot;</span>;    &#125;    <span class="meta">@Override</span>    <span class="function"><span class="keyword">public</span> String <span class="title">getType</span><span class="params">()</span> </span>&#123;        <span class="keyword">return</span> <span class="string">&quot;txt&quot;</span>;    &#125;&#125;</span><br></pre></td></tr></table></figure><ul><li><p>配置SPI扩展点</p><ul><li><p>在resource目录下创建 META-INF/services/org.example.Parser</p></li><li><p>把自定义实现类写的全路径写入该文件中</p></li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">com.gupao.sharding.example.TxtParser</span><br></pre></td></tr></table></figure></li><li><p>定义controller进行测试</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestControllerpublic</span> <span class="class"><span class="keyword">class</span> <span class="title">SPIController</span> </span>&#123;    <span class="meta">@GetMapping(&quot;/spi&quot;)</span>    <span class="function"><span class="keyword">public</span> String <span class="title">parser</span><span class="params">()</span></span>&#123;        <span class="keyword">try</span> &#123;            <span class="keyword">return</span> ParserManager.getParser(<span class="string">&quot;txt&quot;</span>).parse(<span class="keyword">new</span> File(<span class="string">&quot;&quot;</span>));        &#125; <span class="keyword">catch</span> (Exception e) &#123;            <span class="keyword">return</span> <span class="string">&quot;异常&quot;</span>;        &#125;    &#125;&#125;</span><br></pre></td></tr></table></figure></li></ul><p>通过url访问测试，可以发现ParserManager可以调用到我们自己扩展实现的解析器。</p><h1 id="分布式序列算法"><a href="#分布式序列算法" class="headerlink" title="分布式序列算法"></a>分布式序列算法</h1><p>Sharding-JDBC中默认提供了两种分布式序列算法</p><ul><li>UUID</li><li>雪花算法</li></ul><p>这两种在前面都说过，就不在重复说明。</p><p>分布式序列算法是为了保证水平分表之后，保证全局唯一性，关于雪花算法的定义如下。</p><p>类型：SNOWFLAKE</p><p><strong>可配置属性：</strong></p><table><thead><tr><th align="left"><em>属性名称</em></th><th align="left"><em>数据类型</em></th><th align="left"><em>说明</em></th><th align="left"><em>默认值</em></th></tr></thead><tbody><tr><td align="left">worker-id (?)</td><td align="left">long</td><td align="left">工作机器唯一标识</td><td align="left">0</td></tr><tr><td align="left">max-vibration-offset (?)</td><td align="left">int</td><td align="left">最大抖动上限值，范围[0, 4096)。注：若使用此算法生成值作分片值，建议配置此属性。此算法在不同毫秒内所生成的 key 取模 2^n (2^n一般为分库或分表数) 之后结果总为 0 或 1。为防止上述分片问题，建议将此属性值配置为 (2^n)-1</td><td align="left">1</td></tr><tr><td align="left">max-tolerate-time-difference-milliseconds (?)</td><td align="left">long</td><td align="left">最大容忍时钟回退时间，单位：毫秒</td><td align="left"></td></tr></tbody></table>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> ShardingSphere </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> 分库分表 </tag>
            
            <tag> ShardingSphere </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>千万级并发架构下，关系型数据库应该如何优化？大厂是如何做分库分表的！</title>
      <link href="/posts/3654917940/"/>
      <url>/posts/3654917940/</url>
      
        <content type="html"><![CDATA[<p>   随着互联网的高速发展，带来了海量数据存储的问题，比如像物联网行业，每个智能终端每天进行数据采集和上报，每天能够产几千万甚至上亿的数据。在互联网电商行业，或者一些O2O平台，每天也能产生上千万的订单数据，这些量级的数据在传统的关系型数据库中已经无法支撑了，那么如何解决海量数据存储和计算等问题，在业内引入了分布式存储和分布式计算等解决方案，特别是NoSql的生态，我在前面讲过的k-v数据库、文档数据库、图形数据库等，都是比较主流的分布式数据库解决方案。</p><p> 即便如此，关系型数据库仍然有它不可替代的特性，所以关系型数据库仍然是核心业务的基础数据平台，因此关系型数据库必然会面临数据量日益增长带来的海量数据处理问题。</p><h1 id="Mysql数据库海量数据带来的性能问题"><a href="#Mysql数据库海量数据带来的性能问题" class="headerlink" title="Mysql数据库海量数据带来的性能问题"></a>Mysql数据库海量数据带来的性能问题</h1><p>目前几乎所有的互联网公司都是采用mysql这个开源数据库，根据阿里巴巴的《Java开发手册》上提到的，当单表行数超过500W行或者单表数据容量超过2G时，就会对查询性能产生较大影响，这个时候建议对表进行优化。</p><blockquote><p>其实500W数据只是一个折中的值，具体的数据量和数据库服务器配置以及mysql配置有关，因为Mysql为了提升性能，会把表的索引装载到内存，innodb_buffer_pool_size 足够的情况下，mysql能把全部数据加载进内存，查询不会有问题。</p><p>但是，当单表数据库到达某个量级的上限时，导致内存无法存储其索引，使得之后的 SQL 查询会产生磁盘 IO，从而导致性能下降。当然，这个还有具体的表结构的设计有关，最终导致的问题都是内存限制，这里，增加硬件配置，可能会带来立竿见影的性能提升。</p></blockquote><blockquote><p><strong>innodb_buffer_pool_size 包含数据缓存、索引缓存等。</strong></p></blockquote><h2 id="Mysql常见的优化手段"><a href="#Mysql常见的优化手段" class="headerlink" title="Mysql常见的优化手段"></a>Mysql常见的优化手段</h2><p>当然，我们首先要进行的优化是基于Mysql本身的优化，常见的优化手段有：</p><ul><li>增加索引，索引是直观也是最快速优化检索效率的方式。</li><li>基于Sql语句的优化，比如最左匹配原则，用索引字段查询、降低sql语句的复杂度等</li><li>表的合理设计，比如符合三范式、或者为了一定的效率破坏三范式设计等</li><li>数据库参数优化，比如并发连接数、数据刷盘策略、调整缓存大小</li><li>数据库服务器硬件升级</li><li>mysql大家主从复制方案，实现读写分离</li></ul><p>这些常见的优化手段，在数据量较小的情况下效果非常好，但是数据量到达一定瓶颈时，常规的优化手段已经解决不了实际问题，那怎么办呢？</p><h2 id="大数据表优化方案"><a href="#大数据表优化方案" class="headerlink" title="大数据表优化方案"></a>大数据表优化方案</h2><p>对于大数据表的优化最直观的方式就是减少单表数据量，所以常见的解决方案是：</p><ul><li><p>分库分表，大表拆小表。</p></li><li><p>冷热数据分离，所谓的冷热数据，其实就是根据访问频次来划分的，访问频次较多的数据是热数据，访问频次少的数据是冷数据。冷热数据分离就是把这两类数据分离到不同的表中，从而减少热数据表的大小。</p><p>其实在很多地方大家都能看到类似的实现，比如去一些网站查询订单或者交易记录，默认只允许查询1到3个月，3个月之前的数据，基本上大家都很少关心，访问频次较少，所以可以把3个月之前的数据保存到冷库中。</p></li><li><p>历史数据归档，简单来说就是把时间比较久远的数据分离出来存档，保证实时库的数据的有效生命周期。</p></li></ul><p>其实这些解决方案都是属于偏业务类的方案，并不完全是技术上的方案，所以在实施的时候，需要根据业务的特性来选择合适的方式。</p><h1 id="详解分库分表"><a href="#详解分库分表" class="headerlink" title="详解分库分表"></a>详解分库分表</h1><p>分库分表是非常常见针对单个数据表数据量过大的优化方式，它的核心思想是把一个大的数据表拆分成多个小的数据表，这个过程也叫（数据分片），它的本质其实有点类似于传统数据库中的分区表，比如mysql和oracle都支持分区表机制。</p><p>分库分表是一种水平扩展手段，每个分片上包含原来总的数据集的一个子集。这种分而治之的思想在技术中很常见，比如多CPU、分布式架构、分布式缓存等等，像前面我们讲redis cluster集群时，slot槽的分配就是一种数据分片的思想。</p><p>如图6-1所示，数据库分库分表一般有两种实现方式：</p><ul><li>水平拆分，基于表或字段划分，表结构不同，有单库的分表，也有多库的分库。</li><li>垂直拆分，基于数据划分，表结构相同，数据不同，也有同库的水平切分和多库的切分。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354359.jpg" alt="img"></p><center>图6-1</center><h2 id="垂直拆分"><a href="#垂直拆分" class="headerlink" title="垂直拆分"></a>垂直拆分</h2><p>垂直拆分有两种，一种是单库的垂直拆分，另一种是多个数据库的垂直拆分。</p><h3 id="单库垂直分表"><a href="#单库垂直分表" class="headerlink" title="单库垂直分表"></a>单库垂直分表</h3><p>单个表的字段数量建议控制在20~50个之间，之所以建议做这个限制，是因为如果字段加上数据累计的长度超过一个阈值后，数据就不是存储在一个页上，就会产生分页的问题，而这个问题会导致查询性能下降。</p><p>所以如果当某些业务表的字段过多时，我们一般会拆去垂直拆分的方式，把一个表的字段拆分成多个表，如图6-2所示，把一个订单表垂直拆分成一个订单主表和一个订单明细表。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354422.png" alt="image-20210714220827072"></p><center>图6-2</center><blockquote><p>在Innodb引擎中，单表字段最大限制为1017</p><p>参考： <a href="https://dev.mysql.com/doc/mysql-reslimits-excerpt/5.6/en/column-count-limit.html">https://dev.mysql.com/doc/mysql-reslimits-excerpt/5.6/en/column-count-limit.html</a></p></blockquote><h3 id="多库垂直分表"><a href="#多库垂直分表" class="headerlink" title="多库垂直分表"></a>多库垂直分表</h3><p>多库垂直拆分实际上就是把存在于一个库中的多个表，按照一定的纬度拆分到多个库中，如图6-3所示。这种拆分方式在微服务架构中也是很常见，基本上会按照业务纬度拆分数据库，同样该纬度也会影响到微服务的拆分，基本上服务和数据库是独立的。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354570.png" alt="image-20210714223358398"></p><center>图6-3</center><p>多库垂直拆分最大的好处就是实现了业务数据的隔离。其次就是缓解了请求的压力，原本所有的表在一个库的时候，所有请求都会打到一个数据库服务器上，通过数据库的拆分，可以分摊掉请求，在这个层面上提升了数据库的吞吐能力。</p><h2 id="水平拆分"><a href="#水平拆分" class="headerlink" title="水平拆分"></a>水平拆分</h2><p>垂直拆分的方式并没有解决单表数据量过大的问题，所以我们还需要通过水平拆分的方式把大表数据做数据分片。</p><p>水平切分也可以分成两种，一种是单库的，一种是多库的。</p><h3 id="单库水平分表"><a href="#单库水平分表" class="headerlink" title="单库水平分表"></a>单库水平分表</h3><p>如图6-4所示，表示把一张有10000条数据的用户表，按照某种规则拆分成了4张表，每张表的数据量是2500条。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354179.png" alt="image-20210714225317172"></p><center>图6-4</center><p>两个案例：</p><p><strong>银行的交易流水表</strong>，所有进出的交易都需要登记这张表，因为绝大部分时候客户都是查询当天的交易和一个月以内的交易数据，所以我们根据使用频率把这张表拆分成三张表：</p><p>当天表：只存储当天的数据。</p><p>当月表：我们在夜间运行一个定时任务，前一天的数据，全部迁移到当月表。用的是insert into select，然后delete。</p><p>历史表：同样是通过定时任务，把登记时间超过30天的数据，迁移到history历史表（历史表的数据非常大，我们按照月度，每个月建立分区）。</p><p><strong>费用表</strong>：消费金融公司跟线下商户合作，给客户办理了贷款以后，消费金融公司要给商户返费用，或者叫提成，每天都会产生很多的费用的数据。为了方便管理，我们每个月建立一张费用表，例如fee_detail_201901……fee_detail_201912。</p><p>但是注意，跟分区一样，这种方式虽然可以一定程度解决单表查询性能的问题，但是并不能解决单机存储瓶颈的问题。</p><h3 id="多库水平分表"><a href="#多库水平分表" class="headerlink" title="多库水平分表"></a>多库水平分表</h3><p>多库水平分表，其实有点类似于分库分表的综合实现方案，从分表来说是减少了单表的数据量，从分库层面来说，降低了单个数据库访问的性能瓶颈，如图6-5所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354715.png" alt="image-20210714230103964"></p><center>图6-5</center><h1 id="常见的水平分表策略"><a href="#常见的水平分表策略" class="headerlink" title="常见的水平分表策略"></a>常见的水平分表策略</h1><p>分库更多的是关注业务的耦合度，也就是每个库应该放那些表，是由业务耦合度来决定的，这个在前期做领域建模的时候都会先考虑好，所以问题不大，只是分库之后带来的其他问题，我们在后续内容中来分析。</p><p>而分表这块，需要考虑的问题会更多一些，也就是我们应该根据什么样的策略来水平分表？这里就需要涉及到分表策略了，下面简单介绍几种最常见的分片策略。</p><h2 id="哈希取模分片"><a href="#哈希取模分片" class="headerlink" title="哈希取模分片"></a>哈希取模分片</h2><p>哈希分片，其实就是通过表中的某一个字段进行hash算法得到一个哈希值，然后通过取模运算确定数据应该放在哪个分片中，如图6-6所示。这种方式非常适合随机读写的场景中，它能够很好的将一个大表的数据随机分散到多个小表。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354277.png" alt="image-20210715135858728"></p><center>图6-6</center><h3 id="hash取模的问题"><a href="#hash取模的问题" class="headerlink" title="hash取模的问题"></a>hash取模的问题</h3><p>hash取模运算有个比较严重的问题，假设根据当前数据表的量以及增长情况，我们把一个大表拆分成了4个小表，看起来满足目前的需求，但是经过一段时间的运行后，发现四个表不够，需要再增加4个表来存储，这种情况下，就需要对原来的数据进行整体迁移，这个过程非常麻烦。</p><p>一般为了减少这种方式带来的数据迁移的影响，我们会采用一致性hash算法。</p><h3 id="一致性hash算法"><a href="#一致性hash算法" class="headerlink" title="一致性hash算法"></a>一致性hash算法</h3><p>在前面我们讲的hash取模算法，实际上对目标表或者目标数据库进行hash取模，一旦目标表或者数据库发生数量上的变化，就会导致所有数据都需要进行迁移，为了减少这种大规模的数据影响，才引入了一致性hash算法。</p><p>如图6-7所示，简单来说，一致性哈希将整个哈希值空间组织成一个虚拟的圆环，如假设某哈希函数H的值空间为0-2^32^-1（即哈希值是一个32位无符号整形），什么意思呢？</p><p>就是我们通过0-2^32^-1的数字组成一个虚拟的圆环，圆环的正上方的点代表0，0点右侧的第一个点代表1，以此类推，2、3、4、5、6……直到2^32^-1,也就是说0点左侧的第一个点代表2^32^-1。我们把这个由2的32次方个点组成的圆环称为hash环。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354772.png" alt="image-20210715145949618"></p><center>图6-7</center><p>那一致性hash算法和上面的虚拟环有什么关系呢？继续回到前面我们讲解hash取模的例子，假设现在有四个表，table_1、table_2、table_3、table_4，在一致性hash算法中，取模运算不是直接对这四个表来完成，而是对2^32^来实现。</p><blockquote><p> <strong>hash(table编号)%2^32^</strong></p></blockquote><p>通过上述公式算出的结果一定是一个0到2^32^-1之间的一个整数，然后在这个数对应的位置标注目标表，如图6-8所示，四个表通过hash取模之后分别落在hash环的某个位置上。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354039.png" alt="image-20210715151246280"></p><center>图6-8</center><p>好了，到目前为止，我们已经把目标表与hash环联系在了一起，那么接下来我们需要把一条数据保存到某个目标表中，怎么做呢？如图6-9所示，当添加一条数据时，同样通过hash和hash环取模运算得到一个目标值，然后根据目标值所在的hash环的位置顺时针查找最近的一个目标表，把数据存储到这个目标表中即可。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354562.png" alt="image-20210715152329100"></p><center>图6-9</center><p>不知道大家是否发现了一致性hash的好处，就是hash运算不是直接面向目标表，而是面向hash环，这样的好处就是当需要删除某张表或者增加表的时候，对于整个数据变化的影响是局部的，而不是全局。举个例子，假设我们发现需要增加一张表table_04，如图6-10所示，增加一个表，并不会对其他四个已经产生了数据的表造成影响，原来已经分片的数据完全不需要做任何改动。</p><p>如果需要删除一个节点，同样只会影响删除节点本身的数据，前后表的数据完全不受影响。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354795.png" alt="image-20210715153001773"></p><center>图6-10</center><h3 id="hash环偏斜"><a href="#hash环偏斜" class="headerlink" title="hash环偏斜"></a>hash环偏斜</h3><p>上述设计有一个问题，理论情况下我们目标表是能够均衡的分布在整个hash环中，但实际情况有可能是图6-11所示的样子。也就是产生了hash环偏斜的现象，这种现象导致的问题就是大量的数据都会保存到同一个表中，倒是数据分配极度不均匀。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354254.png" alt="image-20210715155332466"></p><center>图6-11</center><p>为了解决这个问题，必须要保证目标节点要均匀的分布在整个hash环中，但是真实的节点就只有4个，如何均匀分布呢？最简单的方法就是，把这四个节点分别复制一份出来分散到这个hash环中，这个复制出来的节点叫虚拟节点，根据实际需要可以虚拟出多个节点出来，如图6-12所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354437.png" alt="image-20210715160141288"></p><center>图6-12</center><h2 id="按照范围分片"><a href="#按照范围分片" class="headerlink" title="按照范围分片"></a>按照范围分片</h2><p>按范围分片，其实就是基于数据表的业务特性，按照某种范围拆分，这个范围的有很多含义，比如：</p><ul><li>时间范围，比如我们按照数据创建时间，按照每一个月保存一个表。基于时间划分还可以用来做冷热数据分离，越早的数据访问频次越少。</li><li>区域范围，区域一般指的是地理位置，比如一个表里面存储了来自全国各地的数据，如果数据量较大的情况下，可以按照地域来划分多个表。</li><li>数据范围，比如根据某个字段的数据区间来进行划分。</li></ul><p>如图6-7所示，表示按照数据范围进行拆分。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354929.png" alt="image-20210714230103964"></p><center>图6-7</center><p>范围分片最终要的是选择一个合适的分片键，这个是否合适来自于业务需求，比如之前有个学员是在做智能家居的，他们卖的是硬件设备，这些设备会采集数据上报到服务器上，当来自全国范围的数据统一保存在一个表中后，数据量达到了亿级别，所以这种场景比较适合按照城市和地域来拆分。</p><h1 id="分库分表实战"><a href="#分库分表实战" class="headerlink" title="分库分表实战"></a>分库分表实战</h1><p>为了让大家理解分库分表以及实操，我们通过一个简单的案例来演示一下。代码详见：<strong>springboot-split-table-example</strong>项目</p><p>假设存在一个用户表，用户表的字段如下。</p><p>该表主要提供注册、登录、查询、修改等功能。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354534.png" alt="image-20210715201725385"></p><center>图6-8</center><p>该表的具体的业务情况如下（需要注意，在进行分表之前，需要了解业务层面对这个表的使用情况，然后再决定使用什么样的方案，否则脱离业务去设计技术方案是耍流氓）</p><p><strong>用户端</strong>： 前台访问量较大，主要涉及两类请求：</p><ul><li>用户登录，面向C端，对可用性和一致性要求较高，主要通过login_name、email、phone来查询用户信息，1%的请求属于这种类型</li><li>用户信息查询，登录成功后，通过uid来查询用户信息，99%属于这种类型。</li></ul><p><strong>运营端</strong>： 主要是运营后台的信息访问，需要支持根据性别、手机号、注册时间、用户昵称等进行分页查询，由于是内部系统，访问量较低，对可用性一致性要求不高。</p><h2 id="根据uid进行水平分表"><a href="#根据uid进行水平分表" class="headerlink" title="根据uid进行水平分表"></a>根据uid进行水平分表</h2><p>由于99%的请求是基于uid进行用户信息查询，所以毫无疑问我们选择使用uid进行水平分表。那么这里我们采用uid的hash取模方法来进行分表，具体的实施如图6-9所示，根据uid进行一致性hash取模运算得到目标表进行存储。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191354899.png" alt="image-20210715204044151"></p><center>图6-9</center><p>按照图6-9的结构，分别复制user_info表，重新命名为01~04，如图6-10所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191355990.png" alt="image-20210715204629468"></p><center>图6-10</center><h2 id="如何生成全局唯一id"><a href="#如何生成全局唯一id" class="headerlink" title="如何生成全局唯一id"></a>如何生成全局唯一id</h2><p>当完成上述动作后，就需要开始开始落地实施，这里需要考虑在数据添加、修改、删除时，要正确路由到目标数据表，其次是老数据的迁移。</p><p>老数据迁移，一般我们是写一个脚本或者一个程序，把旧表中的数据查询出来，然后根据分表规则重新路由分发到新的表中，这里不是很复杂，就不做展开说明，我们重点说一下数据添加/修改/删除的路由。</p><p>在实施之前，我们需要先考虑一个非常重要的问题，就是在单个表中，我们使用递增主键来保证数据的唯一性，但是如果把数据拆分到了四个表，每个表都采用自己的递增主键规则，就会存在重复id的问题，也就是说递增主键不是全局唯一的。</p><p>我们需要知道一个点是，user_info虽然拆分成了多张表，但是本质上它应该还是一个完整的数据整体，当id存在重复的时候，就失去了数据的唯一性，因此我们需要考虑如何生成一个全局唯一ID。</p><h3 id="如何实现全局唯一ID"><a href="#如何实现全局唯一ID" class="headerlink" title="如何实现全局唯一ID"></a>如何实现全局唯一ID</h3><p>全局唯一ID的特性就是能够保证ID的唯一性，那么基于这个特性，我们可以轻松找到很多的解决方案。</p><ul><li>数据库自增ID（定义全局表）</li><li>UUID</li><li>Redis的原子递增</li><li>Twitter-Snowflake算法</li><li>美团的leaf</li><li>MongoDB的ObjectId</li><li>百度的UidGenerator</li></ul><h3 id="分布式ID的特性"><a href="#分布式ID的特性" class="headerlink" title="分布式ID的特性"></a>分布式ID的特性</h3><ul><li>唯一性：确保生成的ID是全局唯一的。</li><li>有序递增性：确保生成的ID是对于某个用户或者业务是按一定的数字有序递增的。</li><li>高可用性：确保任何时候都能正确的生成ID。</li><li>带时间：ID里面包含时间，一眼扫过去就知道哪天的数据</li></ul><h3 id="数据库自增方案"><a href="#数据库自增方案" class="headerlink" title="数据库自增方案"></a>数据库自增方案</h3><p>在数据库中专门创建一张序列表，利用数据库表中的自增ID来为其他业务的数据生成一个全局ID，那么每次要用ID的时候，直接从这个表中获取即可。</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> `uid_table`  (</span><br><span class="line">  `id` <span class="type">bigint</span>(<span class="number">20</span>) <span class="keyword">NOT</span> <span class="keyword">NULL</span> AUTO_INCREMENT,</span><br><span class="line">  `business_id` <span class="type">int</span>(<span class="number">11</span>)  <span class="keyword">NOT</span> <span class="keyword">NULL</span>,</span><br><span class="line">  <span class="keyword">PRIMARY</span> KEY (`id`) <span class="keyword">USING</span> BTREE,</span><br><span class="line"><span class="keyword">UNIQUE</span> (business_type) </span><br><span class="line">) </span><br></pre></td></tr></table></figure><p>在应用程序中，每次调用下面这段代码，就可以持续获得一个递增的ID。</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">begin</span>;</span><br><span class="line">REPLACE <span class="keyword">INTO</span> uid_table (business_id) <span class="keyword">VALUES</span> (<span class="number">2</span>);</span><br><span class="line"><span class="keyword">SELECT</span> LAST_INSERT_ID();</span><br><span class="line"><span class="keyword">commit</span>;</span><br></pre></td></tr></table></figure><p>其中，replace into是每次删除原来相同的数据，同时加1条，就能保证我们每次得到的就是一个自增的ID</p><blockquote><p>这个方案的优点是非常简单，它也有缺点，就是对于数据库的压力比较大，而且最好是独立部署一个DB，而独立部署又会增加整体的成本，这个在美团的leaf里面设计了一个很巧妙的设计方案，后面再讲</p></blockquote><p>优点：</p><ul><li>非常简单，利用现有数据库系统的功能实现，成本小，有DBA专业维护。</li><li>ID号单调自增，可以实现一些对ID有特殊要求的业务。</li></ul><p>缺点：</p><ul><li>强依赖DB，当DB异常时整个系统不可用，属于致命问题。配置主从复制可以尽可能的增加可用性，但是数据一致性在特殊情况下难以保证。主从切换时的不一致可能会导致重复发号。</li><li>ID发号性能瓶颈限制在单台MySQL的读写性能。</li></ul><h3 id="UUID"><a href="#UUID" class="headerlink" title="UUID"></a>UUID</h3><p>UUID的格式是： xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx 8-4-4-4-12共36个字符，它是一个128bit的二进制转化为16进制的32个字符，然后用4个<code>-</code>连接起来的字符串。</p><p><strong>UUID的五种生成方式</strong></p><ul><li>基于时间的UUID（date-time &amp; MAC address）： 主要依赖当前的时间戳及机器mac地址，因此可以保证全球唯一性。（使用了Mac地址，因此会暴露Mac地址和生成时间。）</li><li>分布式安全的UUID（date-time &amp; group/user id）将版本1的时间戳前四位换为POSIX的UID或GID。</li><li>基于名字空间的UUID-MD5版（MD5 hash &amp; namespace），基于指定的名字空间/名字生成MD5散列值得到，标准不推荐。</li><li>基于随机数的UUID（pseudo-random number）：基于随机数或伪随机数生成。</li><li>基于名字空间的UUID-SHA1版（SHA-1 hash &amp; namespace）：将版本3的散列算法改为SHA1</li></ul><p>在Java中，提供了基于MD5算法的UUID、以及基于随机数的UUID。</p><p><strong>优点：</strong></p><ul><li>本地生成，没有网络消耗，生成简单，没有高可用风险。</li></ul><p><strong>缺点：</strong></p><ul><li>不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。</li><li>信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。</li><li>无序查询效率低：由于生成的UUID是无序不可读的字符串，所以其查询效率低。</li><li>UUID不适合用来做数据库的唯一ID，如果用UUID做主键，无序的不递增，大家都知道，主键是有索引的，然后mysql的索引是通过b+树来实现的，每一次新的UUID数据的插入，为了查询的优化，都会对索引底层的b+树进行修改，因为UUID数据是无序的，所以每一次UUID数据的插入都会对主键的b+树进行很大的修改，严重影响性能</li></ul><h3 id="雪花算法"><a href="#雪花算法" class="headerlink" title="雪花算法"></a>雪花算法</h3><p>SnowFlake 算法，是 Twitter 开源的分布式 id 生成算法。其核心思想就是：使用一个 64 bit 的 long 型的数字作为全局唯一 id。雪花算法比较常见，在百度的UidGenerator、美团的Leaf中，都有用到雪花算法的实现。</p><p>如图6-11所示，表示雪花算法的组成，一共64bit，这64个bit位由四个部分组成。</p><ul><li><p><strong>第一部分</strong>，1bit位，用来表示符号位，而ID一般是正数，所以这个符号位一般情况下是0。</p></li><li><p><strong>第二部分</strong>，占41 个 bit：表示的是时间戳，是系统时间的毫秒数，但是这个时间戳不是当前系统的时间，而是当前<code>系统时间-开始时间</code>，更大的保证这个ID生成方案的使用的时间！</p></li><li><p>那么我们为什么需要这个时间戳，目的是为了保证有序性，可读性,我一看我就能猜到ID是什么时候生成的。</p><blockquote><p>41位可以2^41^ - 1表示个数字，</p><p>如果只用来表示正整数（计算机中正数包含0），可以表示的数值范围是：0 至 2^41^-1，减1是因为可表示的数值范围是从0开始算的，而不是1。</p><p>也就是说41位可以表示2^41^-1个毫秒的值，转化成单位年则是(2^41^-1)/1000 * 60 * 60 * 24 *365=69年，也就是能容纳69年的时间</p></blockquote></li><li><p><strong>第三部分</strong>，用来记录工作机器id，id包含10bit，意味着这个服务最多可以部署在 2^10 台机器上，也就是 1024 台机器。</p><p>其中这10bit又可以分成2个5bit，前5bit表示机房id、5bit表示机器id，意味着最多支持2^5个机房（32），每个机房可以支持32台机器。</p></li><li><p><strong>第四部分</strong>，第四部分由12bit组成，它表示一个递增序列，用来记录同毫秒内产生的不同id。</p><p>那么我们为什么需要这个序列号，设想下，如果是同一毫秒同一台机器来请求，那么我们怎么保证他的唯一性，这个时候，我们就能用到我们的序列号，</p><p>目的是为了保证同一毫秒内同一机器生成的ID是唯一的，这个其实就是为了满足我们ID的这个高并发，就是保证我同一毫秒进来的并发场景的唯一性</p><p>12位（bit）可以表示的最大正整数是2^12-1=4095，即可以用0、1、2、3、….4094这4095个数字，来表示同一机器同一时间截（毫秒)内产生的4095个ID序号。</p><blockquote><p> 12位2进制，如果全部都是1的情况下，那么最终的值就是4095，也就是12bit能够存储的最大的数字是4095.</p></blockquote></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191355404.png" alt="image-20210715213656945"></p><center>图6-11</center><h2 id="分库分表之后的数据DML操作"><a href="#分库分表之后的数据DML操作" class="headerlink" title="分库分表之后的数据DML操作"></a>分库分表之后的数据DML操作</h2><p>有序需要用到全局id，所以在user_info表需要添加一个唯一id的字段。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191355706.png" alt="image-20210715215839419"></p><center>图6-12</center><p>配置完成之后，在如下代码中引入signal方法。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/users&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">UserInfoController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    IUserInfoService userInfoService;</span><br><span class="line">    SnowFlakeGenerator snowFlakeGenerator=<span class="keyword">new</span> SnowFlakeGenerator(<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>);</span><br><span class="line">    <span class="meta">@PostMapping(&quot;/batch&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">user</span><span class="params">(<span class="meta">@RequestBody</span> List&lt;UserInfo&gt; userInfos)</span></span>&#123;</span><br><span class="line">        log.info(<span class="string">&quot;begin UserInfoController.user&quot;</span>);</span><br><span class="line">        userInfoService.saveBatch(userInfos);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@PostMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">signal</span><span class="params">(<span class="meta">@RequestBody</span> UserInfo userInfo)</span></span>&#123;</span><br><span class="line">        Long bizId=snowFlakeGenerator.nextId();</span><br><span class="line">        userInfo.setBizId(bizId);</span><br><span class="line">        String table=ConsistentHashing.getServer(bizId.toString());</span><br><span class="line">        log.info(<span class="string">&quot;UserInfoController.signal:&#123;&#125;&quot;</span>,table);</span><br><span class="line">        MybatisPlusConfig.TABLE_NAME.set(table);</span><br><span class="line">        userInfoService.save(userInfo);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>并且，需要增加一个mybatis拦截器，针对user_info表进行拦截和替换，从而实现动态表的路由。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MybatisPlusConfig</span> </span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> ThreadLocal&lt;String&gt; TABLE_NAME = <span class="keyword">new</span> ThreadLocal&lt;&gt;();</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> MybatisPlusInterceptor <span class="title">mybatisPlusInterceptor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        MybatisPlusInterceptor interceptor = <span class="keyword">new</span> MybatisPlusInterceptor();</span><br><span class="line">        PaginationInnerInterceptor paginationInnerInterceptor = <span class="keyword">new</span> PaginationInnerInterceptor(DbType.MYSQL);</span><br><span class="line">        interceptor.addInnerInterceptor(paginationInnerInterceptor);</span><br><span class="line">        DynamicTableNameInnerInterceptor dynamicTableNameInnerInterceptor = <span class="keyword">new</span> DynamicTableNameInnerInterceptor();</span><br><span class="line">        Map&lt;String, TableNameHandler&gt; tableNameHandlerMap = <span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        tableNameHandlerMap.put(<span class="string">&quot;user_info&quot;</span>, (sql, tableName) -&gt; TABLE_NAME.get());</span><br><span class="line">        dynamicTableNameInnerInterceptor.setTableNameHandlerMap(tableNameHandlerMap);</span><br><span class="line">        interceptor.addInnerInterceptor(dynamicTableNameInnerInterceptor);</span><br><span class="line">        <span class="keyword">return</span> interceptor;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>至此，一个基础的分库分表的演练就完成了，但问题仍然还未完全解决。</p><h2 id="非分片键查询"><a href="#非分片键查询" class="headerlink" title="非分片键查询"></a>非分片键查询</h2><p>我们对user_info表的分片，是基于biz_id来实现的，也就是意味着如果我们想查询某张表的数据，必须先要使用biz_id路由找到对应的表才能查询到。</p><p>那么问题来了，如果查询的字段不是分片键（也就是不是biz_id），比如本次分库分表实战案例中，运营端查询就有根据名字、手机号、性别等字段来查，这时候我们并不知道去哪张表查询这些信息。</p><h3 id="非分片键和分片键建立映射关系"><a href="#非分片键和分片键建立映射关系" class="headerlink" title="非分片键和分片键建立映射关系"></a>非分片键和分片键建立映射关系</h3><p>第一种解决办法就是，把非分片键和分片键建立映射关系，比如login_name -&gt; biz_id 建立映射，相当于建立一个简单的索引，当基于login_name查询数据时，先通过映射表查询出login_name对应的biz_id，再通过biz_id定位到目标表。</p><p>映射表的只有两列，可以成再很多的数据，当数据量过大时，也可以对映射表做水平拆分。 同时这种映射关系其实就是k-v键值对的关系，所以我们可以使用k-v缓存来存储提升性能。</p><p>同时因为这种映射关系的变更频率很低，所以缓存命中率很高，性能也很好。</p><h3 id="用户端数据库和运营端数据库进行分离"><a href="#用户端数据库和运营端数据库进行分离" class="headerlink" title="用户端数据库和运营端数据库进行分离"></a>用户端数据库和运营端数据库进行分离</h3><p>运营端的查询可能不止于单个字段的映射来查询，可能更多的会涉及到一些复杂查询，以及分页查询等，这种查询本身对数据库性能影响较大，很可能影响到用户端对于用户表的操作，所以一般主流的解决方案就是把两个库进行分离。</p><p>由于运营端对于数据的一致性和可用性要求不是很高，也不需要实时访问数据库，所以我们可以把C端用户表的数据同步到运营端的用户表，而且用户表可以不需要做分表操作，直接全量查表即可。</p><p>当然，如果运营端的操作性能实在是太慢了，我们还可以采用ElasticSearch搜索引擎来满足后台复杂查询的需求。</p><h2 id="实际应用中会遇到的问题"><a href="#实际应用中会遇到的问题" class="headerlink" title="实际应用中会遇到的问题"></a>实际应用中会遇到的问题</h2><p>在实际应用中，并不是一开始就会想到未来会对这个表做拆分，因此很多时候我们面临的问题是在数据量已经达到一定瓶颈的时候，才开始去考虑这个问题。</p><p>所以分库分表最大的难点不是在于拆分的方法论，而是在运行了很长时间的数据库中，如何根据实际业务情况选择合适的拆分方式，以及在拆分之前对于数据的迁移方案的思考。而且，在整个数据迁移和拆分过程中，系统仍然需要保持可用。</p><p>对于运行中的表的分表，一般会分为三个阶段。</p><p><strong>阶段一，新老库双写</strong></p><p>由于老的数据表肯定没有考虑到未来分表的设计，同时随着业务的迭代，可能有些模型也需要优化，因此会设计一个新的表来承载老的数据，而这个过程中，需要做几件事情</p><ul><li>数据库表的双写，老的数据库表和新的数据库表同步写入数据，事务的成功以老的模型为准，查询也走老的模型</li><li>通过定时任务对数据进行核对，补平差异</li><li>通过定时任务把历史数据迁移到新的模型中</li></ul><p><strong>阶段二，以新的模型为准</strong></p><p>到了第二个阶段，历史数据已经导完了，并且校验数据没有问题。</p><ul><li>仍然保持数据双写，但是事务的成功和查询都以新模型为准。</li><li>定时任务进行数据核对，补平数据差异</li></ul><p><strong>阶段三，结束双写</strong></p><p>到了第三个阶段，说明数据已经完全迁移好了，因此。</p><ul><li>取消双写，所有数据只需要保存到新的模型中，老模型不需要再写入新的数据。</li><li>如果仍然有部分老的业务依赖老的模型，所以等到所有业务都改造完成后， 再废除老的模型。</li></ul><h1 id="分库分表后带来的问题"><a href="#分库分表后带来的问题" class="headerlink" title="分库分表后带来的问题"></a>分库分表后带来的问题</h1><p>分库分表带来性能提升的好处的同时，也带来了很多的麻烦，</p><h2 id="分布式事务问题"><a href="#分布式事务问题" class="headerlink" title="分布式事务问题"></a>分布式事务问题</h2><p>分库分表之后，原本在一个库中的事务，变成了跨越多个库，如何保证跨库数据的一致性问题，也是一个常见的难题。如图6-13所示，用户创建订单时，需要在订单库中保存一条订单记录，并且修改库存库中的商品库存，这里就涉及到跨库事务的一致性问题。也就是说我怎么保证当前两个事务操作要么同时成功，要么同时失败。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191355737.png" alt="image-20210716144133821"></p><center>图6-13</center><h2 id="跨库查询"><a href="#跨库查询" class="headerlink" title="跨库查询"></a>跨库查询</h2><p>比如查询在合同信息的时候要关联客户数据，由于是合同数据和客户数据是在不同的数据库，那么我们肯定不能直接使用join的这种方式去做关联查询。</p><p>我们有几种主要的解决方案：</p><ul><li><strong>字段冗余</strong>，比如我们查询合同库的合同表的时候需要关联客户库的客户表，我们可以直接把一些经常关联查询的客户字段放到合同表，通过这种方式避免跨库关联查询的问题。</li><li><strong>数据同步</strong>：比如商户系统要查询产品系统的产品表，我们干脆在商户系统创建一张产品表，通过ETL或者其他方式定时同步产品数据。</li><li><strong>全局表</strong>（广播表） 比如基础数据被很多业务系统用到，如果我们放在核心系统，每个系统都要去关联查询，这个时候我们可以在所有的数据库都存储相同的基础数据。</li><li>ER表（绑定表），我们有些表的数据是存在逻辑的主外键关系的，比如订单表order_info，存的是汇总的商品数，商品金额；订单明细表order_detail，是每个商品的价格，个数等等。或者叫做从属关系，父表和子表的关系。他们之间会经常有关联查询的操作，如果父表的数据和子表的数据分别存储在不同的数据库，跨库关联查询也比较麻烦。所以我们能不能把父表和数据和从属于父表的数据落到一个节点上呢？比如order_id=1001的数据在node1，它所有的明细数据也放到node1；order_id=1002的数据在node2，它所有的明细数据都放到node2，这样在关联查询的时候依然是在一个数据库。</li></ul><blockquote><p>上面的思路都是通过合理的数据分布避免跨库关联查询，实际上在我们的业务中，也是尽量不要用跨库关联查询，如果出现了这种情况，就要分析一下业务或者数据拆分是不是合理。如果还是出现了需要跨库关联的情况，那我们就只能用最后一种办法。</p></blockquote><ul><li>系统层组装</li></ul><p>在不同的数据库节点把符合条件数据的数据查询出来，然后重新组装，返回给客户端。</p><h2 id="排序、翻页、函数计算等问题"><a href="#排序、翻页、函数计算等问题" class="headerlink" title="排序、翻页、函数计算等问题"></a>排序、翻页、函数计算等问题</h2><p>跨节点多库进行查询时，会出现limit分页，order by排序的问题。比如有两个节点，节点1存的是奇数id=1,3,5,7,9……；节点2存的是偶数id=2,4,6,8,10……</p><p>执行select * from user_info order by id limit 0,10</p><p>需要在两个节点上各取出10条，然后合并数据，重新排序。</p><p>max、min、sum、count之类的函数在进行计算的时候，也需要先在每个分片上执行相应的函数，然后将各个分片的结果集进行汇总和再次计算，最终将结果返回。</p><h2 id="全局唯一ID"><a href="#全局唯一ID" class="headerlink" title="全局唯一ID"></a>全局唯一ID</h2><p>全局唯一id的问题，前面已经说了，水平分表之后，需要考虑全局唯一id设计问题。</p><h2 id="多数据源的问题"><a href="#多数据源的问题" class="headerlink" title="多数据源的问题"></a>多数据源的问题</h2><p>分库分表之后，难免会存在一个应用配置多个数据源。 </p><p>另外，数据库层面有可能会设计读写分离的方案，也使得一个应用会访问多个数据源，并且还需要实现读写分离的动态路由。</p><p>而这些问题在每个应用系统中都会存在并且需要解决，所以为了提供统一的分库分表相关问题的解决方案，引入了很多的开源技术。</p><h2 id="分库分表解决方案"><a href="#分库分表解决方案" class="headerlink" title="分库分表解决方案"></a>分库分表解决方案</h2><p>目前市面上分库分表的中间件相对来说说比较多，比如</p><ul><li>Cobar，淘宝开源的分库分表组件，目前基本上没有维护了。</li><li>Sharding-Sphere，当当开源的一个分库分表组件，已经捐献给了Apache基金会</li><li>Atlas， 奇虎360开源的分库分表组件，也是没怎么维护了</li><li>Mycat，从阿里cobar升级而来，由开源组织维护。</li><li>Vitess，谷歌开源的分库分表组件</li></ul><p>目前很多公司选择较多的是Mycat或者Sharding-Sphere，所以我重点介绍Sharding-Sphere的使用和原理。</p><p>对于同类技术的选择，无非就是看社区活跃度、技术的成熟度、以及功能和当前需求是否匹配。</p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
          <category> ShardingSphere </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> 性能优化 </tag>
            
            <tag> 分库分表 </tag>
            
            <tag> ShardingSphere </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>想要彻底搞懂大厂是如何实现Redis高可用的？看这篇文章就够了！(1.2W字，建议收藏）</title>
      <link href="/posts/1429145604/"/>
      <url>/posts/1429145604/</url>
      
        <content type="html"><![CDATA[<p>高可用HA（High Availability）是分布式系统架构设计中必须考虑的因素之一，它通常是指，通过设计减少系统不能提供服务的时间。</p><p>假设系统一直能够提供服务，我们说系统的可用性是100%。如果系统每运行100个时间单位，会有1个时间单位无法提供服务，我们说系统的可用性是99%。很多公司的高可用目标是4个9，也就是99.99%，这就意味着，系统的年停机时间为8.76个小时。</p><p><strong>那么如何保证系统的高可用呢</strong></p><p>首先，在整个架构的每个节点中，不允许存在单点问题，因为单点一定是高可用最大的风险点，我们应该在系统设计过程中去避免单点问题。</p><p>在实现方法上，一般采用的就是集群部署、或者冗余部署来实现。这样的设计使得如果某个节点出现故障，其他的节点还可以继续使用。</p><h1 id="Redis中高可用设计的必要性"><a href="#Redis中高可用设计的必要性" class="headerlink" title="Redis中高可用设计的必要性"></a>Redis中高可用设计的必要性</h1><p>Redis作为一个高性能Nosq中间件，会有很多热点数据存放在Redis中，一旦Redis-server出现故障，会导致所有相关业务访问都出现问题。另外，即便是设计了数据库兜底的方案，大量请求对数据库的访问也很容易导致数据库出现瓶颈，造成更大的灾难。</p><p>除此之外，Redis的集群部署还可以带来额外的收益：</p><ul><li>负载（性能），Redis本身的QPS已经很高了，但是如果在一些并发量非常高的情况下，性能还是会受到影响。这个时候我们希望有更多的Redis服务来完成工作</li><li>扩容（水平扩展），第二个是出于存储的考虑。因为Redis所有的数据都放在内存中，如果数据量大，很容易受到硬件的限制。升级硬件收效和成本比太低，所以我们需要有一种横向扩展的方法</li></ul><p>在Redis中，提供了高可用方案包含以下几种：</p><ul><li>主从复制（用来实现读写分离）</li><li>哨兵机制（实现master选举）</li><li>集群机制（实现数据的分片）</li></ul><h1 id="Redis的Master-Slave方法"><a href="#Redis的Master-Slave方法" class="headerlink" title="Redis的Master-Slave方法"></a>Redis的Master-Slave方法</h1><p>主从复制模式，简单来说就是把一台Redis服务器的数据，复制到其他Redis服务器中。其中负责复制数据的来源称为master，被动接收数据并同步的节点称为slave，数据的复制是单向的，如图5-1所示，对于主从模式，其实有很多的变体。</p><p>在很多组件中都有使用这种思想，比如mysql的主从复制、redis的主从复制、activemq的主从复制、kafka里面的数据副本机制等等，所以大家需要举一反三，融会贯通。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191352426.png" alt="image-20210712213026784"></p><center>图5-1</center><h2 id="主从复制的好处"><a href="#主从复制的好处" class="headerlink" title="主从复制的好处"></a>主从复制的好处</h2><ol><li>数据冗余，主从复制实现了数据的热备，是除了持久化机制之外的另外一种数据冗余方式。</li><li>读写分离，使数据库能支撑更大的并发。在报表中尤其重要。由于部分报表sql语句非常的慢，导致锁表，影响前台服务。如果前台使用master，报表使用slave，那么报表sql将不会造成前台锁，保证了前台速度。</li><li>负载均衡，在主从复制的基础上，配合读写分离机制，可以由主节点提供写服务，从节点提供服务。在读多写少的场景中，可以增加从节点来分担redis-server读操作的负载能力，从而大大提高redis-server的并发量</li><li>保证高可用，作为后备数据库，如果主节点出现故障后，可以切换到从节点继续工作，保证redis-server的高可用。</li></ol><h2 id="Redis如何配置主从复制"><a href="#Redis如何配置主从复制" class="headerlink" title="Redis如何配置主从复制"></a>Redis如何配置主从复制</h2><p><strong>需要注意，Redis的主从复制，是直接在从节点发起就行，主节点不需要做任何事情</strong></p><p>在Redis中有三种方式来开启主从复制。</p><ul><li><p>在从服务器的redis.conf配置文件中加入下面这个配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">replicaof &lt;masterip&gt; &lt;masterport&gt;</span><br></pre></td></tr></table></figure></li><li><p>通过启动命令来配置，也就是启动slave节点时执行如下命令</p></li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./redis-server ../redis.conf --replicaof &lt;masterip&gt; &lt;masterport&gt;</span><br></pre></td></tr></table></figure><ul><li><p>启动redis-server之后，直接在客户端窗口执行下面命令</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash">replicaof &lt;masterip&gt; &lt;masterport&gt;</span></span><br></pre></td></tr></table></figure></li></ul><h3 id="准备三台虚拟机"><a href="#准备三台虚拟机" class="headerlink" title="准备三台虚拟机"></a>准备三台虚拟机</h3><p>准备好三台虚拟机，并且这三台虚拟机需要能相互ping通，以及相互能够访问6379这个端口，如果访问不了，需要关闭防火墙。</p><blockquote><p>firewall-cmd –zone=public –add-port=6379/tcp –permanent</p></blockquote><ul><li>192.168.221.128（master）</li><li>192.168.221.129（slave）</li><li>192.168.221.130（slave）</li></ul><p>这三台机器上都需要安装redis-server，安装步骤如下。</p><blockquote><p>注意事项，Redis6安装需要gcc版本大于5.3以上，否则安装会报错。</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 升级到gcc 9.3：</span></span><br><span class="line">yum -y install centos-release-scl</span><br><span class="line">yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils</span><br><span class="line">scl enable devtoolset-9 bash</span><br><span class="line"><span class="meta">#</span><span class="bash"> 需要注意的是scl命令启用只是临时的，退出shell或重启就会恢复原系统gcc版本。</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果要长期使用gcc 9.3的话：</span></span><br><span class="line">echo -e &quot;\nsource /opt/rh/devtoolset-9/enable&quot; &gt;&gt;/etc/profile</span><br></pre></td></tr></table></figure><blockquote><p><strong>开始安装</strong></p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cd /usr/local/</span><br><span class="line">wget http://download.redis.io/releases/redis-6.0.9.tar.gz</span><br><span class="line">tar -zxvf redis-6.0.9.tar.gz</span><br><span class="line">cd redis-6.0.9</span><br><span class="line">make</span><br><span class="line">make test</span><br><span class="line">make install PREFIX=/data/program/redis </span><br><span class="line">cp redis.conf /data/program/redis/redis.conf</span><br></pre></td></tr></table></figure><h3 id="演示配置过程"><a href="#演示配置过程" class="headerlink" title="演示配置过程"></a>演示配置过程</h3><p>在192.168.221.129和192.168.221.130这两台机器上分别按照下面的操作增加配置。</p><ul><li><p>编辑redis.conf文件，通过shift+g跳转到最后一行，增加如下配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">replicaof 192.168.221.128 6379</span><br></pre></td></tr></table></figure></li><li><p>分别启动这两台机器，启动成功后，使用如下命令查看集群状态</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> info replication</span></span><br></pre></td></tr></table></figure></li><li><p>启动日志中可以看到，在启动过程中已经从master节点复制了信息。</p></li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">66267:S 12 Jul 2021 22:21:46.013 * Loading RDB produced by version 6.0.9</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.013 * RDB age 50 seconds</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.013 * RDB memory usage when created 0.77 Mb</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.013 * DB loaded from disk: 0.000 seconds</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.013 * Ready to accept connections</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.013 * Connecting to MASTER 192.168.221.128:6379</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.014 * MASTER &lt;-&gt; REPLICA sync started</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.015 * Non blocking connect for SYNC fired the event.</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.016 * Master replied to PING, replication can continue...</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.017 * Partial resynchronization not possible (no cached master)</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.039 * Full resync from master: acb74093b4c9d6fb527d3c713a44820ff0564508:0</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.058 * MASTER &lt;-&gt; REPLICA sync: receiving 188 bytes from master to disk</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.058 * MASTER &lt;-&gt; REPLICA sync: Flushing old data</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.058 * MASTER &lt;-&gt; REPLICA sync: Loading DB in memory</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.060 * Loading RDB produced by version 6.2.4</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.060 * RDB age 0 seconds</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.060 * RDB memory usage when created 1.83 Mb</span><br><span class="line">66267:S 12 Jul 2021 22:21:46.060 * MASTER &lt;-&gt; REPLICA sync: Finished with success</span><br></pre></td></tr></table></figure><p><strong>如果没有开启日志，可以通过下面的方法进行开启</strong></p><blockquote><ul><li>找到Redis的配置文件 redis.conf</li><li>打开该配置文件， vi redis.conf;</li><li>通过linux的查询命令找到 (loglevel下面)logfile “ “ ;</li><li>在冒号里面输入日志的路径，比如logfile “/usr/local/redis/log/redis.log”， 需要提前创建好目录和文件，redis默认不会创建该文件。</li></ul></blockquote><p>接着，我们在master节点上通过设置一些key，会发现数据立刻就同步到了两个slave节点上，从而完成了主从同步功能。不过在默认情况下，slave服务器是只读的，如果直接在slave服务器上做修改，会报错.  不过可以在slave服务器的redis.conf中找到一个属性，允许slave服务器可以写，但是不建议这么做。因为slave服务器上的更改不能往master上同步，会造成数据不同步的问题</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">slave-read-only no </span><br></pre></td></tr></table></figure><h2 id="Redis主从复制的原理分析"><a href="#Redis主从复制的原理分析" class="headerlink" title="Redis主从复制的原理分析"></a>Redis主从复制的原理分析</h2><p>Redis的主从复制分两种，一种是全量复制，另一种是增量复制。</p><h3 id="全量复制"><a href="#全量复制" class="headerlink" title="全量复制"></a>全量复制</h3><p>如图5-2所示，表示Redis主从全量复制的整体时序图，全量复制一般发生在Slave节点初始化阶段，这个时候需要把master上所有数据都复制一份，具体步骤是：</p><ul><li><p>从服务器连接主服务器，发送SYNC命令； </p></li><li><p>主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的所有写命令； </p></li><li><p>主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命令（<strong>表示RDB异步生成快照期间的数据变更</strong>）； </p></li><li><p>从服务器收到快照文件后丢弃所有旧数据，载入收到的快照；</p></li><li><p>主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；</p></li><li><p>从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；</p></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191352091.png" alt="image-20210713134526344"></p><center>图5-2</center><p><strong>问题：生成RDB期间，master接收到的命令怎么处理？</strong></p><p>开始生成RDB文件时，master会把所有新的写命令缓存在内存中。在 slave node 保存了RDB之后，再将新的写命令复制给 slave node。（跟AOF重写期间的思路是一样的）</p><blockquote><p>完成上面几个步骤后就完成了slave服务器数据初始化的所有操作，savle服务器此时可以接收来自用户的读请求，同时，主从节点进入到命令传播阶段，在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。</p></blockquote><p>在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK，下面演示一下具体的实现。</p><ol><li><p>在slave服务器redis cli上执行 <strong>REPLCONF listening-port 6379</strong>  (向主数据库发送replconf命令说明自己的端口号)</p></li><li><p>开始同步，向master服务器发送sync命令开始同步，此时master会发送快照文件和缓存的命令。</p></li></ol> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; sync</span><br><span class="line">Entering replica output mode...  (press Ctrl-C to quit)</span><br><span class="line">SYNC with master, discarding 202 bytes of bulk transfer...</span><br><span class="line">SYNC done. Logging commands from master.</span><br><span class="line">&quot;ping&quot;</span><br><span class="line">&quot;ping&quot;</span><br></pre></td></tr></table></figure><ol start="3"><li><p>slave会将收到的内容写入到硬盘上的临时文件，当写入完成后会用该临时文件替换原有的RDB快照文件。需要注意的是，在同步的过程中slave并不会阻塞，仍然可以处理客户端的命令。默认情况下slave会用同步前的数据对命令进行响应，如果我们希望读取的数据不能出现脏数据，那么可以在redis.conf文件中配置下面的参数，来使得slave在同步完成对所有命令之前，都回复错误:<strong>SYNC with master in progress</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">slave-serve-stale-data no</span><br></pre></td></tr></table></figure></li><li><p>复制阶段结束后，master执行的任何非查询语句都会异步发送给slave。 可以在master节点执行set命令，可以在slave节点看到如下同步的指令。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis &gt; sync</span><br><span class="line">&quot;set&quot;,&quot;11&quot;,&quot;11&quot;</span><br><span class="line">&quot;ping&quot;</span><br></pre></td></tr></table></figure></li></ol><p>另外需要注意的是：</p><p>master/slave 复制策略是采用乐观复制，也就是说可以容忍在一定时间内master/slave数据的内容是不同的，但是两者的数据会最终同步成功。</p><p>具体来说，redis的主从同步过程本身是异步的，意味着master执行完客户端请求的命令后会立即返回结果给客户端，然后异步的方式把命令同步给slave。这一特征保证启用master/slave后 master的性能不会受到影响。</p><p>但是另一方面，如果在这个数据不一致的窗口期间，master/slave因为网络问题断开连接，而这个时候，master是无法得知某个命令最终同步给了多少个slave数据库。不过redis提供了一个配置项来限制只有数据至少同步给多少个slave的时候，master才是可写的：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">min-replicas-to-write 3     表示只有当3个或以上的slave连接到master，master才是可写的</span><br><span class="line"></span><br><span class="line">min-replicas-max-lag 10     表示允许slave最长失去连接的时间，如果10秒还没收到slave的响应，则master认为该slave以断开</span><br></pre></td></tr></table></figure><p>修改master redis服务的redis.conf， 打开这两个配置，重启即可看到效果 </p><h3 id="增量复制"><a href="#增量复制" class="headerlink" title="增量复制"></a>增量复制</h3><p>从Redis2.8开始，主从节点支持增量复制，并且是支持断点续传的增量复制，也就是说如果出现复制异常或者网络连接断开导致复制中断的情况，在系统恢复之后仍然可以按照上次复制的地方继续同步，而不是全量复制。</p><p>它的具体原理是：主节点和从节点分别维护一个复制偏移量（offset），代表的是<strong>主节点向从节点传递的字节数</strong>；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。主从节点的偏移量可以分别保存在：<code>master_repl_offset:78130</code>和<code>slave_repl_offset</code>这两个字段中，通过下面的命令可以查看。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:6379&gt; info replication</span><br><span class="line"><span class="meta">#</span><span class="bash"> Replication</span></span><br><span class="line">role:slave</span><br><span class="line">master_host:192.168.221.128</span><br><span class="line">master_port:6379</span><br><span class="line">master_link_status:up</span><br><span class="line">master_last_io_seconds_ago:1</span><br><span class="line">master_sync_in_progress:0</span><br><span class="line">slave_repl_offset:77864</span><br><span class="line">slave_priority:100</span><br><span class="line">slave_read_only:1</span><br><span class="line">connected_slaves:0</span><br><span class="line">master_replid:acb74093b4c9d6fb527d3c713a44820ff0564508</span><br><span class="line">master_replid2:0000000000000000000000000000000000000000</span><br><span class="line">master_repl_offset:77864</span><br><span class="line">second_repl_offset:-1</span><br><span class="line">repl_backlog_active:1   # 开启复制缓冲区</span><br><span class="line">repl_backlog_size:1048576  # 缓冲区最大长度</span><br><span class="line">repl_backlog_first_byte_offset:771  # 起始偏移量，计算当前缓存区可用范围</span><br><span class="line">repl_backlog_histlen:77094  # 以保存数据的有效长度</span><br></pre></td></tr></table></figure><h3 id="无磁盘复制"><a href="#无磁盘复制" class="headerlink" title="无磁盘复制"></a>无磁盘复制</h3><p>前面我们说过，Redis复制的工作原理基于RDB方式的持久化实现的，也就是master在后台保存RDB快照，slave接收到rdb文件并载入，但是这种方式会存在一些问题。</p><ol><li><p>当master禁用RDB时，如果执行了复制初始化操作，Redis依然会生成RDB快照，当master下次启动时执行该RDB文件的恢复，但是因为复制发生的时间点不确定，所以恢复的数据可能是任何时间点的。就会造成数据出现问题</p></li><li><p>当硬盘性能比较慢的情况下（网络硬盘），那初始化复制过程会对性能产生影响</p></li></ol><p>因此2.8.18以后的版本，Redis引入了无硬盘复制选项，可以不需要通过RDB文件去同步，直接发送数据，通过以下配置来开启该功能：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">repl-diskless-sync yes</span><br></pre></td></tr></table></figure><p><strong>master在内存中直接创建rdb，然后发送给slave，不会在自己本地落地磁盘了</strong></p><h3 id="主从复制注意事项"><a href="#主从复制注意事项" class="headerlink" title="主从复制注意事项"></a>主从复制注意事项</h3><p>主从模式解决了数据备份和性能（通过读写分离）的问题，但是还是存在一些不足：</p><p>1、第一次建立复制的时候一定是全量复制，所以如果主节点数据量较大，那么复制延迟就比较长，此时应该尽量避开流量的高峰期，避免造成阻塞；如果有多个从节点需要建立对主节点的复制，可以考虑将几个从节点错开，避免主节点带宽占用过大。此外，如果从节点过多，也可以调整主从复制的拓扑结构，由一主多从结构变为树状结构。</p><p>2、在一主一从或者一主多从的情况下，如果主服务器挂了，对外提供的服务就不可用了，单点问题没有得到解决。如果每次都是手动把之前的从服务器切换成主服务器，这个比较费时费力，还会造成一定时间的服务不可用。</p><h1 id="Master自动选举之Sentinel哨兵机制"><a href="#Master自动选举之Sentinel哨兵机制" class="headerlink" title="Master自动选举之Sentinel哨兵机制"></a>Master自动选举之Sentinel哨兵机制</h1><p>在前面讲的master/slave模式，在一个典型的一主多从的系统中，slave在整个体系中起到了数据冗余备份和读写分离的作用。当master遇到异常终端后，开发者可以通过手动方式选择一个slave数据库来升级到master，使得系统能够继续提供服务。然后这个过程需要人工干预，比较麻烦； redis并没有提供自动master选举功能，而是需要借助一个哨兵来进行监控。</p><h2 id="什么是哨兵"><a href="#什么是哨兵" class="headerlink" title="什么是哨兵"></a>什么是哨兵</h2><p>顾名思义，哨兵的作用就是监控Redis系统的运行状况，它的功能包括两个</p><ol><li><p>监控master和slave是否正常运行</p></li><li><p>master出现故障时自动将slave数据库升级为master</p></li></ol><p>哨兵是一个独立的进程，使用哨兵后的架构如图5-3所示，同时为了保证哨兵的高可用，我们会对Sentinel做集群部署，因此Sentinel不仅仅监控Redis所有的主从节点，Sentinel也会实现相互监控。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191353098.png" alt="image-20210713150113766"></p><center>图5-3</center><h2 id="配置哨兵集群"><a href="#配置哨兵集群" class="headerlink" title="配置哨兵集群"></a>配置哨兵集群</h2><p>在前面主从复制的基础上，增加三个sentinel节点，来实现对redis中master选举的功能。</p><ul><li>192.168.221.128（sentinel）</li><li>192.168.221.129（sentinel）</li><li>192.168.221.130（sentinel）</li></ul><p>sentinel哨兵的配置方式如下：</p><ul><li>从redis-6.0.9源码包中拷贝sentinel.conf文件到redis/bin安装目录下</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp /data/program/redis-6.0.9/sentinel.conf /data/program/redis/sentinel.conf</span><br></pre></td></tr></table></figure><ul><li>修改以下配置</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 其中name表示要监控的master的名字，这个名字是自己定义，ip和port表示master的ip和端口号,最后一个2表示最低通过票数，也就是说至少需要几个哨兵节点认为master下线才算是真的下线</span></span><br><span class="line">sentinel monitor mymaster 192.168.221.128 6379 2 </span><br><span class="line">sentinel down-after-milliseconds mymaster 5000   # 表示如果5s内mymaster没响应，就认为SDOWN</span><br><span class="line">sentinel failover-timeout mymaster 15000         # 表示如果15秒后,mysater仍没活过来，则启动failover，从剩下的slave中选一个升级为master</span><br><span class="line">logfile &quot;/data/program/redis/logs/sentinels.log&quot;  # 需要提前创建好文件</span><br></pre></td></tr></table></figure><ul><li>通过下面这个命令启动sentinel哨兵</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./redis-sentinel ../sentinel.conf</span><br></pre></td></tr></table></figure><ul><li>启动成功后，得到一下信息，表示哨兵启动成功并且开始监控集群节点</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">103323:X 13 Jul 2021 15:16:28.624 # Sentinel ID is 2e9b0ac7ffbfca08e80debff744a4541a31b3951</span><br><span class="line">103323:X 13 Jul 2021 15:16:28.624 # +monitor master mymaster 192.168.221.128 6379 quorum 2</span><br><span class="line">103323:X 13 Jul 2021 15:16:28.627 * +slave slave 192.168.221.129:6379 192.168.221.129 6379 @ mymaster 192.168.221.128 6379</span><br><span class="line">103323:X 13 Jul 2021 15:16:28.628 * +slave slave 192.168.221.130:6379 192.168.221.130 6379 @ mymaster 192.168.221.128 6379</span><br><span class="line">103323:X 13 Jul 2021 15:16:48.765 * +fix-slave-config slave 192.168.221.130:6379 192.168.221.130 6379 @ mymaster 192.168.221.128 6379</span><br><span class="line">103323:X 13 Jul 2021 15:16:48.765 * +fix-slave-config slave 192.168.221.129:6379 192.168.221.129 6379 @ mymaster 192.168.221.128 6379</span><br></pre></td></tr></table></figure><p><strong>其他两个节点的配置和上面完全相同，都去监视master节点即可，主要，sentinel.conf文件中master节点的ip一定不能输127.0.0.1，否则其他sentinel节点无法和它通信</strong></p><p>当其他sentinel哨兵节点启动后，第一台启动的sentinel节点还会输出如下日志，表示有其他sentinel节点加入进来。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">+sentinel sentinel d760d62e190354654490e75e0b427d8ae095ac5a 192.168.221.129 26379 @ mymaster 192.168.221.128 6379</span><br><span class="line">103323:X 13 Jul 2021 15:24:31.421 </span><br><span class="line">+sentinel sentinel dc6d874fe71e4f8f25e15946940f2b8eb087b2e8 192.168.221.130 26379 @ mymaster 192.168.221.128 6379</span><br></pre></td></tr></table></figure><h2 id="模拟master节点故障"><a href="#模拟master节点故障" class="headerlink" title="模拟master节点故障"></a>模拟master节点故障</h2><p>我们直接把redis主从复制集群的master节点，通过<code>./redis-cli shutdown</code>命令停止，于是我们观察三个sentinel哨兵的日志，先来看第一台启动的sentinel日志，得到如下内容。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">103625:X 13 Jul 2021 15:35:01.241 # +new-epoch 9</span><br><span class="line">103625:X 13 Jul 2021 15:35:01.244 # +vote-for-leader d760d62e190354654490e75e0b427d8ae095ac5a 9</span><br><span class="line">103625:X 13 Jul 2021 15:35:01.267 # +odown master mymaster 192.168.221.128 6379 #quorum 2/2</span><br><span class="line">103625:X 13 Jul 2021 15:35:01.267 # Next failover delay: I will not start a failover before Tue Jul 13 15:35:31 2021</span><br><span class="line">103625:X 13 Jul 2021 15:35:02.113 # +config-update-from sentinel d760d62e190354654490e75e0b427d8ae095ac5a 192.168.221.129 26379 @ mymaster 192.168.221.128 6379</span><br><span class="line">103625:X 13 Jul 2021 15:35:02.113 # +switch-master mymaster 192.168.221.128 6379 192.168.221.130 6379</span><br><span class="line">103625:X 13 Jul 2021 15:35:02.113 * +slave slave 192.168.221.129:6379 192.168.221.129 6379 @ mymaster 192.168.221.130 6379</span><br><span class="line">103625:X 13 Jul 2021 15:35:02.113 * +slave slave 192.168.221.128:6379 192.168.221.128 6379 @ mymaster 192.168.221.130 6379</span><br><span class="line">103625:X 13 Jul 2021 15:35:07.153 # +sdown slave 192.168.221.128:6379 192.168.221.128 6379 @ mymaster 192.168.221.130 6379</span><br></pre></td></tr></table></figure><p>+sdown表示哨兵主观认为master已经停止服务了。</p><p>+odown表示哨兵客观认为master停止服务了（关于主观和客观，后面会给大家讲解）。</p><p>接着哨兵开始进行故障恢复，挑选一个slave升级为master，其他哨兵节点的日志。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">76274:X 13 Jul 2021 15:35:01.240 # +try-failover master mymaster 192.168.221.128 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:01.242 # +vote-for-leader d760d62e190354654490e75e0b427d8ae095ac5a 9</span><br><span class="line">76274:X 13 Jul 2021 15:35:01.242 # d760d62e190354654490e75e0b427d8ae095ac5a voted for d760d62e190354654490e75e0b427d8ae095ac5a 9</span><br><span class="line">76274:X 13 Jul 2021 15:35:01.247 # dc6d874fe71e4f8f25e15946940f2b8eb087b2e8 voted for d760d62e190354654490e75e0b427d8ae095ac5a 9</span><br><span class="line">76274:X 13 Jul 2021 15:35:01.247 # 2e9b0ac7ffbfca08e80debff744a4541a31b3951 voted for d760d62e190354654490e75e0b427d8ae095ac5a 9</span><br><span class="line">76274:X 13 Jul 2021 15:35:01.309 # +elected-leader master mymaster 192.168.221.128 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:01.309 # +failover-state-select-slave master mymaster 192.168.221.128 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:01.400 # +selected-slave slave 192.168.221.130:6379 192.168.221.130 6379 @ mymaster 192.168.221.128 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:01.400 * +failover-state-send-slaveof-noone slave 192.168.221.130:6379 192.168.221.130 6379 @ mymaster 192.168.221.128 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:01.477 * +failover-state-wait-promotion slave 192.168.221.130:6379 192.168.221.130 6379 @ mymaster 192.168.221.128 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:02.045 # +promoted-slave slave 192.168.221.130:6379 192.168.221.130 6379 @ mymaster 192.168.221.128 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:02.045 # +failover-state-reconf-slaves master mymaster 192.168.221.128 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:02.115 * +slave-reconf-sent slave 192.168.221.129:6379 192.168.221.129 6379 @ mymaster 192.168.221.128 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:03.070 * +slave-reconf-inprog slave 192.168.221.129:6379 192.168.221.129 6379 @ mymaster 192.168.221.128 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:03.070 * +slave-reconf-done slave 192.168.221.129:6379 192.168.221.129 6379 @ mymaster 192.168.221.128 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:03.133 # +failover-end master mymaster 192.168.221.128 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:03.133 # +switch-master mymaster 192.168.221.128 6379 192.168.221.130 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:03.133 * +slave slave 192.168.221.129:6379 192.168.221.129 6379 @ mymaster 192.168.221.130 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:03.133 * +slave slave 192.168.221.128:6379 192.168.221.128 6379 @ mymaster 192.168.221.130 6379</span><br><span class="line">76274:X 13 Jul 2021 15:35:08.165 # +sdown slave 192.168.221.128:6379 192.168.221.128 6379 @ mymaster 192.168.221.130 6379</span><br></pre></td></tr></table></figure><p><strong>+try-failover</strong>表示哨兵开始进行故障恢复</p><p><strong>+failover-end</strong> 表示哨兵完成故障恢复</p><p><strong>+slave</strong>表示列出新的master和slave服务器，我们仍然可以看到已经停掉的master，哨兵并没有清除已停止的服务的实例，这是因为已经停止的服务器有可能会在某个时间进行恢复，恢复以后会以slave角色加入到整个集群中。</p><h2 id="实现原理"><a href="#实现原理" class="headerlink" title="实现原理"></a>实现原理</h2><p>1)：每个Sentinel以每秒钟一次的频率向它所知的Master/Slave以及其他 Sentinel 实例发送一个 PING 命令 </p><p>2)：如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 <strong>down-after-milliseconds</strong> 选项所指定的值， 则这个实例会被 Sentinel 标记为主观下线。 </p><p>3)：如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。</p><p>4)：当有足够数量的 Sentinel（大于等于配置文件指定的值：quorum）在指定的时间范围内确认Master的确进入了主观下线状态， 则Master会被标记为客观下线 。</p><p>5)：在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有Master，Slave发送 INFO 命令</p><p>6)：当Master被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次 ，若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就会被移除。 </p><p>8)：若 Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。</p><p><strong>主观下线：</strong>Subjectively Down，简称 SDOWN，指的是当前 Sentinel 实例对某个redis服务器做出的下线判断。 </p><p><strong>客观下线：</strong>Objectively Down， 简称 ODOWN，指的是多个 Sentinel 实例在对Master Server做出 SDOWN 判断，并且通过 SENTINEL之间交流后得出Master下线的判断。然后开启failover</p><h2 id="谁来完成故障转移？"><a href="#谁来完成故障转移？" class="headerlink" title="谁来完成故障转移？"></a>谁来完成故障转移？</h2><p>当redis中的master节点被判定为客观下线之后，需要重新从slave节点选择一个作为新的master节点，那现在有三个sentinel节点，应该由谁来完成这个故障转移过程呢？所以这三个sentinel节点必须要通过某种机制达成一致，在Redis中采用了Raft算法来实现这个功能。</p><blockquote><p>每次master出现故障时，都会触发raft算法来选择一个leader完成redis主从集群中的master选举功能。</p></blockquote><h3 id="数据一致性问题"><a href="#数据一致性问题" class="headerlink" title="数据一致性问题"></a>数据一致性问题</h3><p>了解raft算法之前，我们来了解一个拜占庭将军问题。</p><p>拜占庭将军问题（Byzantine failures），是由<strong>莱斯利·兰伯</strong>特提出的点对点通信中的基本问题。具体含义是在存在消息丢失的不可靠信道上试图通过消息传递的方式达到一致性是不可能的。</p><p>拜占庭位于如今的土耳其的伊斯坦布尔，是东罗马帝国的首都。由于当时拜占庭罗马帝国国土辽阔，为了达到防御目的，每个军队都分隔很远，将军与将军之间只能靠信差传消息。在战争的时候，拜占庭军队内所有将军和副官必须达成一致的共识，决定是否有赢的机会才去攻打敌人的阵营。但是，在军队内有可能存有叛徒和敌军的间谍，左右将军们的决定又扰乱整体军队的秩序。在进行共识时，结果并不代表大多数人的意见。这时候，在已知有成员谋反的情况下，其余忠诚的将军在不受叛徒的影响下如何达成一致的协议，这就是是著名的拜占庭问题。</p><p>拜占庭将军问题本质上所描述的是计算机领域中的一个协议问题，拜占庭帝国军队的将军们必须全体一致的决定是否攻击某一支敌军。问题是这些将军在地理上是分隔开来的，并且将军中存在叛徒。叛徒可以任意行动以达到以下目标：</p><ul><li>欺骗某些将军采取进攻行动；</li><li>促成一个不是所有将军都同意的决定，如当将军们不希望进攻时促成进攻行动；</li><li>或者迷惑某些将军，使他们无法做出决定。</li></ul><p>如果叛徒达到了这些目的之一，则任何攻击行动的结果都是注定要失败的，只有完全达成一致的努力才能获得胜利 。</p><p>拜占庭假设是对现实世界的模型化，由于硬件错误、网络拥塞或断开以及遭到恶意攻击，计算机和网络可能出现不可预料的行为，所以如何在这样的环境下达成一致，这就是所谓的数据一致性问题。</p><p>回到Sentinel中，这三个Sentinel节点，需要选择一个节点来负责针对redis集群进行故障恢复，那这三个节点中谁能做这个事情？因此同样需要基于某个机制来达成共识。</p><p>在很多中间件中都需要用到数据一致性算法，最直观的是像zookeeper这样一个组件，他的高可用设计是由leader和follow组成，当leader节点因为异常宕机了， 需要从生下的follow节点选举出一个新的leader节点，那么这个选举过程需要集群中所有节点达成一致，也就是只有所有节点都赞同某个follow节点成为leader，它才能成为leader节点。而这个共识达成的前提是所有节点需要对某个投票结果达成一致，否则就无法选举出新的leader，因此这里必然需要用到共识算法。</p><h3 id="常见的数据一致性算法"><a href="#常见的数据一致性算法" class="headerlink" title="常见的数据一致性算法"></a>常见的数据一致性算法</h3><ul><li>paxos，paxos应该是最早也是最正统的数据一致性算法，也是最复杂难懂的算法。</li><li>raft，raft算法应该是最通俗易懂的一致性算法，它在nacos、sentinel、consul等组件中都有使用。</li><li>zab协议，是zookeeper中基于paxos算法上演变过来的一种一致性算法</li><li>distro，Distro协议。Distro是阿里巴巴的私有协议，目前流行的Nacos服务管理框架就采用了Distro协议。Distro 协议被定位为 <strong>临时数据的一致性协议</strong></li></ul><h3 id="Raft协议说明"><a href="#Raft协议说明" class="headerlink" title="Raft协议说明"></a>Raft协议说明</h3><blockquote><p>Raft算法动画演示地址： <a href="http://thesecretlivesofdata.com/raft/">http://thesecretlivesofdata.com/raft/</a></p></blockquote><p>Raft算法的核心思想：先到先得，少数服从多数。</p><h3 id="故障转移过程"><a href="#故障转移过程" class="headerlink" title="故障转移过程"></a>故障转移过程</h3><p>怎么让一个原来的slave节点成为主节点？</p><ul><li><p>选出Sentinel Leader之后，由Sentinel Leader向某个节点发送slaveof no one命令，让它成为独立节点。</p></li><li><p>然后向其他节点发送replicaof x.x.x.x xxxx（本机服务），让它们成为这个节点的子节点，故障转移完成。</p></li></ul><p>如何选择合适的slave节点成为master呢？有四个因素影响。</p><ul><li>断开连接时长，如果与哨兵连接断开的比较久，超过了某个阈值，就直接失去了选举权</li><li>优先级排序，如果拥有选举权，那就看谁的优先级高，这个在配置文件里可以设置（replica-priority 100），数值越小优先级越高</li><li>复制数量，如果优先级相同，就看谁从master中复制的数据最多（复制偏移量最大）</li><li>进程id，如果复制数量也相同，就选择进程id最小的那个</li></ul><h3 id="Sentinel功能总结"><a href="#Sentinel功能总结" class="headerlink" title="Sentinel功能总结"></a>Sentinel功能总结</h3><p>监控：Sentinel会不断检查主服务器和从服务器是否正常运行。</p><p>通知：如果某一个被监控的实例出现问题，Sentinel可以通过API发出通知。</p><p>自动故障转移（failover）：如果主服务器发生故障，Sentinel可以启动故障转移过程。把某台服务器升级为主服务器，并发出通知。</p><p>配置管理：客户端连接到Sentinel，获取当前的Redis主服务器的地址。</p><h1 id="Redis分布式扩展之Redis-Cluster方案"><a href="#Redis分布式扩展之Redis-Cluster方案" class="headerlink" title="Redis分布式扩展之Redis Cluster方案"></a>Redis分布式扩展之Redis Cluster方案</h1><p>主从切换的过程中会丢失数据，因为只有一个master，只能单点写，没有解决水平扩容的问题。而且每个节点都保存了所有数据，一个是内存的占用率较高，另外就是如果进行数据恢复时，非常慢。而且数据量过大对数据IO操作的性能也会有影响。</p><p>所以我们同样也有对Redis数据分片的需求，所谓分片就是把一份大数据拆分成多份小数据，在3.0之前，我们只能通过构建多个redis主从节点集群，把不同业务数据拆分到不冉的集群中，这种方式在业务层需要有大量的代码来完成数据分片、路由等工作，导致维护成本高、增加、移除节点比较繁琐。</p><p>Redis3.0之后引入了Redis Cluster集群方案，它用来解决分布式扩展的需求，同时也实现了高可用机制。</p><h2 id="Redis-Cluster架构"><a href="#Redis-Cluster架构" class="headerlink" title="Redis Cluster架构"></a>Redis Cluster架构</h2><p>一个Redis Cluster由多个Redis节点构成，不同节点组服务的数据没有交集，也就是每个一节点组对应数据sharding的一个分片。</p><p>节点组内部分为主备两类节点，对应master和slave节点。两者数据准实时一致，通过异步化订的主备复制机制来保证。</p><p>一个节点组有且只有一个master节点，同时可以有0到多个slave节点，在这个节点组中只有master节点对用户提供些服务，读服务可以由master或者slave提供。如图5-4中，包含三个master节点以及三个master对应的slave节点，一般一组集群至少要6个节点才能保证完整的高可用。</p><p>其中三个master会分配不同的slot（表示数据分片区间），当master出现故障时，slave会自动选举成为master顶替主节点继续提供服务。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191353090.png" alt="image-20210713212050665"></p><center>图5-4</center><h3 id="关于gossip协议"><a href="#关于gossip协议" class="headerlink" title="关于gossip协议"></a>关于gossip协议</h3><p>在图5-4描述的架构中，其他的点都好理解，就是关于gossip协议是干嘛的，需要单独说明一下。</p><p>在整个redis cluster架构中，如果出现以下情况</p><ul><li>新加入节点</li><li>slot迁移</li><li>节点宕机</li><li>slave选举成为master</li></ul><p>我们希望这些变化能够让整个集群中的每个节点都能够尽快发现，传播到整个集群并且集群中所有节点达成一致，那么各个节点之间就需要相互连通并且携带相关状态数据进行传播，</p><p>按照正常的逻辑是采用广播的方式想集群中的所有节点发送消息，有点是集群中的数据同步较快，但是每条消息都需要发送给所有节点，对CPU和带宽的消耗过大，所以这里采用了gossip协议。</p><p>Gossip protocol 也叫 Epidemic Protocol （流行病协议），别名很多比如：“流言算法”、“疫情传播算法”等。</p><p>它的特点是，在节点数量有限的网络中，每个节点都会“随机”（不是真正随机，而是根据规则选择通信节点）与部分节点通信，经过一番杂乱无章的通信后，每个节点的状态在一定时间内会达成一致，如图5-5所示。</p><p>假设我们提前设置如下规则：</p><p>1、Gossip 是周期性的散播消息，把周期限定为 1 秒</p><p>2、被感染节点随机选择 k 个邻接节点（fan-out）散播消息，这里把 fan-out 设置为 3，每次最多往 3 个节点散播。</p><p>3、每次散播消息都选择尚未发送过的节点进行散播</p><p>4、收到消息的节点不再往发送节点散播，比如 A -&gt; B，那么 B 进行散播的时候，不再发给 A。</p><p>这里一共有 16 个节点，节点 1 为初始被感染节点，通过 Gossip 过程，最终所有节点都被感染：</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191353348.gif" alt="在这里插入图片描述"></p><center>图5-5</center><h3 id="gossip协议消息"><a href="#gossip协议消息" class="headerlink" title="gossip协议消息"></a>gossip协议消息</h3><p>gossip协议包含多种消息，包括ping，pong，meet，fail等等。</p><p><strong>ping</strong>：每个节点都会频繁给其他节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据；</p><p><strong>pong</strong>: 返回ping和meet，包含自己的状态和其他信息，也可以用于信息广播和更新；</p><p><strong>fail</strong>: 某个节点判断另一个节点fail之后，就发送fail给其他节点，通知其他节点，指定的节点宕机了。</p><p><strong>meet</strong>：某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信，不需要发送形成网络的所需的所有CLUSTER MEET命令。发送CLUSTER MEET消息以便每个节点能够达到其他每个节点只需通过一条已知的节点链就够了。由于在心跳包中会交换gossip信息，将会创建节点间缺失的链接。</p><h3 id="gossip的优缺点"><a href="#gossip的优缺点" class="headerlink" title="gossip的优缺点"></a>gossip的优缺点</h3><p><strong>优点：</strong> gossip协议的优点在于元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新有一定的延时，降低了压力； 去中心化、可扩展、容错、一致性收敛、简单。 由于不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，因此它是一个最终一致性协议。</p><p><strong>缺点：</strong> 元数据更新有延时可能导致集群的一些操作会有一些滞后。 消息的延迟 ， 消息冗余 。</p><h3 id="Redis-Cluster集群搭建"><a href="#Redis-Cluster集群搭建" class="headerlink" title="Redis Cluster集群搭建"></a>Redis Cluster集群搭建</h3><p>集群至少需要6个节点（3主3从模式），每一个节点可以搭建在同一台机器上，也可以搭建在不同的服务器上。</p><ul><li><p>192.168.221.128   7000 、 7001</p></li><li><p>192.168.221.129   7002 、 7003</p></li><li><p>192.168.221.130  7004 、  7005</p></li></ul><h3 id="分别启动6个节点。"><a href="#分别启动6个节点。" class="headerlink" title="分别启动6个节点。"></a>分别启动6个节点。</h3><ul><li>在redis安装目录下，分别创建以下目录，这些目录必须要提前创建好，redis启动时不会主动创建这些目录。</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mkdir -p /data/program/redis/run</span><br><span class="line">mkdir -p /data/program/redis/logs</span><br><span class="line">mkdir -p /data/program/redis/data/7000、7001</span><br><span class="line">mkdir -p /data/program/redis/conf</span><br><span class="line">mkdir -p /data/program/redis/redis-cluster</span><br></pre></td></tr></table></figure><ul><li>拷贝一份redis.conf到redis-cluster目录下，由于只有三台机器，所以每个机器上需要运行两个redis-server，因此需要修改redis.conf文件的名字来做区分，redis_7000.conf。并且修改该文件的一下内容。</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pidfile &quot;/data/program/redis/run/redis_7000.pid&quot;   #pid存储目录</span><br><span class="line">logfile &quot;/data/program/redis/logs/redis_7000.log&quot;  #日志存储目录</span><br><span class="line">dir &quot;/data/program/redis/data/7000&quot;   #数据存储目录，目录要提前创建好</span><br><span class="line">cluster-enabled yes                   #开启集群</span><br><span class="line">cluster-config-file nodes-7000.conf   #集群节点配置文件，这个文件是不能手动编辑的。确保每一个集群节点的配置文件不同</span><br><span class="line">cluster-node-timeout 15000            #集群节点的超时时间，单位：ms，超时后集群会认为该节点失败</span><br></pre></td></tr></table></figure><ul><li>每个节点需要启动两个redis-server，所以对配置文件做一份拷贝，然后修改以下配置</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pidfile &quot;/data/program/redis/run/redis_7001.pid&quot;   #pid存储目录</span><br><span class="line">logfile &quot;/data/program/redis/logs/redis_7001.log&quot;  #日志存储目录</span><br><span class="line">dir &quot;/data/program/redis/data/7001&quot;   #数据存储目录，目录要提前创建好</span><br><span class="line">cluster-enabled yes                   #开启集群</span><br><span class="line">cluster-config-file nodes-7001.conf   #集群节点配置文件，这个文件是不能手动编辑的。确保每一个集群节点的配置文件不同</span><br><span class="line">cluster-node-timeout 15000            #集群节点的超时时间，单位：ms，超时后集群会认为该节点失败</span><br></pre></td></tr></table></figure><ul><li><p>创建两个脚本用来进行统一的服务运行</p><p><strong>cluster-start.sh</strong></p></li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">./redis-server ../conf/redis_7000.conf</span><br><span class="line">./redis-server ../conf/redis_7001.conf</span><br></pre></td></tr></table></figure><p>  <strong>cluster-shutdown.sh</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pgrep redis-server | xargs -exec kill -9</span><br></pre></td></tr></table></figure><p>  通过下面命令让上述脚本拥有执行权限</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">chmod +x cluster-*.sh</span><br></pre></td></tr></table></figure><ul><li>其他两个节点重复上述的过程，完成6个节点的启动。</li></ul><h3 id="配置redis-集群"><a href="#配置redis-集群" class="headerlink" title="配置redis 集群"></a>配置redis 集群</h3><p>启动完这5台服务器后，需要通过下面的操作来配置集群节点。在redis6.0版本中，创建集群的方式为redis-cli方式直接创建，以下命令在任意一台服务器上执行即可</p><p>用以下命令创建集群，–cluster-replicas 1 参数表示希望每个主服务器都有一个从服务器，这里则代表3主3从，通过该方式创建的带有从节点的机器不能够自己手动指定主节点，redis集群会尽量把主从服务器分配在不同机器上</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# ./redis-cli --cluster create 192.168.221.128:7000 192.168.221.128:7001 192.168.221.129 7002 192.168.221.129 7003 192.168.221.130 7004 192.168.221.130 7005 --cluster-replicas 1</span><br></pre></td></tr></table></figure><p>执行上述命令后，会得到以下执行结果，</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">&gt;</span><span class="bash">&gt;&gt; Performing <span class="built_in">hash</span> slots allocation on 6 nodes...</span></span><br><span class="line">Master[0] -&gt; Slots 0 - 5460</span><br><span class="line">Master[1] -&gt; Slots 5461 - 10922</span><br><span class="line">Master[2] -&gt; Slots 10923 - 16383</span><br><span class="line">Adding replica 192.168.221.129:7003 to 192.168.221.128:7000</span><br><span class="line">Adding replica 192.168.221.130:7005 to 192.168.221.129:7002</span><br><span class="line">Adding replica 192.168.221.128:7001 to 192.168.221.130:7004</span><br><span class="line">M: 36d34fd3985179786eeab50338e3972608df2f21 192.168.221.128:7000  #master</span><br><span class="line">   slots:[0-5460] (5461 slots) master</span><br><span class="line">S: 202028cfaf69fd5c8fcd5b7b75677d6963184ad9 192.168.221.128:7001</span><br><span class="line">   replicates 124683446267c8910cd080238e72e3b1b589f41f</span><br><span class="line">M: 5927296015093b9474fed5a354c4a04b9345e7a9 192.168.221.129:7002   #master</span><br><span class="line">   slots:[5461-10922] (5462 slots) master</span><br><span class="line">S: 089b77cb753c1ef62bd10f23230c38d4a0a64a09 192.168.221.129:7003</span><br><span class="line">   replicates 36d34fd3985179786eeab50338e3972608df2f21</span><br><span class="line">M: 124683446267c8910cd080238e72e3b1b589f41f 192.168.221.130:7004   #master</span><br><span class="line">   slots:[10923-16383] (5461 slots) master</span><br><span class="line">S: 82a9fe027179f197ff82547863c4252de8ba1354 192.168.221.130:7005</span><br><span class="line">   replicates 5927296015093b9474fed5a354c4a04b9345e7a9</span><br><span class="line">Can I set the above configuration? (type &#x27;yes&#x27; to accept): yes</span><br></pre></td></tr></table></figure><p>从上述结果中看到两个点：</p><ul><li>预先分配三个节点的slot区间</li><li>自动选择合适的节点作为master</li></ul><h3 id="查看集群状态等信息"><a href="#查看集群状态等信息" class="headerlink" title="查看集群状态等信息"></a>查看集群状态等信息</h3><ul><li>cluster info 查看集群状态信息</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">[root@localhost bin]# ./redis-cli -p 7000</span><br><span class="line">127.0.0.1:7000&gt; cluster info</span><br><span class="line">cluster_state:ok</span><br><span class="line">cluster_slots_assigned:16384</span><br><span class="line">cluster_slots_ok:16384</span><br><span class="line">cluster_slots_pfail:0</span><br><span class="line">cluster_slots_fail:0</span><br><span class="line">cluster_known_nodes:6</span><br><span class="line">cluster_size:3</span><br><span class="line">cluster_current_epoch:6</span><br><span class="line">cluster_my_epoch:1</span><br><span class="line">cluster_stats_messages_ping_sent:276</span><br><span class="line">cluster_stats_messages_pong_sent:262</span><br><span class="line">cluster_stats_messages_sent:538</span><br><span class="line">cluster_stats_messages_ping_received:257</span><br><span class="line">cluster_stats_messages_pong_received:276</span><br><span class="line">cluster_stats_messages_meet_received:5</span><br><span class="line">cluster_stats_messages_received:538</span><br></pre></td></tr></table></figure><ul><li>查看集群节点信息</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:7000&gt; cluster nodes</span><br><span class="line">5927296015093b9474fed5a354c4a04b9345e7a9 192.168.221.129:7002@17002 master - 0 1626247374000 3 connected 5461-10922</span><br><span class="line">36d34fd3985179786eeab50338e3972608df2f21 192.168.221.128:7000@17000 myself,master - 0 1626247375000 1 connected 0-5460</span><br><span class="line">82a9fe027179f197ff82547863c4252de8ba1354 192.168.221.130:7005@17005 slave 5927296015093b9474fed5a354c4a04b9345e7a9 0 1626247376000 3 connected</span><br><span class="line">089b77cb753c1ef62bd10f23230c38d4a0a64a09 192.168.221.129:7003@17003 slave 36d34fd3985179786eeab50338e3972608df2f21 0 1626247375000 1 connected</span><br><span class="line">124683446267c8910cd080238e72e3b1b589f41f 192.168.221.130:7004@17004 master - 0 1626247376830 5 connected 10923-16383</span><br><span class="line">202028cfaf69fd5c8fcd5b7b75677d6963184ad9 192.168.221.128:7001@17001 slave 124683446267c8910cd080238e72e3b1b589f41f 0 1626247375000 5 connected</span><br></pre></td></tr></table></figure><h2 id="数据分布"><a href="#数据分布" class="headerlink" title="数据分布"></a>数据分布</h2><p>Redis Cluster中，Sharding采用slot(槽)的概念，一共分成16384个槽，这有点儿类似pre sharding思路。对于每个进入Redis的键值对，根据key进行散列，分配到这16384个slot中的某一个中。使用的hash算法也比较简单，就是CRC16后16384取模**[<strong>crc16(key)%16384</strong>]**。</p><p>Redis集群中的每个node(节点)负责分摊这16384个slot中的一部分，也就是说，每个slot都对应一个node负责处理。</p><p>如图5-6所示，<em>假设现在我们是三个主节点分别是：A, B, C 三个节点，它们可以是一台机器上的三个端口，也可以是三台不同的服务器。那么，采用哈希槽 (hash slot)的方式来分配16384个slot 的话，它们三个节点分别承担的slot 区间是：</em></p><ul><li><p>节点A覆盖0－5000;</p></li><li><p>节点B覆盖5001－10000;</p></li><li><p>节点C覆盖10001－16383</p></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191353802.png" alt="image-20210713220135369"></p><center>图5-6</center><h2 id="客户端重定向"><a href="#客户端重定向" class="headerlink" title="客户端重定向"></a>客户端重定向</h2><p>如图5-6所示，假设k这个key应该存储在node3上，而此时用户在node1或者node2上调用<code>set k v</code>指令，这个时候redis cluster怎么处理呢？</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:7291&gt; set qs 1</span><br><span class="line">(error) MOVED 13724 127.0.0.1:7293</span><br></pre></td></tr></table></figure><p>服务端返回MOVED，也就是根据key计算出来的slot不归当前节点管理，服务端返回MOVED告诉客户端去7293端口操作。</p><p>这个时候更换端口，用redis-cli –p 7293操作，才会返回OK。或者用./redis-cli -c -p port的命令。但是导致的问题是，客户端需要连接两次才能完成操作。所以大部分的redis客户端都会在本地维护一份slot和node的对应关系，在执行指令之前先计算当前key应该存储的目标节点，然后再连接到目标节点进行数据操作。</p><p>在redis集群中提供了下面的命令来计算当前key应该属于哪个slot</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> cluster keyslot key1</span></span><br></pre></td></tr></table></figure><h2 id="高可用主从切换原理"><a href="#高可用主从切换原理" class="headerlink" title="高可用主从切换原理"></a>高可用主从切换原理</h2><p><strong>如果主节点没有从节点，那么当它发生故障时，集群就将处于不可用状态。</strong></p><p>一旦某个master节点进入到FAIL状态，那么整个集群都会变成FAIL状态，同时触发failover机制，failover的目的是从slave节点中选举出新的主节点，使得集群可以恢复正常，这个过程实现如下：</p><p>当slave发现自己的master变为FAIL状态时，便尝试进行Failover，以期成为新的master。由于挂掉的master可能会有多个slave，从而存在多个slave竞争成为master节点的过程， 其过程如下：</p><ul><li>slave发现自己的master变为FAIL</li><li>将自己记录的集群currentEpoch加1，并广播FAILOVER_AUTH_REQUEST 信息</li><li>其他节点收到该信息，只有master响应，判断请求者的合法性，并发送FAILOVER_AUTH_ACK，对每一个epoch只发送一次ack</li><li>尝试failover的slave收集master返回的FAILOVER_AUTH_ACK</li><li>slave收到超过半数master的ack后变成新Master (这里解释了集群为什么至少需要三个主节点，如果只有两个，当其中一个挂了，只剩一个主节点是不能选举成功的)</li><li>广播Pong消息通知其他集群节点。</li></ul><p>从节点并不是在主节点一进入 FAIL 状态就马上尝试发起选举，而是有一定延迟，一定的延迟确保我们等待FAIL状态在集群中传播，slave如果立即尝试选举，其它masters或许尚未意识到FAIL状态，可能会拒绝投票。</p><p>延迟计算公式： DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms</p><p>SLAVE_RANK表示此slave已经从master复制数据的总量的rank。Rank越小代表已复制的数据越新。这种方式下，持有最新数据的slave将会首先发起选举</p><h2 id="常见问题分析"><a href="#常见问题分析" class="headerlink" title="常见问题分析"></a>常见问题分析</h2><p><strong>问题：怎么让相关的数据落到同一个节点上？</strong></p><p>比如有些multi key操作是不能跨节点的，例如用户2673的基本信息和金融信息？</p><p>在key里面加入{hash tag}即可。Redis在计算槽编号的时候只会获取{}之间的字符串进行槽编号计算，这样由于上面两个不同的键，{}里面的字符串是相同的，因此他们可以被计算出相同的槽</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">user&#123;2673&#125;base=…</span><br><span class="line">user&#123;2673&#125;fin=…</span><br></pre></td></tr></table></figure><p>操作步骤如下，下面这些key都会保存到同一个node中。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">127.0.0.1:7293&gt; set a&#123;qs&#125;a 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7293&gt; set a&#123;qs&#125;b 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7293&gt; set a&#123;qs&#125;c 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7293&gt; set a&#123;qs&#125;d 1</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:7293&gt; set a&#123;qs&#125;e 1</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><strong>优势</strong></p><ol><li><p>无中心架构。</p></li><li><p>数据按照slot存储分布在多个节点，节点间数据共享，可动态调整数据分布。</p></li><li><p>可扩展性，可线性扩展到1000个节点（官方推荐不超过1000个），节点可动态添加或删除。</p></li><li><p>高可用性，部分节点不可用时，集群仍可用。通过增加Slave做standby数据副本，能够实现故障自动failover，节点之间通过gossip协议交换状态信息，用投票机制完成Slave到Master的角色提升。</p></li><li><p>降低运维成本，提高系统的扩展性和可用性。</p></li></ol><p><strong>不足</strong></p><ol><li>Client实现复杂，驱动要求实现Smart Client，缓存slots mapping信息并及时更新，提高了开发难度，客户端的不成熟影响业务的稳定性。</li><li>节点会因为某些原因发生阻塞（阻塞时间大于clutser-node-timeout），被判断下线，这种failover是没有必要的。</li><li>数据通过异步复制，不保证数据的强一致性。</li><li>多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。</li><li>Slave在集群中充当“冷备”，不能缓解读压力，当然可以通过SDK的合理设计来提高Slave资源的利用率。</li></ol><h2 id="Redission连接cluster"><a href="#Redission连接cluster" class="headerlink" title="Redission连接cluster"></a>Redission连接cluster</h2><p>修改redisson.yml文件，参考spring-boot-redis-client-example这个项目</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="attr">clusterServersConfig</span>:<span class="string"></span></span><br><span class="line">  <span class="attr">nodeAddresses</span>:<span class="string"></span></span><br><span class="line">    <span class="meta">-</span> <span class="string">&quot;redis://192.168.221.129:7003&quot;</span></span><br><span class="line">    <span class="meta">-</span> <span class="string">&quot;redis://192.168.221.129:7002&quot;</span></span><br><span class="line">    <span class="meta">-</span> <span class="string">&quot;redis://192.168.221.130:7004&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="attr">codec</span>: <span class="string">!&lt;org.redisson.codec.JsonJacksonCodec&gt; &#123;&#125;</span></span><br></pre></td></tr></table></figure><p>注意，nodeAddresses对应的节点都是master。</p><h1 id="Codis"><a href="#Codis" class="headerlink" title="Codis"></a>Codis</h1><p>Codis 是一个分布式 Redis 解决方案, 对于上层的应用来说, 连接到 Codis Proxy 和连接原生的 Redis Server 没有明显的区别(不支持的命令列表), 上层应用可以像使用单机的 Redis 一样使用, Codis 底层会处理请求的转发, 不停机的数据迁移等工作,<br>所有后边的一切事情, 对于前面的客户端来说是透明的, 可以简单的认为后边连接的是一个内存无限大的 Redis 服务。</p><h2 id="codis的架构"><a href="#codis的架构" class="headerlink" title="codis的架构"></a>codis的架构</h2><p>如图5-7所示，表示Codis的整体架构图。</p><p><strong>Codis Proxy</strong>： 客户端连接的 Redis 代理服务, 实现了 Redis 协议。 除部分命令不支持以外(不支持的命令列表)，表现的和原生的 Redis 没有区别（就像 Twemproxy）。对于同一个业务集群而言，可以同时部署多个 codis-proxy 实例；不同 codis-proxy 之间由 codis-dashboard 保证状态同<br><strong>codis-redis-group:</strong> 代表一个redis服务集群节点，一个RedisGroup里有一个Master，和多个Slave</p><p><strong>Zookeeper：</strong>Codis 依赖 ZooKeeper 来存放数据路由表和 codis-proxy 节点的元信息, codis-config 发起的命令都会通过 ZooKeeper 同步到各个存活的 codis-proxy.</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191353989.png"></p><center>图5-7</center>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 高可用 </tag>
            
            <tag> Redis高可用设计 </tag>
            
            <tag> Codis </tag>
            
            <tag> Redis Cluster </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度剖析Redis6的持久化机制（大量图片说明，简洁易懂）</title>
      <link href="/posts/2542151685/"/>
      <url>/posts/2542151685/</url>
      
        <content type="html"><![CDATA[<p>Redis的强劲性能很大程度上是由于它所有的数据都存储在内存中，当然如果redis重启或者服务器故障导致redis重启，所有存储在内存中的数据就会丢失。但是在某些情况下，我们希望Redis在重启后能够保证数据不会丢失。</p><ol><li><p>将redis作为nosql数据库使用。</p></li><li><p>将Redis作为高效缓存服务器，缓存被击穿后对后端数据库层面的瞬时压力是特别大的，所有缓存同时失效可能会导致雪崩。</p></li></ol><p>这时我们希望Redis能将数据从内存中以某种形式同步到硬盘上，使得重启后可以根据硬盘中的记录来恢复数据。</p><p>Redis支持两种方式的持久化，一种是RDB方式、另一种是AOF（append-only-file）方式，两种持久化方式可以单独使用其中一种，也可以将这两种方式结合使用。</p><ul><li><strong>RDB</strong>：根据指定的规则“<strong>定时</strong>”将内存中的数据存储在硬盘上，</li><li><strong>AOF</strong>：每次执行命令后将命令本身记录下来。</li></ul><h1 id="RDB模式"><a href="#RDB模式" class="headerlink" title="RDB模式"></a>RDB模式</h1><p>RDB的持久化方式是通过快照（snapshotting）完成的，它是Redis默认的持久化方式，配置如下。</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># save 3600 1</span></span><br><span class="line"><span class="comment"># save 300 100</span></span><br><span class="line"><span class="comment"># save 60 10000</span></span><br></pre></td></tr></table></figure><p>Redis允许用户自定义快照条件，当符合快照条件时，Redis会自动执行快照操作。快照的条件可以由用户在配置文件中配置。配置格式如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">save &lt;seconds&gt; &lt;changes&gt;</span><br></pre></td></tr></table></figure><p>第一个参数是时间窗口，第二个是键的个数，也就是说，在第一个时间参数配置范围内被更改的键的个数大于后面的changes时，即符合快照条件。当触发条件时，Redis会自动将内存中的数据生成一份副本并存储在磁盘上，</p><p>这个过程称之为“快照”，除了上述规则之外，还有以下几种方式生成快照。</p><ol><li>根据配置规则进行自动快照</li><li>用户执行SAVE或者GBSAVE命令</li><li>执行FLUSHALL命令</li><li>执行复制(replication)时</li></ol><h2 id="根据配置规则进行自动快照"><a href="#根据配置规则进行自动快照" class="headerlink" title="根据配置规则进行自动快照"></a>根据配置规则进行自动快照</h2><ul><li>修改redis.conf文件，表示5秒内，有一个key发生变化，就会生成rdb文件。</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">save 5 1                # 表示3600s以内至少发生1个key变化（新增、修改、删除），则重写rdb文件</span><br><span class="line">save 300 100</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure><ul><li><p>修改文件存储路径</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dir /data/program/redis/bin</span><br></pre></td></tr></table></figure></li><li><p>其他参数配置说明</p><table><thead><tr><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>dir</td><td>rdb文件默认在启动目录下（相对路径） <code>config get dir</code> 获取</td></tr><tr><td>dbfilename</td><td>文件名称</td></tr><tr><td>rdbcompression</td><td>开启压缩可以节省存储空间，但是会消耗一些CPU的计算时间，默认开启</td></tr><tr><td>rdbchecksum</td><td>使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。</td></tr></tbody></table></li></ul><p><strong>如果需要关闭RDB的持久化机制，可以参考如下配置，开启<code>save</code>，并注释其他规则即可</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">save &quot;&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash">save 900 1</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 300 10</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 60 10000</span></span><br></pre></td></tr></table></figure><h2 id="用户执行SAVE或者GBSAVE命令"><a href="#用户执行SAVE或者GBSAVE命令" class="headerlink" title="用户执行SAVE或者GBSAVE命令"></a>用户执行SAVE或者GBSAVE命令</h2><p>除了让Redis自动进行快照以外，当我们对服务进行重启或者服务器迁移我们需要人工去干预备份。redis提供了两条命令来完成这个任务</p><ol><li><p><strong>save命令</strong></p><p>如图4-24所示，当执行save命令时，Redis同步做快照操作，在快照执行过程中会阻塞所有来自客户端的请求。当redis内存中的数据较多时，通过该命令将导致Redis较长时间的不响应。所以不建议在生产环境上使用这个命令，而是推荐使用bgsave命令</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191352820.png" alt="image-20210712184050955"></p><center>图4-24</center></li><li><p><strong>bgsave命令</strong></p><p>如图4-25所示，bgsave命令可以在后台异步地进行快照操作，快照的同时服务器还可以继续响应来自客户端的请求。执行BGSAVE后，Redis会立即返回ok表示开始执行快照操作，在redis-cli终端，通过下面这个命令可以获取最近一次成功执行快照的时间（以 UNIX 时间戳格式表示）。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">LASTSAVE</span><br></pre></td></tr></table></figure></li></ol><p>1：redis使用fork函数复制一份当前进程的副本(子进程)</p><p>2：父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件</p><p>3：当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此，一次快照操作完成。 </p><blockquote><p>注意：redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。 这就使得我们可以通过定时备份RDB文件来实现redis数据库的备份， RDB文件是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。</p><p><strong>bgsave是异步执行快照的，bgsave写入的数据就是for进程时redis的数据状态，一旦完成fork，后续执行的新的客户端命令对数据产生的变更都不会反应到本次快照</strong></p></blockquote><p>Redis启动后会读取RDB快照文件，并将数据从硬盘载入到内存。根据数据量大小以及服务器性能不同，这个载入的时间也不同。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191352242.png" alt="image-20210712183559812"></p><center>图4-25</center><h2 id="执行FLUSHALL命令"><a href="#执行FLUSHALL命令" class="headerlink" title="执行FLUSHALL命令"></a>执行FLUSHALL命令</h2><p>该命令在前面讲过，会清除redis在内存中的所有数据。执行该命令后，只要redis中配置的快照规则不为空，</p><p>也就是save 的规则存在。redis就会执行一次快照操作。不管规则是什么样的都会执行。如果没有定义快照规则，就不会执行快照操作。</p><h2 id="执行复制-replication-时"><a href="#执行复制-replication-时" class="headerlink" title="执行复制(replication)时"></a>执行复制(replication)时</h2><p>该操作主要是在主从模式下，redis会在复制初始化时进行自动快照。这个会在后面讲到；</p><p>这里只需要了解当执行复制操作时，即时没有定义自动快照规则，并且没有手动执行过快照操作，它仍然会生成RDB快照文件。</p><h2 id="RDB数据恢复演示"><a href="#RDB数据恢复演示" class="headerlink" title="RDB数据恢复演示"></a>RDB数据恢复演示</h2><ul><li>准备初始数据</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k1 1</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k2 2</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k3 3</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k4 4</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k5 5</span></span><br></pre></td></tr></table></figure><ul><li><p>通过shutdown命令关闭触发save</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> shutdown</span></span><br></pre></td></tr></table></figure></li><li><p>备份dump.rdb文件(用来后续恢复)</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp dump.rdb dump.rdb.bak</span><br></pre></td></tr></table></figure></li><li><p>接着再启动redis-server(systemctl restart redis_6379)，通过keys命令查看，发现数据还在</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">keys *</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>模拟数据丢失</p></blockquote><ul><li><p>执行flushall</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> flushall</span></span><br></pre></td></tr></table></figure></li><li><p>shutdown(重新生成没有数据的快照，用来模拟后续的数据恢复)</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> shutdown</span></span><br></pre></td></tr></table></figure></li><li><p>再次启动redis, 通过keys 命令查看，此时rdb中没有任何数据。</p></li><li><p>恢复之前备份的rdb文件（之前保存了数据的rdb快照）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv dump.rdb.bak dump.rdb</span><br></pre></td></tr></table></figure></li><li><p>再次重启redis，可以看到之前快照保存的数据</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">keys *</span><br></pre></td></tr></table></figure></li></ul><h2 id="文件的优势和劣势"><a href="#文件的优势和劣势" class="headerlink" title="文件的优势和劣势"></a>文件的优势和劣势</h2><p><strong>一、优势</strong></p><p>　　1.RDB是一个非常紧凑(compact)的文件，它保存了redis 在某个时间点上的数据集，这种文件非常适合用于进行备份和灾难恢复。</p><p>　　2.生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。</p><p>　　3.RDB 在恢复大数据集时的速度比AOF的恢复速度要快。</p><p><strong>二、劣势</strong></p><ul><li><p>1、RDB方式数据没办法做到实时持久化/秒级持久化。因为bgsave每次运行都要执行fork操作创建子进程，频繁执行成本过高</p></li><li><p>2、在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照之后的所有修改（数据有丢失）。</p></li></ul><p><strong>如果数据相对来说比较重要，希望将损失降到最小，则可以使用AOF方式进行持久化。</strong></p><h1 id="AOF模式"><a href="#AOF模式" class="headerlink" title="AOF模式"></a>AOF模式</h1><p>AOF(Append Only File)：Redis 默认不开启。AOF采用日志的形式来记录每个写操作，并<strong>追加</strong>到文件中。开启后，执行更改Redis数据的命令时，就会把命令写入到AOF文件中。</p><p>Redis 重启时会根据日志文件的内容把写指令从前到后执行一次以完成数据的恢复工作。</p><h2 id="AOF配置开关"><a href="#AOF配置开关" class="headerlink" title="AOF配置开关"></a>AOF配置开关</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 开关</span></span><br><span class="line">appendonly no  /yes</span><br><span class="line"><span class="meta">#</span><span class="bash"> 文件名</span></span><br><span class="line">appendfilename &quot;appendonly.aof&quot;</span><br></pre></td></tr></table></figure><p>通过修改redis.conf重启redis之后：systemctl restart redis_6379。</p><p>再次运行redis的相关操作命令，会发现在指定的<code>dir</code>目录下生成appendonly.aof文件，通过vim查看该文件内容如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">*2</span><br><span class="line"><span class="meta">$</span><span class="bash">6</span></span><br><span class="line">SELECT</span><br><span class="line"><span class="meta">$</span><span class="bash">1</span></span><br><span class="line">0</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">name</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">mic</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">name</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">123</span><br></pre></td></tr></table></figure><h2 id="AOF配置相关问题解答"><a href="#AOF配置相关问题解答" class="headerlink" title="AOF配置相关问题解答"></a>AOF配置相关问题解答</h2><p><strong>问题1：数据都是实时持久化到磁盘吗？</strong></p><p>虽然每次执行更改Redis数据库内容的操作时，AOF都会将命令记录在AOF文件中，但是事实上，由于操作系统的缓存机制，数据并没有真正地写入硬盘，而是进入了系统的硬盘缓存。在默认情况下系统每30秒会执行一次同步操作。以便将硬盘缓存中的内容真正地写入硬盘。</p><p>在这30秒的过程中如果系统异常退出则会导致硬盘缓存中的数据丢失。一般来说能够启用AOF的前提是业务场景不能容忍这样的数据损失，这个时候就需要Redis在写入AOF文件后主动要求系统将缓存内容同步到硬盘中。在redis.conf中通过如下配置来设置同步机制。</p><table><thead><tr><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>appendfsync everysec</td><td>AOF持久化策略（硬盘缓存到磁盘），默认<strong>everysec</strong> <br /> 1 no  表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快，但是不太安全；  <br /> 2 always  表示每次写入都执行fsync，以保证数据同步到磁盘，效率很低；<br /> 3 everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。通常选择 everysec ，兼顾安全性和效率。</td></tr></tbody></table><p><strong>问题2：文件越来越大，怎么办？</strong></p><p>由于AOF持久化是Redis不断将写命令记录到 AOF 文件中，随着Redis不断的运行，AOF 的文件会越来越大，文件越大，占用服务器内存越大以及 AOF 恢复要求时间越长。</p><p><strong>例如set gupao 666，执行1000次，结果都是gupao=666。</strong></p><p>为了解决这个问题，Redis新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。</p><p>可以使用命令下面这个命令主动触发重写</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> bgrewriteaof</span></span><br></pre></td></tr></table></figure><p>AOF 文件重写并不是对原文件进行重新整理，而是直接读取服务器现有的键值对，然后用一条命令去代替之前记录这个键值对的多条命令，生成一个新的文件后去替换原来的 AOF 文件。</p><p><strong>重写触发机制如下</strong></p><table><thead><tr><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>auto-aof-rewrite-percentage</td><td>默认值为100。表示的是当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时AOF文件大小为依据</td></tr><tr><td>auto-aof-rewrite-min-size</td><td>默认64M。表示限制了允许重写的最小AOF文件大小，通常在AOF文件很小的情况下即使其中有很多冗余的命令我们也并不太关心</td></tr></tbody></table><p>在启动时，Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相对于RDB会慢一些</p><p><strong>问题：重写过程中，AOF文件被更改了怎么办？</strong></p><p>Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 </p><p>重写的流程是这样，</p><ul><li>主进程会fork一个子进程出来进行AOF重写，这个重写过程并不是基于原有的aof文件来做的，而是有点类似于快照的方式，全量遍历内存中的数据，然后逐个序列到aof文件中。</li><li>在fork子进程这个过程中，服务端仍然可以对外提供服务，<strong>那这个时候重写的aof文件的数据和redis内存数据不一致了怎么办？</strong>不用担心，这个过程中，主进程的数据更新操作，会缓存到<strong>aof_rewrite_buf</strong>中，也就是单独开辟一块缓存来存储重写期间收到的命令，当子进程重写完以后再把缓存中的数据追加到新的aof文件。</li><li>当所有的数据全部追加到新的aof文件中后，把新的aof文件重命名正式的文件名字，此后所有的操作都会被写入新的aof文件。</li><li>如果在rewrite过程中出现故障，不会影响原来aof文件的正常工作，只有当rewrite完成后才会切换文件。因此这个rewrite过程是比较可靠的。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191352315.png" alt="img"></p><center>图4-26</center><p>Redis允许同时开启AOF和RDB，既保证了数据安全又使得进行备份等操作十分容易。如果同时开启后，Redis重启会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的数据更少。</p><h2 id="AOF的优劣势"><a href="#AOF的优劣势" class="headerlink" title="AOF的优劣势"></a>AOF的优劣势</h2><p><strong>优点：</strong></p><p>1、AOF 持久化的方法提供了多种的同步频率，即使使用默认的同步频率每秒同步一次，Redis 最多也就丢失 1 秒的数据而已。</p><p><strong>缺点：</strong></p><p>1、对于具有相同数据的的Redis，AOF 文件通常会比 RDB 文件体积更大（RDB存的是数据快照）。</p><p>2、虽然 AOF 提供了多种同步的频率，默认情况下，每秒同步一次的频率也具有较高的性能。在高并发的情况下，RDB 比 AOF 具好更好的性能保证。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 高性能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Redis持久化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>时间轮机制在Redisson分布式锁中的实际应用以及时间轮源码分析</title>
      <link href="/posts/1553902520/"/>
      <url>/posts/1553902520/</url>
      
        <content type="html"><![CDATA[<p>本篇文章主要基于Redisson中实现的分布式锁机制继续进行展开，分析Redisson中的时间轮机制。</p><p>在前面分析的Redisson的分布式锁实现中，有一个Watch Dog机制来对锁键进行续约，代码如下:</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">renewExpiration</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ExpirationEntry ee = EXPIRATION_RENEWAL_MAP.get(getEntryName());</span><br><span class="line">    <span class="keyword">if</span> (ee == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//用到了时间轮机制</span></span><br><span class="line">    Timeout task = commandExecutor.getConnectionManager().newTimeout(<span class="keyword">new</span> TimerTask() &#123;</span><br><span class="line">        <span class="comment">//添加一个任务到时间轮 </span></span><br><span class="line">        <span class="comment">//省略部分代码....</span></span><br><span class="line">    &#125;, internalLockLeaseTime / <span class="number">3</span>, TimeUnit.MILLISECONDS);<span class="comment">//每次间隔租期的1/3时间执行</span></span><br><span class="line"></span><br><span class="line">    ee.setTimeout(task);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际上是构建了一个TimerTask，通过<code>timer.newTimeout(task, delay, unit);</code>添加到时间轮中。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Timeout <span class="title">newTimeout</span><span class="params">(TimerTask task, <span class="keyword">long</span> delay, TimeUnit unit)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//delay: 延迟执行时间</span></span><br><span class="line">        <span class="comment">//unit： 延迟执行时间单位</span></span><br><span class="line">        <span class="keyword">return</span> timer.newTimeout(task, delay, unit);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IllegalStateException e) &#123;</span><br><span class="line">        <span class="keyword">if</span> (isShuttingDown()) &#123;</span><br><span class="line">            <span class="keyword">return</span> DUMMY_TIMEOUT;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> HashedWheelTimer timer;</span><br></pre></td></tr></table></figure><h2 id="先来了解一下什么是时间轮"><a href="#先来了解一下什么是时间轮" class="headerlink" title="先来了解一下什么是时间轮"></a>先来了解一下什么是时间轮</h2><p>时间轮这个技术其实出来很久了，在kafka、zookeeper等技术中都有时间轮使用的方式。我第一次听这个概念，是当时我一个朋友在拼多多，负责整体架构设计时需要考虑到超时订单的自动关单，而订单交易量又特别多，直接去轮询数据的效率有点低，所以当时沟通下来聊到了时间轮这个东西。什么是时间轮呢？</p><p>简单来说： 时间轮是一种高效利用线程资源进行批量化调度的一种调度模型。把大批量的调度任务全部绑定到同一个调度器上，使用这一个调度器来进行所有任务的管理、触发、以及运行。</p><p>所以时间轮的模型能够高效管理各种延时任务、周期任务、通知任务。 以后大家在工作中遇到类似的功能，可以采用时间轮机制。</p><p>如图3-11，时间轮，从图片上来看，就和手表的表圈是一样，所以称为时间轮，是因为它是以时间作为刻度组成的一个环形队列，这个环形队列采用数组来实现，数组的每个元素称为槽，每个槽可以放一个定时任务列表，叫HashedWheelBucket，它是一个双向链表，量表的每一项表示一个定时任务项（HashedWhellTimeout），其中封装了真正的定时任务TimerTask。</p><p>时间轮是由多个时间格组成，下图中有8个时间格，每个时间格代表当前时间轮的基本时间跨度（tickDuration），其中时间轮的时间格的个数是固定的。</p><p>在下图中，有8个时间格（槽），假设每个时间格的单位为1s，那么整个时间轮走完一圈需要8s钟。每秒钟指针会沿着顺时针方向移动一个，这个单位可以设置，比如以秒为单位，可以以一小时为单位，这个单位可以代表时间精度。通过指针移动，来获得每个时间格中的任务列表，然后遍历这一个时间格中的双向链表来执行任务，以此循环。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320370.png" alt="img"></p><center>图3-11</center><h2 id="时间轮的使用"><a href="#时间轮的使用" class="headerlink" title="时间轮的使用"></a>时间轮的使用</h2><p>这里使用的时间轮是Netty这个包中提供的，使用方法比较简单。</p><ul><li>先构建一个HashedWheelTimer时间轮。<ul><li>tickDuration： 100  ，表示每个时间格代表当前时间轮的基本时间跨度，这里是100ms，也就是指针100ms跳动一次，每次跳动一个窗格</li><li>ticksPerWheel：1024，表示时间轮上一共有多少个窗格，分配的窗格越多，占用内存空间就越大</li><li>leakDetection：是否开启内存泄漏检测。</li><li>maxPendingTimeouts[可选参数]，最大允许等待的任务数，默认没有限制。</li></ul></li><li>通过newTimeout()把需要延迟执行的任务添加到时间轮中</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedissonController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    RedissonClient redissonClient;</span><br><span class="line">    HashedWheelTimer hashedWheelTimer= <span class="keyword">new</span> HashedWheelTimer(<span class="keyword">new</span> DefaultThreadFactory(<span class="string">&quot;demo-timer&quot;</span>), <span class="number">100</span>, TimeUnit.MILLISECONDS, <span class="number">1024</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 添加延迟任务</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> delay</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/&#123;delay&#125;&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">tick</span><span class="params">(<span class="meta">@PathVariable(&quot;delay&quot;)</span>Long delay)</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;currentDate:&quot;</span>+<span class="keyword">new</span> Date());</span><br><span class="line">        hashedWheelTimer.newTimeout(timeout -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;executeDate:&quot;</span>+<span class="keyword">new</span> Date());</span><br><span class="line">        &#125;, delay, TimeUnit.SECONDS);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="时间轮的原理解析"><a href="#时间轮的原理解析" class="headerlink" title="时间轮的原理解析"></a>时间轮的原理解析</h2><p>时间轮的整体原理，分为几个部分。</p><ul><li><p>创建时间轮</p><p>时间轮本质上是一个环状数组，比如我们初始化时间轮时：ticksPerWheel=8，那么意味着这个环状数组的长度是8，如图3-12所示。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">HashedWheelBucket[] wheel = <span class="keyword">new</span> HashedWheelBucket[ticksPerWheel];</span><br></pre></td></tr></table></figure><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320708.png" alt="image-20210707210354869"></p><center>图3-12</center></li><li><p>添加任务，如图3-13所示</p><ul><li><p>当通过newTimeout()方法添加一个延迟任务时，该任务首先会加入到一个阻塞队列中中。</p></li><li><p>然后会有一个定时任务从该队列获取任务，添加到时间轮的指定位置，计算方法如下。</p></li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//当前任务的开始执行时间除以每个窗口的时间间隔，得到一个calculated值（表示需要经过多少tick，指针没跳动一个窗格，tick会递增），单位为nanos（微毫秒）</span></span><br><span class="line"><span class="keyword">long</span> calculated = timeout.deadline / tickDuration;</span><br><span class="line"><span class="comment">//计算当前任务需要在时间轮中经历的圈数，因为当前任务执行时间有可能大于完整一圈的时间，所以需要计算经过几圈之后才能执行该任务。</span></span><br><span class="line">timeout.remainingRounds = (calculated - tick) / wheel.length;</span><br><span class="line"><span class="comment">//取最大的一个tick，有可能当前任务在队列中已经过了执行时间，这种情况下直接用calculated这个值就没意义了。</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">long</span> ticks = Math.max(calculated, tick); <span class="comment">// Ensure we don&#x27;t schedule for past.</span></span><br><span class="line"><span class="keyword">int</span> stopIndex = (<span class="keyword">int</span>) (ticks &amp; mask); <span class="comment">//通过ticks取模mask，得到一个下标</span></span><br><span class="line"></span><br><span class="line">HashedWheelBucket bucket = wheel[stopIndex]; <span class="comment">//把任务添加到指定数组下标位置</span></span><br></pre></td></tr></table></figure><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320829.png" alt="image-20210707212929968"></p><center>图3-13</center></li><li><p>任务执行</p><p>Worker线程按照每次间隔时间转动后，得到该时间窗格中的任务链表，然后从链表的head开始逐个取出任务，有两个判断条件</p><ul><li>当前任务需要转动的圈数为0，表示任务是当前圈开始执行</li><li>当前任务达到了delay时间，也就是<code>timeout.deadline &lt;= deadline</code></li><li>最终调用timeout.expire()方法执行任务。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">expireTimeouts</span><span class="params">(<span class="keyword">long</span> deadline)</span> </span>&#123;</span><br><span class="line">    HashedWheelTimeout timeout = head;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// process all timeouts</span></span><br><span class="line">    <span class="keyword">while</span> (timeout != <span class="keyword">null</span>) &#123;</span><br><span class="line">        HashedWheelTimeout next = timeout.next;</span><br><span class="line">        <span class="keyword">if</span> (timeout.remainingRounds &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            next = remove(timeout);</span><br><span class="line">            <span class="keyword">if</span> (timeout.deadline &lt;= deadline) &#123;</span><br><span class="line">                timeout.expire();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// The timeout was placed into a wrong slot. This should never happen.</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(String.format(</span><br><span class="line">                    <span class="string">&quot;timeout.deadline (%d) &gt; deadline (%d)&quot;</span>, timeout.deadline, deadline));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (timeout.isCancelled()) &#123;</span><br><span class="line">            next = remove(timeout);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            timeout.remainingRounds --;</span><br><span class="line">        &#125;</span><br><span class="line">        timeout = next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h1 id="时间轮的源码分析"><a href="#时间轮的源码分析" class="headerlink" title="时间轮的源码分析"></a>时间轮的源码分析</h1><h2 id="HashedWheelTimer的构造"><a href="#HashedWheelTimer的构造" class="headerlink" title="HashedWheelTimer的构造"></a>HashedWheelTimer的构造</h2><ul><li>调用createWheel创建一个时间轮，时间轮数组一定是2的幂次方，比如传入的ticksPerWheel=6，那么初始化的wheel长度一定是8，这样是便于时间格的计算。</li><li>tickDuration，表示时间轮的跨度，代表每个时间格的时间精度，以纳秒的方式来表现。</li><li>把工作线程Worker封装成WorkerThread，从名字可以知道，它就是最终那个负责干活的线程。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashedWheelTimer</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    ThreadFactory threadFactory,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">long</span> tickDuration, TimeUnit unit, <span class="keyword">int</span> ticksPerWheel,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">long</span> maxPendingTimeouts)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建时间轮基本的数据结构，一个数组。长度为不小于ticksPerWheel的最小2的n次方</span></span><br><span class="line">    wheel = createWheel(ticksPerWheel);</span><br><span class="line">    <span class="comment">// 这是一个标示符，用来快速计算任务应该呆的格子。</span></span><br><span class="line">    <span class="comment">// 我们知道，给定一个deadline的定时任务，其应该呆的格子=deadline%wheel.length.但是%操作是个相对耗时的操作，所以使用一种变通的位运算代替：</span></span><br><span class="line">    <span class="comment">// 因为一圈的长度为2的n次方，mask = 2^n-1后低位将全部是1，然后deadline&amp;mast == deadline%wheel.length</span></span><br><span class="line">    <span class="comment">// java中的HashMap在进行hash之后，进行index的hash寻址寻址的算法也是和这个一样的</span></span><br><span class="line">    mask = wheel.length - <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//时间轮的基本时间跨度，（tickDuration传入是1的话，这里会转换成1000000）</span></span><br><span class="line">    <span class="keyword">this</span>.tickDuration = unit.toNanos(tickDuration);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 校验是否存在溢出。即指针转动的时间间隔不能太长而导致tickDuration*wheel.length&gt;Long.MAX_VALUE</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.tickDuration &gt;= Long.MAX_VALUE / wheel.length) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(String.format(</span><br><span class="line">            <span class="string">&quot;tickDuration: %d (expected: 0 &lt; tickDuration in nanos &lt; %d&quot;</span>,</span><br><span class="line">            tickDuration, Long.MAX_VALUE / wheel.length));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//把worker包装成thread</span></span><br><span class="line">    workerThread = threadFactory.newThread(worker);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">this</span>.maxPendingTimeouts = maxPendingTimeouts;</span><br><span class="line">    <span class="comment">//如果HashedWheelTimer实例太多，那么就会打印一个error日志</span></span><br><span class="line">    <span class="keyword">if</span> (INSTANCE_COUNTER.incrementAndGet() &gt; INSTANCE_COUNT_LIMIT &amp;&amp;</span><br><span class="line">        WARNED_TOO_MANY_INSTANCES.compareAndSet(<span class="keyword">false</span>, <span class="keyword">true</span>)) &#123;</span><br><span class="line">        reportTooManyInstances();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>对传入的ticksPerWheel进行整形</li><li>初始化固定长度的HashedWheelBucket</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> HashedWheelBucket[] createWheel(<span class="keyword">int</span> ticksPerWheel) &#123;</span><br><span class="line">    <span class="keyword">if</span> (ticksPerWheel &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</span><br><span class="line">            <span class="string">&quot;ticksPerWheel must be greater than 0: &quot;</span> + ticksPerWheel);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (ticksPerWheel &gt; <span class="number">1073741824</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</span><br><span class="line">            <span class="string">&quot;ticksPerWheel may not be greater than 2^30: &quot;</span> + ticksPerWheel);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//对传入的时间轮大小进行整形，整形成2的幂次方</span></span><br><span class="line">    ticksPerWheel = normalizeTicksPerWheel(ticksPerWheel);</span><br><span class="line">    <span class="comment">//初始化一个固定长度的Bucket数组</span></span><br><span class="line">    HashedWheelBucket[] wheel = <span class="keyword">new</span> HashedWheelBucket[ticksPerWheel];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; wheel.length; i++) &#123;</span><br><span class="line">        wheel[i] = <span class="keyword">new</span> HashedWheelBucket();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> wheel;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="添加任务到时间轮"><a href="#添加任务到时间轮" class="headerlink" title="添加任务到时间轮"></a>添加任务到时间轮</h2><p>完成时间轮的初始化之后，并没有去启动时间轮，继续看FailbackClusterInvoker中的代码。</p><p>构建了一个RetryTimerTask，也就是一个重试的定时任务，接着把这个任务通过newTimeout加入到时间轮中，其中</p><ul><li>retryTimerTask，表示具体的重试任务</li><li>RETRY_FAILED_PERIOD ， 表示重试间隔时间，默认为5s</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">RetryTimerTask retryTimerTask = <span class="keyword">new</span> RetryTimerTask(loadbalance, invocation, invokers, lastInvoker, retries, RETRY_FAILED_PERIOD);</span><br><span class="line">failTimer.newTimeout(retryTimerTask, RETRY_FAILED_PERIOD, TimeUnit.SECONDS);</span><br></pre></td></tr></table></figure><p>调用newTimeout方法，把任务添加进来。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Timeout <span class="title">newTimeout</span><span class="params">(TimerTask task, <span class="keyword">long</span> delay, TimeUnit unit)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (task == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException(<span class="string">&quot;task&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unit == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException(<span class="string">&quot;unit&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//统计任务个数</span></span><br><span class="line">    <span class="keyword">long</span> pendingTimeoutsCount = pendingTimeouts.incrementAndGet();</span><br><span class="line">    <span class="comment">//判断最大任务数量是否超过限制</span></span><br><span class="line">    <span class="keyword">if</span> (maxPendingTimeouts &gt; <span class="number">0</span> &amp;&amp; pendingTimeoutsCount &gt; maxPendingTimeouts) &#123;</span><br><span class="line">        pendingTimeouts.decrementAndGet();</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RejectedExecutionException(<span class="string">&quot;Number of pending timeouts (&quot;</span></span><br><span class="line">                                             + pendingTimeoutsCount + <span class="string">&quot;) is greater than or equal to maximum allowed pending &quot;</span></span><br><span class="line">                                             + <span class="string">&quot;timeouts (&quot;</span> + maxPendingTimeouts + <span class="string">&quot;)&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="comment">//如果时间轮没有启动，则通过start方法进行启动</span></span><br><span class="line">    start();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Add the timeout to the timeout queue which will be processed on the next tick.</span></span><br><span class="line">    <span class="comment">// During processing all the queued HashedWheelTimeouts will be added to the correct HashedWheelBucket.</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//计算任务的延迟时间，通过当前的时间+当前任务执行的延迟时间-时间轮启动的时间。</span></span><br><span class="line">    <span class="keyword">long</span> deadline = System.nanoTime() + unit.toNanos(delay) - startTime;</span><br><span class="line"></span><br><span class="line">     <span class="comment">//在delay为正数的情况下，deadline是不可能为负数</span></span><br><span class="line">    <span class="comment">//如果为负数，那么说明超过了long的最大值</span></span><br><span class="line">    <span class="keyword">if</span> (delay &gt; <span class="number">0</span> &amp;&amp; deadline &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        deadline = Long.MAX_VALUE;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//创建一个Timeout任务，理论上来说，这个任务应该要加入到时间轮的时间格子中，但是这里并不是先添加到时间格，而是先</span></span><br><span class="line">    <span class="comment">//加入到一个阻塞队列，然后等到时间轮执行到下一个格子时，再从队列中取出最多100000个任务添加到指定的时间格（槽）中。</span></span><br><span class="line">    HashedWheelTimeout timeout = <span class="keyword">new</span> HashedWheelTimeout(<span class="keyword">this</span>, task, deadline);</span><br><span class="line">    timeouts.add(timeout);</span><br><span class="line">    <span class="keyword">return</span> timeout;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="start"><a href="#start" class="headerlink" title="start"></a>start</h3><p>任务添加到阻塞队列之后，我们再来看启动方法</p><p>start方法会根据当前的workerState状态来启动时间轮。并且用了startTimeInitialized来控制线程的运行，如果workerThread没有启动起来，那么newTimeout方法会一直阻塞在运行start方法中。如果不阻塞，newTimeout方法会获取不到startTime。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">//workerState一开始的时候是0（WORKER_STATE_INIT），然后才会设置为1（WORKER_STATE_STARTED）</span></span><br><span class="line">    <span class="keyword">switch</span> (WORKER_STATE_UPDATER.get(<span class="keyword">this</span>)) &#123;</span><br><span class="line">        <span class="keyword">case</span> WORKER_STATE_INIT:</span><br><span class="line">            <span class="keyword">if</span> (WORKER_STATE_UPDATER.compareAndSet(<span class="keyword">this</span>, WORKER_STATE_INIT, WORKER_STATE_STARTED)) &#123;</span><br><span class="line">                workerThread.start();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> WORKER_STATE_STARTED:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> WORKER_STATE_SHUTDOWN:</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">&quot;cannot be started once stopped&quot;</span>);</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> Error(<span class="string">&quot;Invalid WorkerState&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 等待worker线程初始化时间轮的启动时间</span></span><br><span class="line">    <span class="keyword">while</span> (startTime == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//这里使用countDownLauch来确保调度的线程已经被启动</span></span><br><span class="line">            startTimeInitialized.await();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException ignore) &#123;</span><br><span class="line">            <span class="comment">// Ignore - it will be ready very soon.</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="启动时间轮"><a href="#启动时间轮" class="headerlink" title="启动时间轮"></a>启动时间轮</h3><p>调用start（）方法， 会调用<code>workerThread.start();</code>来启动一个工作线程，这个工作线程是在构造方法中初始化的，包装的是一个Worker内部线程类。</p><p>所以直接进入到Worker这个类的run方法，了解下它的设计逻辑</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化startTime，表示时间轮的启动时间</span></span><br><span class="line">    startTime = System.nanoTime();</span><br><span class="line">    <span class="keyword">if</span> (startTime == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// We use 0 as an indicator for the uninitialized value here, so make sure it&#x27;s not 0 when initialized.</span></span><br><span class="line">        startTime = <span class="number">1</span>;</span><br><span class="line">    &#125; </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 唤醒被阻塞的start()方法。</span></span><br><span class="line">    startTimeInitialized.countDown();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="comment">//返回每tick一次的时间间隔</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">long</span> deadline = waitForNextTick();</span><br><span class="line">        <span class="keyword">if</span> (deadline &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">//计算时间轮的槽位</span></span><br><span class="line">            <span class="keyword">int</span> idx = (<span class="keyword">int</span>) (tick &amp; mask);</span><br><span class="line">            <span class="comment">//移除掉CancelledTask</span></span><br><span class="line">            processCancelledTasks();</span><br><span class="line">            <span class="comment">//得到当前指针位置的时间槽</span></span><br><span class="line">            HashedWheelBucket bucket =</span><br><span class="line">                wheel[idx];</span><br><span class="line">            <span class="comment">//将newTimeout()方法中加入到待处理定时任务队列中的任务加入到指定的格子中</span></span><br><span class="line">            transferTimeoutsToBuckets();</span><br><span class="line">            <span class="comment">//运行目前指针指向的槽中的bucket链表中的任务</span></span><br><span class="line">            bucket.expireTimeouts(deadline);</span><br><span class="line">            tick++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">while</span> (WORKER_STATE_UPDATER.get(HashedWheelTimer.<span class="keyword">this</span>) == WORKER_STATE_STARTED);</span><br><span class="line">     <span class="comment">//如果Worker_State一只是started状态，就一直循环</span></span><br><span class="line">    <span class="comment">// Fill the unprocessedTimeouts so we can return them from stop() method.</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (HashedWheelBucket bucket : wheel) &#123;</span><br><span class="line">        bucket.clearTimeouts(unprocessedTimeouts); <span class="comment">//清除时间轮中不需要处理的任务</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (; ; ) &#123;</span><br><span class="line">        <span class="comment">//遍历任务队列，发现如果有任务被取消，则添加到unprocessedTimeouts,也就是不需要处理的队列中。</span></span><br><span class="line">        HashedWheelTimeout timeout = timeouts.poll();</span><br><span class="line">        <span class="keyword">if</span> (timeout == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">       </span><br><span class="line">        <span class="keyword">if</span> (!timeout.isCancelled()) &#123;</span><br><span class="line">            unprocessedTimeouts.add(timeout);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//处理被取消的任务.</span></span><br><span class="line">    processCancelledTasks();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="时间轮指针跳动"><a href="#时间轮指针跳动" class="headerlink" title="时间轮指针跳动"></a>时间轮指针跳动</h2><p>这个方法的主要作用就是返回下一个指针指向的时间间隔，然后进行sleep操作。</p><p>大家可以想象一下，一个钟表上秒与秒之间是有时间间隔的，那么waitForNextTick就是根据当前时间计算出跳动到下个时间的时间间隔，然后进行sleep，然后再返回当前时间距离时间轮启动时间的时间间隔。</p><p>说得再直白一点：，假设当前的tickDuration的间隔是1s，tick默认=0， 此时第一次进来，得到的deadline=1，也就是下一次跳动的时间间隔是1s。假设当前处于</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">waitForNextTick</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">//tick表示总的tick数</span></span><br><span class="line">    <span class="comment">//tickDuration表示每个时间格的跨度，所以deadline返回的是下一次时间轮指针跳动的时间</span></span><br><span class="line">    <span class="keyword">long</span> deadline = tickDuration * (tick + <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (; ; ) &#123;</span><br><span class="line">        <span class="comment">//计算当前时间距离启动时间的时间间隔</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">long</span> currentTime = System.nanoTime() - startTime;</span><br><span class="line">        <span class="comment">//通过下一次指针跳动的延迟时间距离当前时间的差额，这个作为sleep时间使用。</span></span><br><span class="line">        <span class="comment">// 其实线程是以睡眠一定的时候再来执行下一个ticket的任务的</span></span><br><span class="line">        <span class="keyword">long</span> sleepTimeMs = (deadline - currentTime + <span class="number">999999</span>) / <span class="number">1000000</span>;</span><br><span class="line">        <span class="comment">//sleepTimeMs小于零表示走到了下一个时间槽位置</span></span><br><span class="line">        <span class="keyword">if</span> (sleepTimeMs &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (currentTime == Long.MIN_VALUE) &#123;</span><br><span class="line">                <span class="keyword">return</span> -Long.MAX_VALUE;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> currentTime;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (isWindows()) &#123;</span><br><span class="line">            sleepTimeMs = sleepTimeMs / <span class="number">10</span> * <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//进入到这里进行sleep，表示当前时间距离下一次tick时间还有一段距离，需要sleep。</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(sleepTimeMs);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException ignored) &#123;</span><br><span class="line">            <span class="keyword">if</span> (WORKER_STATE_UPDATER.get(HashedWheelTimer.<span class="keyword">this</span>) == WORKER_STATE_SHUTDOWN) &#123;</span><br><span class="line">                <span class="keyword">return</span> Long.MIN_VALUE;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="transferTimeoutsToBuckets"><a href="#transferTimeoutsToBuckets" class="headerlink" title="transferTimeoutsToBuckets"></a>transferTimeoutsToBuckets</h2><p>转移任务到时间轮中，前面我们讲过，任务添加进来时，是先放入到阻塞队列。</p><p>而在现在这个方法中，就是把阻塞队列中的数据转移到时间轮的指定位置。</p><p>在这个转移方法中，写死了一个循环，每次都只转移10万个任务。</p><p>然后根据HashedWheelTimeout的deadline延迟时间计算出时间轮需要运行多少次才能运行当前的任务，如果当前的任务延迟时间大于时间轮跑一圈所需要的时间，那么就计算需要跑几圈才能到这个任务运行。</p><p>最后计算出该任务在时间轮中的槽位，添加到时间轮的链表中。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">transferTimeoutsToBuckets</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 循环100000次，也就是每次转移10w个任务</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100000</span>; i++) &#123;</span><br><span class="line">        <span class="comment">//从阻塞队列中获得具体的任务</span></span><br><span class="line">        HashedWheelTimeout timeout = timeouts.poll();</span><br><span class="line">        <span class="keyword">if</span> (timeout == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// all processed</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (timeout.state() == HashedWheelTimeout.ST_CANCELLED) &#123;</span><br><span class="line">            <span class="comment">// Was cancelled in the meantime.</span></span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//计算tick次数，deadline表示当前任务的延迟时间，tickDuration表示时间槽的间隔，两者相除就可以计算当前任务需要tick几次才能被执行</span></span><br><span class="line">        <span class="keyword">long</span> calculated = timeout.deadline / tickDuration;</span><br><span class="line">         <span class="comment">// 计算剩余的轮数, 只有 timer 走够轮数, 并且到达了 task 所在的 slot, task 才会过期.(被执行)</span></span><br><span class="line">        timeout.remainingRounds = (calculated - tick) / wheel.length;</span><br><span class="line">     </span><br><span class="line">        <span class="comment">//如果任务在timeouts队列里面放久了, 以至于已经过了执行时间, 这个时候就使用当前tick, 也就是放到当前bucket, 此方法调用完后就会被执行</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">long</span> ticks = Math.max(calculated, tick);</span><br><span class="line">        <span class="comment">// 算出任务应该插入的 wheel 的 slot, stopIndex = tick 次数 &amp; mask, mask = wheel.length - 1</span></span><br><span class="line">        <span class="keyword">int</span> stopIndex = (<span class="keyword">int</span>) (ticks &amp; mask);</span><br><span class="line">        <span class="comment">//把timeout任务插入到指定的bucket链中。</span></span><br><span class="line">        HashedWheelBucket bucket = wheel[stopIndex];</span><br><span class="line">        bucket.addTimeout(timeout);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="运行时间轮中的任务"><a href="#运行时间轮中的任务" class="headerlink" title="运行时间轮中的任务"></a>运行时间轮中的任务</h2><p>当指针跳动到某一个时间槽中时，会就触发这个槽中的任务的执行。该功能是通过expireTimeouts来实现</p><p>这个方法的主要作用是： 过期并执行格子中到期的任务。也就是当tick进入到指定格子时，worker线程会调用这个方法</p><p>HashedWheelBucket是一个链表，所以我们需要从head节点往下进行遍历。如果链表没有遍历到链表尾部那么就继续往下遍历。</p><p>获取的timeout节点节点，如果剩余轮数remainingRounds大于0，那么就说明要到下一圈才能运行，所以将剩余轮数减一；</p><p>如果当前剩余轮数小于等于零了，那么就将当前节点从bucket链表中移除，并判断一下当前的时间是否大于timeout的延迟时间，如果是则调用timeout的expire执行任务。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">expireTimeouts</span><span class="params">(<span class="keyword">long</span> deadline)</span> </span>&#123;</span><br><span class="line">    HashedWheelTimeout timeout = head;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历当前时间槽中的所有任务</span></span><br><span class="line">    <span class="keyword">while</span> (timeout != <span class="keyword">null</span>) &#123;</span><br><span class="line">        HashedWheelTimeout next = timeout.next;</span><br><span class="line">        <span class="comment">//如果当前任务要被执行，那么remainingRounds应该小于或者等于0</span></span><br><span class="line">        <span class="keyword">if</span> (timeout.remainingRounds &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">//从bucket链表中移除当前timeout，并返回链表中下一个timeout</span></span><br><span class="line">            next = remove(timeout);</span><br><span class="line">            <span class="comment">//如果timeout的时间小于当前的时间，那么就调用expire执行task</span></span><br><span class="line">            <span class="keyword">if</span> (timeout.deadline &lt;= deadline) &#123;</span><br><span class="line">                timeout.expire();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                 <span class="comment">//不可能发生的情况，就是说round已经为0了，deadline却&gt;当前槽的deadline</span></span><br><span class="line">                <span class="comment">// The timeout was placed into a wrong slot. This should never happen.</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(String.format(</span><br><span class="line">                    <span class="string">&quot;timeout.deadline (%d) &gt; deadline (%d)&quot;</span>, timeout.deadline, deadline));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (timeout.isCancelled()) &#123;</span><br><span class="line">            next = remove(timeout);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//因为当前的槽位已经过了，说明已经走了一圈了，把轮数减一</span></span><br><span class="line">            timeout.remainingRounds--;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//把指针放置到下一个timeout</span></span><br><span class="line">        timeout = next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Redisson </tag>
            
            <tag> 时间轮 </tag>
            
            <tag> Redisson分布式锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从源码层面深度剖析Redisson实现分布式锁的原理（全程干货，注意收藏）</title>
      <link href="/posts/1208754375/"/>
      <url>/posts/1208754375/</url>
      
        <content type="html"><![CDATA[<p>Redis的使用场景很多，本篇文章主要给大家分享一下Redis实现分布式锁机制的原理。</p><p>下面通过Redisson框架封装的分布式锁机制，来演示一下分布式锁的实现。</p><ul><li><p>引入redisson依赖</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.redisson<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>redisson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.16.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>编写简单的测试代码</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedissonTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> RedissonClient redissonClient;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        Config config=<span class="keyword">new</span> Config();</span><br><span class="line">        config.useSingleServer().setAddress(<span class="string">&quot;redis://192.168.221.128:6379&quot;</span>);</span><br><span class="line">        redissonClient=Redisson.create(config);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        RLock rLock=redissonClient.getLock(<span class="string">&quot;updateOrder&quot;</span>);</span><br><span class="line">        <span class="comment">//最多等待100秒、上锁10s以后自动解锁</span></span><br><span class="line">        <span class="keyword">if</span>(rLock.tryLock(<span class="number">100</span>,<span class="number">10</span>,TimeUnit.SECONDS))&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;获取锁成功&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">        rLock.unlock();</span><br><span class="line"></span><br><span class="line">        redissonClient.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h1 id="Redisson分布式锁的实现原理"><a href="#Redisson分布式锁的实现原理" class="headerlink" title="Redisson分布式锁的实现原理"></a>Redisson分布式锁的实现原理</h1><p>你们会发现，通过redisson，非常简单就可以实现我们所需要的功能，当然这只是redisson的冰山一角，redisson最强大的地方就是提供了分布式特性的常用工具类。使得原本作为协调单机多线程并发程序的并发程序的工具包获得了协调分布式多级多线程并发系统的能力，降低了程序员在分布式环境下解决分布式问题的难度，下面分析一下RedissonLock的实现原理</p><h2 id="RedissonLock-tryLock"><a href="#RedissonLock-tryLock" class="headerlink" title="RedissonLock.tryLock"></a>RedissonLock.tryLock</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> time = unit.toMillis(waitTime);</span><br><span class="line">    <span class="keyword">long</span> current = System.currentTimeMillis();</span><br><span class="line">    <span class="keyword">long</span> threadId = Thread.currentThread().getId();</span><br><span class="line">    <span class="comment">//通过tryAcquire方法尝试获取锁</span></span><br><span class="line">    Long ttl = tryAcquire(waitTime, leaseTime, unit, threadId);</span><br><span class="line">    <span class="comment">// lock acquired</span></span><br><span class="line">    <span class="keyword">if</span> (ttl == <span class="keyword">null</span>) &#123; <span class="comment">//表示成功获取到锁，直接返回</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//省略部分代码....</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="tryAcquire"><a href="#tryAcquire" class="headerlink" title="tryAcquire"></a>tryAcquire</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;T&gt; <span class="function">RFuture&lt;Long&gt; <span class="title">tryAcquireAsync</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit, <span class="keyword">long</span> threadId)</span> </span>&#123;</span><br><span class="line">    RFuture&lt;Long&gt; ttlRemainingFuture;</span><br><span class="line">    <span class="comment">//leaseTime就是租约时间，就是redis key的过期时间。</span></span><br><span class="line">    <span class="keyword">if</span> (leaseTime != -<span class="number">1</span>) &#123; <span class="comment">//如果设置过期时间</span></span><br><span class="line">        ttlRemainingFuture = tryLockInnerAsync(waitTime, leaseTime, unit, threadId, RedisCommands.EVAL_LONG);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;<span class="comment">//如果没设置了过期时间，则从配置中获取key超时时间,默认是30s过期</span></span><br><span class="line">        ttlRemainingFuture = tryLockInnerAsync(waitTime, internalLockLeaseTime,</span><br><span class="line">                                               TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//当tryLockInnerAsync执行结束后，触发下面回调</span></span><br><span class="line">    ttlRemainingFuture.onComplete((ttlRemaining, e) -&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123; <span class="comment">//说明出现异常，直接返回</span></span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// lock acquired</span></span><br><span class="line">        <span class="keyword">if</span> (ttlRemaining == <span class="keyword">null</span>) &#123; <span class="comment">//表示第一次设置锁键</span></span><br><span class="line">            <span class="keyword">if</span> (leaseTime != -<span class="number">1</span>) &#123; <span class="comment">//表示设置过超时时间，更新internalLockLeaseTime，并返回</span></span><br><span class="line">                internalLockLeaseTime = unit.toMillis(leaseTime);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123; <span class="comment">//leaseTime=-1,启动Watch Dog</span></span><br><span class="line">                scheduleExpirationRenewal(threadId);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">return</span> ttlRemainingFuture;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="tryLockInnerAsync"><a href="#tryLockInnerAsync" class="headerlink" title="tryLockInnerAsync"></a>tryLockInnerAsync</h2><p>通过lua脚本来实现加锁的操作</p><ol><li><p>判断lock键是否存在，不存在直接调用hset存储当前线程信息并且设置过期时间,返回nil，告诉客户端直接获取到锁。</p></li><li><p>判断lock键是否存在，存在则将重入次数加1，并重新设置过期时间，返回nil，告诉客户端直接获取到锁。</p></li><li><p>被其它线程已经锁定，返回锁有效期的剩余时间，告诉客户端需要等待。</p></li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&lt;T&gt; <span class="function">RFuture&lt;T&gt; <span class="title">tryLockInnerAsync</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit, <span class="keyword">long</span> threadId, RedisStrictCommand&lt;T&gt; command)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> evalWriteAsync(getRawName(), LongCodec.INSTANCE, command,</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;exists&#x27;, KEYS[1]) == 0) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return redis.call(&#x27;pttl&#x27;, KEYS[1]);&quot;</span>,</span><br><span class="line">                          Collections.singletonList(getRawName()), unit.toMillis(leaseTime), getLockName(threadId));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>关于Lua脚本，我们稍后再解释。</p></blockquote><h2 id="unlock释放锁流程"><a href="#unlock释放锁流程" class="headerlink" title="unlock释放锁流程"></a>unlock释放锁流程</h2><p>释放锁的流程，脚本看起来会稍微复杂一点</p><ol><li><p>如果lock键不存在，通过<code>publish</code>指令发送一个消息表示锁已经可用。</p></li><li><p>如果锁不是被当前线程锁定，则返回nil</p></li><li><p>由于支持可重入，在解锁时将重入次数需要减1</p></li><li><p>如果计算后的重入次数&gt;0，则重新设置过期时间</p></li><li><p>如果计算后的重入次数&lt;=0，则发消息说锁已经可用</p></li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> RFuture&lt;Boolean&gt; <span class="title">unlockInnerAsync</span><span class="params">(<span class="keyword">long</span> threadId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[3]) == 0) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil;&quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;local counter = redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[3], -1); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;if (counter &gt; 0) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[2]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return 0; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;else &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;del&#x27;, KEYS[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;publish&#x27;, KEYS[2], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return 1; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil;&quot;</span>,</span><br><span class="line">                          Arrays.asList(getRawName(), getChannelName()), LockPubSub.UNLOCK_MESSAGE, internalLockLeaseTime, getLockName(threadId));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="RedissonLock有竞争的情况"><a href="#RedissonLock有竞争的情况" class="headerlink" title="RedissonLock有竞争的情况"></a>RedissonLock有竞争的情况</h1><p>有竞争的情况在redis端的lua脚本是相同的，只是不同的条件执行不同的redis命令。当通过tryAcquire发现锁被其它线程申请时，需要进入等待竞争逻辑中</p><ol><li><p>this.await返回false，说明等待时间已经超出获取锁最大等待时间，取消订阅并返回获取锁失败</p></li><li><p>this.await返回true，进入循环尝试获取锁。</p></li></ol><blockquote><p>继续看RedissonLock.tryLock后半部分代码如下：</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line"><span class="comment">//省略部分代码</span></span><br><span class="line">        time -= System.currentTimeMillis() - current;</span><br><span class="line">        <span class="keyword">if</span> (time &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            acquireFailed(waitTime, unit, threadId);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        current = System.currentTimeMillis();</span><br><span class="line">       <span class="comment">// 订阅监听redis消息，并且创建RedissonLockEntry</span></span><br><span class="line">        RFuture&lt;RedissonLockEntry&gt; subscribeFuture = subscribe(threadId);</span><br><span class="line">      <span class="comment">// 阻塞等待subscribe的future的结果对象，如果subscribe方法调用超过了time，说明已经超过了客户端设置的最大wait time，则直接返回false，取消订阅，不再继续申请锁了。</span></span><br><span class="line">        <span class="keyword">if</span> (!subscribeFuture.await(time, TimeUnit.MILLISECONDS)) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!subscribeFuture.cancel(<span class="keyword">false</span>)) &#123; <span class="comment">//取消订阅</span></span><br><span class="line">                subscribeFuture.onComplete((res, e) -&gt; &#123;</span><br><span class="line">                    <span class="keyword">if</span> (e == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        unsubscribe(subscribeFuture, threadId);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">            acquireFailed(waitTime, unit, threadId); <span class="comment">//表示抢占锁失败</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>; <span class="comment">//返回false</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//判断是否超时，如果等待超时，返回获的锁失败</span></span><br><span class="line">            time -= System.currentTimeMillis() - current;</span><br><span class="line">            <span class="keyword">if</span> (time &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                acquireFailed(waitTime, unit, threadId);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//通过while循环再次尝试竞争锁</span></span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123; </span><br><span class="line">                <span class="keyword">long</span> currentTime = System.currentTimeMillis();</span><br><span class="line">                ttl = tryAcquire(waitTime, leaseTime, unit, threadId); <span class="comment">//竞争锁，返回锁超时时间</span></span><br><span class="line">                <span class="comment">// lock acquired</span></span><br><span class="line">                <span class="keyword">if</span> (ttl == <span class="keyword">null</span>) &#123; <span class="comment">//如果超时时间为null，说明获得锁成功</span></span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//判断是否超时，如果超时，表示获取锁失败</span></span><br><span class="line">                time -= System.currentTimeMillis() - currentTime;</span><br><span class="line">                <span class="keyword">if</span> (time &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                    acquireFailed(waitTime, unit, threadId);</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 通过信号量(共享锁)阻塞,等待解锁消息.  (减少申请锁调用的频率)</span></span><br><span class="line"><span class="comment">// 如果剩余时间(ttl)小于wait time ,就在 ttl 时间内，从Entry的信号量获取一个许可(除非被中断或者一直没有可用的许可)。</span></span><br><span class="line"><span class="comment">// 否则就在wait time 时间范围内等待可以通过信号量</span></span><br><span class="line">                currentTime = System.currentTimeMillis();</span><br><span class="line">                <span class="keyword">if</span> (ttl &gt;= <span class="number">0</span> &amp;&amp; ttl &lt; time) &#123;</span><br><span class="line">                    subscribeFuture.getNow().getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    subscribeFuture.getNow().getLatch().tryAcquire(time, TimeUnit.MILLISECONDS);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 更新等待时间(最大等待时间-已经消耗的阻塞时间)</span></span><br><span class="line">                time -= System.currentTimeMillis() - currentTime;</span><br><span class="line">                <span class="keyword">if</span> (time &lt;= <span class="number">0</span>) &#123; <span class="comment">//获取锁失败</span></span><br><span class="line">                    acquireFailed(waitTime, unit, threadId);</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            unsubscribe(subscribeFuture, threadId); <span class="comment">//取消订阅</span></span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">//        return get(tryLockAsync(waitTime, leaseTime, unit));</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h1 id="锁过期了怎么办？"><a href="#锁过期了怎么办？" class="headerlink" title="锁过期了怎么办？"></a>锁过期了怎么办？</h1><p>一般来说，我们去获得分布式锁时，为了避免死锁的情况，我们会对锁设置一个超时时间，但是有一种情况是，如果在指定时间内当前线程没有执行完，由于锁超时导致锁被释放，那么其他线程就会拿到这把锁，从而导致一些故障。</p><p>为了避免这种情况，Redisson引入了一个Watch Dog机制，这个机制是针对分布式锁来实现锁的自动续约，简单来说，如果当前获得锁的线程没有执行完，那么Redisson会自动给Redis中目标key延长超时时间。</p><blockquote><p>默认情况下，看门狗的续期时间是30s，也可以通过修改Config.lockWatchdogTimeout来另行指定。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(<span class="keyword">long</span> waitTime, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> tryLock(waitTime, -<span class="number">1</span>, unit);  <span class="comment">//leaseTime=-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际上，当我们通过tryLock方法没有传递超时时间时，默认会设置一个30s的超时时间，避免出现死锁的问题。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;T&gt; <span class="function">RFuture&lt;Long&gt; <span class="title">tryAcquireAsync</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit, <span class="keyword">long</span> threadId)</span> </span>&#123;</span><br><span class="line">    RFuture&lt;Long&gt; ttlRemainingFuture;</span><br><span class="line">    <span class="keyword">if</span> (leaseTime != -<span class="number">1</span>) &#123; </span><br><span class="line">        ttlRemainingFuture = tryLockInnerAsync(waitTime, leaseTime, unit, threadId, RedisCommands.EVAL_LONG);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">//当leaseTime为-1时，leaseTime=internalLockLeaseTime，默认是30s，表示当前锁的过期时间。</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">//this.internalLockLeaseTime = commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout();</span></span><br><span class="line">        ttlRemainingFuture = tryLockInnerAsync(waitTime, internalLockLeaseTime,</span><br><span class="line">                                               TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);</span><br><span class="line">    &#125;</span><br><span class="line">    ttlRemainingFuture.onComplete((ttlRemaining, e) -&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123; <span class="comment">//说明出现异常，直接返回</span></span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// lock acquired</span></span><br><span class="line">        <span class="keyword">if</span> (ttlRemaining == <span class="keyword">null</span>) &#123; <span class="comment">//表示第一次设置锁键</span></span><br><span class="line">            <span class="keyword">if</span> (leaseTime != -<span class="number">1</span>) &#123; <span class="comment">//表示设置过超时时间，更新internalLockLeaseTime，并返回</span></span><br><span class="line">                internalLockLeaseTime = unit.toMillis(leaseTime);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123; <span class="comment">//leaseTime=-1,启动Watch Dog</span></span><br><span class="line">                scheduleExpirationRenewal(threadId);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">return</span> ttlRemainingFuture;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于默认设置了一个30s的过期时间，为了防止过期之后当前线程还未执行完，所以通过定时任务对过期时间进行续约。</p><ul><li>首先，会先判断在expirationRenewalMap中是否存在了entryName，这是个map结构，主要还是判断在这个服务实例中的加锁客户端的锁key是否存在，</li><li>如果已经存在了，就直接返回；主要是考虑到RedissonLock是可重入锁。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">scheduleExpirationRenewal</span><span class="params">(<span class="keyword">long</span> threadId)</span> </span>&#123;</span><br><span class="line">    ExpirationEntry entry = <span class="keyword">new</span> ExpirationEntry();</span><br><span class="line">    ExpirationEntry oldEntry = EXPIRATION_RENEWAL_MAP.putIfAbsent(getEntryName(), entry);</span><br><span class="line">    <span class="keyword">if</span> (oldEntry != <span class="keyword">null</span>) &#123;</span><br><span class="line">        oldEntry.addThreadId(threadId);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;<span class="comment">// 第一次加锁的时候会调用，内部会启动WatchDog</span></span><br><span class="line">        entry.addThreadId(threadId);</span><br><span class="line">        renewExpiration();</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义一个定时任务，该任务中调用<code>renewExpirationAsync</code>方法进行续约。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">renewExpiration</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ExpirationEntry ee = EXPIRATION_RENEWAL_MAP.get(getEntryName());</span><br><span class="line">    <span class="keyword">if</span> (ee == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//用到了时间轮机制</span></span><br><span class="line">    Timeout task = commandExecutor.getConnectionManager().newTimeout(<span class="keyword">new</span> TimerTask() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Timeout timeout)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            ExpirationEntry ent = EXPIRATION_RENEWAL_MAP.get(getEntryName());</span><br><span class="line">            <span class="keyword">if</span> (ent == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            Long threadId = ent.getFirstThreadId();</span><br><span class="line">            <span class="keyword">if</span> (threadId == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// renewExpirationAsync续约租期</span></span><br><span class="line">            RFuture&lt;Boolean&gt; future = renewExpirationAsync(threadId);</span><br><span class="line">            future.onComplete((res, e) -&gt; &#123;</span><br><span class="line">                <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    log.error(<span class="string">&quot;Can&#x27;t update lock &quot;</span> + getRawName() + <span class="string">&quot; expiration&quot;</span>, e);</span><br><span class="line">                    EXPIRATION_RENEWAL_MAP.remove(getEntryName());</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (res) &#123;</span><br><span class="line">                    <span class="comment">// reschedule itself</span></span><br><span class="line">                    renewExpiration();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, internalLockLeaseTime / <span class="number">3</span>, TimeUnit.MILLISECONDS);<span class="comment">//每次间隔租期的1/3时间执行</span></span><br><span class="line"></span><br><span class="line">    ee.setTimeout(task);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行Lua脚本，对指定的key进行续约。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> RFuture&lt;Boolean&gt; <span class="title">renewExpirationAsync</span><span class="params">(<span class="keyword">long</span> threadId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return 1; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return 0;&quot;</span>,</span><br><span class="line">                          Collections.singletonList(getRawName()),</span><br><span class="line">                          internalLockLeaseTime, getLockName(threadId));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Lua脚本"><a href="#Lua脚本" class="headerlink" title="Lua脚本"></a>Lua脚本</h1><p>Lua是一个高效的轻量级脚本语言（和JavaScript类似），用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。Lua在葡萄牙语中是“月亮”的意思，它的logo形式卫星，寓意是Lua是一个“卫星语言”，能够方便地嵌入到其他语言中使用；其实在很多常见的框架中，都有嵌入Lua脚本的功能，比如OpenResty、Redis等。</p><p>使用Lua脚本的好处：</p><ol><li><p>减少网络开销，在Lua脚本中可以把多个命令放在同一个脚本中运行</p></li><li><p>原子操作，redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。换句话说，编写脚本的过程中无需担心会出现竞态条件</p></li><li><p>复用性，客户端发送的脚本会永远存储在redis中，这意味着其他客户端可以复用这一脚本来完成同样的逻辑</p></li></ol><h2 id="Lua的下载和安装"><a href="#Lua的下载和安装" class="headerlink" title="Lua的下载和安装"></a>Lua的下载和安装</h2><p>Lua是一个独立的脚本语言，所以它有专门的编译执行工具，下面简单带大家安装一下。</p><ul><li><p>下载Lua源码包： <a href="https://www.lua.org/download.html">https://www.lua.org/download.html</a></p><p><a href="https://www.lua.org/ftp/lua-5.4.3.tar.gz">https://www.lua.org/ftp/lua-5.4.3.tar.gz</a></p></li><li><p>安装步骤如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf lua-5.4.3.tar.gz</span><br><span class="line">cd lua-5.4.3</span><br><span class="line">make linux</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li></ul><p>如果报错，说找不到readline/readline.h, 可以通过yum命令安装</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">yum -y install readline-devel ncurses-devel</span><br></pre></td></tr></table></figure><p>最后，直接输入<code>lua</code>命令即可进入lua的控制台。Lua脚本有自己的语法、变量、逻辑运算符、函数等，这块我就不在这里做过多的说明，用过JavaScript的同学，应该只需要花几个小时就可以全部学完，简单演示两个案例如下。</p><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">array = &#123;<span class="string">&quot;Lua&quot;</span>, <span class="string">&quot;mic&quot;</span>&#125;</span><br><span class="line"><span class="keyword">for</span> i= <span class="number">0</span>, <span class="number">2</span> <span class="keyword">do</span></span><br><span class="line">   <span class="built_in">print</span>(array[i])</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">array = &#123;&quot;mic&quot;, &quot;redis&quot;&#125;</span><br><span class="line"></span><br><span class="line">for key,value in ipairs(array)</span><br><span class="line">do</span><br><span class="line">   print(key, value)</span><br><span class="line">end</span><br></pre></td></tr></table></figure><h2 id="Redis与Lua"><a href="#Redis与Lua" class="headerlink" title="Redis与Lua"></a>Redis与Lua</h2><p>Redis中集成了Lua的编译和执行器，所以我们可以在Redis中定义Lua脚本去执行。同时，在Lua脚本中，可以直接调用Redis的命令，来操作Redis中的数据。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis.call(‘set’,&#x27;hello&#x27;,&#x27;world&#x27;)</span><br><span class="line"></span><br><span class="line">local value=redis.call(‘get’,’hello’) </span><br></pre></td></tr></table></figure><p>redis.call 函数的返回值就是redis命令的执行结果，前面我们介绍过redis的5中类型的数据返回的值的类型也都不一样，redis.call函数会将这5种类型的返回值转化对应的Lua的数据类型</p><p>在很多情况下我们都需要脚本可以有返回值，毕竟这个脚本也是一个我们所编写的命令集，我们可以像调用其他redis内置命令一样调用我们自己写的脚本，所以同样redis会自动将脚本返回值的Lua数据类型转化为Redis的返回值类型。 在脚本中可以使用return 语句将值返回给redis客户端，通过return语句来执行，如果没有执行return，默认返回为nil。</p><h2 id="Redis中执行Lua脚本相关的命令"><a href="#Redis中执行Lua脚本相关的命令" class="headerlink" title="Redis中执行Lua脚本相关的命令"></a>Redis中执行Lua脚本相关的命令</h2><p>编写完脚本后最重要的就是在程序中执行脚本。Redis提供了EVAL命令可以使开发者像调用其他Redis内置命令一样调用脚本。</p><h3 id="EVAL命令-执行脚本"><a href="#EVAL命令-执行脚本" class="headerlink" title="EVAL命令-执行脚本"></a>EVAL命令-执行脚本</h3><p><strong>[EVAL] [脚本内容] [key参数的数量] [key …] [arg …]</strong></p><p>可以通过key和arg这两个参数向脚本中传递数据，他们的值可以在脚本中分别使用<strong>KEYS</strong>和<strong>ARGV</strong> 这两个类型的全局变量访问。</p><p>比如我们通过脚本实现一个set命令，通过在redis客户端中调用，那么执行的语句是：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">eval &quot;return redis.call(&#x27;set&#x27;,KEYS[1],ARGV[1])&quot; 1 lua hello</span><br></pre></td></tr></table></figure><p>上述脚本相当于使用Lua脚本调用了Redis的<code>set</code>命令，存储了一个key=lua，value=hello到Redis中。</p><h3 id="EVALSHA命令"><a href="#EVALSHA命令" class="headerlink" title="EVALSHA命令"></a>EVALSHA命令</h3><p>考虑到我们通过eval执行lua脚本，脚本比较长的情况下，每次调用脚本都需要把整个脚本传给redis，比较占用带宽。为了解决这个问题，redis提供了EVALSHA命令允许开发者通过脚本内容的SHA1摘要来执行脚本。该命令的用法和EVAL一样，只不过是将脚本内容替换成脚本内容的SHA1摘要</p><ol><li><p>Redis在执行EVAL命令时会计算脚本的SHA1摘要并记录在脚本缓存中</p></li><li><p>执行EVALSHA命令时Redis会根据提供的摘要从脚本缓存中查找对应的脚本内容，如果找到了就执行脚本，否则返回“NOSCRIPT No matching script,Please use EVAL”</p></li></ol> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 将脚本加入缓存并生成sha1命令</span></span><br><span class="line">script load &quot;return redis.call(&#x27;get&#x27;,&#x27;lua&#x27;)&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> [<span class="string">&quot;13bd040587b891aedc00a72458cbf8588a27df90&quot;</span>]</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 传递sha1的值来执行该命令</span></span><br><span class="line">evalsha &quot;13bd040587b891aedc00a72458cbf8588a27df90&quot; 0</span><br></pre></td></tr></table></figure><h3 id="Redisson执行Lua脚本"><a href="#Redisson执行Lua脚本" class="headerlink" title="Redisson执行Lua脚本"></a>Redisson执行Lua脚本</h3><p>通过lua脚本来实现一个访问频率限制功能。</p><p>思路，定义一个key，key中包含ip地址。 value为指定时间内的访问次数，比如说是10秒内只能访问3次。</p><ul><li><p>定义Lua脚本。</p><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="keyword">local</span> times=redis.call(<span class="string">&#x27;incr&#x27;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="comment">-- 如果是第一次进来，设置一个过期时间</span></span><br><span class="line"><span class="keyword">if</span> times == <span class="number">1</span> <span class="keyword">then</span></span><br><span class="line">   redis.call(<span class="string">&#x27;expire&#x27;</span>,KEYS[<span class="number">1</span>],ARGV[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">-- 如果在指定时间内访问次数大于指定次数，则返回0，表示访问被限制</span></span><br><span class="line"><span class="keyword">if</span> times &gt; <span class="built_in">tonumber</span>(ARGV[<span class="number">2</span>]) <span class="keyword">then</span></span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">-- 返回1，允许被访问</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><p>定义controller，提供访问测试方法</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedissonController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    RedissonClient redissonClient;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String LIMIT_LUA=</span><br><span class="line">        <span class="string">&quot;local times=redis.call(&#x27;incr&#x27;,KEYS[1])\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;if times == 1 then\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;   redis.call(&#x27;expire&#x27;,KEYS[1],ARGV[1])\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;end\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;if times &gt; tonumber(ARGV[2]) then\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;   return 0\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;end\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;return 1&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/lua/&#123;id&#125;&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">lua</span><span class="params">(<span class="meta">@PathVariable(&quot;id&quot;)</span> Integer id)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        List&lt;Object&gt; keys= Arrays.asList(<span class="string">&quot;LIMIT:&quot;</span>+id);</span><br><span class="line">        RFuture&lt;Object&gt; future=redissonClient.getScript().</span><br><span class="line">            evalAsync(RScript.Mode.READ_WRITE,LIMIT_LUA, RScript.ReturnType.INTEGER,keys,<span class="number">10</span>,<span class="number">3</span>);</span><br><span class="line">        <span class="keyword">return</span> future.get().toString();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>需要注意，上述脚本执行的时候会有问题，因为redis默认的序列化方式导致value的值在传递到脚本中时，转成了对象类型，需要修改<code>redisson.yml</code>文件，增加codec的序列化方式。</p><ul><li><p><strong>application.yml</strong></p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">redisson:</span></span><br><span class="line">      <span class="attr">file:</span> <span class="string">classpath:redisson.yml</span></span><br></pre></td></tr></table></figure></li><li><p><strong>redisson.yml</strong></p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">singleServerConfig:</span></span><br><span class="line">  <span class="attr">address:</span> <span class="string">redis://192.168.221.128:6379</span></span><br><span class="line"></span><br><span class="line"><span class="attr">codec:</span> <span class="type">!&lt;org.redisson.codec.JsonJacksonCodec&gt;</span> &#123;&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="Lua脚本的原子性"><a href="#Lua脚本的原子性" class="headerlink" title="Lua脚本的原子性"></a>Lua脚本的原子性</h2><p>redis的脚本执行是原子的，即脚本执行期间Redis不会执行其他命令。所有的命令必须等待脚本执行完以后才能执行。为了防止某个脚本执行时间过程导致Redis无法提供服务。Redis提供了lua-time-limit参数限制脚本的最长运行时间。默认是5秒钟。</p><h3 id="非事务性操作"><a href="#非事务性操作" class="headerlink" title="非事务性操作"></a>非事务性操作</h3><p>当脚本运行时间超过这个限制后，Redis将开始接受其他命令但不会执行（以确保脚本的原子性），而是返回BUSY的错误，下面演示一下这种情况。</p><p>打开两个客户端窗口，在第一个窗口中执行lua脚本的死循环</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">eval &quot;while true do end&quot; 0</span><br></pre></td></tr></table></figure><p>在第二个窗口中运行<code>get lua</code>，会得到如下的异常。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(error) BUSY Redis is busy running a script. You can only call SCRIPT KILL or SHUTDOWN NOSAVE.</span><br></pre></td></tr></table></figure><p>我们会发现执行结果是Busy， 接着我们通过<strong>script kill</strong> 的命令终止当前执行的脚本，第二个窗口的显示又恢复正常了。</p><h3 id="存在事务性操作"><a href="#存在事务性操作" class="headerlink" title="存在事务性操作"></a>存在事务性操作</h3><p>如果当前执行的Lua脚本对Redis的数据进行了修改（SET、DEL等），那么通过SCRIPT KILL 命令是不能终止脚本运行的，因为要保证脚本运行的原子性，如果脚本执行了一部分终止，那就违背了脚本原子性的要求。最终要保证脚本要么都执行，要么都不执行</p><p>同样打开两个窗口，第一个窗口运行如下命令</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">eval &quot;redis.call(&#x27;set&#x27;,&#x27;name&#x27;,&#x27;mic&#x27;) while true do end&quot; 0</span><br></pre></td></tr></table></figure><p>在第二个窗口运行</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get lua</span><br></pre></td></tr></table></figure><p>结果一样，仍然是busy，但是这个时候通过script kill命令，会发现报错，没办法kill。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(error) UNKILLABLE Sorry the script already executed write commands against the dataset. You can either wait the script termination or kill the server in a hard way using the SHUTDOWN NOSAVE command.</span><br></pre></td></tr></table></figure><p>遇到这种情况，只能通过<strong>shutdown nosave</strong>命令来强行终止redis。</p><p>shutdown nosave和shutdown的区别在于 shutdown nosave不会进行持久化操作，意味着发生在上一次快照后的数据库修改都会丢失。</p><h2 id="Redisson的Lua脚本"><a href="#Redisson的Lua脚本" class="headerlink" title="Redisson的Lua脚本"></a>Redisson的Lua脚本</h2><p>了解了lua之后，我们再回过头来看看Redisson的Lua脚本，就不难理解了。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&lt;T&gt; <span class="function">RFuture&lt;T&gt; <span class="title">tryLockInnerAsync</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit, <span class="keyword">long</span> threadId, RedisStrictCommand&lt;T&gt; command)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> evalWriteAsync(getRawName(), LongCodec.INSTANCE, command,</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;exists&#x27;, KEYS[1]) == 0) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return redis.call(&#x27;pttl&#x27;, KEYS[1]);&quot;</span>,</span><br><span class="line">                          Collections.singletonList(getRawName()), unit.toMillis(leaseTime), getLockName(threadId));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Redis中的Pub-Sub机制"><a href="#Redis中的Pub-Sub机制" class="headerlink" title="Redis中的Pub/Sub机制"></a>Redis中的Pub/Sub机制</h1><p>下面是Redisson中释放锁的代码，在代码中我们发现一个publish的指令<code>redis.call(&#39;publish&#39;, KEYS[2], ARGV[1])</code>，这个指令是干啥的呢？</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> RFuture&lt;Boolean&gt; <span class="title">unlockInnerAsync</span><span class="params">(<span class="keyword">long</span> threadId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[3]) == 0) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil;&quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;local counter = redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[3], -1); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;if (counter &gt; 0) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[2]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return 0; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;else &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;del&#x27;, KEYS[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;publish&#x27;, KEYS[2], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return 1; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil;&quot;</span>,</span><br><span class="line">                          Arrays.asList(getRawName(), getChannelName()), LockPubSub.UNLOCK_MESSAGE, internalLockLeaseTime, getLockName(threadId));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Redis提供了一组命令可以让开发者实现“发布/订阅”模式(publish/subscribe) . 该模式同样可以实现进程间的消息传递，它的实现原理是：</p><ul><li><p>发布/订阅模式包含两种角色，分别是发布者和订阅者。订阅者可以订阅一个或多个频道，而发布者可以向指定的频道发送消息，所有订阅此频道的订阅者都会收到该消息</p></li><li><p>发布者发布消息的命令是PUBLISH， 用法是</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">PUBLISH channel message</span><br></pre></td></tr></table></figure><p>比如向channel.1发一条消息:hello</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">PUBLISH channel.1 “hello”</span><br></pre></td></tr></table></figure></li></ul><p>这样就实现了消息的发送，该命令的返回值表示接收到这条消息的订阅者数量。因为在执行这条命令的时候还没有订阅者订阅该频道，所以返回为0. 另外值得注意的是消息发送出去不会持久化，如果发送之前没有订阅者，那么后续再有订阅者订阅该频道，之前的消息就收不到了</p><p>订阅者订阅消息的命令是：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">SUBSCRIBE channel [channel …]</span><br></pre></td></tr></table></figure><p>该命令同时可以订阅多个频道，比如订阅channel.1的频道：<strong>SUBSCRIBE channel.1</strong>，执行SUBSCRIBE命令后客户端会进入订阅状态。</p><p>一般情况下，我们不会用pub/sub来做消息发送机制，毕竟有这么多MQ技术在。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Redisson </tag>
            
            <tag> 分布式锁 </tag>
            
            <tag> Redis应用实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis使用过程中有哪些注意事项？缓存雪崩？缓存一致性？</title>
      <link href="/posts/2137391109/"/>
      <url>/posts/2137391109/</url>
      
        <content type="html"><![CDATA[<p>Redis使用起来很简单，但是在实际应用过程中，一定会碰到一些比较麻烦的问题，常见的问题有</p><ul><li>redis和数据库数据的一致性</li><li>缓存雪崩</li><li>缓存穿透</li><li>热点数据发现</li></ul><p>下面逐一来分析这些问题的原理及解决方案。</p><h1 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a>数据一致性</h1><p>针对读多写少的高并发场景，我们可以使用缓存来提升查询速度。当我们使用Redis作为缓存的时候，一般流程如图3-4所示。</p><ul><li>如果数据在Redis存在，应用就可以直接从Redis拿到数据，不用访问数据库。</li><li>如果Redis里面没有，先到数据库查询，然后写入到Redis，再返回给应用。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320507.png" alt="image-20210705200053476"></p><center>图3-4</center><p>因为这些数据是很少修改的，所以在绝大部分的情况下可以命中缓存。但是，一旦被缓存的数据发生变化的时候，我们既要操作数据库的数据，也要操作Redis的数据，所以问题来了。现在我们有两种选择：</p><ul><li><p>先操作Redis的数据再操作数据库的数据</p></li><li><p>先操作数据库的数据再操作Redis的数据</p></li></ul><p>到底选哪一种？</p><p>首先需要明确的是，不管选择哪一种方案， 我们肯定是希望两个操作要么都成功，要么都一个都不成功。不然就会发生Redis跟数据库的数据不一致的问题。但是，Redis的数据和数据库的数据是不可能通过事务达到统一的，我们只能根据相应的场景和所需要付出的代价来采取一些措施降低数据不一致的问题出现的概率，在数据一致性和性能之间取得一个权衡。</p><p>对于数据库的实时性一致性要求不是特别高的场合，比如T+1的报表，可以采用定时任务查询数据库数据同步到Redis的方案。由于我们是以数据库的数据为准的，所以给缓存设置一个过期时间，是保证最终一致性的解决方案。</p><h2 id="Redis：删除还是更新？"><a href="#Redis：删除还是更新？" class="headerlink" title="Redis：删除还是更新？"></a>Redis：删除还是更新？</h2><p>这里我们先要补充一点，当存储的数据发生变化，Redis的数据也要更新的时候，我们有两种方案，一种就是直接更新，调用set；还有一种是直接删除缓存，让应用在下次查询的时候重新写入。</p><p>这两种方案怎么选择呢？这里我们主要考虑更新缓存的代价。</p><p>更新缓存之前，判断是不是要经过其他表的查询、接口调用、计算才能得到最新的数据，而不是直接从数据库拿到的值，如果是的话，建议直接删除缓存，这种方案更加简单，一般情况下也推荐删除缓存方案。</p><p>这一点明确之后，现在我们就剩一个问题：</p><ul><li><p>到底是先更新数据库，再删除缓存</p></li><li><p>还是先删除缓存，再更新数据库</p></li></ul><h2 id="先更新数据库，再删除缓存"><a href="#先更新数据库，再删除缓存" class="headerlink" title="先更新数据库，再删除缓存"></a>先更新数据库，再删除缓存</h2><p><strong>正常情况</strong>：更新数据库，成功。删除缓存，成功。</p><p><strong>异常情况</strong>：</p><p>1、更新数据库失败，程序捕获异常，不会走到下一步，所以数据不会出现不一致。</p><p>2、更新数据库成功，删除缓存失败。数据库是新数据，缓存是旧数据，发生了不一致的情况。</p><p>这种问题怎么解决呢？我们可以提供一个重试的机制。</p><p>比如：如果删除缓存失败，我们捕获这个异常，把需要删除的key发送到消息队列。然后自己创建一个消费者消费，尝试再次删除这个key，如图3-5所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320836.png" alt="image-20210705201740430"></p><center>图3-5</center><p>另外一种方案，<strong>异步更新缓存</strong>：</p><p>因为更新数据库时会往<strong>binlog</strong>写入日志，所以我们可以通过一个服务来监听<strong>binlog</strong>的变化（比如阿里的canal），然后在客户端完成删除key的操作。如果删除失败的话，再发送到消息队列。</p><p>总之，对于后删除缓存失败的情况，我们的做法是不断地重试删除，直到成功。无论是重试还是异步删除，都是最终一致性的思想，如图3-6所示。</p><blockquote><p>基于数据库增量日志解析，提供增量数据订阅&amp;消费，目前主要支持了mysql。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320962.png" alt="image-20210705202304171"></p><center>图3-6</center><h2 id="先删除缓存，再更新数据库"><a href="#先删除缓存，再更新数据库" class="headerlink" title="先删除缓存，再更新数据库"></a>先删除缓存，再更新数据库</h2><p>正常情况：删除缓存，成功。更新数据库，成功。</p><p>异常情况：</p><ul><li><p>删除缓存，程序捕获异常，不会走到下一步，所以数据不会出现不一致。</p></li><li><p>删除缓存成功，更新数据库失败。 因为以数据库的数据为准，所以不存在数据不一致的情况。</p></li></ul><p>看起来好像没问题，但是如果有程序并发操作的情况下：</p><ul><li><p>线程A需要更新数据，首先删除了Redis缓存</p></li><li><p>线程B查询数据，发现缓存不存在，到数据库查询旧值，写入Redis，返回</p></li><li><p>线程A更新了数据库</p></li></ul><p>这个时候，Redis是旧的值，数据库是新的值，发生了数据不一致的情况，如图3-7所示，这种情况就比较难处理了，只有针对同一条数据进行串行化访问，才能解决这个问题，但是这种实现起来对性能影响较大，因此一般情况下不会采用这种做法。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320709.png" alt="image-20210705204932980"></p><center>图3-7</center><h1 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h1><p>缓存雪崩就是Redis的大量热点数据同时过期（失效），因为设置了相同的过期时间，刚好这个时候Redis请求的并发量又很大，就会导致所有的请求落到数据库。</p><h2 id="关于缓存过期"><a href="#关于缓存过期" class="headerlink" title="关于缓存过期"></a>关于缓存过期</h2><p>在实际开发中，我们经常会，比如限时优惠、缓存、验证码有效期等。一旦过了指定的有效时间就需要自动删除这些数据，否则这些无效数据会一直占用内存但是缺没有任何价值，因此在Redis中提供了Expire命令设置一个键的过期时间，到期以后Redis会自动删除它。这个在我们实际使用过程中用得非常多。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">expire key seconds # 设置键在给定秒后过期</span><br><span class="line">pexpire key milliseconds # 设置键在给定毫秒后过期</span><br><span class="line"></span><br><span class="line">expireat key timestamp # 到达指定秒数时间戳之后键过期</span><br><span class="line">pexpireat key timestamp # 到达指定毫秒数时间戳之后键过期</span><br></pre></td></tr></table></figure><p>EXPIRE 返回值为1表示设置成功，0表示设置失败或者键不存在，如果向知道一个键还有多久时间被删除，可以使用TTL命令</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ttl key # 返回键多少秒后过期</span><br><span class="line">pttl key # 返回键多少毫秒后过期</span><br></pre></td></tr></table></figure><p>当键不存在时，TTL命令会返回-2，而对于没有给指定键设置过期时间的，通过TTL命令会返回-1。</p><p>除此之外，针对String类型的key的过期时间，我们还可以通过下面这个方法来设置，其中可选参数<code>ex</code>表示设置过期时间。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set key value [ex seconds]</span><br></pre></td></tr></table></figure><p>如果向取消键的过期时间设置（使该键恢复成为永久的），可以使用PERSIST命令，如果该命令执行成功或者成功清除了过期时间，则返回1 。 否则返回0（键不存在或者本身就是永久的）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">SET expire.demo 1 ex 20</span><br><span class="line">TTL expire.demo</span><br><span class="line">PERSIST expire.demo</span><br><span class="line">TTL expire</span><br></pre></td></tr></table></figure><p>除了PERSIST命令，使用set命令为键赋值的操作也会导致过期时间失效。</p><h2 id="关于key过期的实现原理"><a href="#关于key过期的实现原理" class="headerlink" title="关于key过期的实现原理"></a>关于key过期的实现原理</h2><p>Redis使用一个过期字典（Redis字典使用哈希表实现，可以将字典看作哈希表）存储键的过期时间，字典的键是指向数据库键的指针（使用指针可以避免浪费内存空间），字典的值是一个毫秒时间戳，所以在当前时间戳大于字典值的时候这个键就过期了，就可以对这个键进行删除（删除一个键不仅要删除数据库中的键，也要删除过期字典中的键）。</p><p>设置过期时间的命令都是使用<code>pexpireat</code>命令实现的，其他命令也会转换成<code>pexpireat</code>。给一个键设置过期时间，就是将这个键的指针以及给定的到期时间戳添加到过期字典中。比如，执行命令<code>pexpireat key 1608290696843</code>，那么过期字典结构将如图3-8所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320438.png" alt="image-20210705221859849"></p><center>图3-8</center><h2 id="过期键的删除"><a href="#过期键的删除" class="headerlink" title="过期键的删除"></a>过期键的删除</h2><p>过期键的删除有两种方法。</p><ul><li><p>被动方式删除</p><p>被动方式的核心原理是，当客户端尝试访问某个key时，发现当前key已经过期了，就直接删除这个key。</p><p>当然，有可能会存在一些key，一直没有客户端访问，就会导致这部分key一直占用内存，因此加了一个主动删除方式。</p></li><li><p>主动方式删除</p><p>主动删除就是Redis定期扫描国期间中的key进行删除，它的删除策略是：</p><ul><li>从过期键中随机获取20个key，删除这20个key中已经过期的key。</li><li>如果在这20个key中有超过25%的key过期，则重新执行当前步骤。实际上这是利用了一种概率算法。</li></ul></li></ul><p>Redis结合这两种设计很好的解决了过期key的处理问题。</p><h2 id="如何解决缓存雪崩"><a href="#如何解决缓存雪崩" class="headerlink" title="如何解决缓存雪崩"></a>如何解决缓存雪崩</h2><p>了解了过期key的删除后，再来分析缓存雪崩问题。缓存雪崩有几个方面的原因导致。</p><ul><li>Redis的大量热点数据同时过期（失效）</li><li>Redis服务器出现故障， 这种情况，我们需要考虑到redis的高可用集群，这块后面再说。</li></ul><p>我们来分析第一种情况，这种情况无非就是程序再去查一次数据库，再把数据库中的数据保存到缓存中就行，问题也不大。可是一旦涉及大数据量的需求，比如一些商品抢购的情景，或者是主页访问量瞬间较大的时候，单一使用数据库来保存数据的系统会因为面向磁盘，磁盘读/写速度比较慢的问题而存在严重的性能弊端，一瞬间成千上万的请求到来，需要系统在极短的时间内完成成千上万次的读/写操作，这个时候往往不是数据库能够承受的，极其容易造成数据库系统瘫痪，最终导致服务宕机的严重生产问题。</p><p>解决这类问题的方法有几个。</p><ul><li>对过期时间增加一个随机值，避免同一时刻大量key失效。</li><li>对于热点数据，不设置过期时间。</li><li>当从redis中获取数据为空时，去数据库查询数据的地方互斥锁，这种方式会造成性能下降。</li><li>增加二级缓存，以及缓存和二级缓存的过期时间不同，当一级缓存失效后，可以再通过二级缓存获取。</li></ul><h1 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h1><p>缓存穿透，一般是指当前访问的数据在redis和mysql中都不存在的情况，有可能是一次错误的查询，也可能是恶意攻击。</p><p>在这种情况下，因为数据库值不存在，所以肯定不会写入Redis，那么下一次查询相同的key的时候，肯定还是会再到数据库查一次。试想一下，如果有人恶意设置大量请求去访问一些不存在的key，这些请求同样最终会访问到数据库中，有可能导致数据库的压力过大而宕机。</p><p>这种情况一般有两种处理方法。</p><h2 id="缓存空值"><a href="#缓存空值" class="headerlink" title="缓存空值"></a>缓存空值</h2><p>我们可以在数据库缓存一个空字符串，或者缓存一个特殊的字符串，那么在应用里面拿到这个特殊字符串的时候，就知道数据库没有值了，也没有必要再到数据库查询了。</p><p>但是这里需要设置一个过期时间，不然的会数据库已经新增了这一条记录，应用也还是拿不到值。</p><p>这个是应用重复查询同一个不存在的值的情况，如果应用每一次查询的不存在的值是不一样的呢？即使你每次都缓存特殊字符串也没用，因为它的值不一样，比如我们的用户系统登录的场景，如果是恶意的请求，它每次都生成了一个符合ID规则的账号，但是这个账号在我们的数据库是不存在的，那Redis就完全失去了作用，因此我们有另外一种方法，布隆过滤器。</p><h2 id="布隆过滤器解决缓存穿透"><a href="#布隆过滤器解决缓存穿透" class="headerlink" title="布隆过滤器解决缓存穿透"></a>布隆过滤器解决缓存穿透</h2><p>先来了解一下布隆过滤器的原理，</p><ul><li>首先，项目在启动的时候，把所有的数据加载到布隆过滤器中。</li><li>然后，当客户端有请求过来时，先到布隆过滤器中查询一下当前访问的key是否存在，如果布隆过滤器中没有该key，则不需要去数据库查询直接反馈即可</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320226.png" alt="image-20210705232359445"></p><center>图3-9</center><p>下面我们通过一个案例来演示一下布隆过滤器的工作机制。</p><p>注意，该案例是在[springboot-redis-example]这个工程中进行演示。</p><ul><li><p>添加guava依赖，guava中提供了布隆过滤器的api</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.google.guava<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>guava<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>21.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>增加一个ApplicationRunner实现，当spring boot启动完成后执行初始化</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BloomFilterDataLoadApplicationRunner</span> <span class="keyword">implements</span> <span class="title">ApplicationRunner</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    ICityService cityService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(ApplicationArguments args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        List&lt;City&gt; cityList=cityService.list();</span><br><span class="line">        <span class="comment">// expectedInsertions: 预计添加的元素个数</span></span><br><span class="line">        <span class="comment">// fpp: 误判率（后续再讲）</span></span><br><span class="line">        BloomFilter&lt;String&gt; bloomFilter=BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8),<span class="number">10000000</span>,<span class="number">0.03</span>);</span><br><span class="line">        cityList.parallelStream().forEach(city -&gt; &#123;</span><br><span class="line">            bloomFilter.put(RedisKeyConstants.CITY_KEY+<span class="string">&quot;:&quot;</span>+city.getId());</span><br><span class="line">        &#125;);</span><br><span class="line">        BooleanFilterCache.bloomFilter=bloomFilter;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>添加一个controller用来访问测试</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BloomFilterController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    RedisTemplate redisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/bloom/&#123;id&#125;&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">filter</span><span class="params">(<span class="meta">@PathVariable(&quot;id&quot;)</span>Integer id)</span></span>&#123;</span><br><span class="line">        String key=RedisKeyConstants.CITY_KEY+<span class="string">&quot;:&quot;</span>+id;</span><br><span class="line">        <span class="keyword">if</span>(BooleanFilterCache.bloomFilter.mightContain(key))&#123; <span class="comment">//判断当前数据在布隆过滤器中是否存在，如果存在则从缓存中加载</span></span><br><span class="line">            <span class="keyword">return</span> redisTemplate.opsForValue().get(key).toString();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;数据不存在&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>布隆过滤器存储空间大小计算： <a href="https://hur.st/bloomfilter/?n=1000000&amp;p=0.03&amp;m=&amp;k=">https://hur.st/bloomfilter/?n=1000000&amp;p=0.03&amp;m=&amp;k=</a></p></blockquote><h1 id="布隆过滤器原理分析"><a href="#布隆过滤器原理分析" class="headerlink" title="布隆过滤器原理分析"></a>布隆过滤器原理分析</h1><p>完成上述实验过程后，很多同学会产生疑问，</p><ul><li>老师，如果我的数据量有上千万，那不会很占内存啊？</li><li>老师，布隆过滤器的实现原理是什么呀？</li></ul><h2 id="什么是布隆过滤器"><a href="#什么是布隆过滤器" class="headerlink" title="什么是布隆过滤器"></a>什么是布隆过滤器</h2><p>布隆过滤器是Burton Howard Bloom在1970年提出来的，一种空间效率极高的概率型算法和数据结构，主要用来判断一个元素是否在集合中存在。因为他是一个概率型的算法，所以会存在一定的误差，如果传入一个值去布隆过滤器中检索，可能会出现检测存在的结果但是实际上可能是不存在的，但是肯定不会出现实际上不存在然后反馈存在的结果。因此，Bloom Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省</p><h2 id="BitMap（位图）"><a href="#BitMap（位图）" class="headerlink" title="BitMap（位图）"></a>BitMap（位图）</h2><p>所谓的Bit-map就是用一个bit位来标记某个元素对应的Value，通过Bit为单位来存储数据，可以大大节省存储空间. </p><blockquote><p>ps:比特是一个二进制数的最小单元，就像我们现在金额的最小单位是分。只不过比特是二进制数而已，一个比特只能拥有一个值，不是0就是1，所以如果我给你一个值0，你可以说它就是一个比特，如果我给你两个（00），你就可以说它们是两个比特了。如果你将八个0或者1组合在一起，我们可以说说是8比特或者1个字节。在32位的机器上，一个int类型的数据会占用4个字节，也就是32个比特位。</p></blockquote><p>在java中，一个int类型占32个比特，我们用一个int数组来表示时未new int[32],总计占用内存32*32bit,现假如我们用int字节码的每一位表示一个数字的话，那么32个数字只需要一个int类型所占内存空间大小就够了，这样在大数据量的情况下会节省很多内存。</p><p>如果要存储n个数字，那么具体思路如下。</p><ul><li><p>1个int占4字节即4*8=32位，那么我们只需要申请一个int数组长度为 int tmp[1+N/32]即可存储完这些数据，其中N代表要进行查找的总数，tmp中的每个元素在内存在占32位可以对应表示十进制数0~31,所以可得到BitMap表:</p><ul><li>tmp[0]:可表示0~31</li><li>tmp[1]:可表示32~63</li><li>tmp[2]可表示64~95</li><li>…….</li></ul></li><li><p>接着，我们只需要把对应的数字存储到指定数组元素的bit中即可，如何判断int数字在tmp数组的哪个下标，这个其实可以通过直接除以32取整数部分，例如：整数8除以32取整等于0，那么8就在tmp[0]上。另外，我们如何知道了8在tmp[0]中的32个位中的哪个位，这种情况直接mod上32就ok，又如整数8，在tmp[0]中的<code>8 mod 32</code>等于8，那么整数8就在tmp[0]中的第八个bit位（从右边数起）</p></li></ul><p>比如我们要存储5**(101)<strong>、9</strong>(1001)<strong>、3</strong>(11)<strong>、1</strong>(1)**四个数字，那么我们申请int型的内存空间，会有32个比特位。这四个数字的二进制分别对应如下。</p><blockquote><p>从右往左开始数，比如第一个数字是5，对应的二进制数据是101, 那么从有往左数到第5位，把对应的二进制数据存储到32个比特位上。</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">第一个5就是     00000000000000000000000000101000 </span><br><span class="line"></span><br><span class="line">而输入9的时候   00000000000000000000001001000000 </span><br><span class="line"></span><br><span class="line">输入3时候      00000000000000000000000000001100 </span><br><span class="line"></span><br><span class="line">输入1的时候    00000000000000000000000000000010</span><br></pre></td></tr></table></figure><p>思想比较简单，关键是十进制和二进制bit位需要一个map映射表，把10进制映射到bit位上，这样的好处是内存占用少、效率很高（不需要比较和位移）。</p><h2 id="布隆过滤器原理"><a href="#布隆过滤器原理" class="headerlink" title="布隆过滤器原理"></a>布隆过滤器原理</h2><p>有了对位图的理解以后，我们对布隆过滤器的原理理解就会更容易了，基于前面的例子，我们把数据库中的一张表的数据全部先保存到布隆过滤器中，用来判断当前访问的key是否存在于数据库。</p><p>假设我们需要把id=1这个key保存到布隆过滤器中，并且该布隆过滤器中的hash函数个数为3｛x、y、z｝，它的具体实现原理如下：</p><ul><li>首先将位数组进行初始化，将里面每个位都设置位0。</li><li>对于集合里面的每一个元素，将元素依次通过3个哈希函数｛x、y、z｝进行映射，每次映射都会产生一个哈希值，这个值对应位数组上面的一个点，然后将位数组对应的位置标记为1。</li><li>查询<code>id=1</code>元素是否存在集合中的时候，同样的方法将W通过哈希映射到位数组上的3个点。<ul><li>如果3个点的其中有一个点不为1，则可以判断该元素一定不存在集合中。</li><li>反之，如果3个点都为1，则该元素可能存在集合中。</li></ul></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320560.png" alt="image-20210706210232859"></p><center>图3-10</center><p>接下来按照该方法处理所有的输入对象，每个对象都可能把bitMap中一些白位置涂黑，也可能会遇到已经涂黑的位置，遇到已经为黑的让他继续为黑即可。处理完所有的输入对象之后，在bitMap中可能已经有相当多的位置已经被涂黑。至此，一个布隆过滤器生成完成，这个布隆过滤器代表之前所有输入对象组成的集合。</p><p><strong>如何去判断一个元素是否存在bit array中呢？</strong> 原理是一样，根据k个哈希函数去得到的结果，如果所有的结果都是1，表示这个元素可能（<strong>假设某个元素通过映射对应下标为4，5，6这3个点。虽然这3个点都为1，但是很明显这3个点是不同元素经过哈希得到的位置，因此这种情况说明元素虽然不在集合中，也可能对应的都是1</strong>）存在。 如果一旦发现其中一个比特位的元素是0，表示这个元素一定不存在</p><p>至于k个哈希函数的取值为多少，能够最大化的降低错误率（因为哈希函数越多，映射冲突会越少），这个地方就会涉及到最优的哈希函数个数的一个算法逻辑。</p><ul><li><p>fpp表示允许的错误概率</p></li><li><p>expectedInsertions: 预期插入的数量</p></li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    BloomFilter&lt;String&gt; bloomFilter=BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8),<span class="number">10000000</span>,<span class="number">0.03</span>);</span><br><span class="line">    bloomFilter.put(<span class="string">&quot;Mic&quot;</span>);</span><br><span class="line">    System.out.println(bloomFilter.mightContain(<span class="string">&quot;Mic&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 布隆过滤器 </tag>
            
            <tag> 缓存穿透 </tag>
            
            <tag> 缓存一致性 </tag>
            
            <tag> 缓存雪崩 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>盘点一下Redis中常用的Java客户端,或者咱们手写一个？</title>
      <link href="/posts/1921857783/"/>
      <url>/posts/1921857783/</url>
      
        <content type="html"><![CDATA[<p>我们要在Java中操作Redis，怎么做呢？首先我们先来了解一下Redis Serialization Protocol(Redis序列化协议)，这个是Redis提供的一种，客户端和Redis服务端通信传输的编码协议，服务端收到罅隙ihou，会基于这个约定编码进行解码。</p><ul><li><p>打开Wireshark工具，对VMnet8这个网络进行抓包</p></li><li><p>增加过滤条件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ip.dst_host==192.168.221.128 and tcp.port in &#123;6379&#125;</span><br></pre></td></tr></table></figure></li><li><p>使用RDM工具连接到Redis Server进行key-value操作，比如执行 set name mic</p></li><li><p>通过Wireshark工具监控数据包内容，如图3-3所示，可以看到实际发出的数据包是：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*3\r\n$3\r\nSET\r\n$4\r\nname\r\n$3\r\nmic</span><br></pre></td></tr></table></figure><ul><li><p>其中<code>*3*</code>代表参数个数，set  name mic， 表示三个参数。</p></li><li><p><code>$3</code>表示属性长度，<code>$</code>表示包含3个字符。</p></li></ul><blockquote><p>客户端和服务器发送的命令或数据一律以 \r\n （CRLF回车+换行）结尾。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320687.png" alt="image-20210703173900083"></p><center>图3-3</center></li></ul><p>基于这样一个特性，我们可以自己实现一个Java客户端。</p><h2 id="自定义Redis客户端"><a href="#自定义Redis客户端" class="headerlink" title="自定义Redis客户端"></a>自定义Redis客户端</h2><p>下面我们通过抓包相关的命令，了解Redis客户端的工作机制。</p><h3 id="定义常量池。"><a href="#定义常量池。" class="headerlink" title="定义常量池。"></a>定义常量池。</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CommandConstant</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 开始符</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String START = <span class="string">&quot;*&quot;</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 指令长度符</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String LENGTH = <span class="string">&quot;$&quot;</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 换行符</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String LINE = <span class="string">&quot;\r\n&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">CommandEnum</span> </span>&#123;</span><br><span class="line">        SET,</span><br><span class="line">        GET,</span><br><span class="line">        INCR</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="CustomClientSocket"><a href="#CustomClientSocket" class="headerlink" title="CustomClientSocket"></a>CustomClientSocket</h3><p>CustomClientSocket用来建立网络通信连接，并且发送数据指定到RedisServer。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomClientSocket</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Socket socket;</span><br><span class="line">    <span class="keyword">private</span> InputStream inputStream;</span><br><span class="line">    <span class="keyword">private</span> OutputStream outputStream;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CustomClientSocket</span><span class="params">(String ip,<span class="keyword">int</span> port)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            socket=<span class="keyword">new</span> Socket(ip,port);</span><br><span class="line">            inputStream=socket.getInputStream();</span><br><span class="line">            outputStream=socket.getOutputStream();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">(String cmd)</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            outputStream.write(cmd.getBytes());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">read</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">byte</span>[] bytes = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            count = inputStream.read(bytes);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> String(bytes, <span class="number">0</span>, count);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="封装客户端"><a href="#封装客户端" class="headerlink" title="封装客户端"></a>封装客户端</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomRedisClient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> CustomClientSocket customClientSocket;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CustomRedisClient</span><span class="params">(String host,<span class="keyword">int</span> port)</span> </span>&#123;</span><br><span class="line">        customClientSocket=<span class="keyword">new</span> CustomClientSocket(host,port);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">set</span><span class="params">(String key, String value)</span> </span>&#123;</span><br><span class="line">        customClientSocket.send(convertToCommand(CommandConstant.CommandEnum.SET, key.getBytes(), value.getBytes()));</span><br><span class="line">        <span class="keyword">return</span> customClientSocket.read();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">get</span><span class="params">(String key)</span> </span>&#123;</span><br><span class="line">        customClientSocket.send(convertToCommand(CommandConstant.CommandEnum.GET, key.getBytes()));</span><br><span class="line">        <span class="keyword">return</span> customClientSocket.read();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">convertToCommand</span><span class="params">(CommandConstant.CommandEnum command, <span class="keyword">byte</span>[]... bytes)</span> </span>&#123;</span><br><span class="line">        StringBuilder stringBuilder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        stringBuilder.append(CommandConstant.START).append(bytes.length + <span class="number">1</span>).append(CommandConstant.LINE);</span><br><span class="line">        stringBuilder.append(CommandConstant.LENGTH).append(command.toString().length()).append(CommandConstant.LINE);</span><br><span class="line">        stringBuilder.append(command.toString()).append(CommandConstant.LINE);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">byte</span>[] aByte : bytes) &#123;</span><br><span class="line">            stringBuilder.append(CommandConstant.LENGTH).append(aByte.length).append(CommandConstant.LINE);</span><br><span class="line">            stringBuilder.append(<span class="keyword">new</span> String(aByte)).append(CommandConstant.LINE);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> stringBuilder.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="测试方法"><a href="#测试方法" class="headerlink" title="测试方法"></a>测试方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    CustomRedisClient redisClient=<span class="keyword">new</span> CustomRedisClient(<span class="string">&quot;192.168.221.128&quot;</span>,<span class="number">6379</span>);</span><br><span class="line">    System.out.println(redisClient.set(<span class="string">&quot;name&quot;</span>,<span class="string">&quot;mic&quot;</span>));</span><br><span class="line">    System.out.println(redisClient.get(<span class="string">&quot;name&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>你看，理解了原理之后，自己去实现起来发现并不难。</p><p>但是实际开发过程中，我们难倒也需要开发自己开发客户端吗？当然不用，官方推荐了以下三种客户端</p><table><thead><tr><th><strong>配置</strong></th><th><strong>作用</strong></th></tr></thead><tbody><tr><td>Jedis</td><td>A blazingly small and sane redis java  client</td></tr><tr><td>lettuce</td><td>Advanced Redis client for thread-safe  sync, async, and reactive usage. Supports Cluster, Sentinel, Pipelining, and  codecs.</td></tr><tr><td>Redisson</td><td>distributed and scalable Java data  structures on top of Redis server</td></tr></tbody></table><h2 id="Jedis"><a href="#Jedis" class="headerlink" title="Jedis"></a>Jedis</h2><p>Jedis是我们最熟悉和最常用的客户端。轻量，简洁，便于集成和改造。</p><h3 id="简单使用方法"><a href="#简单使用方法" class="headerlink" title="简单使用方法"></a>简单使用方法</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>redis.clients<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jedis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.6.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    Jedis jedis = <span class="keyword">new</span> Jedis(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">6379</span>);</span><br><span class="line">    jedis.set(<span class="string">&quot;qingshan&quot;</span>, <span class="string">&quot;2673&quot;</span>);</span><br><span class="line">    System.out.println(jedis.get(<span class="string">&quot;qingshan&quot;</span>));</span><br><span class="line">    jedis.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一般来说，我们不会使用单个Jedis连接，而是会使用连接池，Jedis提供了连接池的功能。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    JedisPool pool = <span class="keyword">new</span> JedisPool(ip, port);</span><br><span class="line">    Jedis jedis = jedisPool.getResource();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Luttece"><a href="#Luttece" class="headerlink" title="Luttece"></a>Luttece</h2><p><code>Lettuce</code>是一个<code>Redis</code>的<code>Java</code>驱动包，大家常用的spring-boot-starter-data-redis中默认就采用的Lettuce。<code>Lettuce</code>是一个高性能基于<code>Java</code>编写的<code>Redis</code>驱动框架，底层集成了<code>Project Reactor</code>提供天然的反应式编程，通信框架集成了<code>Netty</code>使用了非阻塞<code>IO</code>，<code>5.x</code>版本之后融合了<code>JDK1.8</code>的异步编程特性，在保证高性能的同时提供了十分丰富易用的<code>API</code>。</p><h3 id="简单使用方法-1"><a href="#简单使用方法-1" class="headerlink" title="简单使用方法"></a>简单使用方法</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.lettuce<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lettuce-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.1.8.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>Lettuce</code>使用的时候依赖于四个主要组件：</p><ul><li><code>RedisURI</code>：连接信息。</li><li><code>RedisClient</code>：<code>Redis</code>客户端，特殊地，集群连接有一个定制的<code>RedisClusterClient</code>。</li><li><code>Connection</code>：<code>Redis</code>连接，主要是<code>StatefulConnection</code>或者<code>StatefulRedisConnection</code>的子类，连接的类型主要由连接的具体方式（单机、哨兵、集群、订阅发布等等）选定，比较重要。</li><li><code>RedisCommands</code>：<code>Redis</code>命令<code>API</code>接口，<strong>基本上覆盖了<code>Redis</code>发行版本的所有命令</strong>，提供了同步（<code>sync</code>）、异步（<code>async</code>）、反应式（<code>reative</code>）的调用方式，对于使用者而言，会经常跟<code>RedisCommands</code>系列接口打交道。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        RedisURI redisUri = RedisURI.builder()                    <span class="comment">// &lt;1&gt; 创建单机连接的连接信息</span></span><br><span class="line">                .withHost(<span class="string">&quot;192.168.221.128&quot;</span>)</span><br><span class="line">                .withPort(<span class="number">6379</span>)</span><br><span class="line">                .withTimeout(Duration.of(<span class="number">10</span>, ChronoUnit.SECONDS))</span><br><span class="line">                .build();</span><br><span class="line">        RedisClient redisClient = RedisClient.create(redisUri);   <span class="comment">// &lt;2&gt; 创建客户端</span></span><br><span class="line">        StatefulRedisConnection&lt;String, String&gt; connection = redisClient.connect();     <span class="comment">// &lt;3&gt; 创建线程安全的连接</span></span><br><span class="line">        RedisCommands&lt;String, String&gt; redisCommands = connection.sync();                <span class="comment">// &lt;4&gt; 创建同步命令</span></span><br><span class="line">        SetArgs setArgs = SetArgs.Builder.nx().ex(<span class="number">5</span>);</span><br><span class="line">        String result = redisCommands.set(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;throwable&quot;</span>, setArgs);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">        result = redisCommands.get(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">        <span class="comment">// ... 其他操作</span></span><br><span class="line">        connection.close();   <span class="comment">// &lt;5&gt; 关闭连接</span></span><br><span class="line">        redisClient.shutdown();  <span class="comment">// &lt;6&gt; 关闭客户端</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3 id="和Spring-Boot集成使用"><a href="#和Spring-Boot集成使用" class="headerlink" title="和Spring Boot集成使用"></a>和Spring Boot集成使用</h3><p>Lettuce是Spring Boot 2.x 默认的客户端，替换了Jedis。集成之后我们不需要单独使用它，直接调用Spring的RedisTemplate操作，连接和创建和关闭也不需要我们操心。</p><p>引入依赖jar包</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-data-redis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>application.yml配置文件如下</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">redis:</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">6379</span></span><br><span class="line">    <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.221</span><span class="number">.128</span></span><br><span class="line">    <span class="attr">lettuce:</span></span><br><span class="line">      <span class="attr">pool:</span></span><br><span class="line">        <span class="attr">max-active:</span> <span class="number">-1</span></span><br><span class="line">        <span class="attr">max-idle:</span> <span class="number">2000</span></span><br><span class="line">        <span class="attr">max-wait:</span> <span class="number">-1</span></span><br><span class="line">        <span class="attr">min-idle:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">time-between-eviction-runs:</span> <span class="number">5000</span></span><br></pre></td></tr></table></figure><p>使用方法</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LutteceController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    RedisTemplate redisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ResponseEntity <span class="title">get</span><span class="params">()</span></span>&#123;</span><br><span class="line">        String name=(String)redisTemplate.opsForValue().get(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ResponseEntity.ok(name);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Redisson"><a href="#Redisson" class="headerlink" title="Redisson"></a>Redisson</h2><blockquote><p><a href="https://redisson.org/">https://redisson.org/</a></p><p><a href="https://github.com/redisson/redisson/wiki/%E7%9B%AE%E5%BD%95">https://github.com/redisson/redisson/wiki/目录</a></p></blockquote><p>Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务。其中包括(<code>BitSet</code>, <code>Set</code>, <code>Multimap</code>, <code>SortedSet</code>, <code>Map</code>, <code>List</code>, <code>Queue</code>, <code>BlockingQueue</code>, <code>Deque</code>, <code>BlockingDeque</code>, <code>Semaphore</code>, <code>Lock</code>, <code>AtomicLong</code>, <code>CountDownLatch</code>, <code>Publish / Subscribe</code>, <code>Bloom filter</code>, <code>Remote service</code>, <code>Spring cache</code>, <code>Executor service</code>, <code>Live Object service</code>, <code>Scheduler service</code>) Redisson提供了使用Redis的最简单和最便捷的方法。Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。</p><h3 id="简单使用方法-2"><a href="#简单使用方法-2" class="headerlink" title="简单使用方法"></a>简单使用方法</h3><ul><li><p>引入依赖Jar包</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.redisson<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>redisson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.16.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>时间单节点连接和操作</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    Config config=<span class="keyword">new</span> Config();</span><br><span class="line">    config.useSingleServer().setAddress(<span class="string">&quot;redis://192.168.221.128:6379&quot;</span>);</span><br><span class="line">    RedissonClient redissonClient= Redisson.create(config);</span><br><span class="line">    redissonClient.getBucket(<span class="string">&quot;test&quot;</span>).set(<span class="string">&quot;mic&quot;</span>);</span><br><span class="line">    System.out.println(redissonClient.getBucket(<span class="string">&quot;test&quot;</span>).get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="和Spring-Boot集成"><a href="#和Spring-Boot集成" class="headerlink" title="和Spring Boot集成"></a>和Spring Boot集成</h3><p>Spring Boot的集成方式。</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.redisson<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>redisson-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.16.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>application.yml中的配置。</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">timeout:</span> <span class="number">2000</span></span><br><span class="line">    <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.221</span><span class="number">.128</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">6379</span></span><br></pre></td></tr></table></figure><p>使用方法。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedissonController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    RedissonClient redissonClient;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">get</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> redissonClient.getBucket(<span class="string">&quot;test&quot;</span>).get().toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>另外一种配置方式如下</p></blockquote><ul><li><p>修改application.yml</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">redisson:</span></span><br><span class="line">      <span class="attr">file:</span> <span class="string">classpath:redisson.yml</span></span><br></pre></td></tr></table></figure></li><li><p>创建一个redisson.yml文件，内容如下</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">singleServerConfig:</span></span><br><span class="line">  <span class="attr">address:</span> <span class="string">redis://192.168.221.128:6379</span></span><br><span class="line">  <span class="comment">#---------------------------------------------</span></span><br><span class="line">  <span class="comment"># 连接空闲超时，单位：毫秒</span></span><br><span class="line">  <span class="attr">idleConnectionTimeout:</span> <span class="number">10000</span></span><br><span class="line">  <span class="comment"># 连接超时，单位：毫秒</span></span><br><span class="line">  <span class="attr">connectTimeout:</span> <span class="number">10000</span></span><br><span class="line">  <span class="comment"># 命令等待超时，单位：毫秒</span></span><br><span class="line">  <span class="attr">timeout:</span> <span class="number">3000</span></span><br><span class="line">  <span class="comment"># 命令失败重试次数,如果尝试达到 retryAttempts（命令失败重试次数） 仍然不能将命令发送至某个指定的节点时，将抛出错误。</span></span><br><span class="line">  <span class="comment"># 如果尝试在此限制之内发送成功，则开始启用 timeout（命令等待超时） 计时。</span></span><br><span class="line">  <span class="attr">retryAttempts:</span> <span class="number">3</span></span><br><span class="line">  <span class="comment"># 命令重试发送时间间隔，单位：毫秒</span></span><br><span class="line">  <span class="attr">retryInterval:</span> <span class="number">1500</span></span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Redis Java </tag>
            
            <tag> 手写Redis客户端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图解Redis6中的9种数据结构，墙裂建议准备去面试的人先看（干货，建议收藏）</title>
      <link href="/posts/2848818622/"/>
      <url>/posts/2848818622/</url>
      
        <content type="html"><![CDATA[<p>如图所示，Redis中提供了9种不同的数据操作类型，他们分别代表了不同的数据存储结构。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110131450348.png" alt="image-20211013145055292"></p><center>图2-17 数据类型</center><h2 id="String类型"><a href="#String类型" class="headerlink" title="String类型"></a>String类型</h2><p>String类型是Redis用的较多的一个基本类型，也是最简单的一种类型，它和我们在Java中使用的字符类型什么太大区别，具体结构如图2-18所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451904.png" alt="image-20210630182903375"></p><center>图2-19</center><h3 id="String常用操作指令"><a href="#String常用操作指令" class="headerlink" title="String常用操作指令"></a>String常用操作指令</h3><p>常用炒作指令如图2-20所示，更多的指令查询：<a href="http://doc.redisfans.com/">http://doc.redisfans.com/</a></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451060.png" alt="image-20210630184919969"></p><center>图2-20</center><h3 id="String的实际存储结构"><a href="#String的实际存储结构" class="headerlink" title="String的实际存储结构"></a>String的实际存储结构</h3><p>学过C++的同学都知道，C++中没有String类型，而Redis又是基于C++来实现的，那么它是如何存储String类型的呢？</p><p>Redis并没有采用C语言的传统字符串表示方式（<code>char*</code>或者<code>char[]</code>），在Redis内部，String类型以<code>int/SDS(simple dynamic string)</code>作为结构存储，int用来存放整型数据，sds存放字节/字符串和浮点型数据。</p><p>在C的标准字符串结构下进行了封装，用来提升基本操作的性能，同时充分利用以后的C的标准库，简化实现。我们可以在redis的源码中【<strong>sds.h</strong>】中看到sds的结构如下；</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span> ((__<span class="title">packed__</span>)) <span class="title">sdshdr8</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint8_t</span> len;<span class="comment">//表示当前sds的长度(单位是字节)</span></span><br><span class="line">    <span class="keyword">uint8_t</span> alloc; <span class="comment">//表示已为sds分配的内存大小(单位是字节)</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> flags; <span class="comment">//用一个字节表示当前sdshdr的类型，因为有sdshdr有五种类型，所以至少需要3位来表示000:sdshdr5，001:sdshdr8，010:sdshdr16，011:sdshdr32，100:sdshdr64。高5位用不到所以都为0。</span></span><br><span class="line">    <span class="keyword">char</span> buf[];<span class="comment">//sds实际存放的位置</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>也就是说实际上sds类型就是<code>char*</code>类型，那<code>sds</code>和<code>char*</code>有什么区别呢？</p><p><strong>主要区别就是：sds一定有一个所属的结构(sdshdr)，这个header结构在每次创建sds时被创建，用来存储sds以及sds的相关信息</strong></p><p>对sds结构有一个简单认识以后，我们如果通过set创建一个字符串，那么也就是会创建一个sds来存储这个字符串信息，那么这个过程是怎么样的呢？</p><ul><li>首先第一个要判断选择一个什么类型的sdshdr来存放信息？这就得根据要存储的sds的长度决定了，redis在创建一个sds之前会调用【<strong>sds.c文件</strong>】sdsReqType(size_t string_size)来判断用哪个sdshdr。该函数传递一个sds的长度作为参数，返回应该选用的sdshdr类型。</li><li>然后把数据保存到对应的sdshdr中。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451456.png" alt="image-20210628163803639"></p><center>图2-19</center><blockquote><p>Redis采用类似C的做法存储字符串，也就是以’\0’结尾，’\0’只作为字符串的定界符，不计入alloc或者len</p></blockquote><p><strong>key命名小技巧</strong></p><ul><li>a) redis并没有规定我们对key应该怎么命名，但是最好的实践是“对象类型:对象id:对象属性.子属性”</li><li>b) key不要设置得太长，太长的key不仅仅消耗内存，而且在数据中查找这类键值计算成本很高</li><li>c) key不要设置得太短，比如u:1000:pwd 来代替user:1000:password, 虽然没什么问题，但是后者的可读性更好</li><li>d) 为了更好的管理你的key，对key进行业务上的分类；同时建议有一个wiki统一管理所有的key，通过查询这个文档知道redis中的key的作用</li></ul><h3 id="String类型的应用场景"><a href="#String类型的应用场景" class="headerlink" title="String类型的应用场景"></a>String类型的应用场景</h3><p>String类型使用比较多，一般来说，不太了解Redis的人，几乎所有场景都是用String类型来存储数据。</p><p><strong>分布式缓存</strong></p><p>首先最基本的就是用来做业务数据的缓存，如图2-20，Redis中会缓存一些常用的热点数据，可以提升数据查询的性能。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451205.png" alt="image-20210630191730761"></p><center>如图2-20</center><p><strong>分布式全局ID</strong></p><p>使用String类型的incr命令，实现原子递增</p><p><strong>限流</strong></p><p>使用计数器实现手机验证码频率限流。</p><p><strong>分布式session</strong></p><p>基于登录场景中，保存token信息。</p><h2 id="List类型"><a href="#List类型" class="headerlink" title="List类型"></a>List类型</h2><p>列表类型(list)可以存储一个有序且可重复的字符串列表，常用的操作是向列表两端添加元素或者获得列表的某一个片段，List的存储结构如图2-20所示</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451403.png" alt="image-20210629133004615"></p><center>图2-20</center><h3 id="常用操作命令"><a href="#常用操作命令" class="headerlink" title="常用操作命令"></a>常用操作命令</h3><p>图2-21表示list类型的常用操作命令，具体命令的操作，可以参考： <a href="http://doc.redisfans.com/">http://doc.redisfans.com/</a></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451804.png" alt="image-20210630200506802"></p><center>图2-21</center><h3 id="数据存储结构"><a href="#数据存储结构" class="headerlink" title="数据存储结构"></a>数据存储结构</h3><p>如图2-22所示，在redis6.0中，List采用了QuickList这样一种结构来存储数据，QuickList是一个双向链表，链表的每个节点保存一个ziplist，所有的数据实际上是存储在ziplist中，ziplist是一个压缩列表，它可以节省内存空间。</p><p>ziplist详细说明：<a href="https://www.cnblogs.com/hunternet/p/11306690.html">https://www.cnblogs.com/hunternet/p/11306690.html</a></p><blockquote><p>听到“压缩”两个字，直观的反应就是节省内存。之所以说这种存储结构节省内存,是相较于数组的存储思路而言的。我们知道,数组要求每个元素的大小相同,如果我们要存储不同长度的字符串,那我们就需要用最大长度的字符串大小作为元素的大小(假设是5个字节)。存储小于5个字节长度的字符串的时候，便会浪费部分存储空间，比如下面这个图所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451079.png" alt="image-20210629162512711"></p><p>所以，ziplist就是根据每个节点的长度来决定占用内存大小，然后每个元素保存时同步记录当前数据的长度，这样每次添加元素是就可以计算下一个节点在内存中的存储位置，从而形成一个压缩列表。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451256.png" alt="image-20210629163022632"></p><p>另外，数据的方式存储数据有一个很好的优势，就是它存储的是在一个连续的内存空间，它可以很好的利用CPU的缓存来访问数据，从而提升访问性能。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451747.png" alt="image-20210629143845481"></p><center>图2-22</center><p>其中，QuickList中的每个节点称为QuickListNode，具体的定义在<strong>quicklist.h</strong>文件中。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">prev</span>;</span>   <span class="comment">//链表的上一个node节点</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">next</span>;</span>   <span class="comment">//链表的下一个node节点</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> *zl;            <span class="comment">//数据指针，如果当前节点数据没有压缩，它指向一个ziplist，否则，指向一个quicklistLZF</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> sz;             <span class="comment">/* 指向的ziplist的总大小 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> count : <span class="number">16</span>;     <span class="comment">/* ziplist中的元素个数 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> encoding : <span class="number">2</span>;   <span class="comment">/* 表示ziplist是否压缩了，1表示没压缩，2表示压缩 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> container : <span class="number">2</span>;  <span class="comment">/* 预留字段 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> recompress : <span class="number">1</span>; <span class="comment">/* 当使用类似lindex命令查看某一个本压缩的数据时，需要先解压，这个用来存储标记，等有机会再把数据重新压缩 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> attempted_compress : <span class="number">1</span>; <span class="comment">/* node can&#x27;t compress; too small */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> extra : <span class="number">10</span>; <span class="comment">/* more bits to steal for future usage */</span></span><br><span class="line">&#125; quicklistNode;</span><br></pre></td></tr></table></figure><p>quickList是list类型的存储结构，其定义如下。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklist</span> &#123;</span></span><br><span class="line">    quicklistNode *head;    <span class="comment">//指向quicklistNode头节点</span></span><br><span class="line">    quicklistNode *tail;    <span class="comment">//指向quicklistNode的尾节点</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> count;        <span class="comment">/* 所有ziplist数据项的个数综合 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> len;          <span class="comment">/* quicklist节点个数*/</span></span><br><span class="line">    <span class="keyword">int</span> fill : QL_FILL_BITS;              <span class="comment">/* ziplist大小设置 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> compress : QL_COMP_BITS; <span class="comment">/* 节点压缩深度设置 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> bookmark_count: QL_BM_BITS;</span><br><span class="line">    quicklistBookmark bookmarks[];</span><br><span class="line">&#125; quicklist;</span><br></pre></td></tr></table></figure><p>如图2-23所示，当向list中添加元素时，会直接保存到某个QuickListNode中的ziplist中，不过不管是从头部插入数据，还是从尾部插入数据，都包含两种情况</p><ul><li>如果头节点（尾部节点）上的ziplist大小没有超过限制，新数据会直接插入到ziplist中</li><li>如果头节点上的ziplist达到阈值，则创建一个新的quicklistNode节点，该节点中会创建一个ziplist，然后把这个新创建的节点插入到quicklist双向链表中。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451224.png" alt="image-20210629152807286"></p><center>图2-23</center><h3 id="实际使用场景"><a href="#实际使用场景" class="headerlink" title="实际使用场景"></a>实际使用场景</h3><p><strong>消息队列</strong></p><p>列表类型可以使用 rpush 实现先进先出的功能，同时又可以使用 lpop 轻松的弹出（查询并删除）第一个元素，所以列表类型可以用来实现消息队列，如图2-24所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451792.png" alt="image-20210630200839165"></p><center>图2-24</center><p><strong>发红包的场景</strong></p><p>在发红包的场景中，假设发一个10元，10个红包，需要保证抢红包的人不会多抢到，也不会少抢到，这种情况下，可以根据图2-25所示去实现。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451805.png" alt="image-20210630201807762"></p><center>图2-25</center><h2 id="Hash类型"><a href="#Hash类型" class="headerlink" title="Hash类型"></a>Hash类型</h2><p>Hash类型大家应该都不陌生，他就是一个键值对集合，如图2-26所示。Hash相当于一个 string 类型的 key和 value 的映射表，key 还是key，但是value是一个键值对（key-value），类比于 Java里面的 Map&lt;String,Map&lt;String,Object&gt;&gt; 集合。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451273.png" alt="image-20210629154429976"></p><center>图2-26</center><h3 id="Hash常用操作命令"><a href="#Hash常用操作命令" class="headerlink" title="Hash常用操作命令"></a>Hash常用操作命令</h3><p>Hash结构的常用操作命令如图2-27所示，其他的指令可以参考：<a href="http://doc.redisfans.com/">http://doc.redisfans.com/</a></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451067.png" alt="image-20210629155915069"></p><center>图2-27</center><h3 id="Hash实际存储结构"><a href="#Hash实际存储结构" class="headerlink" title="Hash实际存储结构"></a>Hash实际存储结构</h3><p>如图2-28所示，哈希类型的内部编码有两种：<strong>ziplist压缩列表</strong>,<strong>hashtable哈希表</strong>。只有当存储的数据量比较小的情况下，Redis 才使用压缩列表来实现字典类型。具体需要满足两个条件：</p><ul><li>当哈希类型元素个数小于<strong>hash-max-ziplist-entries</strong>配置（默认512个）</li><li>所有值都小于<strong>hash-max-ziplist-value</strong>配置（默认64字节）<br><code>ziplist</code>使用更加紧凑的结构实现多个元素的连续存储，所以在节省内存方面比<code>hashtable</code>更加优秀。当哈希类型无法满足<code>ziplist</code>的条件时，Redis会使用<code>hashtable</code>作为哈希的内部实现，因为此时<code>ziplist</code>的读写效率会下降，而<code>hashtable</code>的读写时间复杂度为O（1）。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451472.png" alt="image-20210629172553348"></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451263.png" alt="image-20210630202531223"></p><center>图2-28</center><h3 id="Hash实际应用场景"><a href="#Hash实际应用场景" class="headerlink" title="Hash实际应用场景"></a>Hash实际应用场景</h3><p>Hash表使用用来存储对象数据，比如用户信息，相对于通过将对象转化为json存储到String类型中，Hash结构的灵活性更大，它可以任何添加和删除对象中的某些字段。</p><p><strong>购物车功能</strong></p><ul><li><p>1.以用户ID作为key</p></li><li><p>2.以商品id作为field</p></li><li><p>3.以商品的数量作为value</p></li></ul><p><strong>对象类型数据</strong></p><p>比如优化之后的用户信息存储，减少数据库的关联查询导致的性能慢的问题。</p><ul><li>用户信息</li><li>商品信息</li><li>计数器</li></ul><h2 id="Set类型"><a href="#Set类型" class="headerlink" title="Set类型"></a>Set类型</h2><p>如图2-29所示，集合类型 (Set) 是一个无序并唯一的键值集合。它的存储顺序不会按照插入的先后顺序进行存储。</p><p>集合类型和列表类型的区别如下：</p><ul><li>列表可以存储重复元素，集合只能存储非重复元素；</li><li>列表是按照元素的先后顺序存储元素的，而集合则是无序方式存储元素的。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451453.png" alt="image-20210629181723110"></p><center>图2-29</center><h3 id="set类型的常用操作"><a href="#set类型的常用操作" class="headerlink" title="set类型的常用操作"></a>set类型的常用操作</h3><p>Set类型的常用操作指令如下。</p><table><thead><tr><th>命令</th><th>说明</th><th>时间复杂度</th></tr></thead><tbody><tr><td>SADD key member [member …]</td><td>添加一个或者多个元素到集合(set)里</td><td>O(N)</td></tr><tr><td>SCARD key</td><td>获取集合里面的元素数量</td><td>O(1)</td></tr><tr><td>SDIFF key [key …]</td><td>获得队列不存在的元素</td><td>O(N)</td></tr><tr><td>SDIFFSTORE destination key [key …]]</td><td>获得队列不存在的元素，并存储在一个关键的结果集</td><td>O(N)</td></tr><tr><td>SINTER key [key …]</td><td>获得两个集合的交集</td><td>O(N*M)</td></tr><tr><td>SINTERSTORE destination key [key …]</td><td>获得两个集合的交集，并存储在一个关键的结果集</td><td>O(N*M)</td></tr><tr><td>SISMEMBER key member</td><td>确定一个给定的值是一个集合的成员</td><td>O(1)</td></tr><tr><td>SMEMBERS key</td><td>获取集合里面的所有元素</td><td>O(N)</td></tr><tr><td>SMOVE source destination member</td><td>移动集合里面的一个元素到另一个集合</td><td>O(1)</td></tr><tr><td>SPOP key [count]</td><td>删除并获取一个集合里面的元素</td><td>O(1)</td></tr><tr><td>SRANDMEMBER key [count]</td><td>从集合里面随机获取一个元素</td><td></td></tr><tr><td>SREM key member [member …]]</td><td>从集合里删除一个或多个元素</td><td>O(N)</td></tr><tr><td>SUNION key [key …]]</td><td>添加多个set元素</td><td>O(N)</td></tr><tr><td>SUNIONSTORE destination key [key …]</td><td>合并set元素，并将结果存入新的set里面</td><td>O(N)</td></tr></tbody></table><h3 id="Set类型实际存储结构"><a href="#Set类型实际存储结构" class="headerlink" title="Set类型实际存储结构"></a>Set类型实际存储结构</h3><p>Set在的底层数据结构以intset或者hashtable来存储。当set中只包含整数型的元素时，采用intset来存储，否则，采用hashtable存储，但是对于set来说，该hashtable的value值用于为NULL，通过key来存储元素。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">intset</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> encoding;</span><br><span class="line">    <span class="keyword">uint32_t</span> length;</span><br><span class="line">    <span class="keyword">int8_t</span> contents[];</span><br><span class="line">&#125; intset;</span><br></pre></td></tr></table></figure><p>intset将整数元素按顺序存储在数组里，并通过二分法降低查找元素的时间复杂度。数据量大时，</p><p>依赖于“查找”的命令（如SISMEMBER）就会由于O(logn)的时间复杂度而遇到一定的瓶颈，所以数据量大时会用dict来代替intset。</p><p>但是intset的优势就在于比dict更省内存，而且数据量小的时候O(logn)未必会慢于O(1)的hash function，这也是intset存在的原因。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451936.png" alt="image-20210629233537351"></p><center>图2-30</center><h3 id="set类型的实际应用场景"><a href="#set类型的实际应用场景" class="headerlink" title="set类型的实际应用场景"></a>set类型的实际应用场景</h3><p><strong>标签管理功能</strong></p><ol><li><p>给用户添加标签。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">sadd user:<span class="number">1</span>:basketball game coding swing</span><br><span class="line">sadd user:<span class="number">2</span>:sing coding sleep basketball</span><br><span class="line">...</span><br><span class="line">sadd user:k:tags tag1 tag2 tag4</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li><p>使用sinter命令，可以来计算用户共同感兴趣的标签</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">sinter user:<span class="number">1</span> user:<span class="number">2</span></span><br></pre></td></tr></table></figure></li></ol><p>这种标签系统在电商系统、社交系统、视频网站，图书网站，旅游网站等都有着广泛的应用。例如一个用户可能对娱乐、体育比较感兴趣，另一个用户可能对历史、新闻比较感兴趣，</p><p>这些兴趣点就是标签。有了这些数据就可以得到喜欢同一个标签的人，以及用户的共同喜好的标签，这些数据对于用户体验以及增强用户黏度比较重要。</p><p>例如一个社交系统可以根据用户的标签进行好友的推荐，已经用户感兴趣的新闻的推荐等，一个电子商务的网站会对不同标签的用户做不同类型的推荐，比如对数码产品比较感兴趣的人，</p><p>在各个页面或者通过邮件的形式给他们推荐最新的数码产品，通常会为网站带来更多的利益</p><p><strong>相关商品信息展示</strong></p><p>比如在电商系统中，当用户查看某个商品时，可以推荐和这个商品标签有关的商品信息。</p><h2 id="ZSet类型"><a href="#ZSet类型" class="headerlink" title="ZSet类型"></a>ZSet类型</h2><p>有序集合类型，顾名思义，和前面讲的集合类型的区别就是多了有序的功能。</p><p>如图2-31所示，在集合类型的基础上，有序集合类型为集合中的每个元素都关联了一个分数（浮点型），这使得我们不仅可以完成插入、删除和判断元素是否存在等集合类型支持的操作，还能获得分数最高(或最低)的前N个元素、获得指定分数范围内的元素等与分数有关的操作。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451026.png" alt="image-20210630151900199"></p><center>图2-31</center><h3 id="ZSet常用操作命令"><a href="#ZSet常用操作命令" class="headerlink" title="ZSet常用操作命令"></a>ZSet常用操作命令</h3><p>ZSet的常用命令如图2-32所示，完整的操作命令，详见：<a href="http://doc.redisfans.com/">http://doc.redisfans.com/</a></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451774.png" alt="image-20210630154837864"></p><center>图2-32</center><h3 id="ZSet的数据存储结构"><a href="#ZSet的数据存储结构" class="headerlink" title="ZSet的数据存储结构"></a>ZSet的数据存储结构</h3><p>ZSet的底层数据结构采用了zipList（压缩表）和skiplist（跳跃表）组成，当同时满足以下两个条件时，有序集合采用的是ziplist存储。</p><ul><li>有序集合保存的元素个数要小于128个</li><li>有序集合保存的所有元素成员的长度必须小于64个字节</li></ul><p>如果不能满足以上任意一个条件，有序集合会采用skiplist（跳跃表）结构进行存储，如图2-33所示，zSet不只是用skiplist，实际上，它使用了dict（字典表）和zskiplist（跳跃表）同时进行数据存储。</p><ul><li>dict，字典类型， 其中key表示zset的成员数据，value表示zset的分值，<strong>用来支持O(1)复杂度的按照成员取分值的操作</strong></li><li>zskiplist，跳跃表，按分值排序成员，<strong>用来支持平均复杂度为O<del>(logn)</del>的按照分值定位成员的操作，以及范围查找操作</strong>。</li></ul><p>其中zskiplistNode中<code>*obj</code>和Dic中<code>*key</code>指向同一个具体元素，所以不会存在多余的内存消耗问题。另外，backward表示后退指针，方便进行回溯。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451536.png" alt="image-20210630172259860"></p><center>图2-33</center><h3 id="关于跳跃表"><a href="#关于跳跃表" class="headerlink" title="关于跳跃表"></a>关于跳跃表</h3><p>跳表(skip list) 对标的是平衡树(AVL Tree)，是一种 插入/删除/搜索 都是 <code>O(log n)</code> 的数据结构。它最大的优势是原理简单、容易实现、方便扩展、效率更高。因此在一些热门的项目里用来替代平衡树，如 redis, leveldb 等。</p><p><strong>跳表的基本思想</strong></p><p>首先，跳表处理的是有序的链表（一般是双向链表，下图未表示双向），如下：</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211020105629079.png" alt="image-20211020105629079"></p><p>这个链表中，如果要搜索一个数，需要从头到尾比较每个元素是否匹配，直到找到匹配的数为止，即时间复杂度是 O(n)O(n)。同理，插入一个数并保持链表有序，需要先找到合适的插入位置，再执行插入，总计也是 O(n)O(n) 的时间。</p><p>那么如何提高搜索的速度呢？很简单，做个索引：</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211020105657884.png" alt="image-20211020105657884"></p><p>如上图，我们新创建一个链表，它包含的元素为前一个链表的偶数个元素。这样在搜索一个元素时，我们先在上层链表进行搜索，当元素未找到时再到下层链表中搜索。例如搜索数字 <code>19</code> 时的路径如下图：</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211020105730457.png" alt="image-20211020105730457"></p><p>先在上层中搜索，到达节点 <code>17</code> 时发现下一个节点为 <code>21</code>，已经大于 <code>19</code>，于是转到下一层搜索，找到的目标数字 <code>19</code>。</p><p>我们知道上层的节点数目为 n/2n/2，因此，有了这层索引，我们搜索的时间复杂度降为了：O(n/2)O(n/2)。同理，我们可以不断地增加层数，来减少搜索的时间：</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211020105757674.png" alt="image-20211020105757674"></p><p>在上面的 4 层链表中搜索 <code>25</code>，在最上层搜索时就可以直接跳过 <code>21</code> 之前的所有节点，因此十分高效。</p><p>更一般地，如果有 kk 层，我们需要的搜索次数会小于 ⌈n2k⌉+k⌈n2k⌉+k ，这样当层数 kk 增加到 ⌈log2n⌉⌈log2⁡n⌉ 时，搜索的时间复杂度就变成了 lognlog⁡n。其实这背后的原理和二叉搜索树或二分查找很类似，通过索引来跳过大量的节点，从而提高搜索效率。</p><p><strong>动态跳表</strong></p><p>上节的结构是“静态”的，即我们先拥有了一个链表，再在之上建了多层的索引。但是在实际使用中，我们的链表是通过多次插入/删除形成的，换句话说是“动态”的。上节的结构要求上层相邻节点与对应下层节点间的个数比是 <code>1:2</code>，随意插入/删除一个节点，这个要求就被被破坏了。</p><p>因此跳表（skip list）表示，我们就不强制要求 <code>1:2</code> 了，一个节点要不要被索引，建几层的索引，都在节点插入时由抛硬币决定。当然，虽然索引的节点、索引的层数是随机的，为了保证搜索的效率，要大致保证每层的节点数目与上节的结构相当。下面是一个随机生成的跳表：</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211020105929667.png" alt="image-20211020105929667"></p><p>可以看到它每层的节点数还和上节的结构差不多，但是上下层的节点的对应关系已经完全被打破了。</p><p>现在假设节点 <code>17</code> 是最后插入的，在插入之前，我们需要搜索得到插入的位置：</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211020110003178.png" alt="image-20211020110003178"></p><p>接着，抛硬币决定要建立几层的索引，伪代码如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">randomLevel()</span><br><span class="line">    lvl := 1</span><br><span class="line">    -- random() that returns a random value in [0...1)</span><br><span class="line">    while random() &lt; p and lvl &lt; MaxLevel do</span><br><span class="line">        lvl := lvl + 1</span><br><span class="line">    return lvl</span><br></pre></td></tr></table></figure><p>上面的伪代码相当于抛硬币，如果是正面（<code>random() &lt; p</code>）则层数加一，直到抛出反面为止。其中的 <code>MaxLevel</code> 是防止如果运气太好，层数就会太高，而太高的层数往往并不会提供额外的性能，</p><p>一般 MaxLevel=log1/pnMaxLevel=log1/p⁡n。现在假设 <code>randomLevel</code> 返回的结果是 <code>2</code>，那么就得到下面的结果。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110131359558.png" alt="image-20211013135934802"></p><p>如果要删除节点，则把节点和对应的所有索引节点全部删除即可。当然，要删除节点时需要先搜索得到该节点，搜索过程中可以把路径记录下来，这样删除索引层节点的时候就不需要多次搜索了</p><h3 id="ZSet的使用场景"><a href="#ZSet的使用场景" class="headerlink" title="ZSet的使用场景"></a>ZSet的使用场景</h3><ul><li><p><strong>排行榜系统</strong></p><p>有序集合比较典型的使用场景就是排行榜系统。例如学生成绩的排名。某视频(博客等)网站的用户点赞、播放排名、电商系统中商品的销量排名等。我们以博客点赞为例。</p><ul><li><p>添加用户赞数</p><p>例如小编Tom发表了一篇博文，并且获得了10个赞。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zadd user:ranking article1 10</span><br></pre></td></tr></table></figure></li><li><p>取消用户赞数</p><p>这个时候有一个读者又觉得Tom写的不好，又取消了赞，此时需要将文章的赞数从榜单中减去1，可以使用zincrby。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zincrby user:ranking -1 article1 </span><br></pre></td></tr></table></figure></li><li><p>查看某篇文章的赞数</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ZSCORE user:ranking arcticle1 </span><br></pre></td></tr></table></figure></li><li><p>展示获取赞数最多的十篇文章</p><p>此功能使用zrevrange命令实现：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zrevrange user:ranking 0 10  #0 到 10表示元素个数索引</span><br><span class="line">zrevrangebyscore user:ranking 99 0 #  按照分数从高到低排名，99，0表示score</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>热点话题排名</strong></p><p>比如想微博的热搜，就可以使用ZSet来实现。</p></li></ul><h1 id="其他数据类型介绍"><a href="#其他数据类型介绍" class="headerlink" title="其他数据类型介绍"></a>其他数据类型介绍</h1><p>在Redis中，还有一些使用得非常少的数据类型，简单给大家普及一下。</p><h2 id="Geospatial"><a href="#Geospatial" class="headerlink" title="Geospatial"></a>Geospatial</h2><p>Geo是Redis3.2推出的一个类型，它提供了地理位置的计算功能，也就是可以计算出两个地理位置的距离。</p><blockquote><p>文档：<a href="https://www.redis.net.cn/order/3687.html">https://www.redis.net.cn/order/3687.html</a></p></blockquote><p>下面演示一下Geo的基本使用，其中需要用到经纬度信息，可以从 <a href="http://www.jsons.cn/lngcode/%E6%9F%A5%E8%AF%A2%E3%80%82">http://www.jsons.cn/lngcode/查询。</a></p><ol><li><p>添加模拟数据</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">geoadd china:city 116.40 39.90 beijing</span><br><span class="line">geoadd china:city 121.47 31.23 shanghai</span><br><span class="line">geoadd china:city 114.05 22.52 shengzhen</span><br><span class="line">geoadd china:city 113.28 23.12 guangzhou</span><br></pre></td></tr></table></figure></li><li><p>获取当前位置的坐标值</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">geopos china:city beijing</span><br><span class="line">geopos china:city shanghai</span><br></pre></td></tr></table></figure></li><li><p>获取两个位置之间的距离：<code>m-表示米/km-表示千米/mi-表示英里/ft表示英尺</code></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看北京到上海的直线距离</span></span><br><span class="line">geodist china:city beijing shanghai km</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看北京到深圳的直线距离</span></span><br><span class="line">geodist china:city beijing shenzhen km</span><br></pre></td></tr></table></figure></li><li><p>给定一个经纬度，找出该经纬度某一半径内的元素</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 以110 30这个点为中心，寻找方圆1000km的城市</span></span><br><span class="line">georadius china:city 110 30 1000 km</span><br></pre></td></tr></table></figure></li><li><p>找出指定位置周围的其他元素</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">georadiusbymember china:city shanghai 1000 km</span><br></pre></td></tr></table></figure></li></ol><p>比如现在比较火的直播业务，我们需要检索附近的主播，那么GEO就可以很好的实现这个功能。</p><ul><li>一是主播开播的时候写入主播<code>Id</code>的经纬度，</li><li>二是主播关播的时候删除主播<code>Id</code>元素，这样就维护了一个具有位置信息的在线主播集合提供给线上检索。</li></ul><h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><p>HyperLogLog是Redis2.8.9提供的一种数据结构，他提供了一种基数统计方法。什么是基数统计呢？简单来说就是一个集合中不重复元素的个数，比如有一个集合{1,2,3,1,2}，那么它的基数就是3。</p><p>HyperLogLog提供了三种指令。</p><ul><li>pfadd  ，Redis Pfadd 命令将所有元素参数添加到 HyperLogLog 数据结构中。</li><li>pfcount，Redis Pfcount 命令返回给定 HyperLogLog 的基数估算值。</li><li>pgmerge，Redis Pgmerge 命令将多个 HyperLogLog 合并为一个 HyperLogLog ，合并后的 HyperLogLog 的基数估算值是通过对所有 给定 HyperLogLog 进行并集计算得出的。</li></ul><p>使用方法如下。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pfadd uv a b c a c d e f   # 创建一组元素</span><br><span class="line">pfcount uv                 # 统计基数</span><br></pre></td></tr></table></figure><p>有同学会问了，这个功能，我用String类型、或者Set类型都可以实现，为什么要用HyperLogLog呢？</p><p>最大的特性就是： HyperLogLog在数据量非常大的情况下，占用的存储空间非常小，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64（2的64次方） 个不同元素的基数，这个是一个非常庞大的数字，为什么能够用这么小的空间来存储这么大的数据呢？</p><p>不知道大家是否注意到，HyperLogLog并没有提供数据查询的命令，只提供了数据添加和数据统计。这是因为HyperLogLog并没有存储每个元素的值，它使用的是概率算法，通过存储元素的hash值的第一个1的位置，来计算元素数量，这块在这里就不做过多展开。</p><p><strong>应用场景：</strong></p><ul><li><p>HyperLogLog更适合做一些统计类的工作，比如统计一个网站的UV。</p></li><li><p>计算日活、7日活、月活数据.</p><p>如果我们通过解析日志，把 ip 信息（或用户 id）放到集合中，例如：HashSet。如果数量不多则还好，但是假如每天访问的用户有几百万。无疑会占用大量的存储空间。且计算月活时，还需要将一个整月的数据放到一个 Set 中，这随时可能导致我们的程序 OOM。</p><p>有了 HyperLogLog，这件事就变得很简单了。因为存储日活数据所需要的内存只有 12K，例如。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用日来存储每天的ip地址</span></span><br><span class="line">pfadd ip_20190301 192.168.8.1</span><br><span class="line">pfadd ip_20190302 xxx</span><br><span class="line">pfadd ip_20190303 xxx</span><br><span class="line">...</span><br><span class="line">pfadd ip_20190331 xxx</span><br></pre></td></tr></table></figure><p>计算某一天的日活，只需要执行 PFCOUNT ip_201903XX 就可以了。每个月的第一天，执行 PFMERGE 将上一个月的所有数据合并成一个 HyperLogLog，例如：ip_201903。再去执行 PFCOUNT ip_201903，就得到了 3 月的月活。</p></li></ul><h2 id="Bit"><a href="#Bit" class="headerlink" title="Bit"></a>Bit</h2><p>Bit，其实是String类型中提供的一个功能，他可以设置key对应存储的值指定偏移量上的bit位的值，可能大家理解起来比较抽象，举个例子</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121452834.jpg" alt="img"></p><ul><li><p>使用string类型保存一个key</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set key m</span><br></pre></td></tr></table></figure></li><li><p>通过getbit命令获取 <code>key</code>的bit位的值</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">getbit key 0</span><br><span class="line">getbit key 1</span><br><span class="line">getbit key 2</span><br><span class="line">getbit key 3</span><br><span class="line">getbit key 4</span><br><span class="line">getbit key 5</span><br><span class="line">getbit key 6</span><br><span class="line">getbit key 7</span><br><span class="line">getbit key 8</span><br></pre></td></tr></table></figure><p>打印上面的所有输出，会发现得到一个<strong>0 1 1 0 1 1 0 1</strong>的二进制数据，这个二进制拼接得到的结果。 <code>m</code>的ascII码对应的是109， 109的二进制正好是0 1 1 0 1 1 0 1。</p><p>所以从这里可以看出来，bit其实就是针对一个String类型的value值的bit位进行操作。</p></li><li><p>对<code>key</code>进行修改，修改第6位的值变成1， 第7位的值编程0.</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">setbit key 6 1</span><br><span class="line">setbit key 7 0</span><br></pre></td></tr></table></figure><p>在此使用<code> get key</code>命令，会发现得到的结果是n。</p><p>因为n的二进制是1101110,(十进制是110)。把上面的指定位修改之后，自然就得到了这样的结果。</p></li></ul><p>bit操作在实际应用中，可以怎么使用呢？</p><p>比如学习打卡功能就可以使用setbit操作，比如记录一周的打卡记录。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 设置用户id 1001的打卡记录</span></span><br><span class="line">set sign:1001 0 1   # 已打卡</span><br><span class="line">set sign:1001 1 0   # 未打卡</span><br><span class="line">set sign:1001 2 1   </span><br><span class="line">set sign:1001 3 1</span><br><span class="line">set sign:1001 4 1</span><br></pre></td></tr></table></figure><blockquote><p>查看某天是否已打卡</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">getbit sign 3</span><br></pre></td></tr></table></figure><blockquote><p>统计当前用户总的打卡天数</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bitcount sign:1001</span><br></pre></td></tr></table></figure><p>除了这个场景之外，还有很多类似的场景都可以使用，</p><ul><li>统计活跃用户</li><li>记录用户在线状态</li></ul><p>bit最大的好处在于，它通过bit位来存储0/1表示特定含义，我们知道一个int类型是8个字节，占32个bit位，意味着一个int类型的数字就可以存储32个有意义的场景，大大压缩了存储空间。</p><h1 id="阶段性总结"><a href="#阶段性总结" class="headerlink" title="阶段性总结"></a>阶段性总结</h1><h2 id="数据结构总结"><a href="#数据结构总结" class="headerlink" title="数据结构总结"></a>数据结构总结</h2><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121452115.png" alt="image-20210630235340028"></p><h2 id="应用场景总结"><a href="#应用场景总结" class="headerlink" title="应用场景总结"></a>应用场景总结</h2><p>实际上，所谓的应用场景，其实就是合理的利用Redis本身的数据结构的特性来完成相关业务功能，就像mysql，它可以用来做服务注册，也可以用来做分布式锁，但是mysql它本质是一个关系型数据库，只是用到了其他特性而已。</p><ul><li><p>缓存——提升热点数据的访问速度</p></li><li><p>共享数据——数据的存储和共享的问题</p></li><li><p>全局ID —— 分布式全局ID的生成方案（分库分表）</p></li><li><p>分布式锁——进程间共享数据的原子操作保证</p></li><li><p>在线用户统计和计数</p></li><li><p>队列、栈——跨进程的队列/栈</p></li><li><p>消息队列——异步解耦的消息机制</p></li><li><p>服务注册与发现 —— RPC通信机制的服务协调中心（Dubbo支持Redis）</p></li><li><p>购物车</p></li><li><p>新浪/Twitter 用户消息时间线</p></li><li><p>抽奖逻辑（礼物、转发）</p></li><li><p>点赞、签到、打卡</p></li><li><p>商品标签</p></li><li><p>用户（商品）关注（推荐）模型</p></li><li><p>电商产品筛选</p></li><li><p>排行榜</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 数据结构 </tag>
            
            <tag> Redis存储原理 </tag>
            
            <tag> Redis应用场景 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从网络通信的演进过程彻底搞懂Redis高性能通信的原理（全网最详细，建议收藏）</title>
      <link href="/posts/3231701875/"/>
      <url>/posts/3231701875/</url>
      
        <content type="html"><![CDATA[<p>我们一直说Redis的性能很快，那为什么快？Redis为了达到性能最大化，做了哪些方面的优化呢？<br>在<a href="https://mp.weixin.qq.com/s?__biz=MzI0MzI1Mjg5Nw==&mid=2247483929&idx=1&sn=9fc45f293738b7bc397c81dc27e6cc16&chksm=e96ea9d7de1920c1bf23962fe56d4a2f9308a21a21d2f815d4a1d425fb7b8dd313c879d36080&token=768967670&lang=zh_CN#rd">深度解析Redis的数据结构</a><br>这篇文章中，其实从数据结构上分析了Redis性能高的一方面原因。</p><p>在目前的k-v数据库的技术选型中，Redis几乎是首选的用来实现高性能缓存的方案，它的性能有多快呢？</p><p>根据官方的基准测试数据，一台普通硬件配置的Linux机器上运行单个Redis实例，处理简单命令（O(n)或者O（logn）），QPS可以达到8W，如果使用pipeline批处理功能，QPS最高可以达到10W。</p><h1 id="Redis-为什么那么快"><a href="#Redis-为什么那么快" class="headerlink" title="Redis 为什么那么快"></a>Redis 为什么那么快</h1><p>Redis的高性能主要依赖于几个方面。</p><ul><li>C语言实现，C语言在一定程度上还是比Java语言性能要高一些，因为C语言不需要经过JVM进行翻译。</li><li>纯内存I/O，内存I/O比磁盘I/O性能更快</li><li>I/O多路复用，基于epoll的I/O多路复用技术，实现高吞吐网络I/O</li><li>单线程模型，单线程无法利用到多核CPU，但是在Redis中，性能瓶颈并不是在计算上，而是在I/O能力，所以单线程能够满足高并发的要求。 从另一个层面来说，单线程可以避免多线程的频繁上下文切换以及同步锁机制带来的性能开销。</li></ul><p>下面我们分别从上述几个方面进行展开说明，先来看网络I/O的多路复用模型。</p><h1 id="从请求处理开始分析"><a href="#从请求处理开始分析" class="headerlink" title="从请求处理开始分析"></a>从请求处理开始分析</h1><p>当我们在客户端向Redis Server发送一条指令，并且得到Redis回复的整个过程中，Redis做了什么呢？</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354817.png" alt="image-20210707221959664"></p><center>图4-1</center><p>要处理命令，则redis必须完整地接收客户端的请求，并将命令解析出来，再将结果读出来，通过网络回写到客户端。整个工序分为以下几个部分：</p><ul><li>接收，通过TCP接收到命令，可能会历经多次TCP包、ack、IO操作</li><li>解析，将命令取出来</li><li>执行，到对应的地方将value读出来</li><li>返回，将value通过TCP返回给客户端，如果value较大，则IO负荷会更重</li></ul><p>其中<strong>解析</strong>和<strong>执行</strong>是纯cpu/内存操作，而接收和返回主要是IO操作，首先我们先来看通信的过程。</p><h2 id="网络IO的通信原理"><a href="#网络IO的通信原理" class="headerlink" title="网络IO的通信原理"></a>网络IO的通信原理</h2><p>同样，我也画了一幅图来描述网络数据的传输流程</p><p>首先，对于TCP通信来说，每个TCP Socket的内核中都有一个发送缓冲区和一个接收缓冲区</p><p>接收缓冲区把数据缓存到内核，若应用进程一直没有调用Socket的read方法进行读取，那么该数据会一直被缓存在接收缓冲区内。不管进程是否读取Socket，对端发来的数据都会经过内核接收并缓存到Socket的内核接收缓冲区。</p><p>read所要做的工作，就是把内核接收缓冲区中的数据复制到应用层用户的Buffer里。</p><p>进程调用Socket的send发送数据的时候，一般情况下是将数据从应用层用户的Buffer里复制到Socket的内核发送缓冲区，然后send就会在上层返回。换句话说，send返回时，数据不一定会被发送到对端。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354929.png" alt="1576066931883"></p><p>网卡中的缓冲区既不属于内核空间，也不属于用户空间。它属于硬件缓冲，允许网卡与操作系统之间有个缓冲；<br>内核缓冲区在内核空间，在内存中，用于内核程序，做为读自或写往硬件的数据缓冲区；<br>用户缓冲区在用户空间，在内存中，用于用户程序，做为读自或写往硬件的数据缓冲区</p><p>网卡芯片收到网络数据会以中断的方式通知CPU，我有数据了，存在我的硬件缓冲里了，来读我啊。<br>CPU收到这个中断信号后，会调用相应的驱动接口函数从网卡的硬件缓冲里把数据读到内核缓冲区，正常情况下会向上传递给TCP/IP模块一层一层的处理。</p><h2 id="NIO多路复用机制"><a href="#NIO多路复用机制" class="headerlink" title="NIO多路复用机制"></a>NIO多路复用机制</h2><p>Redis的通信采用的是多路复用机制，什么是多路复用机制呢？ </p><blockquote><p>由于Redis是C语言实现，为了简化大家的理解，我们采用Java语言来描述这个过程。</p></blockquote><p>在理解多路复用之前，我们先来了解一下BIO。</p><h2 id="BIO模型"><a href="#BIO模型" class="headerlink" title="BIO模型"></a>BIO模型</h2><p>在Java中，如果要实现网络通信，我们会采用Socket套接字来完成。</p><p>Socket这不是一个协议，而是一个通信模型。其实它最初是<strong>BSD</strong>发明的，主要用来一台电脑的两个进程间通信，然后把它用到了两台电脑的进程间通信。所以，可以把它简单理解为进程间通信，不是什么高级的东西。主要做的事情不就是：</p><ul><li><p>A发包：发请求包给某个已经绑定的端口（所以我们经常会访问这样的地址182.13.15.16:1235，1235就是端口）；收到B的允许；然后正式发送；发送完了，告诉B要断开链接；收到断开允许，马上断开，然后发送已经断开信息给B。</p></li><li><p>B收包：绑定端口和IP；然后在这个端口监听；接收到A的请求，发允许给A，并做好接收准备，主要就是清理缓存等待接收新数据；然后正式接收；接受到断开请求，允许断开；确认断开后，继续监听其它请求。</p></li></ul><p>可见，Socket其实就是I/O操作，Socket并不仅限于网络通信，在网络通信中，它涵盖了网络层、传输层、会话层、表示层、应用层——其实这都不需要记，因为Socket通信时候用到了IP和端口，仅这两个就表明了它用到了网络层和传输层；而且它无视多台电脑通信的系统差别，所以它涉及了表示层；一般Socket都是基于一个应用程序的，所以会涉及到会话层和应用层。</p><h3 id="构建基础的BIO通信模型"><a href="#构建基础的BIO通信模型" class="headerlink" title="构建基础的BIO通信模型"></a>构建基础的BIO通信模型</h3><p><strong>BIOServerSocket</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BIOServerSocket</span> </span>&#123;</span><br><span class="line">    <span class="comment">//先定义一个端口号，这个端口的值是可以自己调整的。</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_PORT=<span class="number">8080</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//先定义一个端口号，这个端口的值是可以自己调整的。</span></span><br><span class="line">        <span class="comment">//在服务器端，我们需要使用ServerSocket，所以我们先声明一个ServerSocket变量</span></span><br><span class="line">        ServerSocket serverSocket=<span class="keyword">null</span>;</span><br><span class="line">        <span class="comment">//接下来，我们需要绑定监听端口, 那我们怎么做呢？只需要创建使用serverSocket实例</span></span><br><span class="line">        <span class="comment">//ServerSocket有很多构造重载，在这里，我们把前边定义的端口传入，表示当前</span></span><br><span class="line">        <span class="comment">//ServerSocket监听的端口是8080</span></span><br><span class="line">        serverSocket=<span class="keyword">new</span> ServerSocket(DEFAULT_PORT);</span><br><span class="line">        System.out.println(<span class="string">&quot;启动服务，监听端口：&quot;</span>+DEFAULT_PORT);</span><br><span class="line">        <span class="comment">//回顾一下前面我们讲的内容，接下来我们就需要开始等待客户端的连接了。</span></span><br><span class="line">        <span class="comment">//所以我们要使用的是accept这个函数，并且当accept方法获得一个客户端请求时，会返回</span></span><br><span class="line">        <span class="comment">//一个socket对象， 这个socket对象让服务器可以用来和客户端通信的一个端点。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//开始等待客户端连接，如果没有客户端连接，就会一直阻塞在这个位置</span></span><br><span class="line">        Socket socket=serverSocket.accept();</span><br><span class="line">        <span class="comment">//很可能有多个客户端来发起连接，为了区分客户端，咱们可以输出客户端的端口号</span></span><br><span class="line">        System.out.println(<span class="string">&quot;客户端：&quot;</span>+socket.getPort()+<span class="string">&quot;已连接&quot;</span>);</span><br><span class="line">        <span class="comment">//一旦有客户端连接过来，我们就可以用到IO来获得客户端传过来的数据。</span></span><br><span class="line">        <span class="comment">//使用InputStream来获得客户端的输入数据</span></span><br><span class="line">        <span class="comment">//bufferedReader大家还记得吧，他维护了一个缓冲区可以减少数据源读取的频率</span></span><br><span class="line">        BufferedReader bufferedReader=<span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(socket.getInputStream()));</span><br><span class="line">        String clientStr=bufferedReader.readLine(); <span class="comment">//读取一行信息</span></span><br><span class="line">        System.out.println(<span class="string">&quot;客户端发了一段消息：&quot;</span>+clientStr);</span><br><span class="line">        <span class="comment">//服务端收到数据以后，可以给到客户端一个回复。这里咱们用到BufferedWriter</span></span><br><span class="line">        BufferedWriter bufferedWriter=<span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> OutputStreamWriter(socket.getOutputStream()));</span><br><span class="line">        bufferedWriter.write(<span class="string">&quot;我已经收到你的消息了\n&quot;</span>);</span><br><span class="line">        bufferedWriter.flush(); <span class="comment">//清空缓冲区触发消息发送</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>BIOClientSocket</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BIOClientSocket</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_PORT=<span class="number">8080</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//在客户端这边，咱们使用socket来连接到指定的ip和端口</span></span><br><span class="line">        Socket socket=<span class="keyword">new</span> Socket(<span class="string">&quot;localhost&quot;</span>,<span class="number">8080</span>);</span><br><span class="line">        <span class="comment">//使用BufferedWriter，像服务器端写入一个消息</span></span><br><span class="line">        BufferedWriter bufferedWriter=<span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> OutputStreamWriter(socket.getOutputStream()));</span><br><span class="line">        bufferedWriter.write(<span class="string">&quot;我是客户端Client-01\n&quot;</span>);</span><br><span class="line">        bufferedWriter.flush();</span><br><span class="line">        BufferedReader bufferedReader=<span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(socket.getInputStream()));</span><br><span class="line">        String serverStr=bufferedReader.readLine(); <span class="comment">//通过bufferedReader读取服务端返回的消息</span></span><br><span class="line">        System.out.println(<span class="string">&quot;服务端返回的消息：&quot;</span>+serverStr);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码构建了一个简单的BIO通信模型，也就是服务端建立一个监听，客户端向服务端发送一个消息，实现简单的网络通信，那BIO有什么弊端呢？</p><p>我们通过对BIOServerSocket进行改造，关注case1和case2部分。</p><ul><li>case1: 增加了while循环，实现重复监听</li><li>case2: 当服务端收到客户端的请求后，不直接返回，而是等待20s。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BIOServerSocket</span> </span>&#123;</span><br><span class="line">    <span class="comment">//先定义一个端口号，这个端口的值是可以自己调整的。</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_PORT=<span class="number">8080</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        ServerSocket serverSocket=<span class="keyword">null</span>;</span><br><span class="line">        serverSocket=<span class="keyword">new</span> ServerSocket(DEFAULT_PORT);</span><br><span class="line">        System.out.println(<span class="string">&quot;启动服务，监听端口：&quot;</span>+DEFAULT_PORT);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>) &#123; <span class="comment">//case1: 增加循环，允许循环接收请求</span></span><br><span class="line">            Socket socket = serverSocket.accept();</span><br><span class="line">            System.out.println(<span class="string">&quot;客户端：&quot;</span> + socket.getPort() + <span class="string">&quot;已连接&quot;</span>);</span><br><span class="line">            BufferedReader bufferedReader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(socket.getInputStream()));</span><br><span class="line">            String clientStr = bufferedReader.readLine(); <span class="comment">//读取一行信息</span></span><br><span class="line">            System.out.println(<span class="string">&quot;客户端发了一段消息：&quot;</span> + clientStr);</span><br><span class="line">            Thread.sleep(<span class="number">20000</span>); <span class="comment">//case2: 修改：增加等待时间</span></span><br><span class="line">            BufferedWriter bufferedWriter = <span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> OutputStreamWriter(socket.getOutputStream()));</span><br><span class="line">            bufferedWriter.write(<span class="string">&quot;我已经收到你的消息了\n&quot;</span>);</span><br><span class="line">            bufferedWriter.flush(); <span class="comment">//清空缓冲区触发消息发送</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接着，把BIOClientSocket复制两份（client1、client2），同时向BIOServerSocket发起请求。</p><blockquote><p>运行后看到的现象应该是： client1先发送请求到Server端，由于Server端等待20s才返回，导致client2的请求一直被阻塞。</p></blockquote><p>这个情况会导致一个问题，如果服务端在同一个时刻只能处理一个客户端的连接，而如果一个网站同时有1000个用户访问，那么剩下的999个用户都需要等待，而这个等待的耗时取决于前面的请求的处理时长，如图4-2所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354443.png" alt="image-20210708152538953"></p><center>图4-2</center><h3 id="基于多线程优化BIO"><a href="#基于多线程优化BIO" class="headerlink" title="基于多线程优化BIO"></a>基于多线程优化BIO</h3><p>为了让服务端能够同时处理更多的客户端连接，避免因为某个客户端连接阻塞导致后续请求被阻塞，于是引入多线程技术，代码如下。</p><p><strong>ServerSocket</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_PORT=<span class="number">8080</span>;</span><br><span class="line">    ServerSocket serverSocket=<span class="keyword">null</span>;</span><br><span class="line">    serverSocket=<span class="keyword">new</span> ServerSocket(DEFAULT_PORT);</span><br><span class="line">    System.out.println(<span class="string">&quot;启动服务，监听端口：&quot;</span>+DEFAULT_PORT);</span><br><span class="line">    ExecutorService executorService= Executors.newFixedThreadPool(<span class="number">5</span>);</span><br><span class="line">    <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">        Socket socket = serverSocket.accept();</span><br><span class="line">        executorService.submit(<span class="keyword">new</span> SocketThread(socket));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>SocketThread</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SocketThread</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    Socket socket;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SocketThread</span><span class="params">(Socket socket)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.socket = socket;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;客户端：&quot;</span> + socket.getPort() + <span class="string">&quot;已连接&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            BufferedReader bufferedReader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(socket.getInputStream()));</span><br><span class="line">            String clientStr = <span class="keyword">null</span>; <span class="comment">//读取一行信息</span></span><br><span class="line">            clientStr = bufferedReader.readLine();</span><br><span class="line">            System.out.println(<span class="string">&quot;客户端发了一段消息：&quot;</span> + clientStr);</span><br><span class="line">            Thread.sleep(<span class="number">20000</span>);</span><br><span class="line">            BufferedWriter bufferedWriter = <span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> OutputStreamWriter(socket.getOutputStream()));</span><br><span class="line">            bufferedWriter.write(<span class="string">&quot;我已经收到你的消息了\n&quot;</span>);</span><br><span class="line">            bufferedWriter.flush(); <span class="comment">//清空缓冲区触发消息发送</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如图4-3所示，当引入了多线程之后，每个客户端的链接（Socket），我们可以直接给到线程池去执行，而由于这个过程是异步的，所以并不会同步阻塞影响后续链接的监听，因此在一定程度上可以提升服务端链接的处理数量。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354397.png" alt="image-20210708160026412"></p><center>图4-3</center><h2 id="NIO非阻塞IO"><a href="#NIO非阻塞IO" class="headerlink" title="NIO非阻塞IO"></a>NIO非阻塞IO</h2><p>使用多线程的方式来解决这个问题，仍然有一个缺点，线程的数量取决于硬件配置，所以线程数量是有限的，如果请求量比较大的时候，线程本身会收到限制从而并发量也不会太高。那怎么办呢，我们可以采用非阻塞IO。</p><p>NIO 从JDK1.4 提出的，本意是New IO，它的出现为了弥补原本IO的不足，提供了更高效的方式，提出一个通道（channel）的概念，在IO中它始终以流的形式对数据的传输和接受，下面我们演示一下NIO的使用。</p><p><strong>NioServerSocket</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NioServerSocket</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();</span><br><span class="line">            serverSocketChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            serverSocketChannel.socket().bind(<span class="keyword">new</span> InetSocketAddress(<span class="number">8080</span>));</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                SocketChannel socketChannel = serverSocketChannel.accept();</span><br><span class="line">                <span class="keyword">if</span> (socketChannel != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="comment">//读取数据</span></span><br><span class="line">                    ByteBuffer buffer = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">                    socketChannel.read(buffer);</span><br><span class="line">                    System.out.println(<span class="keyword">new</span> String(buffer.array()));</span><br><span class="line">                    <span class="comment">//写出数据</span></span><br><span class="line">                    Thread.sleep(<span class="number">10000</span>); <span class="comment">//阻塞一段时间</span></span><br><span class="line">                    <span class="comment">//当数据读取到缓冲区之后，接下来就需要把缓冲区的数据写出到通道，而在写出之前必须要调用flip方法，实际上就是重置一个有效字节范围，然后把这个数据接触到通道。</span></span><br><span class="line">                    buffer.flip();</span><br><span class="line">                    socketChannel.write(buffer);<span class="comment">//写出数据</span></span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                    System.out.println(<span class="string">&quot;连接未就绪&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>NioClientSocket</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NioClientSocket</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            SocketChannel socketChannel= SocketChannel.open();</span><br><span class="line">            socketChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            socketChannel.connect(<span class="keyword">new</span> InetSocketAddress(<span class="string">&quot;localhost&quot;</span>,<span class="number">8080</span>));</span><br><span class="line">            <span class="keyword">if</span>(socketChannel.isConnectionPending())&#123;</span><br><span class="line">                socketChannel.finishConnect();</span><br><span class="line">            &#125;</span><br><span class="line">            ByteBuffer byteBuffer= ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">            byteBuffer.put(<span class="string">&quot;Hello I&#x27;M SocketChannel Client&quot;</span>.getBytes());</span><br><span class="line">            byteBuffer.flip();</span><br><span class="line">            socketChannel.write(byteBuffer);</span><br><span class="line">            <span class="comment">//读取服务端数据</span></span><br><span class="line">            byteBuffer.clear();</span><br><span class="line">            <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">                <span class="keyword">int</span> i = socketChannel.read(byteBuffer);</span><br><span class="line">                <span class="keyword">if</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;收到服务端的数据：&quot;</span> + <span class="keyword">new</span> String(byteBuffer.array()));</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;服务端数据未准备好&quot;</span>);</span><br><span class="line">                    Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException | InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所谓的NIO（非阻塞IO），其实就是取消了IO阻塞和连接阻塞，当服务端不存在阻塞的时候，就可以不断轮询处理客户端的请求，如图4-4所示，表示NIO下的运行流程。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354021.png" alt="image-20210708165359843"></p><center>图4-4</center><p>上述这种NIO的使用方式，仍然存在一个问题，就是客户端或者服务端需要通过一个线程不断轮询才能获得结果，而这个轮询过程中会浪费线程资源。</p><h2 id="多路复用IO"><a href="#多路复用IO" class="headerlink" title="多路复用IO"></a>多路复用IO</h2><p>大家站在全局的角度再思考一下整个过程，有哪些地方可以优化呢？</p><p>我们回到NIOClientSocket中下面这段代码，当客户端通过<code>read</code>方法去读取服务端返回的数据时，如果此时服务端数据未准备好，对于客户端来说就是一次无效的轮询。</p><p>我们能不能够设计成，当客户端调用<code>read</code>方法之后，不仅仅不阻塞，同时也不需要轮询。而是等到服务端的数据就绪之后， 告诉客户端。然后客户端再去读取服务端返回的数据呢？</p><blockquote><p>就像点外卖一样，我们在网上下单之后，继续做其他事情，等到外卖到了公司，外卖小哥主动打电话告诉你，你直接去前台取餐即可。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="keyword">int</span> i = socketChannel.read(byteBuffer);</span><br><span class="line">    <span class="keyword">if</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;收到服务端的数据：&quot;</span> + <span class="keyword">new</span> String(byteBuffer.array()));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;服务端数据未准备好&quot;</span>);</span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>所以为了优化这个问题，引入了多路复用机制。</p></blockquote><p>I/O多路复用的本质是通过一种机制（系统内核缓冲I/O数据），让单个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是读就绪或写就绪），能够通知程序进行相应的读写操作</p><blockquote><p><strong>什么是fd</strong>：在linux中，内核把所有的外部设备都当成是一个文件来操作，对一个文件的读写会调用内核提供的系统命令，返回一个fd(文件描述符)。而对于一个socket的读写也会有相应的文件描述符，成为socketfd。</p></blockquote><p>常见的IO多路复用方式有<strong>【select、poll、epoll】</strong>，都是Linux API提供的IO复用方式，那么接下来重点讲一下select、和epoll这两个模型</p><ul><li><p><strong>select：</strong>进程可以通过把一个或者多个fd传递给select系统调用，进程会阻塞在select操作上，这样select可以帮我们检测多个fd是否处于就绪状态，这个模式有两个缺点</p><ul><li>由于他能够同时监听多个文件描述符，假如说有1000个，这个时候如果其中一个fd 处于就绪状态了，那么当前进程需要线性轮询所有的fd，也就是监听的fd越多，性能开销越大。</li><li>同时，select在单个进程中能打开的fd是有限制的，默认是1024，对于那些需要支持单机上万的TCP连接来说确实有点少</li></ul></li><li><p><strong>epoll</strong>：linux还提供了epoll的系统调用，epoll是基于事件驱动方式来代替顺序扫描，因此性能相对来说更高，主要原理是，当被监听的fd中，有fd就绪时，会告知当前进程具体哪一个fd就绪，那么当前进程只需要去从指定的fd上读取数据即可，另外，epoll所能支持的fd上线是操作系统的最大文件句柄，这个数字要远远大于1024</p></li></ul><blockquote><p>【由于epoll能够通过事件告知应用进程哪个fd是可读的，所以我们也称这种IO为异步非阻塞IO，当然它是伪异步的，因为它还需要去把数据从内核同步复制到用户空间中，真正的异步非阻塞，应该是数据已经完全准备好了，我只需要从用户空间读就行】</p></blockquote><p>I/O多路复用的好处是可以通过把多个I/O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。它的最大优势是系统开销小，并且不需要创建新的进程或者线程，降低了系统的资源开销，它的整体实现思想如图4-5所示。</p><p>客户端请求到服务端后，此时客户端在传输数据过程中，为了避免Server端在read客户端数据过程中阻塞，服务端会把该请求注册到Selector复路器上，服务端此时不需要等待，只需要启动一个线程，通过selector.select()阻塞轮询复路器上就绪的channel即可，也就是说，如果某个客户端连接数据传输完成，那么select()方法会返回就绪的channel，然后执行相关的处理即可。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354428.png" alt="image-20210708203509498"></p><center>图4-5</center><p><strong>NIOServer的实现如下</strong></p><blockquote><p>测试访问的时候，直接在cmd中通过telnet连接NIOServer，便可发送信息。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NIOServer</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    Selector selector;</span><br><span class="line">    ServerSocketChannel serverSocketChannel;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NIOServer</span><span class="params">(<span class="keyword">int</span> port)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        selector=Selector.open(); <span class="comment">//多路复用器</span></span><br><span class="line">        serverSocketChannel=ServerSocketChannel.open();</span><br><span class="line">        <span class="comment">//绑定监听端口</span></span><br><span class="line">        serverSocketChannel.socket().bind(<span class="keyword">new</span> InetSocketAddress(port));</span><br><span class="line">        serverSocketChannel.configureBlocking(<span class="keyword">false</span>);<span class="comment">//非阻塞配置</span></span><br><span class="line">        <span class="comment">//针对serverSocketChannel注册一个ACCEPT连接监听事件</span></span><br><span class="line">        serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(!Thread.interrupted())&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                selector.select(); <span class="comment">//阻塞等待事件就绪</span></span><br><span class="line">                Set selected=selector.selectedKeys(); <span class="comment">//得到事件列表</span></span><br><span class="line">                Iterator it=selected.iterator();</span><br><span class="line">                <span class="keyword">while</span>(it.hasNext())&#123;</span><br><span class="line">                    dispatch((SelectionKey) it.next()); <span class="comment">//分发事件</span></span><br><span class="line">                    it.remove(); <span class="comment">//移除当前时间</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">dispatch</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(key.isAcceptable())&#123; <span class="comment">//如果是客户端的连接事件，则需要针对该连接注册读写事件</span></span><br><span class="line">            register(key);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(key.isReadable())&#123;</span><br><span class="line">            read(key);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(key.isWritable())&#123;</span><br><span class="line">            write(key);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//得到事件对应的连接</span></span><br><span class="line">        ServerSocketChannel server=(ServerSocketChannel)key.channel();</span><br><span class="line">        SocketChannel channel=server.accept(); <span class="comment">//获得客户端的链接</span></span><br><span class="line">        channel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">        <span class="comment">//把当前客户端连接注册到selector上，注册事件为READ，</span></span><br><span class="line">        <span class="comment">// 也就是当前channel可读时，就会触发事件，然后读取客户端的数据</span></span><br><span class="line">        channel.register(<span class="keyword">this</span>.selector,SelectionKey.OP_READ);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">read</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        SocketChannel channel=(SocketChannel)key.channel();</span><br><span class="line">        ByteBuffer byteBuffer= ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">        channel.read(byteBuffer); <span class="comment">//把数据从channel读取到缓冲区</span></span><br><span class="line">        System.out.println(<span class="string">&quot;server receive msg:&quot;</span>+<span class="keyword">new</span> String(byteBuffer.array()));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        SocketChannel channel=(SocketChannel)key.channel();</span><br><span class="line">        <span class="comment">//写一个信息给到客户端</span></span><br><span class="line">        channel.write(ByteBuffer.wrap(<span class="string">&quot;hello Client,I&#x27;m NIO Server\r\n&quot;</span>.getBytes()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        NIOServer server=<span class="keyword">new</span> NIOServer(<span class="number">8888</span>);</span><br><span class="line">        <span class="keyword">new</span> Thread(server).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>事实上NIO已经解决了上述BIO暴露的下面两个问题：</p><ol><li>同步阻塞IO，读写阻塞，线程等待时间过长。</li><li>在制定线程策略的时候，只能根据CPU的数目来限定可用线程资源，不能根据连接并发数目来制定，也就是连接有限制。否则很难保证对客户端请求的高效和公平。</li></ol><p>到这里为止，通过NIO的多路复用机制，解决了IO阻塞导致客户端连接处理受限的问题，服务端只需要一个线程就可以维护多个客户端，并且客户端的某个连接如果准备就绪时，会通过事件机制告诉应用程序某个channel可用，应用程序通过select方法选出就绪的channel进行处理。</p><h2 id="单线程Reactor-模型（高性能I-O设计模式）"><a href="#单线程Reactor-模型（高性能I-O设计模式）" class="headerlink" title="单线程Reactor 模型（高性能I/O设计模式）"></a>单线程Reactor 模型（高性能I/O设计模式）</h2><p>了解了NIO多路复用后，就有必要再和大家说一下Reactor多路复用高性能I/O设计模式，Reactor本质上就是基于NIO多路复用机制提出的一个高性能IO设计模式，它的核心思想是把响应IO事件和业务处理进行分离，通过一个或者多个线程来处理IO事件，然后将就绪得到事件分发到业务处理handlers线程去异步非阻塞处理，如图4-6所示。</p><p>Reactor模型有三个重要的组件：</p><ul><li><strong>Reactor ：</strong>将I/O事件发派给对应的Handler</li><li><strong>Acceptor ：</strong>处理客户端连接请求</li><li><strong>Handlers ：</strong>执行非阻塞读/写</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354642.png" alt="image-20210708212057895"></p><center>图4-6</center><blockquote><p>下面演示一个单线程的Reactor模型。</p></blockquote><h3 id="Reactor"><a href="#Reactor" class="headerlink" title="Reactor"></a>Reactor</h3><p>Reactor 负责响应IO事件，一旦发生，广播发送给相应的Handler去处理。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Reactor</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Selector selector;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ServerSocketChannel serverSocketChannel;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Reactor</span><span class="params">(<span class="keyword">int</span> port)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//创建选择器</span></span><br><span class="line">        selector= Selector.open();</span><br><span class="line">        <span class="comment">//创建NIO-Server</span></span><br><span class="line">        serverSocketChannel=ServerSocketChannel.open();</span><br><span class="line">        serverSocketChannel.bind(<span class="keyword">new</span> InetSocketAddress(port));</span><br><span class="line">        serverSocketChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">        SelectionKey key=serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line">        <span class="comment">// 绑定一个附加对象</span></span><br><span class="line">        key.attach(<span class="keyword">new</span> Acceptor(selector,serverSocketChannel));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(!Thread.interrupted())&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                selector.select(); <span class="comment">//阻塞等待就绪事件</span></span><br><span class="line">                Set selectionKeys=selector.selectedKeys();</span><br><span class="line">                Iterator it=selectionKeys.iterator();</span><br><span class="line">                <span class="keyword">while</span>(it.hasNext())&#123;</span><br><span class="line">                    dispatch((SelectionKey) it.next());</span><br><span class="line">                    it.remove();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dispatch</span><span class="params">(SelectionKey key)</span></span>&#123;</span><br><span class="line">        <span class="comment">//调用之前注册时附加的对象，也就是attach附加的acceptor</span></span><br><span class="line">        Runnable r=(Runnable)key.attachment();</span><br><span class="line">        <span class="keyword">if</span>(r!=<span class="keyword">null</span>)&#123;</span><br><span class="line">            r.run();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> Thread(<span class="keyword">new</span> Reactor(<span class="number">8888</span>)).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Acceptor"><a href="#Acceptor" class="headerlink" title="Acceptor"></a>Acceptor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Acceptor</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Selector selector;</span><br><span class="line">    <span class="keyword">private</span> ServerSocketChannel serverSocketChannel;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Acceptor</span><span class="params">(Selector selector, ServerSocketChannel serverSocketChannel)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.selector = selector;</span><br><span class="line">        <span class="keyword">this</span>.serverSocketChannel = serverSocketChannel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        SocketChannel channel;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            channel=serverSocketChannel.accept();</span><br><span class="line">            System.out.println(channel.getRemoteAddress()+<span class="string">&quot;: 收到一个客户端连接&quot;</span>);</span><br><span class="line">            channel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            <span class="comment">//当channel连接中数据就绪时，调用DispatchHandler来处理channel</span></span><br><span class="line">            <span class="comment">//巧妙使用了SocketChannel的attach功能，将Hanlder和可能会发生事件的channel链接在一起，当发生事件时，可以立即触发相应链接的Handler。</span></span><br><span class="line">            channel.register(selector, SelectionKey.OP_READ,<span class="keyword">new</span> DispatchHandler(channel));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Handler"><a href="#Handler" class="headerlink" title="Handler"></a>Handler</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DispatchHandler</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> SocketChannel channel;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DispatchHandler</span><span class="params">(SocketChannel channel)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.channel = channel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(Thread.currentThread().getName()+<span class="string">&quot;---handler&quot;</span>); <span class="comment">//case: 打印当前线程名称，证明I/O是同一个线程来处理。</span></span><br><span class="line">        ByteBuffer buffer=ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">        <span class="keyword">int</span> len=<span class="number">0</span>,total=<span class="number">0</span>;</span><br><span class="line">        String msg=<span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">do</span> &#123;</span><br><span class="line">                len = channel.read(buffer);</span><br><span class="line">                <span class="keyword">if</span> (len &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    total += len;</span><br><span class="line">                    msg += <span class="keyword">new</span> String(buffer.array());</span><br><span class="line">                &#125;</span><br><span class="line">                buffer.clear();</span><br><span class="line">            &#125; <span class="keyword">while</span> (len &gt; buffer.capacity());</span><br><span class="line">            System.out.println(channel.getRemoteAddress()+<span class="string">&quot;:Server Receive msg:&quot;</span>+msg);</span><br><span class="line"></span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">if</span>(channel!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    channel.close();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (IOException ioException) &#123;</span><br><span class="line">                    ioException.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>演示方式，通过window的cmd窗口，使用telnet 192.168.1.102 8888 连接到Server端进行数据通信；也可以通过下面这样一个客户端程序来访问。</p></blockquote><h3 id="ReactorClient"><a href="#ReactorClient" class="headerlink" title="ReactorClient"></a>ReactorClient</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReactorClient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Selector selector;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        selector=Selector.open();</span><br><span class="line">        <span class="comment">//创建一个连接通道连接指定的server</span></span><br><span class="line">        SocketChannel socketChannel= SocketChannel.open();</span><br><span class="line">        socketChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">        socketChannel.connect(<span class="keyword">new</span> InetSocketAddress(<span class="string">&quot;192.168.1.102&quot;</span>,<span class="number">8888</span>));</span><br><span class="line">        socketChannel.register(selector, SelectionKey.OP_CONNECT);</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">            selector.select();</span><br><span class="line">            Set&lt;SelectionKey&gt; selectionKeys=selector.selectedKeys();</span><br><span class="line">            Iterator&lt;SelectionKey&gt; iterator=selectionKeys.iterator();</span><br><span class="line">            <span class="keyword">while</span>(iterator.hasNext())&#123;</span><br><span class="line">                SelectionKey key=iterator.next();</span><br><span class="line">                iterator.remove();</span><br><span class="line">                <span class="keyword">if</span>(key.isConnectable())&#123;</span><br><span class="line">                    handleConnection(key);</span><br><span class="line">                &#125;<span class="keyword">else</span> <span class="keyword">if</span>(key.isReadable())&#123;</span><br><span class="line">                    handleRead(key);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">handleConnection</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        SocketChannel socketChannel=(SocketChannel)key.channel();</span><br><span class="line">        <span class="keyword">if</span>(socketChannel.isConnectionPending())&#123;</span><br><span class="line">            socketChannel.finishConnect();</span><br><span class="line">        &#125;</span><br><span class="line">        socketChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">            Scanner in = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">            String msg = in.nextLine();</span><br><span class="line">            socketChannel.write(ByteBuffer.wrap(msg.getBytes()));</span><br><span class="line">            socketChannel.register(selector,SelectionKey.OP_READ);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">handleRead</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        SocketChannel channel=(SocketChannel)key.channel();</span><br><span class="line">        ByteBuffer byteBuffer=ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">        channel.read(byteBuffer);</span><br><span class="line">        System.out.println(<span class="string">&quot;client receive msg:&quot;</span>+<span class="keyword">new</span> String(byteBuffer.array()));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是最基本的单Reactor单线程模型<strong>（整体的I/O操作是由同一个线程完成的）</strong>。</p><p>其中Reactor线程，负责多路分离套接字，有新连接到来触发connect 事件之后，交由Acceptor进行处理，有IO读写事件之后交给hanlder 处理。</p><p>Acceptor主要任务就是构建handler ，在获取到和client相关的SocketChannel之后 ，绑定到相应的hanlder上，对应的SocketChannel有读写事件之后，基于racotor 分发,hanlder就可以处理了（所有的IO事件都绑定到selector上，有Reactor分发）</p><blockquote><p><strong>Reactor 模式本质上指的是使用 I/O 多路复用(I/O multiplexing) + 非阻塞 I/O(non-blocking I/O)的模式。</strong></p></blockquote><h2 id="多线程单Reactor模型"><a href="#多线程单Reactor模型" class="headerlink" title="多线程单Reactor模型"></a>多线程单Reactor模型</h2><p>单线程Reactor这种实现方式有存在着缺点，从实例代码中可以看出，handler的执行是串行的，如果其中一个handler处理线程阻塞将导致其他的业务处理阻塞。由于handler和reactor在同一个线程中的执行，这也将导致新的无法接收新的请求，我们做一个小实验：</p><ul><li>在上述Reactor代码的DispatchHandler的run方法中，增加一个Thread.sleep()。</li><li>打开多个客户端窗口连接到Reactor Server端，其中一个窗口发送一个信息后被阻塞，另外一个窗口再发信息时由于前面的请求阻塞导致后续请求无法被处理。</li></ul><p>为了解决这种问题，有人提出使用多线程的方式来处理业务，也就是在业务处理的地方加入线程池异步处理，将reactor和handler在不同的线程来执行，如图4-7所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354175.png" alt="image-20210709154534593"></p><center>图4-7</center><h3 id="多线程改造-MultiDispatchHandler"><a href="#多线程改造-MultiDispatchHandler" class="headerlink" title="多线程改造-MultiDispatchHandler"></a>多线程改造-MultiDispatchHandler</h3><p>我们直接将4.2.5小节中的Reactor单线程模型改成多线程，其实我们就是把IO阻塞的问题通过异步的方式做了优化，代码如下，</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiDispatchHandler</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> SocketChannel channel;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MultiDispatchHandler</span><span class="params">(SocketChannel channel)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.channel = channel;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Executor executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors() &lt;&lt; <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        processor();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">processor</span><span class="params">()</span></span>&#123;</span><br><span class="line">        executor.execute(<span class="keyword">new</span> ReaderHandler(channel));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ReaderHandler</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">        <span class="keyword">private</span> SocketChannel channel;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">ReaderHandler</span><span class="params">(SocketChannel socketChannel)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.channel = socketChannel;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            System.out.println(Thread.currentThread().getName()+<span class="string">&quot;---handler&quot;</span>); <span class="comment">//case: 打印当前线程名称，证明I/O是同一个线程来处理。</span></span><br><span class="line">            ByteBuffer buffer= ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">            <span class="keyword">int</span> len=<span class="number">0</span>;</span><br><span class="line">            String msg=<span class="string">&quot;&quot;</span>;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">do</span> &#123;</span><br><span class="line">                    len = channel.read(buffer);</span><br><span class="line">                    <span class="keyword">if</span> (len &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                        msg += <span class="keyword">new</span> String(buffer.array());</span><br><span class="line">                    &#125;</span><br><span class="line">                    buffer.clear();</span><br><span class="line">                &#125; <span class="keyword">while</span> (len &gt; buffer.capacity());</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span>(len&gt;<span class="number">0</span>) &#123;</span><br><span class="line">                    System.out.println(channel.getRemoteAddress() + <span class="string">&quot;:Server Receive msg:&quot;</span> + msg);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">                <span class="keyword">if</span>(channel!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        channel.close();</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (IOException ioException) &#123;</span><br><span class="line">                        ioException.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Acceptor-1"><a href="#Acceptor-1" class="headerlink" title="Acceptor"></a>Acceptor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Acceptor</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Selector selector;</span><br><span class="line">    <span class="keyword">private</span> ServerSocketChannel serverSocketChannel;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Acceptor</span><span class="params">(Selector selector, ServerSocketChannel serverSocketChannel)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.selector = selector;</span><br><span class="line">        <span class="keyword">this</span>.serverSocketChannel = serverSocketChannel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        SocketChannel channel;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            channel=serverSocketChannel.accept();</span><br><span class="line">            System.out.println(channel.getRemoteAddress()+<span class="string">&quot;: 收到一个客户端连接&quot;</span>);</span><br><span class="line">            channel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            <span class="comment">//当channel连接中数据就绪时，调用DispatchHandler来处理channel</span></span><br><span class="line">            <span class="comment">//巧妙使用了SocketChannel的attach功能，将Hanlder和可能会发生事件的channel链接在一起，当发生事件时，可以立即触发相应链接的Handler。</span></span><br><span class="line">            channel.register(selector, SelectionKey.OP_READ,<span class="keyword">new</span> MultiDispatchHandler(channel));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="多线程Reactor总结"><a href="#多线程Reactor总结" class="headerlink" title="多线程Reactor总结"></a>多线程Reactor总结</h3><p>在多线程Reactor模型中，添加了一个工作者线程池，并将非I/O操作从Reactor线程中移出转交给工作者线程池来执行。这样能够提高Reactor线程的I/O响应，不至于因为一些耗时的业务逻辑而延迟对后面I/O请求的处理。</p><h2 id="多Reactor多线程模式（主从多Reactor模型）"><a href="#多Reactor多线程模式（主从多Reactor模型）" class="headerlink" title="多Reactor多线程模式（主从多Reactor模型）"></a>多Reactor多线程模式（主从多Reactor模型）</h2><p>在多线程单Reactor模型中，我们发现所有的I/O操作是由一个Reactor来完成，而Reactor运行在单个线程中，它需要处理包括<code>Accept()</code>/<code>read()</code>/<code>write</code>/<code>connect</code>操作，对于小容量的场景，影响不大。但是对于高负载、大并发或大数据量的应用场景时，容易成为瓶颈，主要原因如下：</p><ul><li>一个NIO线程同时处理成百上千的链路，性能上无法支撑，即便NIO线程的CPU负荷达到100%，也无法满足海量消息的读取和发送；</li><li>当NIO线程负载过重之后，处理速度将变慢，这会导致大量客户端连接超时，超时之后往往会进行重发，这更加重了NIO线程的负载，最终会导致大量消息积压和处理超时，成为系统的性能瓶颈；</li></ul><p>所以，我们还可以更进一步优化，引入多Reactor多线程模式，如图4-8所示，Main Reactor负责接收客户端的连接请求，然后把接收到的请求传递给SubReactor（其中subReactor可以有多个），具体的业务IO处理由SubReactor完成。</p><blockquote><p>Multiple Reactors 模式通常也可以等同于 Master-Workers 模式，比如 Nginx 和 Memcached 等就是采用这种多线程模型，虽然不同的项目实现细节略有区别，但总体来说模式是一致的。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354593.png" alt="image-20210709162516832"></p><center>图4-8</center><ul><li><p><strong>Acceptor</strong>，请求接收者，在实践时其职责类似服务器，并不真正负责连接请求的建立，而只将其请求委托 Main Reactor 线程池来实现，起到一个转发的作用。</p></li><li><p><strong>Main Reactor</strong>，主 Reactor 线程组，主要<strong>负责连接事件</strong>，并将<strong>IO读写请求转发到 SubReactor 线程池</strong>。</p></li><li><p><strong>Sub Reactor</strong>，Main Reactor 通常监听客户端连接后会将通道的读写转发到 Sub Reactor 线程池中一个线程(负载均衡)，负责数据的读写。在 NIO 中 通常注册通道的读(OP_READ)、写事件(OP_WRITE)。</p></li></ul><h3 id="MultiplyReactor"><a href="#MultiplyReactor" class="headerlink" title="MultiplyReactor"></a>MultiplyReactor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiplyReactor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        MultiplyReactor mr = <span class="keyword">new</span> MultiplyReactor(<span class="number">8888</span>);</span><br><span class="line">        mr.start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> POOL_SIZE = Runtime.getRuntime().availableProcessors();</span><br><span class="line">    <span class="comment">// Reactor（Selector） 线程池，其中一个线程被 mainReactor 使用，剩余线程都被 subReactor 使用</span></span><br><span class="line">    <span class="keyword">static</span> Executor mainReactorExecutor = Executors.newFixedThreadPool(POOL_SIZE);</span><br><span class="line">    <span class="comment">// 主 Reactor，接收连接，把 SocketChannel 注册到从 Reactor 上</span></span><br><span class="line">    <span class="keyword">private</span> Reactor mainReactor;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> port;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MultiplyReactor</span><span class="params">(<span class="keyword">int</span> port)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.port = port;</span><br><span class="line">            mainReactor = <span class="keyword">new</span> Reactor();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 启动主从 Reactor，初始化并注册 Acceptor 到主 Reactor</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> Acceptor(mainReactor.getSelector(), port); <span class="comment">// 将 ServerSocketChannel 注册到 mainReactor</span></span><br><span class="line">        mainReactorExecutor.execute(mainReactor); <span class="comment">//使用线程池来处理main Reactor的连接请求</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Reactor-1"><a href="#Reactor-1" class="headerlink" title="Reactor"></a>Reactor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Reactor</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ConcurrentLinkedQueue&lt;AsyncHandler&gt; events=<span class="keyword">new</span> ConcurrentLinkedQueue&lt;&gt;();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Selector selector;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Reactor</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.selector = Selector.open();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Selector <span class="title">getSelector</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> selector;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (!Thread.interrupted()) &#123;</span><br><span class="line">                AsyncHandler handler;</span><br><span class="line">                <span class="keyword">while</span> ((handler = events.poll()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    handler.getChannel().configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">                    SelectionKey sk=handler.getChannel().register(selector, SelectionKey.OP_READ);</span><br><span class="line">                    sk.attach(handler);</span><br><span class="line">                    handler.setSk(sk);</span><br><span class="line">                &#125;</span><br><span class="line">                selector.select(); <span class="comment">//阻塞</span></span><br><span class="line">                Set&lt;SelectionKey&gt; selectionKeys=selector.selectedKeys();</span><br><span class="line">                Iterator&lt;SelectionKey&gt; it=selectionKeys.iterator();</span><br><span class="line">                <span class="keyword">while</span>(it.hasNext())&#123;</span><br><span class="line">                    SelectionKey key=it.next();</span><br><span class="line">                    <span class="comment">//获取attach方法传入的附加对象</span></span><br><span class="line">                    Runnable runnable=(Runnable)key.attachment();</span><br><span class="line">                    <span class="keyword">if</span>(runnable!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                        runnable.run();</span><br><span class="line">                    &#125;</span><br><span class="line">                    it.remove();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(AsyncHandler asyncHandler)</span></span>&#123;</span><br><span class="line">        events.offer(asyncHandler);</span><br><span class="line">        selector.wakeup();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Acceptor-2"><a href="#Acceptor-2" class="headerlink" title="Acceptor"></a>Acceptor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Acceptor</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> Selector sel;</span><br><span class="line">    <span class="keyword">final</span> ServerSocketChannel serverSocket;</span><br><span class="line">    <span class="keyword">int</span> handleNext = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> POOL_SIZE=Runtime.getRuntime().availableProcessors();</span><br><span class="line">    <span class="keyword">private</span> Executor subReactorExecutor= Executors.newFixedThreadPool(POOL_SIZE);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Reactor[] subReactors=<span class="keyword">new</span> Reactor[POOL_SIZE-<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Acceptor</span><span class="params">(Selector sel, <span class="keyword">int</span> port)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sel = sel;</span><br><span class="line">        serverSocket = ServerSocketChannel.open();</span><br><span class="line">        serverSocket.socket().bind(<span class="keyword">new</span> InetSocketAddress(port)); <span class="comment">// 绑定端口</span></span><br><span class="line">        <span class="comment">// 设置成非阻塞模式</span></span><br><span class="line">        serverSocket.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">        <span class="comment">// 注册到 选择器 并设置处理 socket 连接事件</span></span><br><span class="line">        serverSocket.register(sel, SelectionKey.OP_ACCEPT,<span class="keyword">this</span>);</span><br><span class="line">        init();</span><br><span class="line">        System.out.println(<span class="string">&quot;mainReactor-&quot;</span> + <span class="string">&quot;Acceptor: Listening on port: &quot;</span> + port);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; subReactors.length; i++) &#123;</span><br><span class="line">            subReactors[i]=<span class="keyword">new</span> Reactor();</span><br><span class="line">            subReactorExecutor.execute(subReactors[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 接收连接，非阻塞模式下，没有连接直接返回 null</span></span><br><span class="line">            SocketChannel sc = serverSocket.accept();</span><br><span class="line">            <span class="keyword">if</span> (sc != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">// 把提示发到界面</span></span><br><span class="line">                sc.write(ByteBuffer.wrap(<span class="string">&quot;Multiply Reactor Pattern Example\r\nreactor&gt; &quot;</span>.getBytes()));</span><br><span class="line">                System.out.println(Thread.currentThread().getName()+<span class="string">&quot;:Main-Reactor-Acceptor: &quot;</span> + sc.socket().getLocalSocketAddress() +<span class="string">&quot; 注册到 subReactor-&quot;</span> + handleNext);</span><br><span class="line">                <span class="comment">// 如何解决呢，直接调用 wakeup，有可能还没有注册成功又阻塞了。这是一个多线程同步的问题，可以借助队列进行处理</span></span><br><span class="line">                Reactor subReactor = subReactors[handleNext];</span><br><span class="line">                subReactor.register(<span class="keyword">new</span> AsyncHandler(sc));</span><br><span class="line">                <span class="keyword">if</span>(++handleNext == subReactors.length) &#123;</span><br><span class="line">                    handleNext = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">            ex.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="AsyncHandler"><a href="#AsyncHandler" class="headerlink" title="AsyncHandler"></a>AsyncHandler</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AsyncHandler</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> SocketChannel channel;</span><br><span class="line">    <span class="keyword">private</span> SelectionKey sk;</span><br><span class="line"></span><br><span class="line">    ByteBuffer inputBuffer=ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">    ByteBuffer outputBuffer=ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">    StringBuilder builder=<span class="keyword">new</span> StringBuilder(); <span class="comment">//存储客户端的完整消息</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">AsyncHandler</span><span class="params">(SocketChannel channel)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.channel=channel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SocketChannel <span class="title">getChannel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> channel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSk</span><span class="params">(SelectionKey sk)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sk = sk;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (sk.isReadable()) &#123;</span><br><span class="line">                read();</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (sk.isWritable()) &#123;</span><br><span class="line">                write();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">this</span>.sk.channel().close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException ioException) &#123;</span><br><span class="line">                ioException.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">read</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        inputBuffer.clear();</span><br><span class="line">        <span class="keyword">int</span> n=channel.read(inputBuffer);</span><br><span class="line">        <span class="keyword">if</span>(inputBufferComplete(n))&#123;</span><br><span class="line">            System.out.println(Thread.currentThread().getName()+<span class="string">&quot;:Server端收到客户端的请求消息：&quot;</span>+builder.toString());</span><br><span class="line">            outputBuffer.put(builder.toString().getBytes(StandardCharsets.UTF_8));</span><br><span class="line">            <span class="keyword">this</span>.sk.interestOps(SelectionKey.OP_WRITE); <span class="comment">//更改服务的逻辑状态以及处理的事件类型</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">inputBufferComplete</span><span class="params">(<span class="keyword">int</span> bytes)</span> <span class="keyword">throws</span> EOFException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(bytes&gt;<span class="number">0</span>)&#123;</span><br><span class="line">            inputBuffer.flip(); <span class="comment">//转化成读取模式</span></span><br><span class="line">            <span class="keyword">while</span>(inputBuffer.hasRemaining())&#123; <span class="comment">//判断缓冲区中是否还有元素</span></span><br><span class="line">                <span class="keyword">byte</span> ch=inputBuffer.get(); <span class="comment">//得到输入的字符</span></span><br><span class="line">                <span class="keyword">if</span>(ch==<span class="number">3</span>)&#123; <span class="comment">//表示Ctrl+c 关闭连接</span></span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> EOFException();</span><br><span class="line">                &#125;<span class="keyword">else</span> <span class="keyword">if</span>(ch==<span class="string">&#x27;\r&#x27;</span>||ch==<span class="string">&#x27;\n&#x27;</span>)&#123; <span class="comment">//表示换行符</span></span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                    builder.append((<span class="keyword">char</span>)ch); <span class="comment">//拼接读取到的数据</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(bytes==-<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> EOFException(); <span class="comment">//客户端关闭了连接</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> written=-<span class="number">1</span>;</span><br><span class="line">        outputBuffer.flip(); <span class="comment">//转化为读模式，判断是否有数据需要发送</span></span><br><span class="line">        <span class="keyword">if</span>(outputBuffer.hasRemaining())&#123;</span><br><span class="line">            written=channel.write(outputBuffer); <span class="comment">//把数据写回客户端</span></span><br><span class="line">        &#125;</span><br><span class="line">        outputBuffer.clear();</span><br><span class="line">        builder.delete(<span class="number">0</span>,builder.length());</span><br><span class="line">        <span class="keyword">if</span>(written&lt;=<span class="number">0</span>)&#123; <span class="comment">//表示客户端没有输信息</span></span><br><span class="line">            <span class="keyword">this</span>.sk.channel().close();</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            channel.write(ByteBuffer.wrap(<span class="string">&quot;\r\nreactor&gt;&quot;</span>.getBytes()));</span><br><span class="line">            <span class="keyword">this</span>.sk.interestOps(SelectionKey.OP_READ);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> NIO多路复用 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> NIO </tag>
            
            <tag> 高性能网络通信 </tag>
            
            <tag> Redis多路复用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>字节跳动二面！面试官直接问我生产环境下如何监控线程池？还好我看了这篇文章！</title>
      <link href="/posts/3554467934/"/>
      <url>/posts/3554467934/</url>
      
        <content type="html"><![CDATA[<p>线程池的监控很重要，对于前面章节讲的动态参数调整，其实还是得依赖于线程池监控的数据反馈之后才能做出调整的决策。还有就是线程池本身的运行过程对于我们来说像一个黑盒，我们没办法了解线程池中的运行状态时，出现问题没有办法及时判断和预警。</p><p>对于监控这类的场景，核心逻辑就是要拿到关键指标，然后进行上报，只要能实时拿到这些关键指标，就可以轻松实现监控以及预警功能。</p><p>ThreadPoolExecutor中提供了以下方法来获取线程池中的指标。</p><ul><li>getCorePoolSize()：获取核心线程数。</li><li>getMaximumPoolSize：获取最大线程数。</li><li>getQueue()：获取线程池中的阻塞队列，并通过阻塞队列中的方法获取队列长度、元素个数等。</li><li>getPoolSize()：获取线程池中的工作线程数（包括核心线程和非核心线程）。</li><li>getActiveCount()：获取活跃线程数，也就是正在执行任务的线程。</li><li>getLargestPoolSize()：获取线程池曾经到过的最大工作线程数。</li><li>getTaskCount()：获取历史已完成以及正在执行的总的任务数量。</li></ul><p>除此之外，ThreadPoolExecutor中还提供了一些未实现的钩子方法，我们可以通过重写这些方法来实现更多指标数据的获取。</p><ul><li>beforeExecute，在Worker线程执行任务之前会调用的方法。</li><li>afterExecute，在Worker线程执行任务之后会调用的方法。</li><li>terminated，当线程池从状态变更到TERMINATED状态之前调用的方法。</li></ul><p>比如我们可以在<code>beforeExecute</code>方法中记录当前任务开始执行的时间，再到<code>afterExecute</code>方法来计算任务执行的耗时、最大耗时、最小耗时、平均耗时等。</p><h1 id="线程池监控的基本原理"><a href="#线程池监控的基本原理" class="headerlink" title="线程池监控的基本原理"></a>线程池监控的基本原理</h1><p>我们可以通过Spring Boot提供的Actuator，自定义一个Endpoint来发布线程池的指标数据，实现线程池监控功能。当然，除了Endpoint以外，我们还可以通过JMX的方式来暴露线程池的指标信息，不管通过什么方法，核心思想都是要有一个地方看到这些数据。</p><p>了解对于Spring Boot应用监控得读者应该知道，通过Endpoint发布指标数据后，可以采用一些主流的开源监控工具来进行采集和展示。如图10-9所示，假设在Spring Boot应用中发布一个获取线程池指标信息的Endpoint，那么我们可以采用Prometheus定时去抓取目标服务器上的Metric数据，Prometheus会将采集到的数据通过Retrieval分发给TSDB进行存储。这些数据可以通过Prometheus自带的UI进行展示，也可以使用Grafana图表工具通过PromQL语句来查询Prometheus中采集的数据进行渲染。最后采用AlertManager这个组件来触发预警功能。</p><p><img src="https://img-blog.csdnimg.cn/575d9defea4e4ce1a4fd82dbaecd63c6.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6Lef552ATWlj5a2m5p625p6E,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p><center>图10-9 线程池指标监控</center><p>图10-9中所涉及到的工具都是比较程度的开源监控组件，大家可以自行根据官方教程配置即可，而在本章节中要重点讲解的就是如何自定义Endpoint发布线程池的Metric数据。</p><h1 id="在Spring-Boot应用中发布线程池信息"><a href="#在Spring-Boot应用中发布线程池信息" class="headerlink" title="在Spring Boot应用中发布线程池信息"></a>在Spring Boot应用中发布线程池信息</h1><p>对于线程池的监控实现，笔者开发了一个相对较为完整的小程序，主要涉及到几个功能：</p><ul><li>可以通过配置文件来构建线程池。</li><li>扩展了ThreadPoolExecutor的实现。</li><li>发布一个自定义的Endpoint。</li></ul><p>该小程序包含的类以及功能说明如下：</p><ul><li>ThreadPoolExecutorForMonitor：扩展ThreadPoolExecutor的实现类。</li><li>ThreadPoolConfigurationProperties：绑定application.properties的配置属性。</li><li>ThreadPoolForMonitorManager：线程池管理类，实现线程池的初始化。</li><li>ThreadPoolProperties：线程池基本属性。</li><li>ResizeLinkedBlockingQueue：这个类是直接复制了LinkedBlockingQueue，提供了<code>setCapacity</code>方法，在前面有讲解到，源码就不贴出来。</li><li>ThreadPoolEndpoint：自定义Endpoint。</li></ul><h1 id="ThreadPoolExecutorForMonitor"><a href="#ThreadPoolExecutorForMonitor" class="headerlink" title="ThreadPoolExecutorForMonitor"></a>ThreadPoolExecutorForMonitor</h1><p>继承了ThreadPoolExecutor，实现了<code>beforeExecute</code>和<code>afterExecute</code>，在原有线程池的基础上新增了最短执行时间、最长执行时间、平均执行耗时的属性。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolExecutorForMonitor</span> <span class="keyword">extends</span> <span class="title">ThreadPoolExecutor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> RejectedExecutionHandler defaultHandler = <span class="keyword">new</span> AbortPolicy();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String defaultPoolName=<span class="string">&quot;Default-Task&quot;</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> ThreadFactory threadFactory=<span class="keyword">new</span> MonitorThreadFactory(defaultPoolName);</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutorForMonitor</span><span class="params">(<span class="keyword">int</span> corePoolSize, <span class="keyword">int</span> maximumPoolSize, <span class="keyword">long</span> keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,threadFactory,defaultHandler);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutorForMonitor</span><span class="params">(<span class="keyword">int</span> corePoolSize, <span class="keyword">int</span> maximumPoolSize, <span class="keyword">long</span> keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,String poolName)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,<span class="keyword">new</span> MonitorThreadFactory(poolName),defaultHandler);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutorForMonitor</span><span class="params">(<span class="keyword">int</span> corePoolSize, <span class="keyword">int</span> maximumPoolSize, <span class="keyword">long</span> keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler,String poolName)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,threadFactory,handler);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//最短执行时间</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">long</span> minCostTime;</span><br><span class="line">  <span class="comment">//最长执行时间</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">long</span> maxCostTime;</span><br><span class="line">  <span class="comment">//总的耗时</span></span><br><span class="line">  <span class="keyword">private</span> AtomicLong totalCostTime=<span class="keyword">new</span> AtomicLong();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> ThreadLocal&lt;Long&gt; startTimeThreadLocal=<span class="keyword">new</span> ThreadLocal&lt;&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shutdown</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.shutdown();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">beforeExecute</span><span class="params">(Thread t, Runnable r)</span> </span>&#123;</span><br><span class="line">    startTimeThreadLocal.set(System.currentTimeMillis());</span><br><span class="line">    <span class="keyword">super</span>.beforeExecute(t, r);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">afterExecute</span><span class="params">(Runnable r, Throwable t)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> costTime=System.currentTimeMillis()-startTimeThreadLocal.get();</span><br><span class="line">    startTimeThreadLocal.remove();</span><br><span class="line">    maxCostTime=maxCostTime&gt;costTime?maxCostTime:costTime;</span><br><span class="line">    <span class="keyword">if</span>(getCompletedTaskCount()==<span class="number">0</span>)&#123;</span><br><span class="line">      minCostTime=costTime;</span><br><span class="line">    &#125;</span><br><span class="line">    minCostTime=minCostTime&lt;costTime?minCostTime:costTime;</span><br><span class="line">    totalCostTime.addAndGet(costTime);</span><br><span class="line">    <span class="keyword">super</span>.afterExecute(r, t);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getMinCostTime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> minCostTime;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getMaxCostTime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> maxCostTime;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getAverageCostTime</span><span class="params">()</span></span>&#123;<span class="comment">//平均耗时</span></span><br><span class="line">    <span class="keyword">if</span>(getCompletedTaskCount()==<span class="number">0</span>||totalCostTime.get()==<span class="number">0</span>)&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> totalCostTime.get()/getCompletedTaskCount();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">terminated</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.terminated();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MonitorThreadFactory</span> <span class="keyword">implements</span> <span class="title">ThreadFactory</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> AtomicInteger poolNumber = <span class="keyword">new</span> AtomicInteger(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ThreadGroup group;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger threadNumber = <span class="keyword">new</span> AtomicInteger(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String namePrefix;</span><br><span class="line"></span><br><span class="line">    MonitorThreadFactory(String poolName) &#123;</span><br><span class="line">      SecurityManager s = System.getSecurityManager();</span><br><span class="line">      group = (s != <span class="keyword">null</span>) ? s.getThreadGroup() :</span><br><span class="line">      Thread.currentThread().getThreadGroup();</span><br><span class="line">      namePrefix = poolName+<span class="string">&quot;-pool-&quot;</span> +</span><br><span class="line">        poolNumber.getAndIncrement() +</span><br><span class="line">        <span class="string">&quot;-thread-&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Thread <span class="title">newThread</span><span class="params">(Runnable r)</span> </span>&#123;</span><br><span class="line">      Thread t = <span class="keyword">new</span> Thread(group, r,</span><br><span class="line">                            namePrefix + threadNumber.getAndIncrement(),</span><br><span class="line">                            <span class="number">0</span>);</span><br><span class="line">      <span class="keyword">if</span> (t.isDaemon())</span><br><span class="line">        t.setDaemon(<span class="keyword">false</span>);</span><br><span class="line">      <span class="keyword">if</span> (t.getPriority() != Thread.NORM_PRIORITY)</span><br><span class="line">        t.setPriority(Thread.NORM_PRIORITY);</span><br><span class="line">      <span class="keyword">return</span> t;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="ThreadPoolConfigurationProperties"><a href="#ThreadPoolConfigurationProperties" class="headerlink" title="ThreadPoolConfigurationProperties"></a>ThreadPoolConfigurationProperties</h1><p>提供了获取application.properties配置文件属性的功能，</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ConfigurationProperties(prefix = &quot;monitor.threadpool&quot;)</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolConfigurationProperties</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> List&lt;ThreadPoolProperties&gt;  executors=<span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>线程池的核心属性声明。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolProperties</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String poolName;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> corePoolSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> maxmumPoolSize=Runtime.getRuntime().availableProcessors();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> keepAliveTime=<span class="number">60</span>;</span><br><span class="line">    <span class="keyword">private</span> TimeUnit unit= TimeUnit.SECONDS;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> queueCapacity=Integer.MAX_VALUE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述配置类要生效，需要通过@EnableConfigurationProperties开启，我们可以在Main方法上开启，代码如下。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@EnableConfigurationProperties(ThreadPoolConfigurationProperties.class)</span></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(ThreadPoolApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="application-properties"><a href="#application-properties" class="headerlink" title="application.properties"></a>application.properties</h1><p>配置类创建好之后，我们就可以在application.properties中，通过如下方式来构建线程池。</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">monitor.threadpool.executors[0].pool-name</span>=<span class="string">first-monitor-thread-pool</span></span><br><span class="line"><span class="meta">monitor.threadpool.executors[0].core-pool-size</span>=<span class="string">4</span></span><br><span class="line"><span class="meta">monitor.threadpool.executors[0].maxmum-pool-size</span>=<span class="string">8</span></span><br><span class="line"><span class="meta">monitor.threadpool.executors[0].queue-capacity</span>=<span class="string">100</span></span><br><span class="line"></span><br><span class="line"><span class="meta">monitor.threadpool.executors[1].pool-name</span>=<span class="string">second-monitor-thread-pool</span></span><br><span class="line"><span class="meta">monitor.threadpool.executors[1].core-pool-size</span>=<span class="string">2</span></span><br><span class="line"><span class="meta">monitor.threadpool.executors[1].maxmum-pool-size</span>=<span class="string">4</span></span><br><span class="line"><span class="meta">monitor.threadpool.executors[1].queue-capacity</span>=<span class="string">40</span></span><br></pre></td></tr></table></figure><h1 id="ThreadPoolForMonitorManager"><a href="#ThreadPoolForMonitorManager" class="headerlink" title="ThreadPoolForMonitorManager"></a>ThreadPoolForMonitorManager</h1><p>用来实现线程池的管理和初始化，实现线程池的统一管理，初始化的逻辑是根据application.properties中配置的属性来实现的。</p><ul><li>从配置类中获得线程池的基本配置。</li><li>根据配置信息构建ThreadPoolExecutorForMonitor实例。</li><li>把实例信息保存到集合中。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolForMonitorManager</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Autowired</span></span><br><span class="line">  ThreadPoolConfigurationProperties poolConfigurationProperties;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> ConcurrentMap&lt;String,ThreadPoolExecutorForMonitor&gt; threadPoolExecutorForMonitorConcurrentMap=<span class="keyword">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="meta">@PostConstruct</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span></span>&#123;</span><br><span class="line">    poolConfigurationProperties.getExecutors().forEach(threadPoolProperties -&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span>(!threadPoolExecutorForMonitorConcurrentMap.containsKey(threadPoolProperties.getPoolName()))&#123;</span><br><span class="line">        ThreadPoolExecutorForMonitor executorForMonitor=<span class="keyword">new</span> ThreadPoolExecutorForMonitor(</span><br><span class="line">          threadPoolProperties.getCorePoolSize(),</span><br><span class="line">          threadPoolProperties.getMaxmumPoolSize(),</span><br><span class="line">          threadPoolProperties.getKeepAliveTime(),</span><br><span class="line">          threadPoolProperties.getUnit(),</span><br><span class="line">          <span class="keyword">new</span> ResizeLinkedBlockingQueue&lt;&gt;(threadPoolProperties.getQueueCapacity()),</span><br><span class="line">          threadPoolProperties.getPoolName());</span><br><span class="line">        threadPoolExecutorForMonitorConcurrentMap.put(threadPoolProperties.getPoolName(),executorForMonitor);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> ThreadPoolExecutorForMonitor <span class="title">getThreadPoolExecutor</span><span class="params">(String poolName)</span></span>&#123;</span><br><span class="line">    ThreadPoolExecutorForMonitor threadPoolExecutorForMonitor=threadPoolExecutorForMonitorConcurrentMap.get(poolName);</span><br><span class="line">    <span class="keyword">if</span>(threadPoolExecutorForMonitor==<span class="keyword">null</span>)&#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;找不到名字为&quot;</span>+poolName+<span class="string">&quot;的线程池&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> threadPoolExecutorForMonitor;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> ConcurrentMap&lt;String,ThreadPoolExecutorForMonitor&gt; <span class="title">getThreadPoolExecutorForMonitorConcurrentMap</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.threadPoolExecutorForMonitorConcurrentMap;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="ThreadPoolEndpoint"><a href="#ThreadPoolEndpoint" class="headerlink" title="ThreadPoolEndpoint"></a>ThreadPoolEndpoint</h1><p>使用Spring-Boot-Actuator发布Endpoint，用来暴露当前应用中所有线程池的Metric数据。</p><blockquote><p>读者如果不清楚在Spring Boot中自定义Endpoint，可以直接去Spring官方文档中配置，比较简单。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@Endpoint(id=&quot;thread-pool&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolEndpoint</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Autowired</span></span><br><span class="line">  <span class="keyword">private</span> ThreadPoolForMonitorManager threadPoolForMonitorManager;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@ReadOperation</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Map&lt;String,Object&gt; <span class="title">threadPoolsMetric</span><span class="params">()</span></span>&#123;</span><br><span class="line">    Map&lt;String,Object&gt; metricMap=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    List&lt;Map&gt; threadPools=<span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    threadPoolForMonitorManager.getThreadPoolExecutorForMonitorConcurrentMap().forEach((k,v)-&gt;&#123;</span><br><span class="line">      ThreadPoolExecutorForMonitor tpe=(ThreadPoolExecutorForMonitor) v;</span><br><span class="line">      Map&lt;String,Object&gt; poolInfo=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.name&quot;</span>,k);</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.core.size&quot;</span>,tpe.getCorePoolSize());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.largest.size&quot;</span>,tpe.getLargestPoolSize());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.max.size&quot;</span>,tpe.getMaximumPoolSize());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.thread.count&quot;</span>,tpe.getPoolSize());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.max.costTime&quot;</span>,tpe.getMaxCostTime());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.average.costTime&quot;</span>,tpe.getAverageCostTime());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.min.costTime&quot;</span>,tpe.getMinCostTime());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.active.count&quot;</span>,tpe.getActiveCount());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.completed.taskCount&quot;</span>,tpe.getCompletedTaskCount());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.queue.name&quot;</span>,tpe.getQueue().getClass().getName());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.rejected.name&quot;</span>,tpe.getRejectedExecutionHandler().getClass().getName());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.task.count&quot;</span>,tpe.getTaskCount());</span><br><span class="line">      threadPools.add(poolInfo);</span><br><span class="line">    &#125;);</span><br><span class="line">    metricMap.put(<span class="string">&quot;threadPools&quot;</span>,threadPools);</span><br><span class="line">    <span class="keyword">return</span> metricMap;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果需要上述自定义的Endpoint可以被访问，还需要在application.properties文件中配置如下代码，意味着thread-pool Endpoint允许被访问。</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">management.endpoints.web.exposure.include</span>=<span class="string">thread-pool</span></span><br></pre></td></tr></table></figure><h1 id="TestController"><a href="#TestController" class="headerlink" title="TestController"></a>TestController</h1><p>提供使用线程池的方法，用来实现在调用之前和调用之后，通过Endpoint获取到Metric数据的变化。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> String poolName=<span class="string">&quot;first-monitor-thread-pool&quot;</span>;</span><br><span class="line">  <span class="meta">@Autowired</span></span><br><span class="line">  ThreadPoolForMonitorManager threadPoolForMonitorManager;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@GetMapping(&quot;/execute&quot;)</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">doExecute</span><span class="params">()</span></span>&#123;</span><br><span class="line">    ThreadPoolExecutorForMonitor tpe=threadPoolForMonitorManager.getThreadPoolExecutor(poolName);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">      tpe.execute(()-&gt;&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          Thread.sleep(<span class="keyword">new</span> Random().nextInt(<span class="number">4000</span>));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">          e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;success&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="效果演示"><a href="#效果演示" class="headerlink" title="效果演示"></a>效果演示</h1><p>访问自定义Endpoint： <a href="http://ip:8080/actuator/thread-pool%EF%BC%8C%E5%B0%B1%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E5%A6%82%E4%B8%8B%E6%95%B0%E6%8D%AE%E3%80%82%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E6%8A%8A%E8%BF%99%E4%B8%AAEndpoint%E9%85%8D%E7%BD%AE%E5%88%B0Prometheus%E4%B8%AD%EF%BC%8CPrometheus%E4%BC%9A%E5%AE%9A%E6%97%B6%E6%8A%93%E5%8F%96%E8%BF%99%E4%BA%9B%E6%8C%87%E6%A0%87%E5%AD%98%E5%82%A8%E5%B9%B6%E5%B1%95%E7%A4%BA%EF%BC%8C%E4%BB%8E%E8%80%8C%E5%AE%8C%E6%88%90%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E6%95%B4%E4%BD%93%E7%9B%91%E6%8E%A7%E3%80%82">http://ip:8080/actuator/thread-pool，就可以看到如下数据。我们可以把这个Endpoint配置到Prometheus中，Prometheus会定时抓取这些指标存储并展示，从而完成线程池的整体监控。</a></p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;threadPools&quot;</span>:[</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;thread.pool.queue.name&quot;</span>:<span class="string">&quot;com.concurrent.demo.ResizeLinkedBlockingQueue&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.core.size&quot;</span>:<span class="number">2</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.min.costTime&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.completed.taskCount&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.max.costTime&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.task.count&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.name&quot;</span>:<span class="string">&quot;second-monitor-thread-pool&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.largest.size&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.rejected.name&quot;</span>:<span class="string">&quot;java.util.concurrent.ThreadPoolExecutor$AbortPolicy&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.active.count&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.thread.count&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.average.costTime&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.max.size&quot;</span>:<span class="number">4</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;thread.pool.queue.name&quot;</span>:<span class="string">&quot;com.concurrent.demo.ResizeLinkedBlockingQueue&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.core.size&quot;</span>:<span class="number">4</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.min.costTime&quot;</span>:<span class="number">65</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.completed.taskCount&quot;</span>:<span class="number">115</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.max.costTime&quot;</span>:<span class="number">3964</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.task.count&quot;</span>:<span class="number">200</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.name&quot;</span>:<span class="string">&quot;first-monitor-thread-pool&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.largest.size&quot;</span>:<span class="number">4</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.rejected.name&quot;</span>:<span class="string">&quot;java.util.concurrent.ThreadPoolExecutor$AbortPolicy&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.active.count&quot;</span>:<span class="number">4</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.thread.count&quot;</span>:<span class="number">4</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.average.costTime&quot;</span>:<span class="number">1955</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.max.size&quot;</span>:<span class="number">8</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>线程池的整体实现并不算太复杂，但是里面涉及到的一些思想和理论是可以值得我们去学习和借鉴，如基于阻塞队列的生产者消费者模型的实现、动态扩容的思想、如何通过AQS来实现安全关闭线程池、降级方案（拒绝策略）、位运算等。实际上越底层的实现，越包含更多技术层面的思想和理论。</p><p>线程池在实际使用中，如果是新手，不建议直接用Executors中提供的工厂方法，因为线程池中的参数会影响到内存以及CPU资源的占用，我们可以自己集成ThreadPoolExecutor这个类，扩展一个自己的实现，也可以自己构造ThreadPoolExecutor实例，这样能够更好的了解线程池中核心参数的意义避免不必要的生产问题。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 线程池 </tag>
            
            <tag> Spring Boot </tag>
            
            <tag> 监控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1万字长文高速你千万级并发架构下如何提高数据库存储性能</title>
      <link href="/posts/4032676932/"/>
      <url>/posts/4032676932/</url>
      
        <content type="html"><![CDATA[<p>如图所示，表示发起一个请求时，涉及到数据库的相关操作，在前面的文章中我们说过，如果服务端要提升整体的吞吐量，就必须要减少每一次请求的处理时长，那么在当前这个场景中，数据库层面哪些因素会影响到性能呢？</p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121455814.png" alt="image-20210624225017321" style="zoom:50%;" /><center>图2-1</center><h2 id="池化技术，减少频繁创建数据库连接"><a href="#池化技术，减少频繁创建数据库连接" class="headerlink" title="池化技术，减少频繁创建数据库连接"></a>池化技术，减少频繁创建数据库连接</h2><p>遇到这样的问题，解决办法就是顺着当前整体的逻辑去思考，首先，应用要和数据库打交道，必然会设计到数据库链接的建立。然后在当前连接中完成数据库的相关操作，最后再关闭连接。</p><p>在这种场景下，客户端每次发起请求，都需要重新建立连接，如果频繁的创建连接是否会影响到性能呢？答案是一定的，我们通过下面这样一个方式来验证一下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> -i指定网卡名称</span></span><br><span class="line">tcpdump -i eth0 -nn -tttt port 3306</span><br></pre></td></tr></table></figure><p>当我们向数据库发起一次连接时，上述抓包命令会打印连接的相关信息如下。（通过Navicat 的链接测试工具测试）</p><blockquote><p>关注前面8行数据即可。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.130812</span> IP <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span> &gt; <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span>: Flags [S], seq <span class="number">759743325</span>, win <span class="number">64240</span>, options [mss <span class="number">1448</span>,nop,wscale <span class="number">8</span>,nop,nop,sackOK], length <span class="number">0</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.130901</span> IP <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span> &gt; <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span>: Flags [S.], seq <span class="number">3058334924</span>, ack <span class="number">759743326</span>, win <span class="number">29200</span>, options [mss <span class="number">1460</span>,nop,nop,sackOK,nop,wscale <span class="number">7</span>], length <span class="number">0</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.160730</span> IP <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span> &gt; <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span>: Flags [.], ack <span class="number">1</span>, win <span class="number">260</span>, length <span class="number">0</span></span><br><span class="line">    </span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.161037</span> IP <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span> &gt; <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span>: Flags [P.], seq <span class="number">1</span>:<span class="number">79</span>, ack <span class="number">1</span>, win <span class="number">229</span>, length <span class="number">78</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.190126</span> IP <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span> &gt; <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span>: Flags [P.], seq <span class="number">1</span>:<span class="number">63</span>, ack <span class="number">79</span>, win <span class="number">259</span>, length <span class="number">62</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.190193</span> IP <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span> &gt; <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span>: Flags [.], ack <span class="number">63</span>, win <span class="number">229</span>, length <span class="number">0</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.190306</span> IP <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span> &gt; <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span>: Flags [P.], seq <span class="number">79</span>:<span class="number">90</span>, ack <span class="number">63</span>, win <span class="number">229</span>, length <span class="number">11</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.219256</span> IP <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span> &gt; <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span>: Flags [P.], seq <span class="number">63</span>:<span class="number">82</span>, ack <span class="number">90</span>, win <span class="number">259</span>, length <span class="number">19</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.219412</span> IP <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span> &gt; <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span>: Flags [P.], seq <span class="number">90</span>:<span class="number">101</span>, ack <span class="number">82</span>, win <span class="number">229</span>, length <span class="number">11</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.288721</span> IP <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span> &gt; <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span>: Flags [.], ack <span class="number">101</span>, win <span class="number">259</span>, length <span class="number">0</span></span><br></pre></td></tr></table></figure><ul><li><p>第一部分是TCP三次握手建立连接的数据包</p><ul><li>第一个数据包是客户端向服务区段发送一个SYN包</li><li>第二个数据包是服务端返回给客户端的ACK包以及一个SYN包</li><li>第三个数据包是客户端返回给服务端的ACK包</li></ul></li><li><p>第二个部分是Mysql服务端校验客户端密码的过程</p></li></ul><p>从开始建立连接的时间130812到最终完成连接288721， 总共耗时157909，接近158ms时间，这个时间看起来很小，而且在请求量较小的情况下，对系统的影响不是很大。但是请求量上来之后，这个请求耗时的影响就非常大了。</p><p>而对于这个问题的解决办法大家都已经知道，就是利用池化技术，预先建立好数据库连接，当应用需要使用连接时，直接从预先建立好的连接中来获取进行调用，如图2-2所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450806.png" alt="image-20210625134607312"></p><center>图2-2</center><p>数据库连接池的工作原理和线程池类似，数据库连接池有两个最重要的配置： <strong>最小连接数和最大连接数，</strong> 它们控制着从连接池中获取连接的流程：</p><ul><li>如果当前连接数小于最小连接数，则创建新的连接处理数据库请求；</li><li>如果连接池中有空闲连接则复用空闲连接；</li><li>如果空闲池中没有连接并且当前连接数小于最大连接数，则创建新的连接处理请求；</li><li>如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间（maxWait）等待旧的连接可用；</li><li>如果等待超过了这个设定时间则向用户抛出错误。</li></ul><p>总的来说，连接池核心思想是空间换时间，期望使用预先创建好的对象来减少频繁创建对象的性能开销，同时还可以对对象进行统一的管理，降低了对象的使用的成本。</p><h2 id="数据库本身的性能优化"><a href="#数据库本身的性能优化" class="headerlink" title="数据库本身的性能优化"></a>数据库本身的性能优化</h2><p>数据库本身的性能优化也很重要，常见的优化手段</p><ul><li>创建并正确使用索引，尽量只通过索引访问数据</li><li>优化SQL执行计划，SQL执行计划是关系型数据库最核心的技术之一，它表示SQL执行时的数据访问算法，优化执行计划也就能够提升sql查询的性能</li><li>每次数据交互时，尽可能返回更少的数据，因为更大的数据意味着会增大网络通信延迟。常见的方式是通过分页来查询数据、只返回当前场景需要的字段</li><li>减少和数据库的交互次数，比如批量提交、批量查询</li><li>…</li></ul><h2 id="数据库读写操作的性能问题"><a href="#数据库读写操作的性能问题" class="headerlink" title="数据库读写操作的性能问题"></a>数据库读写操作的性能问题</h2><p>如果老板说公司准备在下个月搞一场运营活动，用户数量会快速增加，导致对数据库的读压力增加，假设在4 核 8G 的机器上运 MySQL 5.7 时，大概可以支撑 500 的 TPS 和 10000 的 QPS，而实际的QPS可能是10W，那怎么解决呢？</p><p>首先分析一下这个问题，在绝大部分面向用户的系统中，都是读多写少的模型，比如电商，大部分的时候是在搜索和浏览，比如抖音，大部分是在加载短视频，所以我们需要考虑的问题是，数据库如何扛住查询请求。一般的解决方法是读写分离，</p><p>所谓读写分离，就是把同一个数据库分离成两份，一份专门用来做事务操作，另一份专门用来做读操作，如图2-3所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450506.png" alt="image-20210625142110740"></p><center>图2-3</center><p>做了主从复制之后，我们就可以在写入时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响到读请求的执行。同时呢，在读流量比较大的情况下，我们可以部署多个从库共同承担读流量，这就是所说的 <strong>一主多从</strong> 部署方式，在你的垂直电商项目中就可以通过这种方式来抵御较高的并发读流量。另外，从库也可以当成一个备库来使用，以避免主库故障导致数据丢失。</p><p><strong>那么你可能会说，是不是我无限制地增加从库的数量就可以抵抗大量的并发呢？</strong> 实际上并不是的。因为随着从库数量增加，从库连接上来的 IO 线程比较多，<strong>主库也需要创建同样多的 log dump 线程来处理复制的请求</strong>，对于主库资源消耗比较高，同时受限于主库的网络带宽，所以在实际使用中，<strong>一般一个主库最多挂 3～5 个从库</strong>。</p><p><strong>当然，主从复制也有一些缺陷，</strong> 除了带来了部署上的复杂度，还有就是会带来一定的主从同步的延迟，这种延迟有时候会对业务产生一定的影响</p><h2 id="数据量增加带来的性能问题"><a href="#数据量增加带来的性能问题" class="headerlink" title="数据量增加带来的性能问题"></a>数据量增加带来的性能问题</h2><p>随着业务的增长，数据库中的数据量也会随着增加，由于最早开发时主要是为了赶进度，数据都是单表存储，因此单表数据量增加之后，导致数据库的查询和写入都造成非常大的性能开销，具体体现在。</p><ul><li>单表数据量过大，千万级别到上亿级别，这时即使你使用了索引，索引占用的空间也随着数据量的增长而增大，数据库就无法缓存全量的索引信息，那么就需要从磁盘上读取索引数据，就会影响到查询的性能。</li><li>数据量的增加也占据了磁盘的空间，数据库在备份和恢复的时间变长</li><li>不同模块的数据，比如用户数据和用户关系数据，全都存储在一个主库中，一旦主库发生故障，所有的模块儿都会受到影响</li><li>在 4 核 8G 的云服务器上对 MySQL5.7 做 Benchmark，大概可以支撑 500TPS 和 10000QPS，你可以看到数据库对于写入性能要弱于数据查询的能力，那么随着系统写入请求量的增长，对于写请求的耗时也会增加（更新数据操作需要同步更新索引，数据量较大的情况下更新索引耗时较长）</li></ul><p>在这类场景中，解决方案就是对数据进行分片，也就是分库分表的机制，如图2-4所示。数据拆分的核心降低单表和单库的数据IO压力，从而提升对数据库相关操作的性能。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450667.png" alt="image-20210625144502558"></p><center>图2-4</center><h1 id="不同存储设备带来的性能提升"><a href="#不同存储设备带来的性能提升" class="headerlink" title="不同存储设备带来的性能提升"></a>不同存储设备带来的性能提升</h1><p>前面我们了解了对于传统关系型数据库的一些优化思路，整体来说，通过优化之后能够提升程序访问数据库的计算性能。但是还是有一些情况，即便是优化之后，使用传统关系型数据库无法解决的，比如。</p><ul><li>当数据量达到TB级别时，传统关系型数据库基本做了分库分表，单表数据量也是非常大的。</li><li>对于一些不适合用关系型数据库存储的数据，传统数据库无法做到，所以数据库本身的特性限制了多样性数据的管理。</li></ul><p>所以nosql出现了，大家对nosql这个概念已经不陌生了，它是指不同于传统关系型数据库的其他数据库系统的一个统称，它不使用SQL作为查询语言，并且相对于传统关系型数据库来说，</p><p>它提供了更高的性能以及横向扩展能力，非常适合互联网项目中高并发且数据量较大的场景中，如图25所示，表示目前比较主流的不同类型的nosql数据库。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450770.png" alt="image-20210625164052410"></p><center>图2-5 不同的NoSql数据库</center><blockquote><p>这个网站上记录了所有的Nosql框架</p><p><a href="https://hostingdata.co.uk/nosql-database/">https://hostingdata.co.uk/nosql-database/</a></p></blockquote><h2 id="Key-Value数据库"><a href="#Key-Value数据库" class="headerlink" title="Key-Value数据库"></a>Key-Value数据库</h2><p>key-value数据库，典型的代表就是Redis、Memcached，也是目前业内非常主流的Nosq数据库。</p><p>之所以在IO性能方面比传统关系型数据库高，有两个点</p><ul><li>数据基于内存，读写效率高</li><li>KV型数据，时间复杂度为O(1)，查询速度快</li></ul><p>KV型NoSql最大的优点就是<strong>高性能</strong>，利用Redis自带的BenchMark做基准测试，TPS可达达到接近10W的级别，性能非常强劲。同样的Redis也有所有KV型NoSql都有的比较明显的缺点：</p><ul><li>查询方式单一，只有KV的方式，不支持条件查询，多条件查询唯一的做法就是数据冗余，但这会极大的浪费存储空间</li><li>内存是有限的，无法支持海量数据存储</li><li>同样的，由于KV型NoSql的存储是基于内存的，会有丢失数据的风险</li></ul><p>基于Key-Value数据库的特性，这类数据库比较适用于缓存的场景。</p><ul><li>读多写少</li><li>读取能力强</li><li>可以接受数据丢失</li></ul><p>这类存储相比于传统的数据库的优势是极高的读写性能，一般对性能有比较高的要求的场景会使用，主要使用场景。</p><ul><li>用来做分布式缓存，提升程序处理效率。</li><li>用来做会话数据存储</li><li>其他功能性特性，比如消息通信、分布式锁、布隆过滤器</li><li>微博的feed流，早期就是用了redis实现。（持续更新并呈现给用户内容的信息流。每个人的朋友圈，微博关注页等等都是一个 Feed 流）</li></ul><h2 id="列式数据库"><a href="#列式数据库" class="headerlink" title="列式数据库"></a>列式数据库</h2><p>我们最早学习数据库，都是基于以二维表形式存储，每一行代表一条完整的数据。大部分传统的关系型数据库中，都是以行来存储数据。不过最近几年，列式存储也逐步被广泛运用在大数据框架中。</p><p>行存储和列存储，是数据库底层数据组织的形式的区别，如图2-6所示，数据库表中所有列一次排成一行，以行位单位存储，再配合B+树或者SS-Table作为索引，就能快速通过主键找到相应的行数据。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450630.png" alt="image-20210625202700946"></p><center>图2-6</center><p>在实际应用中，大部分的操作都是以实体（Entity）为单位，也就是大部分CRUD操作都是针对一整行记录，如果需要保存一行数据，只需要在原来的数据后追加一行数据即可，所以数据的写入非常快。</p><p>但是对于查询来说，一个典型的查询操作需要遍历整个表，分组、排序、聚合等，对于行存储来说，这样的操作的优势就不存在了，更惨的是，分析型SQL可能不需要用到所有的列，仅仅只需要对某些列进行运算即可，但是那一行中和本次操作无关的列也必须要参与到数据扫描中。</p><p>比如，如图2-7所示，现在我想统计所有文章的总的点赞数量，作为行存储的系统，数据库会怎么操作呢？</p><ul><li>首先需要把所有行的数据加载到内存</li><li>然后对like_num列做sum操作</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450318.png" alt="image-20210625204523910"></p><center>图2-7</center><p>行式存储对于OLAP场景而言，优势就不存在了，所以就引入了列式存储。</p><blockquote><p>OLTP（on-line transaction processing）翻译为联机事务处理， OLAP（On-Line Analytical Processing）翻译为联机分析处理，从字面上来看OLTP是做事务处理，OLAP是做分析处理。从对数据库操作来看，OLTP主要是对数据的增删改，OLAP是对数据的查询</p></blockquote><p>如图2-8所示，列式存储是将每一列数据组织在一起，它方便对于列的操作，比如前面说的统计like_num之和，按列存储之后只需要一次磁盘操作就可以完成三个数据的汇总，所以非常适合OLAP的场景。</p><ul><li>当查询语句只涉及部分列时，只需要扫描相关列</li><li>每一列数据都是相同类型，彼此间的关联性更大，对列数据压缩的效率较高。</li></ul><p>但是对于OLTP来说不是很友好，因为一行数据的写入需要修改多个列。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450057.png" alt="image-20210625221307500"></p><center>图2-8</center><p>列式存储在大数据分析中使用非常多，比如推荐画像（蚂蚁金服的风控）、是空数据（滴滴打车的归集数据）、消息/订单（电信领域、银行领域）不少订单查询底层的存储。 Feeds流（朋友圈类似的应用）等等。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450491.png" alt="image-20210625220018008"></p><center>图2-9</center><h2 id="文档型数据库"><a href="#文档型数据库" class="headerlink" title="文档型数据库"></a>文档型数据库</h2><p>传统的数据库，所有信息会被分割成离散的数据字段，保存在关系型数据库中，甚至对于一些复杂的场景，还会分散在不同的表结构中。</p><p>举个例子，在一个技术论坛中，假设对于用户、文章、文章评论表的关系图如图2-10所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450374.png" alt="image-20210625225801200"></p><center>图2-10</center><p>那用户点一篇文章，里面要显示该文章的创建者、文章详情、文章的评论，那么服务端要做什么呢？</p><ul><li>查找文章详情</li><li>根据文章中的uid查找用户信息</li><li>查询该文章的所有评论列表</li><li>查询每个评论的创建者名字</li></ul><p>这个过程要么就是多次数据库查询，要么就是使用一个复杂关联查询来检索，不管怎么做，都不是很方便。而文档数据库就可以解决这样的问题。</p><p>文档数据库是以文档单位，具体的文档形式有很多种，比如（XML、YAML、JSON、BSON）等，文档中存储具体的字段和值，应用可以使用这些字段进行查询和数据筛选。</p><p>一般情况下，文档中包含了实体中的全部数据，比如图2-10的结构，我们可以直接把一篇文章的基本要素信息构建成一个完整的文档保存到文档数据库中，应用程序只需要发起一次请求就可以获取所有数据。b</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">Article：&#123;</span><br><span class="line">    Creator:&#123;</span><br><span class="line">        uid: &#x27;&#x27;,</span><br><span class="line">        username: &#x27;&#x27;</span><br><span class="line">    &#125;,</span><br><span class="line">    Topic: &#123;</span><br><span class="line">        title: &#x27;&#x27;,</span><br><span class="line">        content: &#x27;&#x27;</span><br><span class="line">    &#125;,</span><br><span class="line">    Reply: [</span><br><span class="line">        &#123;</span><br><span class="line">            replyId:,</span><br><span class="line">            content:&#x27;&#x27;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            replyId:,</span><br><span class="line">            content:&#x27;&#x27;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>MongoDB是目前最流行的Nosql数据库，它是一种面向集合、与模式（Schema Free）无关的文档型数据库。它的数据是以“集合”的方式进行分组，每个集合都有单独的名称并可以包含无线数量的文档，这种集合与关系型数据库中的表类似，唯一的区别就是它并没有任何明确的schema。</p><blockquote><p>在数据库中，schema（发音 “skee-muh” 或者“skee-mah”，中文叫模式）是数据库的组织和结构，<em>schemas</em> 和<em>schemata</em>都可以作为复数形式。模式中包含了schema对象，可以是<strong>表</strong>(table)、<strong>列</strong>(column)、<strong>数据类型</strong>(data type)、<strong>视图</strong>(view)、<strong>存储过程</strong>(stored procedures)、<strong>关系</strong>(relationships)、<strong>主键</strong>(primary key)、**外键(**foreign key)等。数据库模式可以用一个可视化的图来表示，它显示了数据库对象及其相互之间的关系</p></blockquote><p>如图2-11所示， 将数据存储在类似 JSON 的灵活文档中，这意味着字段可能因具体文档而异，并且数据结构可能随着时间的推移而变化。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450288.png" alt="img"></p><center>图2-11</center><p>MongoDB没有“数据一致性检查”、“事务”等，不适合存储对数据事务要求较高的场景，只适合放一些非关键性数据，常见应用场景如下：</p><ul><li>使用Mongodb对应用日志进行记录</li><li>存储监控数据，比如应用的埋点信息，可以直接上报存储到mongoDB中</li><li>MongoDB可以用来实现O2O快递应用，比如快递骑手、快递商家的信息存储在MongoDB，然后通过MongoDB的地理位置查询，方便用来查询附近的商家、骑手等功能。</li></ul><h2 id="图形数据库"><a href="#图形数据库" class="headerlink" title="图形数据库"></a>图形数据库</h2><p>图形数据库，表示以数据结构“图”作为存储的数据库。<br>图形数据存储管理两类信息：节点信息和边缘信息。 节点表示实体，边缘表示这些实体之间的关系。 节点和边缘都可以包含一些属性用于提供有关该节点或边缘的信息（类似于表中的列）。 </p><p>边缘还可以包含一个方向用于指示关系的性质。</p><p>图形数据存储的用途是让应用程序有效执行需遍历节点和边缘网络的查询，以及分析实体之间的关系。 如图2-12所示，显示了已结构化为图形的组织人员数据。 </p><p>实体为员工和部门，边缘指示隶属关系以及员工所在的部门。 在此图中，边缘上的箭头表示关系的方向。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450756.png" alt="image-20210625180249817"></p><center>图2-12</center><p>使用此结构可以简单直接地执行类似于“查找 Sarah 的直接或间接下属”或“谁与 John 在同一个部门工作？”的查询。 对于包含大量实体和关系的大型图形，可以快速执行复杂的分析。 多个图形数据库提供一种可用于高效遍历关系网络的查询语言。比如：关系、地图、网络拓扑、交通路线等场景。</p><h2 id="NewSql"><a href="#NewSql" class="headerlink" title="NewSql"></a>NewSql</h2><p>NewSql也是最近几年出来的概念，想必大家或多或少都有听过，NewSql是Nosql发展之后的下一代数据存储方案。</p><p>前面我们了解了Nosql的优势。</p><ul><li>高可用性和可扩展性，自动分区，轻松扩展</li><li>不保证强一致性，性能大幅提升</li><li>没有关系模型的限制，极其灵活</li></ul><p>但是有些优势在某些场景下不是很适合，比如不保证强一致性，对于普通应用来说没有问题，但是对于一些金融级的企业应用来说，</p><p>强一致的需求会比较高。另外，Nosql不支持SQL语句，不同的Nosql数据库都是有自己独立的API来进行数据操作，相对来说比较麻烦和复杂。</p><p>所以NewSql出现了，简单来说，newSQL 就是在传统关系型数据库上集成了 noSQL 强大的可扩展性，传统的SQL架构设计基因中是没有分布式的，而 newSQL 生于云时代，天生就是分布式架构。</p><p>NewSQL 的主要特性：</p><ul><li>SQL 支持，支持复杂查询和大数据分析。</li><li>支持 ACID 事务，支持隔离级别。</li><li>弹性伸缩，扩容缩容对于业务层完全透明。</li><li>高可用，自动容灾</li></ul><blockquote><p>商用NewSql</p></blockquote><ul><li><p>Spanner、F1：谷歌</p></li><li><p>OceanBase：阿里</p></li><li><p>TDSQL：腾讯</p></li><li><p>UDDB：UCloud</p></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在 NoSQL 数据库刚刚被应用时，它被认为是可以替代关系型数据库的银弹，在我看来，也许因为以下几个方面的原因：</p><ul><li>弥补了传统数据库在性能方面的不足；</li><li>数据库变更方便，不需要更改原先的数据结构；</li><li>适合互联网项目常见的大数据量的场景；</li></ul><p>不过，这种看法是个误区，因为慢慢地我们发现在业务开发的场景下还是需要利用 SQL 语句的强大的查询功能以及传统数据库事务和灵活的索引等功能，NoSQL 只能作为一些场景的补充。</p><h1 id="使用Redis优化性能问题"><a href="#使用Redis优化性能问题" class="headerlink" title="使用Redis优化性能问题"></a>使用Redis优化性能问题</h1><p>Redis是目前用得非常多的一种Key-Vlaue数据库，我们先来通过一个压测数据了解一下redis和mysql的性能差距。</p><p>演示项目： springboot-redis-example</p><p>通过jmeter工具分别压测这个项目中的两个url。</p><ul><li><a href="http://localhost:8080/city/%7Bid%7D">http://localhost:8080/city/{id}</a></li><li><a href="http://localhost:8080/city/redis/%7Bid%7D">http://localhost:8080/city/redis/{id}</a></li></ul><p>其中，基于mysql访问的接口，吞吐量数据如下，qps=4735/s。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450620.png" alt="image-20210628143407508"></p><center>图2-13</center><p>基于redis的压测数据，如图2-14所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450108.png" alt="image-20210628143634472"></p><center>图2-14</center><p>可以很明显的看到，在同样的程序中，Redis的QPS要比Mysql的多了1000。</p><h2 id="了解Redis"><a href="#了解Redis" class="headerlink" title="了解Redis"></a>了解Redis</h2><p>08年的时候有一个意大利西西里岛的小伙子，笔名antirez（<a href="http://invece.org/%EF%BC%89%EF%BC%8C%E5%88%9B%E5%BB%BA%E4%BA%86%E4%B8%80%E4%B8%AA%E8%AE%BF%E5%AE%A2%E4%BF%A1%E6%81%AF%E7%BD%91%E7%AB%99LLOOGG.COM%E3%80%82%E5%A6%82%E6%9E%9C%E6%9C%89%E8%87%AA%E5%B7%B1%E5%81%9A%E8%BF%87%E7%BD%91%E7%AB%99%E7%9A%84%E5%90%8C%E5%AD%A6%E5%BA%94%E8%AF%A5%E7%9F%A5%E9%81%93%EF%BC%8C">http://invece.org/），创建了一个访客信息网站LLOOGG.COM。如果有自己做过网站的同学应该知道，</a></p><p>有的时候我们需要知道网站的访问情况，比如访客的IP、操作系统、浏览器、使用的搜索关键词、所在地区、访问的网页地址等等。在国内，有很多网站提供了这个功能，比如CNZZ，百度统计，国外也有谷歌的Google Analytics。</p><p>也就是说，我们不用自己写代码去实现这个功能，只需要在全局的footer里面嵌入一段JS代码就行了，当页面被访问的时候，就会自动把访客的信息发送到这些网站统计的服务器，然后我们登录后台就可以查看数据了。</p><p>LLOOGG.COM提供的就是这种功能，它可以查看最多10000条的最新浏览记录。这样的话，它需要为每一个网站创建一个列表（List），不同网站的访问记录进入到不同的列表。如果列表的长度超过了用户指定的长度，它需要把最早的记录删除（先进先出）。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450677.jpg" alt="img"></p><center>图2-15</center><p>当LLOOGG.COM的用户越来越多的时候，它需要维护的列表数量也越来越多，这种记录最新的请求和删除最早的请求的操作也越来越多。LLOOGG.COM最初使用的数据库是MySQL，可想而知，因为每一次记录和删除都要读写磁盘，因为数据量和并发量太大，在这种情况下无论怎么去优化数据库都不管用了。</p><p>考虑到最终限制数据库性能的瓶颈在于磁盘，所以antirez打算放弃磁盘，自己去实现一个具有列表结构的数据库的原型，把数据放在内存而不是磁盘，这样可以大大地提升列表的push和pop的效率。antirez发现这种思路确实能解决这个问题，所以用C语言重写了这个内存数据库，并且加上了持久化的功能，09年，Redis横空出世了。从最开始只支持列表的数据库，到现在支持多种数据类型，并且提供了一系列的高级特性，Redis已经成为一个在全世界被广泛使用的开源项目。</p><p>为什么叫REDIS呢？它的全称是Remote Dictionary Service，直接翻译过来是远程字典服务。</p><h2 id="key-value数据库使用排名"><a href="#key-value数据库使用排名" class="headerlink" title="key-value数据库使用排名"></a>key-value数据库使用排名</h2><p>对于Redis，我们大部分时候的认识是一个缓存的组件，当然从它的发展历史我们也可以看到，它最开始并不是作为缓存使用的。只是在很多的互联网应用里面，它作为缓存发挥了最大的作用。所以下面我们来聊一下，Redis的主要特性有哪些，我们为什么要使用它作为数据库的缓存。 </p><p>大家对于缓存应该不陌生，比如我们有硬件层面的CPU的缓存，浏览器的缓存，手机的应用也有缓存。我们把数据缓存起来的原因就是从原始位置取数据的代价太大了，放在一个临时存储起来，取回就可以快一些。</p><p>如果要了解Redis的特性，我们必须回答几个问题：</p><p><strong>1、为什么要把数据放在内存中？</strong></p><ol><li><p>内存的速度更快，10w QPS</p></li><li><p>减少计算的时间</p></li></ol><p><strong>2、如果是用内存的数据结构作为缓存，为什么不用HashMap或者Memcache？</strong></p><ol><li><p>更丰富的数据类型</p></li><li><p>进程内与跨进程；单机与分布式</p></li><li><p>功能丰富：持久化机制、过期策略</p></li><li><p>支持多种编程语言</p></li><li><p>高可用，集群</p></li></ol><blockquote><p><a href="https://db-engines.com/en/ranking/key-value+store">https://db-engines.com/en/ranking/key-value+store</a></p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450702.png" alt="image-20210626202902337"></p><center>图2-16</center>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
            <tag> 高性能 </tag>
            
            <tag> 并发 </tag>
            
            <tag> 数据库优化 </tag>
            
            <tag> 性能调优 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>工作3年的Java程序员，轻松拿到阿里P6Offer，只因为他搞明白了Redis这几个问题！！</title>
      <link href="/posts/2781994300/"/>
      <url>/posts/2781994300/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis中的多路复用模型"><a href="#Redis中的多路复用模型" class="headerlink" title="Redis中的多路复用模型"></a>Redis中的多路复用模型</h1><p>Redis6用到了多线程？那多线程应用在哪些地方，引入多线程后，又改如何保证线程安全性呢？<br>同时，如何在性能和线程安全性方面做好平衡？</p><h2 id="关于Redis的单线程模型"><a href="#关于Redis的单线程模型" class="headerlink" title="关于Redis的单线程模型"></a>关于Redis的单线程模型</h2><p>在Redis6.0之前，我们一直说Redis是单线程，所以并不会存在线程安全问题，而这个单线程，实际上就是在做数据IO处理中，是用的主线程来串行执行，如图4-7所示。</p><p>Redis基于Reactor模式设计开发了自己的一套高效事件处理模型，这个事件处理模型对应的就是Redis中的文件事件处理器，这个文件事件处理器是单线程运行的，这也是为什么我们一直强调Redis是线程安全的。</p><p>既然Redis是基于Reactor模型实现，那它必然用了I/O多路复用机制来监听多个客户端连接，然后把感兴趣的事件（READ/ACCEPT/CLOSE/WRITE）注册到多路复用器中。</p><p>文件事件处理器中使用I/O多路复用模型同时监听多个客户端连接，并且根据当前连接执行的任务类型关联不同的事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）来处理这些事件。</p><p>这样设计的好处：</p><ul><li>文件事件处理器实现了高性能的网络IO通信模型</li><li>通过单线程的方式执行指令，避免同步机制的性能开销、避免过多的上下文切换、整体实现比较简单，不需要考虑多线程场景中的各种数据结构的线程安全问题。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354544.png" alt="image-20210708232804607"></p><center>图4-7</center><p>其实严格意义上来说，在Redis4.x版本就支持了多线程，只是，<strong>负责客户端请求的IO处理使用的是单线程</strong>。但是针对那些非常耗时的命令，Redis4.x提供了异步化的指令来处理，避免因为IO时间过长影响到客户端请求IO处理的线程。比如在 Redis v4.0 之后增加了一些的非阻塞命令如 <code>UNLINK</code>（del命令的异步版本）、<code>FLUSHALL ASYNC</code>、<code>FLUSHDB ASYNC</code>。</p><h2 id="Redis6-0之后的多线程？"><a href="#Redis6-0之后的多线程？" class="headerlink" title="Redis6.0之后的多线程？"></a>Redis6.0之后的多线程？</h2><p>在Redis6.0中引入了多线程，可能很多同学会误以为redis原本的单线程数据IO变成了多线程IO，那作者不就是在打自己的脸吗？</p><blockquote><p>对于Redis来说，CPU通常不是瓶颈，因为大多数请求不是属于CPU密集型，而是I/O密集型。而在Redis中除了数据的持久化方案之外，它是完全的纯内存操作，因此执行速度是非常快的，所以数据的IO并不是Redis的性能瓶颈，Redis真正的性能瓶颈是在网络I/O，也就是客户端和服务端之间的网络传输延迟，所以Redis选择了单线程的IO多路复用来实现它的核心网络模型。</p></blockquote><p>前面我们说过，单线程设计对于Redis来说有很多好处。</p><ul><li>避免过多的上上下文切换开销</li><li>避免同步机制的开销，涉及到数据同步和事务操作时，避免多线程影响所以必然需要加同步机制保证线程安全性。但是加锁同时也会影响到程序的执行性能。 </li><li>维护简单，引入多线程之后，不管是对数据结构的设计，还是在程序代码的维护上，都会变得很复杂。</li></ul><p>所以既然Redis的数据I/O不是瓶颈，同时单线程又有这么多好处，那Redis自然就采用单线程了。既然是这样，那么Redis 6.0引入多线程，一定不是优化数据IO性能，那么我们先来分析一下Redis性能瓶颈主要体现在哪些方面，无非就是三个方面。</p><ul><li>网络IO</li><li>CPU核心数</li><li>内存</li></ul><p>由于CPU核心数并不是redis的瓶颈，所以影响Redis性能的因素只有网络IO和内存，而内存属于硬件范畴，比如采用容量更大、吞吐量更高的内存进行优化就行，因此也不是属于Redis可优化的空间，所以最终我们发现Redis的性能瓶颈还是在网络IO上。</p><p>而在Redis6.0之前，使用的是单线程Reactor模型，单线程模型是指对于客户端的请求，主线程需要负责对这个请求的完整IO过程进行处理，如图4-8所示，从socket中读取数据和往socket中写数据都是比较耗时的网络IO操作，解析请求和内存交互耗时可能远小于这个网络IO操作。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354708.png" alt="image-20210710153215329"></p><center>图4-8</center><p>按照前面我们对多Reactor多线程的理解，那我们能不能改成主从多Reactor多线程模型呢？主Reactor负责接收客户端连接，然后分发给多个Reactor进行网络IO操作。很显然，这样做就会导致Redis编程了一个多线程模型，这对Redis的影响较大，因为多线程带来的线程安全问题和底层复杂的数据结构的操作都非常棘手，所以Redis 6.0并没有这么做。</p><p>Redis 6.0中将处理过程中最耗时的Socket读取、请求解析、单独用一个线程来处理，剩下的命令执行操作仍然由单线程来完成和内存的数据交互，这样一来，网络IO操作就变成了多线程了，但是核心部分仍然是线程安全的，如图4-9所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354391.png" alt="image-20210710154600353"></p><center>图4-9</center><p>为什么说Redis6.0是一个特殊的多线程，原因就在这里，Redis主要针对网络IO这块引入了多线程的方式来提升了网络IO性能，但是真正执行命令的操作仍然是由主线程来完成。因此，总的来说，我们仍然可以说Redis是单线程模型。</p><h2 id="Redis-6-0如何开启多线程"><a href="#Redis-6-0如何开启多线程" class="headerlink" title="Redis 6.0如何开启多线程"></a>Redis 6.0如何开启多线程</h2><p>Redis 6.0默认多线程是禁止的，也就是仍然只是使用主线程来完成网络IO，如果需要开启，则修改redis.conf配置文件中的如下属性</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 默认是关闭，设置为yes打开</span></span><br><span class="line"><span class="meta">io-threads-do-reads</span> <span class="string">no</span></span><br><span class="line"><span class="comment">#默认线程数量是4，官方建议是4核机器上设置为2~3个，8核机器上设置6个</span></span><br><span class="line"><span class="meta">io-threads</span> <span class="string">4</span></span><br></pre></td></tr></table></figure><h2 id="引入多线程之后的性能提升"><a href="#引入多线程之后的性能提升" class="headerlink" title="引入多线程之后的性能提升"></a>引入多线程之后的性能提升</h2><p>图4-20是美团技术团队使用阿里云服务器压测GET/SET命令在4个线程IO时性能上的对比结果，可以明显的看到，Redis 在使用多线程模式之后性能大幅提升，达到了一倍。</p><ul><li>Redis Server 阿里云 Ubuntu 18.04  ，  8CPU 2.5GHZ，8G内存，主机型号： ecs.ic5.2xlarge</li><li>Redis Benchmark client: 阿里云 Unbuntu 18.04 , 8CPU  2.5GHZ，8G内存，主机型号：ecs.ic5.2xlarge</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354177.png" alt="preview"></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354660.png" alt="preview"></p><center>图4-20</center><h1 id="内存回收策略"><a href="#内存回收策略" class="headerlink" title="内存回收策略"></a>内存回收策略</h1><p>很多同学了解了Redis的好处之后，于是把任何数据都往Redis中放，如果使用不合理很容易导致数据超过Redis的内存，这种情况会出现什么问题呢？</p><ul><li>Redis中有很多无效的缓存，这些缓存数据会降低数据IO的性能，因为不同的数据类型时间复杂度算法不同，数据越多可能会造成性能下降</li><li>随着系统的运行，redis的数据越来越多，会导致物理内存不足。通过使用虚拟内存（VM），将很少访问的数据交换到磁盘上，腾出内存空间的方法来解决物理内存不足的情况。虽然能够解决物理内存不足导致的问题，但是由于这部分数据是存储在磁盘上，如果在高并发场景中，频繁访问虚拟内存空间会严重降低系统性能。</li></ul><p>所以遇到这类问题的时候，我们一般有几种方法。</p><ul><li>对每个存储到redis中的key设置过期时间，这个根据实际业务场景来决定。否则，再大的内存都会虽则系统运行被消耗完。</li><li>增加内存</li><li>使用内存淘汰策略。</li></ul><h2 id="设置Redis能够使用的最大内存"><a href="#设置Redis能够使用的最大内存" class="headerlink" title="设置Redis能够使用的最大内存"></a>设置Redis能够使用的最大内存</h2><p>在实际生产环境中，服务器不仅仅只有Redis，为了避免Redis内存使用过多对其他程序造成影响，我们一般会设置最大内存。</p><p>Redis默认的最大内存<code>maxmemory=0</code>，表示不限制Redis内存的使用。我们可以修改<code>redis.conf</code>文件，设置Redis最大使用的内存。</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 单位为byte</span></span><br><span class="line"><span class="attr">maxmemory</span> <span class="string">&lt;bytes&gt;  2147483648（2G）</span></span><br></pre></td></tr></table></figure><p>如何查看当前Redis最大内存设置呢，进入到Redis-Cli控制台，输入下面这个命令。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">config get maxmemory</span><br></pre></td></tr></table></figure><p>当Redis中存储的内存超过maxmemory时，会怎么样呢？下面我们做一个实验</p><ul><li><p>在redis-cli控制台输入下面这个命令，把最大内存设置为1个字节。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">config set maxmemory 1</span><br></pre></td></tr></table></figure></li><li><p>通过下面的命令存储一个string类型的数据</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set name mic</span><br></pre></td></tr></table></figure></li><li><p>此时，控制台会得到下面这个错误信息</p></li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(error) OOM command not allowed when used memory &gt; &#x27;maxmemory&#x27;.</span><br></pre></td></tr></table></figure><h2 id="使用内存淘汰策略释放内存"><a href="#使用内存淘汰策略释放内存" class="headerlink" title="使用内存淘汰策略释放内存"></a>使用内存淘汰策略释放内存</h2><p>设置了maxmemory的选项，redis内存使用达到上限。可以通过设置LRU算法来删除部分key，释放空间。默认是按照过期时间的，如果set时候没有加上过期时间就会导致数据写满maxmemory。</p><p>Redis中提供了一种内存淘汰策略，当内存不足时，Redis会根据相应的淘汰规则对key数据进行淘汰。 Redis一共提供了8种淘汰策略，默认的策略为<strong>noeviction</strong>，当内存使用达到阈值的时候，</p><p>所有引起申请内存的命令会报错。</p><ul><li><strong>volatile-lru</strong>，针对设置了过期时间的key，使用lru算法进行淘汰。</li><li><strong>allkeys-lru</strong>，针对所有key使用lru算法进行淘汰。</li><li><strong>volatile-lfu</strong>，针对设置了过期时间的key，使用lfu算法进行淘汰。</li><li><strong>allkeys-lfu</strong>，针对所有key使用lfu算法进行淘汰。</li><li><strong>volatile-random</strong>，从所有设置了过期时间的key中使用随机淘汰的方式进行淘汰。</li><li><strong>allkeys-random</strong>，针对所有的key使用随机淘汰机制进行淘汰。</li><li><strong>volatile-ttl</strong>，删除生存时间最近的一个键。</li><li><strong>noeviction</strong>，不删除键，值返回错误。</li></ul><p>前缀为volatile-和allkeys-的区别在于二者选择要清除的键时的字典不同，volatile-前缀的策略代表从redisDb中的expire字典中选择键进行清除；allkeys-开头的策略代表从dict字典中选择键进行清除。</p><p>内存淘汰算法的具体工作原理是：</p><ul><li>客户端执行一条新命令，导致数据库需要增加数据（比如set key value）</li><li>Redis会检查内存使用，如果内存使用超过 maxmemory，就会按照置换策略删除一些 key</li><li>新的命令执行成功</li></ul><h3 id="了解并手写LRU算法"><a href="#了解并手写LRU算法" class="headerlink" title="了解并手写LRU算法"></a>了解并手写LRU算法</h3><p>LRU是Least Recently Used的缩写，也就是表示最近很少使用，也可以理解成最久没有使用。也就是说当内存不够的时候，每次添加一条数据，都需要抛弃一条最久时间没有使用的旧数据。</p><p>标准的LRU算法为了降低查找和删除元素的时间复杂度，一般采用Hash表和双向链表结合的数据结构，hash表可以赋予链表快速查找到某个key是否存在链表中，同时可以快速删除、添加节点，如图4-21所示。</p><blockquote><p>双向链表的查找时间复杂度是O(n)，删除和插入是O(1)，借助HashMap结构，可以使得查找的时间复杂度变成O(1)</p></blockquote><p>Hash表用来查询在链表中的数据位置，链表负责数据的插入，当新数据插入到链表头部时有两种情况。</p><ul><li>链表满了，把链表尾部的数据丢弃掉，新加入的缓存直接加入到链表头中。</li><li>当链表中的某个缓存被命中时，直接把数据移到链表头部，原本在头节点的缓存就向链表尾部移动</li></ul><p>这样，经过多次Cache操作之后，最近被命中的缓存，都会存在链表头部的方向，没有命中的，都会在链表尾部方向，当需要替换内容时，由于链表尾部是最少被命中的，我们只需要淘汰链表尾部的数据即可。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354493.png" alt="image-20210710205446429"></p><center>图4-21</center><p>下面我们通过一段代码实现一个简单的LRU算法，加深大家对于LRU算法的理解。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Node head;</span><br><span class="line">    <span class="keyword">private</span> Node tail;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> HashMap&lt;String,Node&gt; nodeHashMap;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> capacity;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LRUCache</span><span class="params">(<span class="keyword">int</span> capacity)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.capacity=capacity;</span><br><span class="line">        nodeHashMap=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        head=<span class="keyword">new</span> Node();</span><br><span class="line">        tail=<span class="keyword">new</span> Node();</span><br><span class="line">        head.next=tail;</span><br><span class="line">        tail.prev=head;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">removeNode</span><span class="params">(Node node)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(node==tail)&#123;</span><br><span class="line">            tail=tail.prev;</span><br><span class="line">            tail.next=<span class="keyword">null</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(node==head)&#123;</span><br><span class="line">            head=head.next;</span><br><span class="line">            head.prev=<span class="keyword">null</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            node.prev.next=node.next;</span><br><span class="line">            node.next.prev=node.prev;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addNodeToHead</span><span class="params">(Node node)</span></span>&#123;</span><br><span class="line">        node.next=head.next;</span><br><span class="line">        head.next.prev=node;</span><br><span class="line">        node.prev=head;</span><br><span class="line">        head.next=node;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addNodeToTail</span><span class="params">(Node node)</span></span>&#123;</span><br><span class="line">        node.prev=tail.prev;</span><br><span class="line">        node.prev.next=node;</span><br><span class="line">        node.next=tail;</span><br><span class="line">        tail.prev=node;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//当链表中的某个缓存被命中时，直接把数据移到链表头部，原本在头节点的缓存就向链表尾部移动</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">moveNodeToHead</span><span class="params">(Node node)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        removeNode(node);</span><br><span class="line">        addNodeToHead(node);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">get</span><span class="params">(String key)</span></span>&#123;</span><br><span class="line">        Node node=nodeHashMap.get(key);</span><br><span class="line">        <span class="keyword">if</span>(node==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//刷新当前节点的位置</span></span><br><span class="line">        moveNodeToHead(node);</span><br><span class="line">        <span class="comment">//返回value值</span></span><br><span class="line">        <span class="keyword">return</span> node.value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(String key,String value)</span></span>&#123;</span><br><span class="line">        Node node=nodeHashMap.get(key);</span><br><span class="line">        <span class="keyword">if</span>(node==<span class="keyword">null</span>)&#123; <span class="comment">//不存在</span></span><br><span class="line">            <span class="comment">//如果当前存储的数据量达到了阈值，则需要淘汰掉访问较少的数据</span></span><br><span class="line">            <span class="keyword">if</span>(nodeHashMap.size()&gt;=capacity)&#123;</span><br><span class="line">                removeNode(tail); <span class="comment">//移除尾部节点</span></span><br><span class="line">                nodeHashMap.remove(tail.key);</span><br><span class="line">            &#125;</span><br><span class="line">            node=<span class="keyword">new</span> Node(key,value);</span><br><span class="line">            nodeHashMap.put(key,node);</span><br><span class="line">            addNodeToTail(node);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            node.value=value;</span><br><span class="line">            <span class="comment">//刷新当前节点的位置</span></span><br><span class="line">            moveNodeToHead(node);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        LRUCache lruCache=<span class="keyword">new</span> LRUCache(<span class="number">3</span>);</span><br><span class="line">        lruCache.put(<span class="string">&quot;1&quot;</span>,<span class="string">&quot;1&quot;</span>);</span><br><span class="line">        lruCache.put(<span class="string">&quot;2&quot;</span>,<span class="string">&quot;2&quot;</span>);</span><br><span class="line">        lruCache.put(<span class="string">&quot;3&quot;</span>,<span class="string">&quot;3&quot;</span>);</span><br><span class="line"><span class="comment">//        lruCache.get(&quot;3&quot;); // 增加一个访问次数之后，被清理的元素就会发生变化</span></span><br><span class="line">        System.out.println(lruCache.nodeHashMap);</span><br><span class="line">        lruCache.put(<span class="string">&quot;4&quot;</span>,<span class="string">&quot;4&quot;</span>);</span><br><span class="line">        System.out.println(lruCache.nodeHashMap);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span></span>&#123;</span><br><span class="line">    <span class="comment">//双向链表中的节点类，存储key是因为我们在双向链表删除表尾的值时，只是返回了一个节点，</span></span><br><span class="line">    <span class="comment">//所以这个节点要包括key值，这样我们的哈希表才可以删除对应key值的映射</span></span><br><span class="line">    <span class="keyword">public</span> String key;</span><br><span class="line">    <span class="keyword">public</span> String value;</span><br><span class="line">    Node prev;</span><br><span class="line">    Node next;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Node</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Node</span><span class="params">(String key, String value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        <span class="keyword">this</span>.value = value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Redis中的LRU算法"><a href="#Redis中的LRU算法" class="headerlink" title="Redis中的LRU算法"></a>Redis中的LRU算法</h3><p>实际上，Redis使用的LRU算法其实是一种不可靠的LRU算法，它实际淘汰的键并不一定是真正最少使用的数据，它的工作机制是：</p><ul><li>随机采集淘汰的key，每次随机选出5个key</li><li>然后淘汰这5个key中最少使用的key</li></ul><p>这5个key是默认的个数，具体的数值可以在redis.conf中配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">maxmemory-samples 5</span><br></pre></td></tr></table></figure><p>当近似LRU算法取值越大的时候就会越接近真实的LRU算法，因为取值越大获取的数据越完整，淘汰中的数据就更加接近最少使用的数据。这里其实涉及一个权衡问题，</p><p>如果需要在所有的数据中搜索最符合条件的数据，那么一定会增加系统的开销，Redis是单线程的，所以耗时的操作会谨慎一些。</p><p>为了在一定成本内实现相对的LRU，早期的Redis版本是基于采样的LRU，也就是放弃了从所有数据中搜索解改为采样空间搜索最优解。Redis3.0版本之后，Redis作者对于基于采样的LRU进行了一些优化：</p><ul><li>Redis中维护一个大小为16的候选池，当第一次随机选取采用数据时，会把数据放入到候选池中，并且候选池中的数据会更具时间进行排序。</li><li>当第二次以后选取数据时，只有小于候选池内最小时间的才会被放进候选池。</li><li>当候选池的数据满了之后，那么时间最大的key就会被挤出候选池。当执行淘汰时，直接从候选池中选取最近访问时间小的key进行淘汰。</li></ul><p>如图4-22所示，首先从目标字典中采集出maxmemory-samples个键，缓存在一个samples数组中，然后从samples数组中一个个取出来，和回收池中以后的键进行键的空闲时间，从而更新回收池。</p><p>在更新过程中，首先利用遍历找到的每个键的实际插入位置x，然后根据不同情况进行处理。</p><ul><li>回收池满了，并且当前插入的key的空闲时间最小（也就是回收池中的所有key都比当前插入的key的空闲时间都要大），则不作任何操作。</li><li>回收池未满，并且插入的位置x没有键，则直接插入即可</li><li>回收池未满，且插入的位置x原本已经存在要淘汰的键，则把第x个以后的元素都往后挪一个位置，然后再执行插入操作。</li><li>回收池满了，将当前第x个以前的元素往前挪一个位置（实际就是淘汰了），然后执行插入操作。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354542.png" alt="image-20210710203108453"></p><center>图4-22</center><p>这样做的目的是能够选出最真实的最少被访问的key，能够正确不常使用的key。因为在Redis3.0之前是随机选取样本，这样的方式很有可能不是真正意义上的最少访问的key。</p><p>LRU算法有一个弊端，加入一个key值访问频率很低，但是最近一次被访问到了，那LRU会认为它是热点数据，不会被淘汰。同样，</p><p>经常被访问的数据，最近一段时间没有被访问，这样会导致这些数据被淘汰掉，导致误判而淘汰掉热点数据，于是在Redis 4.0中，新加了一种LFU算法。</p><h3 id="LFU算法"><a href="#LFU算法" class="headerlink" title="LFU算法"></a>LFU算法</h3><p>LFU（Least Frequently Used），表示最近最少使用，它和key的使用次数有关，其思想是：根据key最近被访问的频率进行淘汰，比较少访问的key优先淘汰，反之则保留。</p><p>LRU的原理是使用计数器来对key进行排序，每次key被访问时，计数器会增大，当计数器越大，意味着当前key的访问越频繁，也就是意味着它是热点数据。 它很好的解决了LRU算法的缺陷：<strong>一个很久没有被访问的key，偶尔被访问一次，导致被误认为是热点数据的问题。</strong></p><p>LFU的实现原理如图4-23所示，LFU维护了两个链表，横向组成的链表用来存储访问频率，每个访问频率的节点下存储另外一个具有相同访问频率的缓存数据。具体的工作原理是：</p><ul><li>当添加元素时，找到相同访问频次的节点，然后添加到该节点的数据链表的头部。如果该数据链表满了，则移除链表尾部的节点</li><li>当获取元素或者修改元素是，都会增加对应key的访问频次，并把当前节点移动到下一个频次节点。</li></ul><blockquote><p>添加元素时，访问频率默认为1，随着访问次数的增加，频率不断递增。而当前被访问的元素也会随着频率增加进行移动。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354188.png" alt="image-20210710213258901"></p><center>图4-23</center><h1 id="持久化机制的实现及原理"><a href="#持久化机制的实现及原理" class="headerlink" title="持久化机制的实现及原理"></a>持久化机制的实现及原理</h1><p>Redis的强劲性能很大程度上是由于它所有的数据都存储在内存中，当然如果redis重启或者服务器故障导致redis重启，所有存储在内存中的数据就会丢失。但是在某些情况下，我们希望Redis在重启后能够保证数据不会丢失。</p><ol><li><p>将redis作为nosql数据库使用。</p></li><li><p>将Redis作为高效缓存服务器，缓存被击穿后对后端数据库层面的瞬时压力是特别大的，所有缓存同时失效可能会导致雪崩。</p></li></ol><p>这时我们希望Redis能将数据从内存中以某种形式同步到硬盘上，使得重启后可以根据硬盘中的记录来恢复数据。</p><p>Redis支持两种方式的持久化，一种是RDB方式、另一种是AOF（append-only-file）方式，两种持久化方式可以单独使用其中一种，也可以将这两种方式结合使用。</p><ul><li><strong>RDB</strong>：根据指定的规则“<strong>定时</strong>”将内存中的数据存储在硬盘上，</li><li><strong>AOF</strong>：每次执行命令后将命令本身记录下来。</li></ul><h3 id="4-3-1-RDB模式"><a href="#4-3-1-RDB模式" class="headerlink" title="4.3.1 RDB模式"></a>4.3.1 RDB模式</h3><p>RDB的持久化方式是通过快照（snapshotting）完成的，它是Redis默认的持久化方式，配置如下。</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># save 3600 1</span></span><br><span class="line"><span class="comment"># save 300 100</span></span><br><span class="line"><span class="comment"># save 60 10000</span></span><br></pre></td></tr></table></figure><p>Redis允许用户自定义快照条件，当符合快照条件时，Redis会自动执行快照操作。快照的条件可以由用户在配置文件中配置。配置格式如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">save &lt;seconds&gt; &lt;changes&gt;</span><br></pre></td></tr></table></figure><p>第一个参数是时间窗口，第二个是键的个数，也就是说，在第一个时间参数配置范围内被更改的键的个数大于后面的changes时，即符合快照条件。当触发条件时，Redis会自动将内存中的数据生成一份副本并存储在磁盘上，这个过程称之为“快照”，除了上述规则之外，还有以下几种方式生成快照。</p><ol><li>根据配置规则进行自动快照</li><li>用户执行SAVE或者GBSAVE命令</li><li>执行FLUSHALL命令</li><li>执行复制(replication)时</li></ol><h3 id="根据配置规则进行自动快照"><a href="#根据配置规则进行自动快照" class="headerlink" title="根据配置规则进行自动快照"></a>根据配置规则进行自动快照</h3><ul><li>修改redis.conf文件，表示5秒内，有一个key发生变化，就会生成rdb文件。</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">save 5 1                # 表示3600s以内至少发生1个key变化（新增、修改、删除），则重写rdb文件</span><br><span class="line">save 300 100</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure><ul><li><p>修改文件存储路径</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dir /data/program/redis/bin</span><br></pre></td></tr></table></figure></li><li><p>其他参数配置说明</p><table><thead><tr><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>dir</td><td>rdb文件默认在启动目录下（相对路径） <code>config get dir</code> 获取</td></tr><tr><td>dbfilename</td><td>文件名称</td></tr><tr><td>rdbcompression</td><td>开启压缩可以节省存储空间，但是会消耗一些CPU的计算时间，默认开启</td></tr><tr><td>rdbchecksum</td><td>使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。</td></tr></tbody></table></li></ul><p><strong>如果需要关闭RDB的持久化机制，可以参考如下配置，开启<code>save</code>，并注释其他规则即可</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">save &quot;&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash">save 900 1</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 300 10</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 60 10000</span></span><br></pre></td></tr></table></figure><h3 id="用户执行SAVE或者GBSAVE命令"><a href="#用户执行SAVE或者GBSAVE命令" class="headerlink" title="用户执行SAVE或者GBSAVE命令"></a>用户执行SAVE或者GBSAVE命令</h3><p>除了让Redis自动进行快照以外，当我们对服务进行重启或者服务器迁移我们需要人工去干预备份。redis提供了两条命令来完成这个任务</p><ol><li><p><strong>save命令</strong></p><p>如图4-24所示，当执行save命令时，Redis同步做快照操作，在快照执行过程中会阻塞所有来自客户端的请求。当redis内存中的数据较多时，通过该命令将导致Redis较长时间的不响应。所以不建议在生产环境上使用这个命令，而是推荐使用bgsave命令</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151355068.png" alt="image-20210712184050955"></p><center>图4-24</center></li><li><p><strong>bgsave命令</strong></p><p>如图4-25所示，bgsave命令可以在后台异步地进行快照操作，快照的同时服务器还可以继续响应来自客户端的请求。执行BGSAVE后，Redis会立即返回ok表示开始执行快照操作，在redis-cli终端，通过下面这个命令可以获取最近一次成功执行快照的时间（以 UNIX 时间戳格式表示）。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">LASTSAVE</span><br></pre></td></tr></table></figure></li></ol><p>1：redis使用fork函数复制一份当前进程的副本(子进程)</p><p>2：父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件</p><p>3：当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此，一次快照操作完成。 </p><blockquote><p>注意：redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。 这就使得我们可以通过定时备份RDB文件来实现redis数据库的备份， RDB文件是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。</p><p><strong>bgsave是异步执行快照的，bgsave写入的数据就是for进程时redis的数据状态，一旦完成fork，后续执行的新的客户端命令对数据产生的变更都不会反应到本次快照</strong></p></blockquote><p>Redis启动后会读取RDB快照文件，并将数据从硬盘载入到内存。根据数据量大小以及服务器性能不同，这个载入的时间也不同。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151355770.png" alt="image-20210712183559812"></p><center>图4-25</center><h3 id="执行FLUSHALL命令"><a href="#执行FLUSHALL命令" class="headerlink" title="执行FLUSHALL命令"></a>执行FLUSHALL命令</h3><p>该命令在前面讲过，会清除redis在内存中的所有数据。执行该命令后，只要redis中配置的快照规则不为空，也就是save 的规则存在。redis就会执行一次快照操作。不管规则是什么样的都会执行。如果没有定义快照规则，就不会执行快照操作。</p><h3 id="执行复制-replication-时"><a href="#执行复制-replication-时" class="headerlink" title="执行复制(replication)时"></a>执行复制(replication)时</h3><p>该操作主要是在主从模式下，redis会在复制初始化时进行自动快照。这个会在后面讲到；</p><p>这里只需要了解当执行复制操作时，即时没有定义自动快照规则，并且没有手动执行过快照操作，它仍然会生成RDB快照文件。</p><h3 id="RDB数据恢复演示"><a href="#RDB数据恢复演示" class="headerlink" title="RDB数据恢复演示"></a>RDB数据恢复演示</h3><ul><li>准备初始数据</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k1 1</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k2 2</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k3 3</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k4 4</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k5 5</span></span><br></pre></td></tr></table></figure><ul><li><p>通过shutdown命令关闭触发save</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> shutdown</span></span><br></pre></td></tr></table></figure></li><li><p>备份dump.rdb文件(用来后续恢复)</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp dump.rdb dump.rdb.bak</span><br></pre></td></tr></table></figure></li><li><p>接着再启动redis-server(systemctl restart redis_6379)，通过keys命令查看，发现数据还在</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">keys *</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>模拟数据丢失</p></blockquote><ul><li><p>执行flushall</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> flushall</span></span><br></pre></td></tr></table></figure></li><li><p>shutdown(重新生成没有数据的快照，用来模拟后续的数据恢复)</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> shutdown</span></span><br></pre></td></tr></table></figure></li><li><p>再次启动redis, 通过keys 命令查看，此时rdb中没有任何数据。</p></li><li><p>恢复之前备份的rdb文件（之前保存了数据的rdb快照）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv dump.rdb.bak dump.rdb</span><br></pre></td></tr></table></figure></li><li><p>再次重启redis，可以看到之前快照保存的数据</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">keys *</span><br></pre></td></tr></table></figure></li></ul><h3 id="RDB文件的优势和劣势"><a href="#RDB文件的优势和劣势" class="headerlink" title="RDB文件的优势和劣势"></a>RDB文件的优势和劣势</h3><p><strong>一、优势</strong></p><p>　　1.RDB是一个非常紧凑(compact)的文件，它保存了redis 在某个时间点上的数据集，这种文件非常适合用于进行备份和灾难恢复。</p><p>　　2.生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。</p><p>　　3.RDB 在恢复大数据集时的速度比AOF的恢复速度要快。</p><p><strong>二、劣势</strong></p><ul><li><p>1、RDB方式数据没办法做到实时持久化/秒级持久化。因为bgsave每次运行都要执行fork操作创建子进程，频繁执行成本过高</p></li><li><p>2、在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照之后的所有修改（数据有丢失）。</p></li></ul><p><strong>如果数据相对来说比较重要，希望将损失降到最小，则可以使用AOF方式进行持久化。</strong></p><h3 id="4-3-2-AOF模式"><a href="#4-3-2-AOF模式" class="headerlink" title="4.3.2 AOF模式"></a>4.3.2 AOF模式</h3><p>AOF(Append Only File)：Redis 默认不开启。AOF采用日志的形式来记录每个写操作，并<strong>追加</strong>到文件中。开启后，执行更改Redis数据的命令时，就会把命令写入到AOF文件中。</p><p>Redis 重启时会根据日志文件的内容把写指令从前到后执行一次以完成数据的恢复工作。</p><h3 id="AOF配置开关"><a href="#AOF配置开关" class="headerlink" title="AOF配置开关"></a>AOF配置开关</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 开关</span></span><br><span class="line">appendonly no  /yes</span><br><span class="line"><span class="meta">#</span><span class="bash"> 文件名</span></span><br><span class="line">appendfilename &quot;appendonly.aof&quot;</span><br></pre></td></tr></table></figure><p>通过修改redis.conf重启redis之后：systemctl restart redis_6379。</p><p>再次运行redis的相关操作命令，会发现在指定的<code>dir</code>目录下生成appendonly.aof文件，通过vim查看该文件内容如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">*2</span><br><span class="line"><span class="meta">$</span><span class="bash">6</span></span><br><span class="line">SELECT</span><br><span class="line"><span class="meta">$</span><span class="bash">1</span></span><br><span class="line">0</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">name</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">mic</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">name</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">123</span><br></pre></td></tr></table></figure><h3 id="AOF配置相关问题解答"><a href="#AOF配置相关问题解答" class="headerlink" title="AOF配置相关问题解答"></a>AOF配置相关问题解答</h3><p><strong>问题1：数据都是实时持久化到磁盘吗？</strong></p><p>虽然每次执行更改Redis数据库内容的操作时，AOF都会将命令记录在AOF文件中，但是事实上，由于操作系统的缓存机制，数据并没有真正地写入硬盘，而是进入了系统的硬盘缓存。在默认情况下系统每30秒会执行一次同步操作。以便将硬盘缓存中的内容真正地写入硬盘。</p><p>在这30秒的过程中如果系统异常退出则会导致硬盘缓存中的数据丢失。一般来说能够启用AOF的前提是业务场景不能容忍这样的数据损失，这个时候就需要Redis在写入AOF文件后主动要求系统将缓存内容同步到硬盘中。在redis.conf中通过如下配置来设置同步机制。</p><table><thead><tr><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>appendfsync everysec</td><td>AOF持久化策略（硬盘缓存到磁盘），默认<strong>everysec</strong> <br /> 1 no  表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快，但是不太安全；  <br /> 2 always  表示每次写入都执行fsync，以保证数据同步到磁盘，效率很低；<br /> 3 everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。通常选择 everysec ，兼顾安全性和效率。</td></tr></tbody></table><p><strong>问题2：文件越来越大，怎么办？</strong></p><p>由于AOF持久化是Redis不断将写命令记录到 AOF 文件中，随着Redis不断的运行，AOF 的文件会越来越大，文件越大，占用服务器内存越大以及 AOF 恢复要求时间越长。</p><p><strong>例如set gupao 666，执行1000次，结果都是gupao=666。</strong></p><p>为了解决这个问题，Redis新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。</p><p>可以使用命令下面这个命令主动触发重写</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> bgrewriteaof</span></span><br></pre></td></tr></table></figure><p>AOF 文件重写并不是对原文件进行重新整理，而是直接读取服务器现有的键值对，然后用一条命令去代替之前记录这个键值对的多条命令，生成一个新的文件后去替换原来的 AOF 文件。</p><p><strong>重写触发机制如下</strong></p><table><thead><tr><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>auto-aof-rewrite-percentage</td><td>默认值为100。表示的是当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时AOF文件大小为依据</td></tr><tr><td>auto-aof-rewrite-min-size</td><td>默认64M。表示限制了允许重写的最小AOF文件大小，通常在AOF文件很小的情况下即使其中有很多冗余的命令我们也并不太关心</td></tr></tbody></table><p>在启动时，Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相对于RDB会慢一些</p><p><strong>问题：重写过程中，AOF文件被更改了怎么办？</strong></p><p>Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 </p><p>重写的流程是这样，</p><ul><li>主进程会fork一个子进程出来进行AOF重写，这个重写过程并不是基于原有的aof文件来做的，而是有点类似于快照的方式，全量遍历内存中的数据，然后逐个序列到aof文件中。</li><li>在fork子进程这个过程中，服务端仍然可以对外提供服务，<strong>那这个时候重写的aof文件的数据和redis内存数据不一致了怎么办？</strong>不用担心，这个过程中，主进程的数据更新操作，会缓存到<strong>aof_rewrite_buf</strong>中，也就是单独开辟一块缓存来存储重写期间收到的命令，当子进程重写完以后再把缓存中的数据追加到新的aof文件。</li><li>当所有的数据全部追加到新的aof文件中后，把新的aof文件重命名正式的文件名字，此后所有的操作都会被写入新的aof文件。</li><li>如果在rewrite过程中出现故障，不会影响原来aof文件的正常工作，只有当rewrite完成后才会切换文件。因此这个rewrite过程是比较可靠的。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151355374.png" alt="img"></p><center>图4-26</center><p>Redis允许同时开启AOF和RDB，既保证了数据安全又使得进行备份等操作十分容易。如果同时开启后，Redis重启会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的数据更少。</p><h3 id="AOF的优劣势"><a href="#AOF的优劣势" class="headerlink" title="AOF的优劣势"></a>AOF的优劣势</h3><p><strong>优点：</strong></p><p>1、AOF 持久化的方法提供了多种的同步频率，即使使用默认的同步频率每秒同步一次，Redis 最多也就丢失 1 秒的数据而已。</p><p><strong>缺点：</strong></p><p>1、对于具有相同数据的的Redis，AOF 文件通常会比 RDB 文件体积更大（RDB存的是数据快照）。</p><p>2、虽然 AOF 提供了多种同步的频率，默认情况下，每秒同步一次的频率也具有较高的性能。在高并发的情况下，RDB 比 AOF 具好更好的性能保证。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 面试题 </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阿里P8面试官：如何设计一个扛住千万级并发的架构（超级详细）-续</title>
      <link href="/posts/2734400627/"/>
      <url>/posts/2734400627/</url>
      
        <content type="html"><![CDATA[<p>在上一篇文章中，详细分析了设计一个千万级并发架构所需要思考的问题，以及解决方案。<br>在这一片文章中，我们主要分析如何在职场足够用户数量的情况下，同步提升架构的性能降低平均响应时间。</p><h1 id="如何降低RT的值"><a href="#如何降低RT的值" class="headerlink" title="如何降低RT的值"></a>如何降低RT的值</h1><p>继续看上面这个图，一个请求只有等到tomcat容器中的应用执行完成才能返回，而请求在执行过程中会做什么事情呢？</p><ul><li>查询数据库</li><li>访问磁盘数据</li><li>进行内存运算</li><li>调用远程服务</li></ul><p>这些操作每一个步骤都会消耗时间，当前客户端的请求只有等到这些操作都完成之后才能返回，所以降低RT的方法，就是优化业务逻辑的处理。</p><h2 id="数据库瓶颈的优化"><a href="#数据库瓶颈的优化" class="headerlink" title="数据库瓶颈的优化"></a>数据库瓶颈的优化</h2><p>当18000个请求进入到服务端并且被接收后，开始执行业务逻辑处理，那么必然会查询数据库。</p><p>每个请求至少都有一次查询数据库的操作，多的需要查询3~5次以上，我们假设按照3次来计算，那么每秒会对数据库形成54000个请求，假设一台数据库服务器每秒支撑10000个请求（影响数据库的请求数量有很多因素，比如数据库表的数据量、数据库服务器本身的系统性能、查询语句的复杂度），那么需要6台数据库服务器才能支撑每秒10000个请求。</p><p>除此之外，数据库层面还有涉及到其他的优化方案。</p><ul><li><p>首先是Mysql的最大连接数设置，大家可能遇到过<code>MySQL: ERROR 1040: Too many connections</code>这样的问题，原因就是访问量过高，连接数耗尽了。</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;%max_connections%&#x27;</span>;</span><br></pre></td></tr></table></figure><p>如果服务器的并发连接请求量比较大，建议调高此值，以增加并行连接数量，当然这建立在机器能支撑的情况下，因为如果连接数越多，介于MySQL会为每个连接提供连接缓冲区，就会开销越多的内存，所以要适当调整该值，不能盲目提高设值。</p></li><li><p>数据表数据量过大，比如达到几千万甚至上亿，这种情况下sql的优化已经毫无意义了，因为这么大的数据量查询必然会涉及到运算。</p><ul><li><p>可以缓存来解决读请求并发过高的问题，一般来说对于数据库的读写请求也都遵循2/8法则，在每秒54000个请求中，大概有43200左右是读请求，这些读请求中基本上90%都是可以通过缓存来解决。</p></li><li><p>分库分表，减少单表数据量，单表数据量少了，那么查询性能就自然得到了有效的提升</p></li><li><p>读写分离，避免事务操作对查询操作带来的性能影响</p><blockquote><ul><li><p>写操作本身耗费资源</p><p>数据库写操作为IO写入，写入过程中通常会涉及唯一性校验、建索引、索引排序等操作，对资源消耗比较大。一次写操作的响应时间往往是读操作的几倍甚至几十倍。</p></li><li><p>锁争用</p><p>写操作很多时候需要加锁，包括表级锁、行级锁等，这类锁都是排他锁，一个会话占据排它锁之后，其他会话是不能读取数据的，这会会极大影响数据读取性能。</p><p>所以MYSQL部署往往会采用读写分离方式，主库用来写入数据及部分时效性要求很高的读操作，从库用来承接大部分读操作，这样数据库整体性能能够得到大幅提升。</p></li></ul></blockquote></li></ul></li><li><p>不同类型的数据采用不同的存储库，</p><ul><li>MongoDB  nosql 文档化存储</li><li>Redis  nosql  key-value存储</li><li>HBase nosql， 列式存储，其实本质上有点类似于key-value数据库。</li><li>cassandra，Cassandra 是一个来自 Apache 的分布式数据库，具有高度可扩展性，可用于管理大量的结构化数据</li><li>TIDB，是PingCAP公司自主设计、研发的开源分布式关系型数据库，是一款同时支持在线事务处理与在线分析处理 (Hybrid Transactional and Analytical Processing, HTAP) 的融合型分布式数据库产品</li></ul></li></ul><blockquote><p>为什么把mysql数据库中的数据放redis缓存中能提升性能？</p><ol><li>Redis存储的是k-v格式的数据。时间复杂度是O(1),常数阶,而mysql引擎的底层实现是B+TREE，时间复杂度是O(logn）是对数阶的。Redis会比Mysql快一点点。</li><li>Mysql数据存储是存储在表中，查找数据时要先对表进行全局扫描或根据索引查找，这涉及到磁盘的查找，磁盘查找如果是单点查找可能会快点，但是顺序查找就比较慢。而redis不用这么麻烦，本身就是存储在内存中，会根据数据在内存的位置直接取出。</li><li>Redis是单线程的多路复用IO,单线程避免了线程切换的开销，而多路复用IO避免了IO等待的开销，在多核处理器下提高处理器的使用效率可以对数据进行分区，然后每个处理器处理不同的数据。</li></ol></blockquote><ul><li><p>池化技术，减少频繁创建数据库连接的性能损耗。</p><p>每次进行数据库操作之前，先建立连接然后再进行数据库操作，最后释放连接。这个过程涉及到网络通信的延时，频繁创建连接对象和销毁对象的性能开销等，当请求量较大时，这块带来的性能影响非常大。</p></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350704.png" alt="数据存储"></p><h2 id="磁盘数据访问优化"><a href="#磁盘数据访问优化" class="headerlink" title="磁盘数据访问优化"></a>磁盘数据访问优化</h2><p>对于磁盘的操作，无非就是读和写。</p><p>比如对于做交易系统的场景来说，一般会设计到对账文件的解析和写入。而对于磁盘的操作，优化方式无非就是</p><ul><li><p>磁盘的页缓存，可以借助缓存 I/O ，充分利用系统缓存，降低实际 I/O 的次数。</p></li><li><p>顺序读写，可以用追加写代替随机写，减少寻址开销，加快 I/O 写的速度。</p></li><li><p>SSD代替HDD，固态硬盘的I/O效率远远高于机械硬盘。</p></li><li><p>在需要频繁读写同一块磁盘空间时，可以用 mmap （内存映射，）代替 read/write，减少内存的拷贝次数</p></li><li><p>在需要同步写的场景中，尽量将写请求合并，而不是让每个请求都同步写入磁盘，即可以用 fsync() 取代 O_SYNC</p></li></ul><h2 id="合理利用内存"><a href="#合理利用内存" class="headerlink" title="合理利用内存"></a>合理利用内存</h2><p>充分利用内存缓存，把一些经常访问的数据和对象保存在内存中，这样可以避免重复加载或者避免数据库访问带来的性能损耗。</p><h2 id="调用远程服务"><a href="#调用远程服务" class="headerlink" title="调用远程服务"></a>调用远程服务</h2><p>远程服务调用，影响到IO性能的因素有。</p><ul><li>远程调用等待返回结果的阻塞<ul><li>异步通信</li></ul></li><li>网络通信的耗时<ul><li>内网通信</li><li>增加网络带宽</li></ul></li><li>远程服务通信的稳定性</li></ul><h2 id="异步化架构"><a href="#异步化架构" class="headerlink" title="异步化架构"></a>异步化架构</h2><p>微服务中的逻辑复杂处理时间长的情况，在高并发量下，导致服务线程消耗尽，不能再创建线程处理请求。对这种情况的优化，除了在程序上不断调优(数据库调优，算法调优，缓存等等)，可以考虑在架构上做些调整，先返回结果给客户端，让用户可以继续使用客户端的其他操作，再把服务端的复杂逻辑处理模块做异步化处理。这种异步化处理的方式适合于客户端对处理结果不敏感不要求实时的情况，比如群发邮件、群发消息等。</p><p>异步化设计的解决方案： 多线程、MQ。</p><h1 id="应用服务的拆分"><a href="#应用服务的拆分" class="headerlink" title="应用服务的拆分"></a>应用服务的拆分</h1><p>除了上述的手段之外，业务系统往微服务化拆分也非常有必要，原因是：</p><ul><li>随着业务的发展，应用程序本身的复杂度会不断增加，同样会产生熵增现象。</li><li>业务系统的功能越来越多，参与开发迭代的人员也越多，多个人维护一个非常庞大的项目，很容易出现问题。</li><li>单个应用系统很难实现横向扩容，并且由于服务器资源有限，导致所有的请求都集中请求到某个服务器节点，造成资源消耗过大，使得系统不稳定</li><li>测试、部署成本越来越高</li><li>…..</li></ul><p>其实，最终要的是，单个应用在性能上的瓶颈很难突破，也就是说如果我们要支持18000QPS，单个服务节点肯定无法支撑，所以服务拆分的好处，就是可以利用多个计算机阶段组成一个大规模的分布式计算网络，通过网络通信的方式完成一整套业务逻辑。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350400.png" alt="img"></p><h2 id="如何拆分服务"><a href="#如何拆分服务" class="headerlink" title="如何拆分服务"></a>如何拆分服务</h2><p>如何拆分服务，这个问题看起来简单，很多同学会说，直接按照业务拆分啊。</p><p>但是实际在实施的时候，会发现拆分存在一些边界性问题，比如有些数据模型可以存在A模块，也可以存在B模块，这个时候怎么划分呢？另外，服务拆分的粒度应该怎么划分？</p><p>一般来说，服务的拆分是按照业务来实现的，然后基于DDD来指导微服务的边界划分。<strong>领域驱动就是一套方法论，通过领域驱动设计方法论来定义领域模型，从而确定业务边界和应用边界，保证业务模型和代码模型的一致性。</strong>不管是DDD还是微服务，都要遵循软件设计的基本原则：<strong>高内聚低耦合</strong>。服务内部高内聚，服务之间低耦合，实际上一个领域服务对应了一个功能集合，这些功能一定是有一些共性的。比如，订单服务，那么创建订单、修改订单、查询订单列表，领域的边界越清晰，功能也就越内聚，服务之间的耦合性也就越低。</p><p>服务拆分还需要根据当前技术团队和公司所处的状态来进行。</p><p>如果是初创团队，不需要过分的追求微服务，否则会导致业务逻辑过于分散，技术架构太过负载，再加上团队的基础设施还不够完善，导致整个交付的时间拉长，对公司的发展来说会造成较大的影响。所以在做服务拆分的时候还需要考虑几个因素。</p><ul><li>当前公司业务所处领域的市场性质，如果是市场较为敏感的项目，前期应该是先出来东西，然后再去迭代和优化。</li><li>开发团队的成熟度，团队技术能否能够承接。</li><li>基础能力是否足够，比如Devops、运维、测试自动化等基础能力。 团队是否有能力来支撑大量服务实例运行带来的运维复杂度，是否可以做好服务的监控。</li><li>测试团队的执行效率，如果测试团队不能支持自动化测试、自动回归、压力测试等手段来提高测试效率，那必然会带来测试工作量的大幅度提升从而导致项目上线周期延期</li></ul><p>如果是针对一个老的系统进行改造，那可能涉及到的风险和问题更多，所以要开始着手改动之前，需要考虑几个步骤：拆分前准备阶段，设计拆分改造方案，实施拆分计划</p><ul><li><p>拆分之前，先梳理好当前的整个架构，以及各个模块的依赖关系，还有接口</p><p>准备阶段主要是梳理清楚了依赖关系和接口，就可以思考如何来拆，第一刀切在哪儿里，即能达到快速把一个复杂单体系统变成两个更小系统的目标，又能对系统的现有业务影响最小。要尽量避免构建出一个分布式的单体应用，一个包含了一大堆互相之间紧耦合的服务，却又必须部署在一起的所谓分布式系统。没分析清楚就强行拆，可能就一不小心剪断了大动脉，立马搞出来一个 A 类大故障，后患无穷。</p></li><li><p>不同阶段拆分要点不同，每个阶段的关注点要聚焦</p><p>拆分本身可以分成三个阶段，核心业务和非业务部分的拆分、核心业务的调整设计、核心业务内部的拆分。</p><ul><li><p>第一阶段将核心业务瘦身，把非核心的部分切开，减少需要处理的系统大小；</p></li><li><p>第二阶段。重新按照微服务设计核心业务部分；</p></li><li><p>第三阶段把核心业务部分重构设计落地。</p></li></ul><p>拆分的方式也有三个：代码拆分、部署拆分、数据拆分。</p></li></ul><p>另外，每个阶段需要聚焦到一两个具体的目标，否则目标太多反而很难把一件事儿做通透。例如某个系统的微服务拆分，制定了如下的几个目标：</p><ol><li>性能指标（吞吐和延迟）：核心交易吞吐提升一倍以上（TPS：1000-&gt;10000），A 业务延迟降低一半（Latency：250ms-&gt;125ms），B 业务延迟降低一半（Latency：70ms-&gt;35ms）。</li><li>稳定性指标（可用性，故障恢复时间）：可用性&gt;=99.99%，A 类故障恢复时间&lt;=15 分钟，季度次数&lt;=1 次。</li><li>质量指标：编写完善的产品需求文档、设计文档、部署运维文档，核心交易部分代码 90%以上单测覆盖率和 100%的自动化测试用例和场景覆盖，实现可持续的性能测试基准环境和长期持续性能优化机制。</li><li>扩展性指标：完成代码、部署、运行时和数据多个维度的合理拆分，对于核心系统重构后的各块业务和交易模块、以及对应的各个数据存储，都可以随时通过增加机器资源实现伸缩扩展。</li><li>可维护性指标：建立全面完善的监控指标、特别是全链路的实时性能指标数据，覆盖所有关键业务和状态，缩短监控报警响应处置时间，配合运维团队实现容量规划和管理，出现问题时可以在一分钟内拉起系统或者回滚到上一个可用版本（启动时间&lt;=1 分钟）。</li><li>易用性指标，通过重构实现新的 API 接口既合理又简单，极大的满足各个层面用户的使用和需要，客户满意度持续上升。</li><li>业务支持指标：对于新的业务需求功能开发，在保障质量的前提下，开发效率提升一倍，开发资源和周期降低一半。</li></ol><p>当然，不要期望一次性完成所有目标，每一个阶段可以选择一个两个优先级高的目标进行执行。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350615.png" alt="img"></p><h2 id="微服务化架构带来的问题"><a href="#微服务化架构带来的问题" class="headerlink" title="微服务化架构带来的问题"></a>微服务化架构带来的问题</h2><p>微服务架构首先是一个分布式的架构，其次我们要暴露和提供业务服务能力，然后我们需要考虑围绕这些业务能力的各种非功能性的能力。这些分散在各处的服务本身需要被管理起来，并且对服务的调用方透明，这样就有了服务的注册发现的功能需求。</p><p>同样地，每个服务可能部署了多台机器多个实例，所以，我们需要有路由和寻址的能力，做负载均衡，提升系统的扩展能力。有了这么多对外提供的不同服务接口，我们一样需要有一种机制对他们进行统一的接入控制，并把一些非业务的策略做到这个接入层，比如权限相关的，这就是服务网关。同时我们发现随着业务的发展和一些特定的运营活动，比如秒杀大促，流量会出现十倍以上的激增，这时候我们就需要考虑系统容量，服务间的强弱依赖关系，做服务降级、熔断，系统过载保护等措施。</p><p>以上这些由于微服务带来的复杂性，导致了应用配置、业务配置，都被散落到各处，所以分布式配置中心的需求也出现了。最后，系统分散部署以后，所有的调用都跨了进程，我们还需要有能在线上做链路跟踪，性能监控的一套技术，来协助我们时刻了解系统内部的状态和指标，让我们能够随时对系统进行分析和干预。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171351673.png" alt="image-20210624133950124"></p><h2 id="整体架构图"><a href="#整体架构图" class="headerlink" title="整体架构图"></a>整体架构图</h2><p>基于上述从微观到宏观的整体分析，我们基本上能够设计出一个整体的架构图。</p><ul><li><p>接入层，外部请求到内部系统之间的关口，所有请求都必须经过api 网关。</p></li><li><p>应用层，也叫聚合层，为相关业务提供聚合接口，它会调用中台服务进行组装。</p></li><li><p>中台服务，也是业务服务层，以业务为纬度提供业务相关的接口。中台的本质是为整个架构提供复用的能力，比如评论系统，在咕泡云课堂和Gper社区都需要，那么这个时候评论系统为了设计得更加可复用性，就不能耦合云课堂或者Gper社区定制化的需求，那么作为设计评论中台的人，就不需要做非常深度的思考，如何提供一种针对不同场景都能复用的能力。</p><p>你会发现，当这个服务做到机制的时候，就变成了一个baas服务。</p><blockquote><p><strong>服务商</strong>为<strong>客户</strong>(开发者)提供整合云后端的服务，如提供文件存储、数据存储、推送服务、身份验证服务等功能，以帮助开发者快速开发应用。</p></blockquote></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110091513908.png" alt="image-20210624152616146"></p><h1 id="了解什么是高并发"><a href="#了解什么是高并发" class="headerlink" title="了解什么是高并发"></a>了解什么是高并发</h1><p>总结一下什么是高并发。</p><p>高并发并没有一个具体的定义，高并发主要是形容突发流量较高的场景。</p><p>如果面试的过程中，或者在实际工作中，你们领导或者面试官问你一个如何设计承接千万级流量的系统时，你应该要按照我说的方法去进行逐一分析。</p><ul><li>一定要形成可以量化的数据指标，比如QPS、DAU、总用户数、TPS、访问峰值</li><li>针对这些数据情况，开始去设计整个架构方案</li><li>接着落地执行</li></ul><h2 id="高并发中的宏观指标"><a href="#高并发中的宏观指标" class="headerlink" title="高并发中的宏观指标"></a>高并发中的宏观指标</h2><p>一个满足高并发系统，不是一味追求高性能，至少需要满足三个宏观层面的目标：</p><ul><li>高性能，性能体现了系统的并行处理能力，在有限的硬件投入下，提高性能意味着节省成本。同时，性能也反映了用户体验，响应时间分别是 100 毫秒和 1 秒，给用户的感受是完全不同的。</li><li>高可用，表示系统可以正常服务的时间。一个全年不停机、无故障；另一个隔三差五出现上事故、宕机，用户肯定选择前者。另外，如果系统只能做到 90%可用，也会大大拖累业务。</li><li>高扩展，表示系统的扩展能力，流量高峰时能否在短时间内完成扩容，更平稳地承接峰值流量，比如双 11 活动、明星离婚等热点事件。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110091513525.png" alt="image-20210624211728937"></p><h2 id="微观指标"><a href="#微观指标" class="headerlink" title="微观指标"></a>微观指标</h2><p><strong>性能指标</strong></p><p>通过性能指标可以度量目前存在的性能问题，同时作为性能优化的评估依据。一般来说，会采用一段时间内的接口响应时间作为指标。</p><p>1、平均响应时间：最常用，但是缺陷很明显，对于慢请求不敏感。比如 1 万次请求，其中 9900 次是 1ms，100 次是 100ms，则平均响应时间为 1.99ms，虽然平均耗时仅增加了 0.99ms，但是 1%请求的响应时间已经增加了 100 倍。</p><p>2、TP90、TP99 等分位值：将响应时间按照从小到大排序，TP90 表示排在第 90 分位的响应时间， 分位值越大，对慢请求越敏感。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110091513882.jpeg" alt="img"></p><p><strong>可用性指标</strong></p><p>高可用性是指系统具有较高的无故障运行能力，可用性 = 平均故障时间 / 系统总运行时间，一般使用几个 9 来描述系统的可用性。</p><p>对于高并发系统来说，最基本的要求是：保证 3 个 9 或者 4 个 9。原因很简单，如果你只能做到 2 个 9，意味着有 1%的故障时间，像一些大公司每年动辄千亿以上的 GMV 或者收入，1%就是 10 亿级别的业务影响。</p><p><strong>可扩展性指标</strong></p><p>面对突发流量，不可能临时改造架构，最快的方式就是增加机器来线性提高系统的处理能力。</p><p>对于业务集群或者基础组件来说，扩展性 = 性能提升比例 / 机器增加比例，理想的扩展能力是：资源增加几倍，性能提升几倍。通常来说，扩展能力要维持在 70%以上。</p><p>但是从高并发系统的整体架构角度来看，扩展的目标不仅仅是把服务设计成无状态就行了，因为当流量增加 10 倍，业务服务可以快速扩容 10 倍，但是数据库可能就成为了新的瓶颈。</p><p>像 MySQL 这种有状态的存储服务通常是扩展的技术难点，如果架构上没提前做好规划（垂直和水平拆分），就会涉及到大量数据的迁移。</p><p>因此，高扩展性需要考虑：服务集群、数据库、缓存和消息队列等中间件、负载均衡、带宽、依赖的第三方等，当并发达到某一个量级后，上述每个因素都可能成为扩展的瓶颈点。</p><h2 id="实践方案"><a href="#实践方案" class="headerlink" title="实践方案"></a>实践方案</h2><p>通用设计方法</p><p><strong>纵向扩展（scale-up）</strong></p><p>它的目标是提升单机的处理能力，方案又包括：</p><p>1、提升单机的硬件性能：通过增加内存、CPU 核数、存储容量、或者将磁盘升级成 SSD 等堆硬件的方式来提升。</p><p>2、提升单机的软件性能：使用缓存减少 IO 次数，使用并发或者异步的方式增加吞吐量。</p><p><strong>横向扩展（scale-out）</strong></p><p>因为单机性能总会存在极限，所以最终还需要引入横向扩展，通过集群部署以进一步提高并发处理能力，又包括以下 2 个方向：</p><p>1、做好分层架构：这是横向扩展的提前，因为高并发系统往往业务复杂，通过分层处理可以简化复杂问题，更容易做到横向扩展。</p><p>2、各层进行水平扩展：无状态水平扩容，有状态做分片路由。业务集群通常能设计成无状态的，而数据库和缓存往往是有状态的，因此需要设计分区键做好存储分片，当然也可以通过主从同步、读写分离的方案提升读性能。</p><h3 id="高性能实践方案"><a href="#高性能实践方案" class="headerlink" title="高性能实践方案"></a>高性能实践方案</h3><p>1、集群部署，通过负载均衡减轻单机压力。</p><p>2、多级缓存，包括静态数据使用 CDN、本地缓存、分布式缓存等，以及对缓存场景中的热点 key、缓存穿透、缓存并发、数据一致性等问题的处理。</p><p>3、分库分表和索引优化，以及借助搜索引擎解决复杂查询问题。</p><p>4、考虑 NoSQL 数据库的使用，比如 HBase、TiDB 等，但是团队必须熟悉这些组件，且有较强的运维能力。</p><p>5、异步化，将次要流程通过多线程、MQ、甚至延时任务进行异步处理。</p><p>6、限流，需要先考虑业务是否允许限流（比如秒杀场景是允许的），包括前端限流、Nginx 接入层的限流、服务端的限流。</p><p>7、对流量进行削峰填谷，通过 MQ 承接流量。</p><p>8、并发处理，通过多线程将串行逻辑并行化。</p><p>9、预计算，比如抢红包场景，可以提前计算好红包金额缓存起来，发红包时直接使用即可。</p><p>10、缓存预热，通过异步任务提前预热数据到本地缓存或者分布式缓存中。</p><p>11、减少 IO 次数，比如数据库和缓存的批量读写、RPC 的批量接口支持、或者通过冗余数据的方式干掉 RPC 调用。</p><p>12、减少 IO 时的数据包大小，包括采用轻量级的通信协议、合适的数据结构、去掉接口中的多余字段、减少缓存 key 的大小、压缩缓存 value 等。</p><p>13、程序逻辑优化，比如将大概率阻断执行流程的判断逻辑前置、For 循环的计算逻辑优化，或者采用更高效的算法。</p><p>14、各种池化技术的使用和池大小的设置，包括 HTTP 请求池、线程池（考虑 CPU 密集型还是 IO 密集型设置核心参数）、数据库和 Redis 连接池等。</p><p>15、JVM 优化，包括新生代和老年代的大小、GC 算法的选择等，尽可能减少 GC 频率和耗时。</p><p>16、锁选择，读多写少的场景用乐观锁，或者考虑通过分段锁的方式减少锁冲突。</p><h3 id="高可用实践方案"><a href="#高可用实践方案" class="headerlink" title="高可用实践方案"></a>高可用实践方案</h3><p>1、对等节点的故障转移，Nginx 和服务治理框架均支持一个节点失败后访问另一个节点。</p><p>2、非对等节点的故障转移，通过心跳检测并实施主备切换（比如 redis 的哨兵模式或者集群模式、MySQL 的主从切换等）。</p><p>3、接口层面的超时设置、重试策略和幂等设计。</p><p>4、降级处理：保证核心服务，牺牲非核心服务，必要时进行熔断；或者核心链路出问题时，有备选链路。</p><p>5、限流处理：对超过系统处理能力的请求直接拒绝或者返回错误码。</p><p>6、MQ 场景的消息可靠性保证，包括 producer 端的重试机制、broker 侧的持久化、consumer 端的 ack 机制等。</p><p>7、灰度发布，能支持按机器维度进行小流量部署，观察系统日志和业务指标，等运行平稳后再推全量。</p><p>8、监控报警：全方位的监控体系，包括最基础的 CPU、内存、磁盘、网络的监控，以及 Web 服务器、JVM、数据库、各类中间件的监控和业务指标的监控。</p><p>9、灾备演练：类似当前的“混沌工程”，对系统进行一些破坏性手段，观察局部故障是否会引起可用性问题。</p><p>高可用的方案主要从冗余、取舍、系统运维 3 个方向考虑，同时需要有配套的值班机制和故障处理流程，当出现线上问题时，可及时跟进处理。</p><h3 id="高扩展的实践方案"><a href="#高扩展的实践方案" class="headerlink" title="高扩展的实践方案"></a>高扩展的实践方案</h3><p>1、合理的分层架构：比如上面谈到的互联网最常见的分层架构，另外还能进一步按照数据访问层、业务逻辑层对微服务做更细粒度的分层（但是需要评估性能，会存在网络多一跳的情况）。</p><p>2、存储层的拆分：按照业务维度做垂直拆分、按照数据特征维度进一步做水平拆分（分库分表）。</p><p>3、业务层的拆分：最常见的是按照业务维度拆（比如电商场景的商品服务、订单服务等），也可以按照核心接口和非核心接口拆，还可以按照请求去拆（比如 To C 和 To B，APP 和 H5）。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 架构设计 </tag>
            
            <tag> 面试题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阿里P8面试官：如何设计一个扛住千万级并发的架构？</title>
      <link href="/posts/1568521894/"/>
      <url>/posts/1568521894/</url>
      
        <content type="html"><![CDATA[<p>大家先思考一个问题，这也是在面试过程中经常遇到的问题。</p><blockquote><p>如果你们公司现在的产品能够支持10W用户访问，你们老板突然和你说，融到钱了，会大量投放广告，预计在1个月后用户量会达到1000W，如果这个任务交给你，你应该怎么做？</p></blockquote><h1 id="1000W用户的问题分解"><a href="#1000W用户的问题分解" class="headerlink" title="1000W用户的问题分解"></a>1000W用户的问题分解</h1><p>如何支撑1000W用户其实是一个非常抽象的问题，对于技术开发来说，我们需要一个非常明确的对于执行关键业务上的性能指标数据，比如，高峰时段下对于事务的响应时间、并发用户数、QPS、成功率、以及基本指标要求等，这些都 必须要非常明确，只有这样才能够指导整个架构的改造和优化。所以，如果大家接到这样一个问题，首先需要去定位到问题的本质，也就是首先得知道一些可量化的数据指标。</p><ul><li><p>如果有过往的相似业务交易历史数据经验，你需要尽量参考，处理这些收集到的原始数据（日志），从而分析出高峰时段，以及该时段下的交易行为，交易规模等，得到你想要看清楚的需求细节</p></li><li><p>另外一种情况，就是没有相关的数据指标作为参考，这个时候就需要经验来分析。比如可以参考一些类似行业的比较成熟的业务交易模型（比如银行业的日常交易活动或交通行业售检票交易活动）或者干脆遵循“2/8”原则和“2/5/8”原则来直接下手实践。</p><blockquote><ul><li>当用户能够在2秒以内得到响应时，会感觉系统的响应很快；</li><li>当用户在2-5秒之间得到响应时，会感觉系统的响应速度还可以；</li><li>当用户在5-8秒以内得到响应时，会感觉系统的响应速度很慢，但是还可以接受；</li><li>而当用户在超过8秒后仍然无法得到响应时，会感觉系统糟透了，或者认为系统已经失去响应，而选择离开这个Web站点，或者发起第二次请求。</li></ul></blockquote></li></ul><p>在估算响应时间、并发用户数、TPS、成功率这些关键指标的同时，你仍需要关心具体的业务功能维度上的需求，每个业务功能都有各自的特点，比如有些场景可以不需要同步返回明确执行结果，有些业务场景可以接受返回“系统忙，请等待！”这样暴力的消息，以避免过大的处理流量所导致的大规模瘫痪，因此，学会平衡这些指标之间的关系是必要的，大多数情况下最好为这些指标做一个优先级排序，并且尽量只考察几个优先级高的指标要求。(SLA服务等级)</p><blockquote><p><strong>SLA</strong>：Service-Level Agreement的缩写，意思是服务等级协议。服务的SLA是服务提供者对服务消费者的正式承诺，是衡量服务能力等级的关键项。服务SLA中定义的项必须是可测量的，有明确的测量方法。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350947.png" alt="image-20210623165109183"></p><h2 id="并发中相关概念的解释"><a href="#并发中相关概念的解释" class="headerlink" title="并发中相关概念的解释"></a>并发中相关概念的解释</h2><p>在分析上述问题之前，先给大家普及一下，系统相关的一些关键衡量指标。</p><h3 id="TPS"><a href="#TPS" class="headerlink" title="TPS"></a>TPS</h3><p>TPS（Transaction Per Second）每秒处理的事务数。</p><p>站在宏观角度来说，一个事务是指客户端向服务端发起一个请求，并且等到请求返回之后的整个过程。从客户端发起请求开始计时，等到收到服务器端响应结果后结束计时，在计算这个时间段内总共完成的事务个数，我们称为TPS。</p><p>站在微观角度来说，一个数据库的事务操作，从开始事务到事务提交完成，表示一个完整事务，这个是数据库层面的TPS。</p><h3 id="QPS"><a href="#QPS" class="headerlink" title="QPS"></a>QPS</h3><p>QPS（Queries Per Second）每秒查询数，表示服务器端每秒能够响应的查询次数。这里的查询是指用户发出请求到服务器做出响应成功的次数，可以简单认为每秒钟的Request数量。</p><p>针对单个接口而言，TPS和QPS是相等的。如果从宏观层面来说，用户打开一个页面到页面渲染结束代表一个TPS，那这个页面中会调用服务器很多次，比如加载静态资源、查询服务器端的渲染数据等，就会产生两个QPS，因此，一个TPS中可能会包含多个QPS。</p><blockquote><p><strong>QPS=并发数/平均响应时间</strong></p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350727.png" alt="image-20210622180649041"></p><h3 id="RT"><a href="#RT" class="headerlink" title="RT"></a>RT</h3><p>RT（Response Time），表示客户端发起请求到服务端返回的时间间隔，一般表示平均响应时间。</p><h3 id="并发数"><a href="#并发数" class="headerlink" title="并发数"></a>并发数</h3><p>并发数是指系统同时能处理的请求数量。</p><p>需要注意，并发数和QPS不要搞混了，QPS表示每秒的请求数量，而并发数是系统同时处理的请求数量，并发数量会大于QPS，因为服务端的一个连接需要有一个处理时长，在这个请求处理结束之前，这个连接一直占用。</p><p>举个例子，如果QPS=1000，表示每秒钟客户端会发起1000个请求到服务端，而如果一个请求的处理耗时是3s，那么意味着总的并发=1000*3=3000，也就是服务端会同时有3000个并发。</p><h3 id="计算方法"><a href="#计算方法" class="headerlink" title="计算方法"></a>计算方法</h3><p>上面说的这些指标，怎么计算呢？举个例子。</p><p>假设在10点到11点这一个小时内，有200W个用户访问我们的系统，假设平均每个用户请求的耗时是3秒，那么计算的结果如下：</p><ul><li>QPS=2000000/60*60 = 556 （表示每秒钟会有556个请求发送到服务端）</li><li>RT=3s（每个请求的平均响应时间是3秒）</li><li>并发数=556*3=1668</li></ul><p>从这个计算过程中发现，随着RT的值越大，那么并发数就越多，而并发数代表着服务器端同时处理的连接请求数量，也就意味服务端占用的连接数越多，这些链接会消耗内存资源以及CPU资源等。所以RT值越大系统资源占用越大，同时也意味着服务端的请求处理耗时较长。</p><p>但实际情况是，RT值越小越好，比如在游戏中，至少做到100ms左右的响应才能达到最好的体验，对于电商系统来说，3s左右的时间是能接受的，那么如何缩短RT的值呢？</p><h2 id="按照2-8法则来推算1000w用户的访问量"><a href="#按照2-8法则来推算1000w用户的访问量" class="headerlink" title="按照2/8法则来推算1000w用户的访问量"></a>按照2/8法则来推算1000w用户的访问量</h2><p>继续回到最开始的问题，假设没有历史数据供我们参考，我们可以使用2/8法则来进行预估。</p><ul><li><p>1000W用户，每天来访问这个网站的用户占到20%，也就是每天有200W用户来访问。</p></li><li><p>假设平均每个用户过来点击50次，那么总共的PV=1亿。</p></li><li><p>一天是24小时，根据2/8法则，每天大部分用户活跃的时间点集中在(24*0.2) 约等于5个小时以内，而大部分用户指的是（1亿点击 * 80%）约等于8000W（PV）， 意味着在5个小时以内，大概会有8000W点击进来，也就是每秒大约有4500(8000W/5小时)个请求。</p></li><li><p>4500只是一个平均数字。在这5个小时中，不可能请求是非常平均的，有可能会存在大量的用户集中访问（比如像淘宝这样的网站，日访问峰值的时间点集中在下午14：00、以及晚上21：00，其中21：00是一天中活跃的峰值），一般情况下访问峰值是平均访问请求的3倍到4倍左右（这个是经验值），我们按照4倍来计算。那么在这5个小时内有可能会出现每秒18000个请求的情况。也就是说，问题由原本的支撑1000W用户，变成了一个具体的问题，<strong>就是服务器端需要能够支撑每秒18000个请求</strong>（QPS=18000）</p></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350543.png" alt="image-20210622160313561"></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350921.png" alt="image-20210622160320454"></p><h2 id="服务器压力预估"><a href="#服务器压力预估" class="headerlink" title="服务器压力预估"></a>服务器压力预估</h2><p>大概预估出了后端服务器需要支撑的最高并发的峰值之后，就需要从整个系统架构层面进行压力预估，然后配置合理的服务器数量和架构。既然是这样，那么首先需要知道一台服务器能够扛做多少的并发，那这个问题怎么去分析呢？我们的应用是部署在Tomcat上，所以需要从Tomcat本身的性能下手。</p><p>下面这个图表示Tomcat的工作原理，该图的说明如下。</p><ul><li><p>LimitLatch是连接控制器，它负责控制Tomcat能够同时处理的最大连接数，在NIO/NIO2的模式中，默认是10000，如果是APR/native，默认是8192</p></li><li><p>Acceptor是一个独立的线程，在run方法中，在while循环中调用socket.accept方法中接收客户端的连接请求，一旦有新的请求过来，accept会返回一个Channel对象，接着把这个Channel对象交给Poller去处理。</p><blockquote><p>Poller 的本质是一个 Selector ，它同样也实现了线程，Poller 在内部维护一个 Channel 数组，它在一个死循环里不断检测 Channel 的数据就绪状态，一旦有 Channel 可读，就生成一个 SocketProcessor 任务对象扔给 Executor 去处理</p></blockquote></li><li><p>SocketProcessor 实现了 Runnable 接口，当线程池在执行SocketProcessor这个任务时，会通过Http11Processor去处理当前这个请求，Http11Processor 读取 Channel 的数据来生成 ServletRequest 对象。</p></li><li><p>Executor 就是线程池，负责运行 SocketProcessor 任务类， SocketProcessor 的 run 方法会调用 Http11Processor 来读取和解析请求数据。我们知道， Http11Processor 是应用层协议的封装，它会调用容器获得响应，再把响应通过 Channel 写出。</p></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350538.png" alt="image-20210622154519229"></p><p>从这个图中可以得出，限制Tomcat请求数量的因素四个方面。</p><h3 id="当前服务器系统资源"><a href="#当前服务器系统资源" class="headerlink" title="当前服务器系统资源"></a>当前服务器系统资源</h3><p>我想可能大家遇到过类似“Socket/File：Can’t open so many files”的异常，这个就是表示Linux系统中的文件句柄限制。</p><p>在Linux中，每一个TCP连接会占用一个文件描述符（fd），一旦文件描述符超过Linux系统当前的限制，就会提示这个错误。</p><p>我们可以通过下面这条命令来查看一个进程可以打开的文件数量</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ulimit -a 或者 ulimit -n</span><br></pre></td></tr></table></figure><p>open files （-n） 1024 是linux操作系统对一个进程打开的文件句柄数量的限制（也包含打开的套接字数量）</p><p>这里只是对用户级别的限制，其实还有个是对系统的总限制，查看系统总线制：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /proc/sys/fs/file-max</span><br></pre></td></tr></table></figure><p>file-max是设置系统所有进程一共可以打开的文件数量 。同时一些程序可以通过<code>setrlimit</code>调用，设置每个进程的限制。如果得到大量使用完文件句柄的错误信息，是应该增加这个值。</p><p>当出现上述异常时，我们可以通过下面的方式来进行修改（针对单个进程的打开数量限制）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/security/limits.conf</span><br><span class="line">  root soft nofile 65535</span><br><span class="line">  root hard nofile 65535</span><br><span class="line">  * soft nofile 65535</span><br><span class="line">  * hard nofile 65535</span><br></pre></td></tr></table></figure><ul><li><code>*</code>代表所有用户、<code>root</code>表示root用户。</li><li>noproc 表示最大进程数量</li><li>nofile代表最大文件打开数量。</li><li>soft/hard，前者当达到阈值时，制作警告，后者会报错。</li></ul><p>另外还要注意，要确保针对进程级别的文件打开数量反问是小于或者等于系统的总限制，否则，我们需要修改系统的总限制。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /proc/sys/fs/file-max</span><br></pre></td></tr></table></figure><p>TCP连接对于系统资源最大的开销就是内存。</p><p>因为tcp连接归根结底需要双方接收和发送数据，那么就需要一个读缓冲区和写缓冲区，这两个buffer在linux下最小为4096字节，可通过cat /proc/sys/net/ipv4/tcp_rmem和cat /proc/sys/net/ipv4/tcp_wmem来查看。</p><p>所以，一个tcp连接最小占用内存为4096+4096 = 8k，那么对于一个8G内存的机器，在不考虑其他限制下，最多支持的并发量为：8<em>1024</em>1024/8 约等于100万。此数字为纯理论上限数值，在实际中，由于linux kernel对一些资源的限制，加上程序的业务处理，所以，8G内存是很难达到100万连接的，当然，我们也可以通过增加内存的方式增加并发量。</p><h3 id="Tomcat依赖的JVM的配置"><a href="#Tomcat依赖的JVM的配置" class="headerlink" title="Tomcat依赖的JVM的配置"></a>Tomcat依赖的JVM的配置</h3><p>我们知道Tomcat是Java程序，运行在JVM上，因此我们还需要对JVM做优化，才能更好的提升Tomcat的性能，简单带大家了解一下JVM，如下图所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350493.png" alt="image-20210623204411021"></p><p>在JVM中，内存划分为堆、程序计数器、本地方发栈、方法区（元空间）、虚拟机栈。</p><h4 id="堆空间说明"><a href="#堆空间说明" class="headerlink" title="堆空间说明"></a>堆空间说明</h4><p>其中，堆内存是JVM内存中最大的一块区域，几乎所有的对象和数组都会被分配到堆内存中，它被所有线程共享。 堆空间被划分为新生代和老年代，新生代进一步划分为Eden和Surivor区，如下图所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350001.png" alt="image-20210623205840226"></p><p>新生代和老年代的比例是1：2，也就是新生代会占1/3的堆空间，老年代会占2/3的堆空间。 另外，在新生代中，空间占比为Eden:Surivor0:Surivor1=8:1:1 。 举个例子来说，如果eden区内存大小是40M，那么两个Survivor区分别是占5M，整个新生代就是50M，然后计算出老年代的内存大小是100M，也就是说堆空间的总内存大小是150M。</p><blockquote><p>可以通过 java -XX:PrintFlagsFinal -version查看默认参数</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">uintx InitialSurvivorRatio                      = 8</span><br><span class="line">uintx NewRatio                                  = 2</span><br></pre></td></tr></table></figure><p>InitialSurvivorRatio:  新生代Eden/Survivor空间的初始比例</p><p>NewRatio ： Old区/Young区的内存比例</p></blockquote><p>堆内存的具体工作原理是：</p><ul><li>绝大部分的对象被创建之后，会保存在Eden区，当Eden区满了的时候，就会触发YGC（Young GC），大部分对象会被回收掉，如果还有活着的对象，就拷贝到Survivor0，这时Eden区被清空。</li><li>如果后续再次触发YGC，活着的对象Eden+Survivor0中的对象拷贝到Survivor1区， 这时Eden和Survivor0都会被清空</li><li>接着再触发YGC，Eden+Survivor1中的对象会被拷贝到Survivor0区，一直这么循环，直到对象的年龄达到阈值，则放入到老年代。（之所以这么设计，是因为Eden区的大部分对象会被回收）</li><li>Survivor区装不下的对象会直接进入到老年代</li><li>老年代满了，会触发Full GC。</li></ul><blockquote><p>GC标记-清除算法 在执行过程中暂停其他线程??</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350497.png" alt="image-20210623214030533"></p><h4 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h4><p>程序计数器是用来记录各个线程执行的字节码地址等，当线程发生上下文切换时，需要依靠这个来记住当前执行的位置，当下次恢复执行后要沿着上一次执行的位置继续执行。</p><h4 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h4><p>方法区是逻辑上的概念，在HotSpot虚拟机的1.8版本中，它的具体实现就是元空间。</p><p>方法区主要用来存放已经被虚拟机加载的类相关信息，包括类元信息、运行时常量池、字符串常量池，类信息又包括类的版本、字段、方法、接口和父类信息等。</p><p>方法区和堆空间类似，它是一个共享内存区域，所以方法区是属于线程共享的。</p><h4 id="本地方发栈和虚拟机栈"><a href="#本地方发栈和虚拟机栈" class="headerlink" title="本地方发栈和虚拟机栈"></a>本地方发栈和虚拟机栈</h4><p>Java虚拟机栈是线程私有的内存空间，当创建一个线程时，会在虚拟机中申请一个线程栈，用来保存方法的局部变量、操作数栈、动态链接方法等信息。每一个方法的调用都伴随这栈帧的入栈操作，当一个方法返回之后，就是栈帧的出栈操作。</p><p>本地方法栈和虚拟机栈类似，本地方法栈是用来管理本地方法的调用，也就是native方法。</p><h4 id="JVM内存应该怎么设置"><a href="#JVM内存应该怎么设置" class="headerlink" title="JVM内存应该怎么设置"></a>JVM内存应该怎么设置</h4><p>了解了上述基本信息之后，那么JVM中内存应该如何设置呢？有哪些参数来设置？</p><p>而在JVM中，要配置的几个核心参数无非是。</p><ul><li><p><code>-Xms</code>，Java堆内存大小</p></li><li><p><code>-Xmx</code>，Java最大堆内存大小</p></li><li><p><code>-Xmn</code>，Java堆内存中的新生代大小，扣除新生代剩下的就是老年代内存</p><p>新生代内存设置过小会频繁触发Minor GC，频繁触发GC会影响系统的稳定性</p></li><li><p><code>-XX:MetaspaceSize</code>，元空间大小， 128M</p></li><li><p><code>-XX:MaxMetaspaceSize</code>，最大云空间大小 （如果没有指定这两个参数，元空间会在运行时根据需要动态调整。）  256M</p><blockquote><p>一个新系统的元空间，基本上没办法有一个测算的方法，一般设置几百兆就够用，因为这里面主要存放一些类信息。</p></blockquote></li><li><p><code>-Xss</code>，线程栈内存大小，这个基本上不需要预估，设置512KB到1M就行，因为值越小，能够分配的线程数越多。</p></li></ul><p>JVM内存的大小，取决于机器的配置，比如一个2核4G的服务器，能够分配给JVM进程也就2G左右，因为机器本身也需要内存，而且机器上还运行了其他的进程也需要占内存。而这2G还得分配给栈内存、堆内存、元空间，那堆内存能够得到的也就1G左右，然后堆内存还要分新生代、老年代。</p><h3 id="Tomcat本身的配置"><a href="#Tomcat本身的配置" class="headerlink" title="Tomcat本身的配置"></a>Tomcat本身的配置</h3><blockquote><p><a href="http://tomcat.apache.org/tomcat-8.0-doc/config/http.html">http://tomcat.apache.org/tomcat-8.0-doc/config/http.html</a></p></blockquote><blockquote><p>The maximum number of request processing threads to be created by this <strong>Connector</strong>, which therefore determines the maximum number of simultaneous requests that can be handled. If not specified, this attribute is set to 200. If an executor is associated with this connector, this attribute is ignored as the connector will execute tasks using the executor rather than an internal thread pool. Note that if an executor is configured any value set for this attribute will be recorded correctly but it will be reported (e.g. via JMX) as <code>-1</code> to make clear that it is not used.</p></blockquote><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">tomcat:</span></span><br><span class="line">    <span class="attr">uri-encoding:</span> <span class="string">UTF-8</span></span><br><span class="line">    <span class="comment">#最大工作线程数，默认200, 4核8g内存，线程数经验值800</span></span><br><span class="line">    <span class="comment">#操作系统做线程之间的切换调度是有系统开销的，所以不是越多越好。</span></span><br><span class="line">    <span class="attr">max-threads:</span> <span class="number">1000</span></span><br><span class="line">    <span class="comment"># 等待队列长度，默认100，</span></span><br><span class="line">    <span class="attr">accept-count:</span> <span class="number">1000</span></span><br><span class="line">    <span class="attr">max-connections:</span> <span class="number">20000</span></span><br><span class="line">    <span class="comment"># 最小工作空闲线程数，默认10, 适当增大一些，以便应对突然增长的访问量</span></span><br><span class="line">    <span class="attr">min-spare-threads:</span> <span class="number">100</span></span><br></pre></td></tr></table></figure><ul><li><p><strong>accept-count:</strong> 最大等待数，当调用HTTP请求数达到tomcat的最大线程数时，还有新的HTTP请求到来，这时tomcat会将该请求放在等待队列中，这个acceptCount就是指能够接受的最大等待数，默认100。如果等待队列也被放满了，这个时候再来新的请求就会被tomcat拒绝（connection refused）</p></li><li><p><strong>maxThreads：</strong>最大线程数，每一次HTTP请求到达Web服务，tomcat都会创建一个线程来处理该请求，那么最大线程数决定了Web服务容器可以同时处理多少个请求。maxThreads默认200，肯定建议增加。但是，增加线程是有成本的，更多的线程，不仅仅会带来更多的线程上下文切换成本，而且意味着带来更多的内存消耗。JVM中默认情况下在创建新线程时会分配大小为1M的线程栈，所以，更多的线程异味着需要更多的内存。线程数的经验值为：1核2g内存为200，线程数经验值200；4核8g内存，线程数经验值800。</p></li><li><p><strong>maxConnections</strong>，最大连接数，这个参数是指在同一时间，tomcat能够接受的最大连接数。对于Java的阻塞式BIO，默认值是maxthreads的值；如果在BIO模式使用定制的Executor执行器，默认值将是执行器中maxthreads的值。对于Java 新的NIO模式，maxConnections 默认值是10000。对于windows上APR/native IO模式，maxConnections默认值为8192</p><p>如果设置为-1，则禁用maxconnections功能，表示不限制tomcat容器的连接数。<br><strong>maxConnections和accept-count的关系为：当连接数达到最大值maxConnections后，系统会继续接收连接，但不会超过acceptCount的值。</strong></p></li></ul><h3 id="1-3-4-应用带来的压力"><a href="#1-3-4-应用带来的压力" class="headerlink" title="1.3.4 应用带来的压力"></a>1.3.4 应用带来的压力</h3><p>前面我们分析过，NIOEndPoint接收到客户端请求连接后，会生成一个SocketProcessor任务给到线程池去处理，SocketProcessor中的run方法会调用HttpProcessor组件去解析应用层的协议，并生成Request对象。最后调用Adapter的Service方法，将请求传递到容器中。</p><p>容器主要负责内部的处理工作，也就是当前置的连接器通过Socket获取到信息之后，得到一个Servlet请求，而容器就是负责处理Servlet请求。</p><p>Tomcat使用Mapper组件将用户请求的URL定位到一个具体的Serlvet，然后Spring中的DispatcherServlet拦截到该Servlet请求后，基于Spring本身的Mapper映射定位到我们具体的Controller中。</p><p>到了Controller之后，对于我们的业务来说，才是一个请求真正的开始，Controller调用Service、Service调用dao，完成数据库操作之后，讲请求原路返回给到客户端，完成一次整体的会话。也就是说，Controller中的业务逻辑处理耗时，对于整个容器的并发来说也会受到影响。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350088.png" alt="image-20210622151107514"></p><h2 id="服务器数量评估"><a href="#服务器数量评估" class="headerlink" title="服务器数量评估"></a>服务器数量评估</h2><p>通过上述分析，我们假设一个tomcat节点的QPS=500，如果要支撑到高峰时期的QPS=18000，那么需要40台服务器，这四台服务器需要通过Nginx软件负载均衡，进行请求分发，Nginx的性能很好，官方给的说明是Nginx处理静态文件的并发能够达到5W/s。另外Nginx由于不能单点，我们可以采用LVS对Nginx做负载均衡，LVS（Linux VirtualServer），它是采用IP负载均衡技术实现负载均衡。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350886.png" alt="image-20210622220213652"></p><p>通过这样的一组架构，我们当前服务端是能够同时承接QPS=18000，但是还不够，再回到前面我们说的两个公式。</p><ul><li><p>QPS=并发量/平均响应时间</p></li><li><p>并发量=QPS*平均响应时间</p></li></ul><p>假设我们的RT是3s，那么意味着服务器端的并发数=18000*3=54000，也就是同时有54000个连接打到服务器端，所以服务端需要同时支持的连接数为54000，这个我们在前文说过如何进行配置。如果RT越大，那么意味着堆积的链接越多，而这些连接会占用内存资源/CPU资源等，容易造成系统崩溃的现象。同时，当链接数超过阈值时，后续的请求无法进来，用户会得到一个请求超时的结果，这显然不是我们所希望看到的，所以我们必须要缩短RT的值。</p>]]></content>
      
      
      <categories>
          
          <category> 架构设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 架构设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/posts/1243066710/"/>
      <url>/posts/1243066710/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>

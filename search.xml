<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>深度剖析Redis6的持久化机制（大量图片说明，简洁易懂）</title>
      <link href="/posts/2542151685/"/>
      <url>/posts/2542151685/</url>
      
        <content type="html"><![CDATA[<p>Redis的强劲性能很大程度上是由于它所有的数据都存储在内存中，当然如果redis重启或者服务器故障导致redis重启，所有存储在内存中的数据就会丢失。但是在某些情况下，我们希望Redis在重启后能够保证数据不会丢失。</p><ol><li><p>将redis作为nosql数据库使用。</p></li><li><p>将Redis作为高效缓存服务器，缓存被击穿后对后端数据库层面的瞬时压力是特别大的，所有缓存同时失效可能会导致雪崩。</p></li></ol><p>这时我们希望Redis能将数据从内存中以某种形式同步到硬盘上，使得重启后可以根据硬盘中的记录来恢复数据。</p><p>Redis支持两种方式的持久化，一种是RDB方式、另一种是AOF（append-only-file）方式，两种持久化方式可以单独使用其中一种，也可以将这两种方式结合使用。</p><ul><li><strong>RDB</strong>：根据指定的规则“<strong>定时</strong>”将内存中的数据存储在硬盘上，</li><li><strong>AOF</strong>：每次执行命令后将命令本身记录下来。</li></ul><h1 id="RDB模式"><a href="#RDB模式" class="headerlink" title="RDB模式"></a>RDB模式</h1><p>RDB的持久化方式是通过快照（snapshotting）完成的，它是Redis默认的持久化方式，配置如下。</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># save 3600 1</span></span><br><span class="line"><span class="comment"># save 300 100</span></span><br><span class="line"><span class="comment"># save 60 10000</span></span><br></pre></td></tr></table></figure><p>Redis允许用户自定义快照条件，当符合快照条件时，Redis会自动执行快照操作。快照的条件可以由用户在配置文件中配置。配置格式如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">save &lt;seconds&gt; &lt;changes&gt;</span><br></pre></td></tr></table></figure><p>第一个参数是时间窗口，第二个是键的个数，也就是说，在第一个时间参数配置范围内被更改的键的个数大于后面的changes时，即符合快照条件。当触发条件时，Redis会自动将内存中的数据生成一份副本并存储在磁盘上，</p><p>这个过程称之为“快照”，除了上述规则之外，还有以下几种方式生成快照。</p><ol><li>根据配置规则进行自动快照</li><li>用户执行SAVE或者GBSAVE命令</li><li>执行FLUSHALL命令</li><li>执行复制(replication)时</li></ol><h2 id="根据配置规则进行自动快照"><a href="#根据配置规则进行自动快照" class="headerlink" title="根据配置规则进行自动快照"></a>根据配置规则进行自动快照</h2><ul><li>修改redis.conf文件，表示5秒内，有一个key发生变化，就会生成rdb文件。</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">save 5 1                # 表示3600s以内至少发生1个key变化（新增、修改、删除），则重写rdb文件</span><br><span class="line">save 300 100</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure><ul><li><p>修改文件存储路径</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dir /data/program/redis/bin</span><br></pre></td></tr></table></figure></li><li><p>其他参数配置说明</p><table><thead><tr><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>dir</td><td>rdb文件默认在启动目录下（相对路径） <code>config get dir</code> 获取</td></tr><tr><td>dbfilename</td><td>文件名称</td></tr><tr><td>rdbcompression</td><td>开启压缩可以节省存储空间，但是会消耗一些CPU的计算时间，默认开启</td></tr><tr><td>rdbchecksum</td><td>使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。</td></tr></tbody></table></li></ul><p><strong>如果需要关闭RDB的持久化机制，可以参考如下配置，开启<code>save</code>，并注释其他规则即可</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">save &quot;&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash">save 900 1</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 300 10</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 60 10000</span></span><br></pre></td></tr></table></figure><h2 id="用户执行SAVE或者GBSAVE命令"><a href="#用户执行SAVE或者GBSAVE命令" class="headerlink" title="用户执行SAVE或者GBSAVE命令"></a>用户执行SAVE或者GBSAVE命令</h2><p>除了让Redis自动进行快照以外，当我们对服务进行重启或者服务器迁移我们需要人工去干预备份。redis提供了两条命令来完成这个任务</p><ol><li><p><strong>save命令</strong></p><p>如图4-24所示，当执行save命令时，Redis同步做快照操作，在快照执行过程中会阻塞所有来自客户端的请求。当redis内存中的数据较多时，通过该命令将导致Redis较长时间的不响应。所以不建议在生产环境上使用这个命令，而是推荐使用bgsave命令</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191352820.png" alt="image-20210712184050955"></p><center>图4-24</center></li><li><p><strong>bgsave命令</strong></p><p>如图4-25所示，bgsave命令可以在后台异步地进行快照操作，快照的同时服务器还可以继续响应来自客户端的请求。执行BGSAVE后，Redis会立即返回ok表示开始执行快照操作，在redis-cli终端，通过下面这个命令可以获取最近一次成功执行快照的时间（以 UNIX 时间戳格式表示）。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">LASTSAVE</span><br></pre></td></tr></table></figure></li></ol><p>1：redis使用fork函数复制一份当前进程的副本(子进程)</p><p>2：父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件</p><p>3：当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此，一次快照操作完成。 </p><blockquote><p>注意：redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。 这就使得我们可以通过定时备份RDB文件来实现redis数据库的备份， RDB文件是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。</p><p><strong>bgsave是异步执行快照的，bgsave写入的数据就是for进程时redis的数据状态，一旦完成fork，后续执行的新的客户端命令对数据产生的变更都不会反应到本次快照</strong></p></blockquote><p>Redis启动后会读取RDB快照文件，并将数据从硬盘载入到内存。根据数据量大小以及服务器性能不同，这个载入的时间也不同。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191352242.png" alt="image-20210712183559812"></p><center>图4-25</center><h2 id="执行FLUSHALL命令"><a href="#执行FLUSHALL命令" class="headerlink" title="执行FLUSHALL命令"></a>执行FLUSHALL命令</h2><p>该命令在前面讲过，会清除redis在内存中的所有数据。执行该命令后，只要redis中配置的快照规则不为空，</p><p>也就是save 的规则存在。redis就会执行一次快照操作。不管规则是什么样的都会执行。如果没有定义快照规则，就不会执行快照操作。</p><h2 id="执行复制-replication-时"><a href="#执行复制-replication-时" class="headerlink" title="执行复制(replication)时"></a>执行复制(replication)时</h2><p>该操作主要是在主从模式下，redis会在复制初始化时进行自动快照。这个会在后面讲到；</p><p>这里只需要了解当执行复制操作时，即时没有定义自动快照规则，并且没有手动执行过快照操作，它仍然会生成RDB快照文件。</p><h2 id="RDB数据恢复演示"><a href="#RDB数据恢复演示" class="headerlink" title="RDB数据恢复演示"></a>RDB数据恢复演示</h2><ul><li>准备初始数据</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k1 1</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k2 2</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k3 3</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k4 4</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k5 5</span></span><br></pre></td></tr></table></figure><ul><li><p>通过shutdown命令关闭触发save</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> shutdown</span></span><br></pre></td></tr></table></figure></li><li><p>备份dump.rdb文件(用来后续恢复)</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp dump.rdb dump.rdb.bak</span><br></pre></td></tr></table></figure></li><li><p>接着再启动redis-server(systemctl restart redis_6379)，通过keys命令查看，发现数据还在</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">keys *</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>模拟数据丢失</p></blockquote><ul><li><p>执行flushall</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> flushall</span></span><br></pre></td></tr></table></figure></li><li><p>shutdown(重新生成没有数据的快照，用来模拟后续的数据恢复)</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> shutdown</span></span><br></pre></td></tr></table></figure></li><li><p>再次启动redis, 通过keys 命令查看，此时rdb中没有任何数据。</p></li><li><p>恢复之前备份的rdb文件（之前保存了数据的rdb快照）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv dump.rdb.bak dump.rdb</span><br></pre></td></tr></table></figure></li><li><p>再次重启redis，可以看到之前快照保存的数据</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">keys *</span><br></pre></td></tr></table></figure></li></ul><h2 id="文件的优势和劣势"><a href="#文件的优势和劣势" class="headerlink" title="文件的优势和劣势"></a>文件的优势和劣势</h2><p><strong>一、优势</strong></p><p>　　1.RDB是一个非常紧凑(compact)的文件，它保存了redis 在某个时间点上的数据集，这种文件非常适合用于进行备份和灾难恢复。</p><p>　　2.生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。</p><p>　　3.RDB 在恢复大数据集时的速度比AOF的恢复速度要快。</p><p><strong>二、劣势</strong></p><ul><li><p>1、RDB方式数据没办法做到实时持久化/秒级持久化。因为bgsave每次运行都要执行fork操作创建子进程，频繁执行成本过高</p></li><li><p>2、在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照之后的所有修改（数据有丢失）。</p></li></ul><p><strong>如果数据相对来说比较重要，希望将损失降到最小，则可以使用AOF方式进行持久化。</strong></p><h1 id="AOF模式"><a href="#AOF模式" class="headerlink" title="AOF模式"></a>AOF模式</h1><p>AOF(Append Only File)：Redis 默认不开启。AOF采用日志的形式来记录每个写操作，并<strong>追加</strong>到文件中。开启后，执行更改Redis数据的命令时，就会把命令写入到AOF文件中。</p><p>Redis 重启时会根据日志文件的内容把写指令从前到后执行一次以完成数据的恢复工作。</p><h2 id="AOF配置开关"><a href="#AOF配置开关" class="headerlink" title="AOF配置开关"></a>AOF配置开关</h2><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 开关</span></span><br><span class="line">appendonly no  /yes</span><br><span class="line"><span class="meta">#</span><span class="bash"> 文件名</span></span><br><span class="line">appendfilename &quot;appendonly.aof&quot;</span><br></pre></td></tr></table></figure><p>通过修改redis.conf重启redis之后：systemctl restart redis_6379。</p><p>再次运行redis的相关操作命令，会发现在指定的<code>dir</code>目录下生成appendonly.aof文件，通过vim查看该文件内容如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">*2</span><br><span class="line"><span class="meta">$</span><span class="bash">6</span></span><br><span class="line">SELECT</span><br><span class="line"><span class="meta">$</span><span class="bash">1</span></span><br><span class="line">0</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">name</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">mic</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">name</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">123</span><br></pre></td></tr></table></figure><h2 id="AOF配置相关问题解答"><a href="#AOF配置相关问题解答" class="headerlink" title="AOF配置相关问题解答"></a>AOF配置相关问题解答</h2><p><strong>问题1：数据都是实时持久化到磁盘吗？</strong></p><p>虽然每次执行更改Redis数据库内容的操作时，AOF都会将命令记录在AOF文件中，但是事实上，由于操作系统的缓存机制，数据并没有真正地写入硬盘，而是进入了系统的硬盘缓存。在默认情况下系统每30秒会执行一次同步操作。以便将硬盘缓存中的内容真正地写入硬盘。</p><p>在这30秒的过程中如果系统异常退出则会导致硬盘缓存中的数据丢失。一般来说能够启用AOF的前提是业务场景不能容忍这样的数据损失，这个时候就需要Redis在写入AOF文件后主动要求系统将缓存内容同步到硬盘中。在redis.conf中通过如下配置来设置同步机制。</p><table><thead><tr><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>appendfsync everysec</td><td>AOF持久化策略（硬盘缓存到磁盘），默认<strong>everysec</strong> <br /> 1 no  表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快，但是不太安全；  <br /> 2 always  表示每次写入都执行fsync，以保证数据同步到磁盘，效率很低；<br /> 3 everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。通常选择 everysec ，兼顾安全性和效率。</td></tr></tbody></table><p><strong>问题2：文件越来越大，怎么办？</strong></p><p>由于AOF持久化是Redis不断将写命令记录到 AOF 文件中，随着Redis不断的运行，AOF 的文件会越来越大，文件越大，占用服务器内存越大以及 AOF 恢复要求时间越长。</p><p><strong>例如set gupao 666，执行1000次，结果都是gupao=666。</strong></p><p>为了解决这个问题，Redis新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。</p><p>可以使用命令下面这个命令主动触发重写</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> bgrewriteaof</span></span><br></pre></td></tr></table></figure><p>AOF 文件重写并不是对原文件进行重新整理，而是直接读取服务器现有的键值对，然后用一条命令去代替之前记录这个键值对的多条命令，生成一个新的文件后去替换原来的 AOF 文件。</p><p><strong>重写触发机制如下</strong></p><table><thead><tr><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>auto-aof-rewrite-percentage</td><td>默认值为100。表示的是当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时AOF文件大小为依据</td></tr><tr><td>auto-aof-rewrite-min-size</td><td>默认64M。表示限制了允许重写的最小AOF文件大小，通常在AOF文件很小的情况下即使其中有很多冗余的命令我们也并不太关心</td></tr></tbody></table><p>在启动时，Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相对于RDB会慢一些</p><p><strong>问题：重写过程中，AOF文件被更改了怎么办？</strong></p><p>Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 </p><p>重写的流程是这样，</p><ul><li>主进程会fork一个子进程出来进行AOF重写，这个重写过程并不是基于原有的aof文件来做的，而是有点类似于快照的方式，全量遍历内存中的数据，然后逐个序列到aof文件中。</li><li>在fork子进程这个过程中，服务端仍然可以对外提供服务，<strong>那这个时候重写的aof文件的数据和redis内存数据不一致了怎么办？</strong>不用担心，这个过程中，主进程的数据更新操作，会缓存到<strong>aof_rewrite_buf</strong>中，也就是单独开辟一块缓存来存储重写期间收到的命令，当子进程重写完以后再把缓存中的数据追加到新的aof文件。</li><li>当所有的数据全部追加到新的aof文件中后，把新的aof文件重命名正式的文件名字，此后所有的操作都会被写入新的aof文件。</li><li>如果在rewrite过程中出现故障，不会影响原来aof文件的正常工作，只有当rewrite完成后才会切换文件。因此这个rewrite过程是比较可靠的。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110191352315.png" alt="img"></p><center>图4-26</center><p>Redis允许同时开启AOF和RDB，既保证了数据安全又使得进行备份等操作十分容易。如果同时开启后，Redis重启会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的数据更少。</p><h2 id="AOF的优劣势"><a href="#AOF的优劣势" class="headerlink" title="AOF的优劣势"></a>AOF的优劣势</h2><p><strong>优点：</strong></p><p>1、AOF 持久化的方法提供了多种的同步频率，即使使用默认的同步频率每秒同步一次，Redis 最多也就丢失 1 秒的数据而已。</p><p><strong>缺点：</strong></p><p>1、对于具有相同数据的的Redis，AOF 文件通常会比 RDB 文件体积更大（RDB存的是数据快照）。</p><p>2、虽然 AOF 提供了多种同步的频率，默认情况下，每秒同步一次的频率也具有较高的性能。在高并发的情况下，RDB 比 AOF 具好更好的性能保证。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> 高性能 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Redis持久化 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>时间轮机制在Redisson分布式锁中的实际应用以及时间轮源码分析</title>
      <link href="/posts/1553902520/"/>
      <url>/posts/1553902520/</url>
      
        <content type="html"><![CDATA[<p>本篇文章主要基于Redisson中实现的分布式锁机制继续进行展开，分析Redisson中的时间轮机制。</p><p>在前面分析的Redisson的分布式锁实现中，有一个Watch Dog机制来对锁键进行续约，代码如下:</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">renewExpiration</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ExpirationEntry ee = EXPIRATION_RENEWAL_MAP.get(getEntryName());</span><br><span class="line">    <span class="keyword">if</span> (ee == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//用到了时间轮机制</span></span><br><span class="line">    Timeout task = commandExecutor.getConnectionManager().newTimeout(<span class="keyword">new</span> TimerTask() &#123;</span><br><span class="line">        <span class="comment">//添加一个任务到时间轮 </span></span><br><span class="line">        <span class="comment">//省略部分代码....</span></span><br><span class="line">    &#125;, internalLockLeaseTime / <span class="number">3</span>, TimeUnit.MILLISECONDS);<span class="comment">//每次间隔租期的1/3时间执行</span></span><br><span class="line"></span><br><span class="line">    ee.setTimeout(task);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际上是构建了一个TimerTask，通过<code>timer.newTimeout(task, delay, unit);</code>添加到时间轮中。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Timeout <span class="title">newTimeout</span><span class="params">(TimerTask task, <span class="keyword">long</span> delay, TimeUnit unit)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="comment">//delay: 延迟执行时间</span></span><br><span class="line">        <span class="comment">//unit： 延迟执行时间单位</span></span><br><span class="line">        <span class="keyword">return</span> timer.newTimeout(task, delay, unit);</span><br><span class="line">    &#125; <span class="keyword">catch</span> (IllegalStateException e) &#123;</span><br><span class="line">        <span class="keyword">if</span> (isShuttingDown()) &#123;</span><br><span class="line">            <span class="keyword">return</span> DUMMY_TIMEOUT;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">throw</span> e;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> HashedWheelTimer timer;</span><br></pre></td></tr></table></figure><h2 id="先来了解一下什么是时间轮"><a href="#先来了解一下什么是时间轮" class="headerlink" title="先来了解一下什么是时间轮"></a>先来了解一下什么是时间轮</h2><p>时间轮这个技术其实出来很久了，在kafka、zookeeper等技术中都有时间轮使用的方式。我第一次听这个概念，是当时我一个朋友在拼多多，负责整体架构设计时需要考虑到超时订单的自动关单，而订单交易量又特别多，直接去轮询数据的效率有点低，所以当时沟通下来聊到了时间轮这个东西。什么是时间轮呢？</p><p>简单来说： 时间轮是一种高效利用线程资源进行批量化调度的一种调度模型。把大批量的调度任务全部绑定到同一个调度器上，使用这一个调度器来进行所有任务的管理、触发、以及运行。</p><p>所以时间轮的模型能够高效管理各种延时任务、周期任务、通知任务。 以后大家在工作中遇到类似的功能，可以采用时间轮机制。</p><p>如图3-11，时间轮，从图片上来看，就和手表的表圈是一样，所以称为时间轮，是因为它是以时间作为刻度组成的一个环形队列，这个环形队列采用数组来实现，数组的每个元素称为槽，每个槽可以放一个定时任务列表，叫HashedWheelBucket，它是一个双向链表，量表的每一项表示一个定时任务项（HashedWhellTimeout），其中封装了真正的定时任务TimerTask。</p><p>时间轮是由多个时间格组成，下图中有8个时间格，每个时间格代表当前时间轮的基本时间跨度（tickDuration），其中时间轮的时间格的个数是固定的。</p><p>在下图中，有8个时间格（槽），假设每个时间格的单位为1s，那么整个时间轮走完一圈需要8s钟。每秒钟指针会沿着顺时针方向移动一个，这个单位可以设置，比如以秒为单位，可以以一小时为单位，这个单位可以代表时间精度。通过指针移动，来获得每个时间格中的任务列表，然后遍历这一个时间格中的双向链表来执行任务，以此循环。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320370.png" alt="img"></p><center>图3-11</center><h2 id="时间轮的使用"><a href="#时间轮的使用" class="headerlink" title="时间轮的使用"></a>时间轮的使用</h2><p>这里使用的时间轮是Netty这个包中提供的，使用方法比较简单。</p><ul><li>先构建一个HashedWheelTimer时间轮。<ul><li>tickDuration： 100  ，表示每个时间格代表当前时间轮的基本时间跨度，这里是100ms，也就是指针100ms跳动一次，每次跳动一个窗格</li><li>ticksPerWheel：1024，表示时间轮上一共有多少个窗格，分配的窗格越多，占用内存空间就越大</li><li>leakDetection：是否开启内存泄漏检测。</li><li>maxPendingTimeouts[可选参数]，最大允许等待的任务数，默认没有限制。</li></ul></li><li>通过newTimeout()把需要延迟执行的任务添加到时间轮中</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedissonController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    RedissonClient redissonClient;</span><br><span class="line">    HashedWheelTimer hashedWheelTimer= <span class="keyword">new</span> HashedWheelTimer(<span class="keyword">new</span> DefaultThreadFactory(<span class="string">&quot;demo-timer&quot;</span>), <span class="number">100</span>, TimeUnit.MILLISECONDS, <span class="number">1024</span>, <span class="keyword">false</span>);</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 添加延迟任务</span></span><br><span class="line"><span class="comment">     * <span class="doctag">@param</span> delay</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/&#123;delay&#125;&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">tick</span><span class="params">(<span class="meta">@PathVariable(&quot;delay&quot;)</span>Long delay)</span></span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;currentDate:&quot;</span>+<span class="keyword">new</span> Date());</span><br><span class="line">        hashedWheelTimer.newTimeout(timeout -&gt; &#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;executeDate:&quot;</span>+<span class="keyword">new</span> Date());</span><br><span class="line">        &#125;, delay, TimeUnit.SECONDS);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="时间轮的原理解析"><a href="#时间轮的原理解析" class="headerlink" title="时间轮的原理解析"></a>时间轮的原理解析</h2><p>时间轮的整体原理，分为几个部分。</p><ul><li><p>创建时间轮</p><p>时间轮本质上是一个环状数组，比如我们初始化时间轮时：ticksPerWheel=8，那么意味着这个环状数组的长度是8，如图3-12所示。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">HashedWheelBucket[] wheel = <span class="keyword">new</span> HashedWheelBucket[ticksPerWheel];</span><br></pre></td></tr></table></figure><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320708.png" alt="image-20210707210354869"></p><center>图3-12</center></li><li><p>添加任务，如图3-13所示</p><ul><li><p>当通过newTimeout()方法添加一个延迟任务时，该任务首先会加入到一个阻塞队列中中。</p></li><li><p>然后会有一个定时任务从该队列获取任务，添加到时间轮的指定位置，计算方法如下。</p></li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//当前任务的开始执行时间除以每个窗口的时间间隔，得到一个calculated值（表示需要经过多少tick，指针没跳动一个窗格，tick会递增），单位为nanos（微毫秒）</span></span><br><span class="line"><span class="keyword">long</span> calculated = timeout.deadline / tickDuration;</span><br><span class="line"><span class="comment">//计算当前任务需要在时间轮中经历的圈数，因为当前任务执行时间有可能大于完整一圈的时间，所以需要计算经过几圈之后才能执行该任务。</span></span><br><span class="line">timeout.remainingRounds = (calculated - tick) / wheel.length;</span><br><span class="line"><span class="comment">//取最大的一个tick，有可能当前任务在队列中已经过了执行时间，这种情况下直接用calculated这个值就没意义了。</span></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">long</span> ticks = Math.max(calculated, tick); <span class="comment">// Ensure we don&#x27;t schedule for past.</span></span><br><span class="line"><span class="keyword">int</span> stopIndex = (<span class="keyword">int</span>) (ticks &amp; mask); <span class="comment">//通过ticks取模mask，得到一个下标</span></span><br><span class="line"></span><br><span class="line">HashedWheelBucket bucket = wheel[stopIndex]; <span class="comment">//把任务添加到指定数组下标位置</span></span><br></pre></td></tr></table></figure><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320829.png" alt="image-20210707212929968"></p><center>图3-13</center></li><li><p>任务执行</p><p>Worker线程按照每次间隔时间转动后，得到该时间窗格中的任务链表，然后从链表的head开始逐个取出任务，有两个判断条件</p><ul><li>当前任务需要转动的圈数为0，表示任务是当前圈开始执行</li><li>当前任务达到了delay时间，也就是<code>timeout.deadline &lt;= deadline</code></li><li>最终调用timeout.expire()方法执行任务。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">expireTimeouts</span><span class="params">(<span class="keyword">long</span> deadline)</span> </span>&#123;</span><br><span class="line">    HashedWheelTimeout timeout = head;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// process all timeouts</span></span><br><span class="line">    <span class="keyword">while</span> (timeout != <span class="keyword">null</span>) &#123;</span><br><span class="line">        HashedWheelTimeout next = timeout.next;</span><br><span class="line">        <span class="keyword">if</span> (timeout.remainingRounds &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            next = remove(timeout);</span><br><span class="line">            <span class="keyword">if</span> (timeout.deadline &lt;= deadline) &#123;</span><br><span class="line">                timeout.expire();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="comment">// The timeout was placed into a wrong slot. This should never happen.</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(String.format(</span><br><span class="line">                    <span class="string">&quot;timeout.deadline (%d) &gt; deadline (%d)&quot;</span>, timeout.deadline, deadline));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (timeout.isCancelled()) &#123;</span><br><span class="line">            next = remove(timeout);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            timeout.remainingRounds --;</span><br><span class="line">        &#125;</span><br><span class="line">        timeout = next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h1 id="时间轮的源码分析"><a href="#时间轮的源码分析" class="headerlink" title="时间轮的源码分析"></a>时间轮的源码分析</h1><h2 id="HashedWheelTimer的构造"><a href="#HashedWheelTimer的构造" class="headerlink" title="HashedWheelTimer的构造"></a>HashedWheelTimer的构造</h2><ul><li>调用createWheel创建一个时间轮，时间轮数组一定是2的幂次方，比如传入的ticksPerWheel=6，那么初始化的wheel长度一定是8，这样是便于时间格的计算。</li><li>tickDuration，表示时间轮的跨度，代表每个时间格的时间精度，以纳秒的方式来表现。</li><li>把工作线程Worker封装成WorkerThread，从名字可以知道，它就是最终那个负责干活的线程。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashedWheelTimer</span><span class="params">(</span></span></span><br><span class="line"><span class="params"><span class="function">    ThreadFactory threadFactory,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">long</span> tickDuration, TimeUnit unit, <span class="keyword">int</span> ticksPerWheel,</span></span></span><br><span class="line"><span class="params"><span class="function">    <span class="keyword">long</span> maxPendingTimeouts)</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 创建时间轮基本的数据结构，一个数组。长度为不小于ticksPerWheel的最小2的n次方</span></span><br><span class="line">    wheel = createWheel(ticksPerWheel);</span><br><span class="line">    <span class="comment">// 这是一个标示符，用来快速计算任务应该呆的格子。</span></span><br><span class="line">    <span class="comment">// 我们知道，给定一个deadline的定时任务，其应该呆的格子=deadline%wheel.length.但是%操作是个相对耗时的操作，所以使用一种变通的位运算代替：</span></span><br><span class="line">    <span class="comment">// 因为一圈的长度为2的n次方，mask = 2^n-1后低位将全部是1，然后deadline&amp;mast == deadline%wheel.length</span></span><br><span class="line">    <span class="comment">// java中的HashMap在进行hash之后，进行index的hash寻址寻址的算法也是和这个一样的</span></span><br><span class="line">    mask = wheel.length - <span class="number">1</span>;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//时间轮的基本时间跨度，（tickDuration传入是1的话，这里会转换成1000000）</span></span><br><span class="line">    <span class="keyword">this</span>.tickDuration = unit.toNanos(tickDuration);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 校验是否存在溢出。即指针转动的时间间隔不能太长而导致tickDuration*wheel.length&gt;Long.MAX_VALUE</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>.tickDuration &gt;= Long.MAX_VALUE / wheel.length) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(String.format(</span><br><span class="line">            <span class="string">&quot;tickDuration: %d (expected: 0 &lt; tickDuration in nanos &lt; %d&quot;</span>,</span><br><span class="line">            tickDuration, Long.MAX_VALUE / wheel.length));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//把worker包装成thread</span></span><br><span class="line">    workerThread = threadFactory.newThread(worker);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">this</span>.maxPendingTimeouts = maxPendingTimeouts;</span><br><span class="line">    <span class="comment">//如果HashedWheelTimer实例太多，那么就会打印一个error日志</span></span><br><span class="line">    <span class="keyword">if</span> (INSTANCE_COUNTER.incrementAndGet() &gt; INSTANCE_COUNT_LIMIT &amp;&amp;</span><br><span class="line">        WARNED_TOO_MANY_INSTANCES.compareAndSet(<span class="keyword">false</span>, <span class="keyword">true</span>)) &#123;</span><br><span class="line">        reportTooManyInstances();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><ul><li>对传入的ticksPerWheel进行整形</li><li>初始化固定长度的HashedWheelBucket</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> HashedWheelBucket[] createWheel(<span class="keyword">int</span> ticksPerWheel) &#123;</span><br><span class="line">    <span class="keyword">if</span> (ticksPerWheel &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</span><br><span class="line">            <span class="string">&quot;ticksPerWheel must be greater than 0: &quot;</span> + ticksPerWheel);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (ticksPerWheel &gt; <span class="number">1073741824</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(</span><br><span class="line">            <span class="string">&quot;ticksPerWheel may not be greater than 2^30: &quot;</span> + ticksPerWheel);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//对传入的时间轮大小进行整形，整形成2的幂次方</span></span><br><span class="line">    ticksPerWheel = normalizeTicksPerWheel(ticksPerWheel);</span><br><span class="line">    <span class="comment">//初始化一个固定长度的Bucket数组</span></span><br><span class="line">    HashedWheelBucket[] wheel = <span class="keyword">new</span> HashedWheelBucket[ticksPerWheel];</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; wheel.length; i++) &#123;</span><br><span class="line">        wheel[i] = <span class="keyword">new</span> HashedWheelBucket();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> wheel;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="添加任务到时间轮"><a href="#添加任务到时间轮" class="headerlink" title="添加任务到时间轮"></a>添加任务到时间轮</h2><p>完成时间轮的初始化之后，并没有去启动时间轮，继续看FailbackClusterInvoker中的代码。</p><p>构建了一个RetryTimerTask，也就是一个重试的定时任务，接着把这个任务通过newTimeout加入到时间轮中，其中</p><ul><li>retryTimerTask，表示具体的重试任务</li><li>RETRY_FAILED_PERIOD ， 表示重试间隔时间，默认为5s</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">RetryTimerTask retryTimerTask = <span class="keyword">new</span> RetryTimerTask(loadbalance, invocation, invokers, lastInvoker, retries, RETRY_FAILED_PERIOD);</span><br><span class="line">failTimer.newTimeout(retryTimerTask, RETRY_FAILED_PERIOD, TimeUnit.SECONDS);</span><br></pre></td></tr></table></figure><p>调用newTimeout方法，把任务添加进来。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> Timeout <span class="title">newTimeout</span><span class="params">(TimerTask task, <span class="keyword">long</span> delay, TimeUnit unit)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (task == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException(<span class="string">&quot;task&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (unit == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> NullPointerException(<span class="string">&quot;unit&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//统计任务个数</span></span><br><span class="line">    <span class="keyword">long</span> pendingTimeoutsCount = pendingTimeouts.incrementAndGet();</span><br><span class="line">    <span class="comment">//判断最大任务数量是否超过限制</span></span><br><span class="line">    <span class="keyword">if</span> (maxPendingTimeouts &gt; <span class="number">0</span> &amp;&amp; pendingTimeoutsCount &gt; maxPendingTimeouts) &#123;</span><br><span class="line">        pendingTimeouts.decrementAndGet();</span><br><span class="line">        <span class="keyword">throw</span> <span class="keyword">new</span> RejectedExecutionException(<span class="string">&quot;Number of pending timeouts (&quot;</span></span><br><span class="line">                                             + pendingTimeoutsCount + <span class="string">&quot;) is greater than or equal to maximum allowed pending &quot;</span></span><br><span class="line">                                             + <span class="string">&quot;timeouts (&quot;</span> + maxPendingTimeouts + <span class="string">&quot;)&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">   <span class="comment">//如果时间轮没有启动，则通过start方法进行启动</span></span><br><span class="line">    start();</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// Add the timeout to the timeout queue which will be processed on the next tick.</span></span><br><span class="line">    <span class="comment">// During processing all the queued HashedWheelTimeouts will be added to the correct HashedWheelBucket.</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment">//计算任务的延迟时间，通过当前的时间+当前任务执行的延迟时间-时间轮启动的时间。</span></span><br><span class="line">    <span class="keyword">long</span> deadline = System.nanoTime() + unit.toNanos(delay) - startTime;</span><br><span class="line"></span><br><span class="line">     <span class="comment">//在delay为正数的情况下，deadline是不可能为负数</span></span><br><span class="line">    <span class="comment">//如果为负数，那么说明超过了long的最大值</span></span><br><span class="line">    <span class="keyword">if</span> (delay &gt; <span class="number">0</span> &amp;&amp; deadline &lt; <span class="number">0</span>) &#123;</span><br><span class="line">        deadline = Long.MAX_VALUE;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//创建一个Timeout任务，理论上来说，这个任务应该要加入到时间轮的时间格子中，但是这里并不是先添加到时间格，而是先</span></span><br><span class="line">    <span class="comment">//加入到一个阻塞队列，然后等到时间轮执行到下一个格子时，再从队列中取出最多100000个任务添加到指定的时间格（槽）中。</span></span><br><span class="line">    HashedWheelTimeout timeout = <span class="keyword">new</span> HashedWheelTimeout(<span class="keyword">this</span>, task, deadline);</span><br><span class="line">    timeouts.add(timeout);</span><br><span class="line">    <span class="keyword">return</span> timeout;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="start"><a href="#start" class="headerlink" title="start"></a>start</h3><p>任务添加到阻塞队列之后，我们再来看启动方法</p><p>start方法会根据当前的workerState状态来启动时间轮。并且用了startTimeInitialized来控制线程的运行，如果workerThread没有启动起来，那么newTimeout方法会一直阻塞在运行start方法中。如果不阻塞，newTimeout方法会获取不到startTime。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">//workerState一开始的时候是0（WORKER_STATE_INIT），然后才会设置为1（WORKER_STATE_STARTED）</span></span><br><span class="line">    <span class="keyword">switch</span> (WORKER_STATE_UPDATER.get(<span class="keyword">this</span>)) &#123;</span><br><span class="line">        <span class="keyword">case</span> WORKER_STATE_INIT:</span><br><span class="line">            <span class="keyword">if</span> (WORKER_STATE_UPDATER.compareAndSet(<span class="keyword">this</span>, WORKER_STATE_INIT, WORKER_STATE_STARTED)) &#123;</span><br><span class="line">                workerThread.start();</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> WORKER_STATE_STARTED:</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> WORKER_STATE_SHUTDOWN:</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(<span class="string">&quot;cannot be started once stopped&quot;</span>);</span><br><span class="line">        <span class="keyword">default</span>:</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> Error(<span class="string">&quot;Invalid WorkerState&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 等待worker线程初始化时间轮的启动时间</span></span><br><span class="line">    <span class="keyword">while</span> (startTime == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//这里使用countDownLauch来确保调度的线程已经被启动</span></span><br><span class="line">            startTimeInitialized.await();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException ignore) &#123;</span><br><span class="line">            <span class="comment">// Ignore - it will be ready very soon.</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="启动时间轮"><a href="#启动时间轮" class="headerlink" title="启动时间轮"></a>启动时间轮</h3><p>调用start（）方法， 会调用<code>workerThread.start();</code>来启动一个工作线程，这个工作线程是在构造方法中初始化的，包装的是一个Worker内部线程类。</p><p>所以直接进入到Worker这个类的run方法，了解下它的设计逻辑</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 初始化startTime，表示时间轮的启动时间</span></span><br><span class="line">    startTime = System.nanoTime();</span><br><span class="line">    <span class="keyword">if</span> (startTime == <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// We use 0 as an indicator for the uninitialized value here, so make sure it&#x27;s not 0 when initialized.</span></span><br><span class="line">        startTime = <span class="number">1</span>;</span><br><span class="line">    &#125; </span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 唤醒被阻塞的start()方法。</span></span><br><span class="line">    startTimeInitialized.countDown();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">do</span> &#123;</span><br><span class="line">        <span class="comment">//返回每tick一次的时间间隔</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">long</span> deadline = waitForNextTick();</span><br><span class="line">        <span class="keyword">if</span> (deadline &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">//计算时间轮的槽位</span></span><br><span class="line">            <span class="keyword">int</span> idx = (<span class="keyword">int</span>) (tick &amp; mask);</span><br><span class="line">            <span class="comment">//移除掉CancelledTask</span></span><br><span class="line">            processCancelledTasks();</span><br><span class="line">            <span class="comment">//得到当前指针位置的时间槽</span></span><br><span class="line">            HashedWheelBucket bucket =</span><br><span class="line">                wheel[idx];</span><br><span class="line">            <span class="comment">//将newTimeout()方法中加入到待处理定时任务队列中的任务加入到指定的格子中</span></span><br><span class="line">            transferTimeoutsToBuckets();</span><br><span class="line">            <span class="comment">//运行目前指针指向的槽中的bucket链表中的任务</span></span><br><span class="line">            bucket.expireTimeouts(deadline);</span><br><span class="line">            tick++;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; <span class="keyword">while</span> (WORKER_STATE_UPDATER.get(HashedWheelTimer.<span class="keyword">this</span>) == WORKER_STATE_STARTED);</span><br><span class="line">     <span class="comment">//如果Worker_State一只是started状态，就一直循环</span></span><br><span class="line">    <span class="comment">// Fill the unprocessedTimeouts so we can return them from stop() method.</span></span><br><span class="line">    </span><br><span class="line">    <span class="keyword">for</span> (HashedWheelBucket bucket : wheel) &#123;</span><br><span class="line">        bucket.clearTimeouts(unprocessedTimeouts); <span class="comment">//清除时间轮中不需要处理的任务</span></span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">for</span> (; ; ) &#123;</span><br><span class="line">        <span class="comment">//遍历任务队列，发现如果有任务被取消，则添加到unprocessedTimeouts,也就是不需要处理的队列中。</span></span><br><span class="line">        HashedWheelTimeout timeout = timeouts.poll();</span><br><span class="line">        <span class="keyword">if</span> (timeout == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">       </span><br><span class="line">        <span class="keyword">if</span> (!timeout.isCancelled()) &#123;</span><br><span class="line">            unprocessedTimeouts.add(timeout);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//处理被取消的任务.</span></span><br><span class="line">    processCancelledTasks();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="时间轮指针跳动"><a href="#时间轮指针跳动" class="headerlink" title="时间轮指针跳动"></a>时间轮指针跳动</h2><p>这个方法的主要作用就是返回下一个指针指向的时间间隔，然后进行sleep操作。</p><p>大家可以想象一下，一个钟表上秒与秒之间是有时间间隔的，那么waitForNextTick就是根据当前时间计算出跳动到下个时间的时间间隔，然后进行sleep，然后再返回当前时间距离时间轮启动时间的时间间隔。</p><p>说得再直白一点：，假设当前的tickDuration的间隔是1s，tick默认=0， 此时第一次进来，得到的deadline=1，也就是下一次跳动的时间间隔是1s。假设当前处于</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">long</span> <span class="title">waitForNextTick</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">//tick表示总的tick数</span></span><br><span class="line">    <span class="comment">//tickDuration表示每个时间格的跨度，所以deadline返回的是下一次时间轮指针跳动的时间</span></span><br><span class="line">    <span class="keyword">long</span> deadline = tickDuration * (tick + <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (; ; ) &#123;</span><br><span class="line">        <span class="comment">//计算当前时间距离启动时间的时间间隔</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">long</span> currentTime = System.nanoTime() - startTime;</span><br><span class="line">        <span class="comment">//通过下一次指针跳动的延迟时间距离当前时间的差额，这个作为sleep时间使用。</span></span><br><span class="line">        <span class="comment">// 其实线程是以睡眠一定的时候再来执行下一个ticket的任务的</span></span><br><span class="line">        <span class="keyword">long</span> sleepTimeMs = (deadline - currentTime + <span class="number">999999</span>) / <span class="number">1000000</span>;</span><br><span class="line">        <span class="comment">//sleepTimeMs小于零表示走到了下一个时间槽位置</span></span><br><span class="line">        <span class="keyword">if</span> (sleepTimeMs &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (currentTime == Long.MIN_VALUE) &#123;</span><br><span class="line">                <span class="keyword">return</span> -Long.MAX_VALUE;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">return</span> currentTime;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (isWindows()) &#123;</span><br><span class="line">            sleepTimeMs = sleepTimeMs / <span class="number">10</span> * <span class="number">10</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//进入到这里进行sleep，表示当前时间距离下一次tick时间还有一段距离，需要sleep。</span></span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            Thread.sleep(sleepTimeMs);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException ignored) &#123;</span><br><span class="line">            <span class="keyword">if</span> (WORKER_STATE_UPDATER.get(HashedWheelTimer.<span class="keyword">this</span>) == WORKER_STATE_SHUTDOWN) &#123;</span><br><span class="line">                <span class="keyword">return</span> Long.MIN_VALUE;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="transferTimeoutsToBuckets"><a href="#transferTimeoutsToBuckets" class="headerlink" title="transferTimeoutsToBuckets"></a>transferTimeoutsToBuckets</h2><p>转移任务到时间轮中，前面我们讲过，任务添加进来时，是先放入到阻塞队列。</p><p>而在现在这个方法中，就是把阻塞队列中的数据转移到时间轮的指定位置。</p><p>在这个转移方法中，写死了一个循环，每次都只转移10万个任务。</p><p>然后根据HashedWheelTimeout的deadline延迟时间计算出时间轮需要运行多少次才能运行当前的任务，如果当前的任务延迟时间大于时间轮跑一圈所需要的时间，那么就计算需要跑几圈才能到这个任务运行。</p><p>最后计算出该任务在时间轮中的槽位，添加到时间轮的链表中。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">transferTimeoutsToBuckets</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="comment">// 循环100000次，也就是每次转移10w个任务</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100000</span>; i++) &#123;</span><br><span class="line">        <span class="comment">//从阻塞队列中获得具体的任务</span></span><br><span class="line">        HashedWheelTimeout timeout = timeouts.poll();</span><br><span class="line">        <span class="keyword">if</span> (timeout == <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// all processed</span></span><br><span class="line">            <span class="keyword">break</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (timeout.state() == HashedWheelTimeout.ST_CANCELLED) &#123;</span><br><span class="line">            <span class="comment">// Was cancelled in the meantime.</span></span><br><span class="line">            <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//计算tick次数，deadline表示当前任务的延迟时间，tickDuration表示时间槽的间隔，两者相除就可以计算当前任务需要tick几次才能被执行</span></span><br><span class="line">        <span class="keyword">long</span> calculated = timeout.deadline / tickDuration;</span><br><span class="line">         <span class="comment">// 计算剩余的轮数, 只有 timer 走够轮数, 并且到达了 task 所在的 slot, task 才会过期.(被执行)</span></span><br><span class="line">        timeout.remainingRounds = (calculated - tick) / wheel.length;</span><br><span class="line">     </span><br><span class="line">        <span class="comment">//如果任务在timeouts队列里面放久了, 以至于已经过了执行时间, 这个时候就使用当前tick, 也就是放到当前bucket, 此方法调用完后就会被执行</span></span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">long</span> ticks = Math.max(calculated, tick);</span><br><span class="line">        <span class="comment">// 算出任务应该插入的 wheel 的 slot, stopIndex = tick 次数 &amp; mask, mask = wheel.length - 1</span></span><br><span class="line">        <span class="keyword">int</span> stopIndex = (<span class="keyword">int</span>) (ticks &amp; mask);</span><br><span class="line">        <span class="comment">//把timeout任务插入到指定的bucket链中。</span></span><br><span class="line">        HashedWheelBucket bucket = wheel[stopIndex];</span><br><span class="line">        bucket.addTimeout(timeout);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="运行时间轮中的任务"><a href="#运行时间轮中的任务" class="headerlink" title="运行时间轮中的任务"></a>运行时间轮中的任务</h2><p>当指针跳动到某一个时间槽中时，会就触发这个槽中的任务的执行。该功能是通过expireTimeouts来实现</p><p>这个方法的主要作用是： 过期并执行格子中到期的任务。也就是当tick进入到指定格子时，worker线程会调用这个方法</p><p>HashedWheelBucket是一个链表，所以我们需要从head节点往下进行遍历。如果链表没有遍历到链表尾部那么就继续往下遍历。</p><p>获取的timeout节点节点，如果剩余轮数remainingRounds大于0，那么就说明要到下一圈才能运行，所以将剩余轮数减一；</p><p>如果当前剩余轮数小于等于零了，那么就将当前节点从bucket链表中移除，并判断一下当前的时间是否大于timeout的延迟时间，如果是则调用timeout的expire执行任务。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">expireTimeouts</span><span class="params">(<span class="keyword">long</span> deadline)</span> </span>&#123;</span><br><span class="line">    HashedWheelTimeout timeout = head;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 遍历当前时间槽中的所有任务</span></span><br><span class="line">    <span class="keyword">while</span> (timeout != <span class="keyword">null</span>) &#123;</span><br><span class="line">        HashedWheelTimeout next = timeout.next;</span><br><span class="line">        <span class="comment">//如果当前任务要被执行，那么remainingRounds应该小于或者等于0</span></span><br><span class="line">        <span class="keyword">if</span> (timeout.remainingRounds &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">//从bucket链表中移除当前timeout，并返回链表中下一个timeout</span></span><br><span class="line">            next = remove(timeout);</span><br><span class="line">            <span class="comment">//如果timeout的时间小于当前的时间，那么就调用expire执行task</span></span><br><span class="line">            <span class="keyword">if</span> (timeout.deadline &lt;= deadline) &#123;</span><br><span class="line">                timeout.expire();</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                 <span class="comment">//不可能发生的情况，就是说round已经为0了，deadline却&gt;当前槽的deadline</span></span><br><span class="line">                <span class="comment">// The timeout was placed into a wrong slot. This should never happen.</span></span><br><span class="line">                <span class="keyword">throw</span> <span class="keyword">new</span> IllegalStateException(String.format(</span><br><span class="line">                    <span class="string">&quot;timeout.deadline (%d) &gt; deadline (%d)&quot;</span>, timeout.deadline, deadline));</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (timeout.isCancelled()) &#123;</span><br><span class="line">            next = remove(timeout);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">//因为当前的槽位已经过了，说明已经走了一圈了，把轮数减一</span></span><br><span class="line">            timeout.remainingRounds--;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//把指针放置到下一个timeout</span></span><br><span class="line">        timeout = next;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Redisson </tag>
            
            <tag> 时间轮 </tag>
            
            <tag> Redisson分布式锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从源码层面深度剖析Redisson实现分布式锁的原理（全程干货，注意收藏）</title>
      <link href="/posts/1208754375/"/>
      <url>/posts/1208754375/</url>
      
        <content type="html"><![CDATA[<p>Redis的使用场景很多，本篇文章主要给大家分享一下Redis实现分布式锁机制的原理。</p><p>下面通过Redisson框架封装的分布式锁机制，来演示一下分布式锁的实现。</p><ul><li><p>引入redisson依赖</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.redisson<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>redisson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.16.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>编写简单的测试代码</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedissonTest</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> RedissonClient redissonClient;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">static</span> &#123;</span><br><span class="line">        Config config=<span class="keyword">new</span> Config();</span><br><span class="line">        config.useSingleServer().setAddress(<span class="string">&quot;redis://192.168.221.128:6379&quot;</span>);</span><br><span class="line">        redissonClient=Redisson.create(config);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        RLock rLock=redissonClient.getLock(<span class="string">&quot;updateOrder&quot;</span>);</span><br><span class="line">        <span class="comment">//最多等待100秒、上锁10s以后自动解锁</span></span><br><span class="line">        <span class="keyword">if</span>(rLock.tryLock(<span class="number">100</span>,<span class="number">10</span>,TimeUnit.SECONDS))&#123;</span><br><span class="line">            System.out.println(<span class="string">&quot;获取锁成功&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line">        Thread.sleep(<span class="number">2000</span>);</span><br><span class="line">        rLock.unlock();</span><br><span class="line"></span><br><span class="line">        redissonClient.shutdown();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure></li></ul><h1 id="Redisson分布式锁的实现原理"><a href="#Redisson分布式锁的实现原理" class="headerlink" title="Redisson分布式锁的实现原理"></a>Redisson分布式锁的实现原理</h1><p>你们会发现，通过redisson，非常简单就可以实现我们所需要的功能，当然这只是redisson的冰山一角，redisson最强大的地方就是提供了分布式特性的常用工具类。使得原本作为协调单机多线程并发程序的并发程序的工具包获得了协调分布式多级多线程并发系统的能力，降低了程序员在分布式环境下解决分布式问题的难度，下面分析一下RedissonLock的实现原理</p><h2 id="RedissonLock-tryLock"><a href="#RedissonLock-tryLock" class="headerlink" title="RedissonLock.tryLock"></a>RedissonLock.tryLock</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> time = unit.toMillis(waitTime);</span><br><span class="line">    <span class="keyword">long</span> current = System.currentTimeMillis();</span><br><span class="line">    <span class="keyword">long</span> threadId = Thread.currentThread().getId();</span><br><span class="line">    <span class="comment">//通过tryAcquire方法尝试获取锁</span></span><br><span class="line">    Long ttl = tryAcquire(waitTime, leaseTime, unit, threadId);</span><br><span class="line">    <span class="comment">// lock acquired</span></span><br><span class="line">    <span class="keyword">if</span> (ttl == <span class="keyword">null</span>) &#123; <span class="comment">//表示成功获取到锁，直接返回</span></span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//省略部分代码....</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="tryAcquire"><a href="#tryAcquire" class="headerlink" title="tryAcquire"></a>tryAcquire</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;T&gt; <span class="function">RFuture&lt;Long&gt; <span class="title">tryAcquireAsync</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit, <span class="keyword">long</span> threadId)</span> </span>&#123;</span><br><span class="line">    RFuture&lt;Long&gt; ttlRemainingFuture;</span><br><span class="line">    <span class="comment">//leaseTime就是租约时间，就是redis key的过期时间。</span></span><br><span class="line">    <span class="keyword">if</span> (leaseTime != -<span class="number">1</span>) &#123; <span class="comment">//如果设置过期时间</span></span><br><span class="line">        ttlRemainingFuture = tryLockInnerAsync(waitTime, leaseTime, unit, threadId, RedisCommands.EVAL_LONG);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;<span class="comment">//如果没设置了过期时间，则从配置中获取key超时时间,默认是30s过期</span></span><br><span class="line">        ttlRemainingFuture = tryLockInnerAsync(waitTime, internalLockLeaseTime,</span><br><span class="line">                                               TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//当tryLockInnerAsync执行结束后，触发下面回调</span></span><br><span class="line">    ttlRemainingFuture.onComplete((ttlRemaining, e) -&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123; <span class="comment">//说明出现异常，直接返回</span></span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// lock acquired</span></span><br><span class="line">        <span class="keyword">if</span> (ttlRemaining == <span class="keyword">null</span>) &#123; <span class="comment">//表示第一次设置锁键</span></span><br><span class="line">            <span class="keyword">if</span> (leaseTime != -<span class="number">1</span>) &#123; <span class="comment">//表示设置过超时时间，更新internalLockLeaseTime，并返回</span></span><br><span class="line">                internalLockLeaseTime = unit.toMillis(leaseTime);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123; <span class="comment">//leaseTime=-1,启动Watch Dog</span></span><br><span class="line">                scheduleExpirationRenewal(threadId);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">return</span> ttlRemainingFuture;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="tryLockInnerAsync"><a href="#tryLockInnerAsync" class="headerlink" title="tryLockInnerAsync"></a>tryLockInnerAsync</h2><p>通过lua脚本来实现加锁的操作</p><ol><li><p>判断lock键是否存在，不存在直接调用hset存储当前线程信息并且设置过期时间,返回nil，告诉客户端直接获取到锁。</p></li><li><p>判断lock键是否存在，存在则将重入次数加1，并重新设置过期时间，返回nil，告诉客户端直接获取到锁。</p></li><li><p>被其它线程已经锁定，返回锁有效期的剩余时间，告诉客户端需要等待。</p></li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&lt;T&gt; <span class="function">RFuture&lt;T&gt; <span class="title">tryLockInnerAsync</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit, <span class="keyword">long</span> threadId, RedisStrictCommand&lt;T&gt; command)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> evalWriteAsync(getRawName(), LongCodec.INSTANCE, command,</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;exists&#x27;, KEYS[1]) == 0) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return redis.call(&#x27;pttl&#x27;, KEYS[1]);&quot;</span>,</span><br><span class="line">                          Collections.singletonList(getRawName()), unit.toMillis(leaseTime), getLockName(threadId));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>关于Lua脚本，我们稍后再解释。</p></blockquote><h2 id="unlock释放锁流程"><a href="#unlock释放锁流程" class="headerlink" title="unlock释放锁流程"></a>unlock释放锁流程</h2><p>释放锁的流程，脚本看起来会稍微复杂一点</p><ol><li><p>如果lock键不存在，通过<code>publish</code>指令发送一个消息表示锁已经可用。</p></li><li><p>如果锁不是被当前线程锁定，则返回nil</p></li><li><p>由于支持可重入，在解锁时将重入次数需要减1</p></li><li><p>如果计算后的重入次数&gt;0，则重新设置过期时间</p></li><li><p>如果计算后的重入次数&lt;=0，则发消息说锁已经可用</p></li></ol><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> RFuture&lt;Boolean&gt; <span class="title">unlockInnerAsync</span><span class="params">(<span class="keyword">long</span> threadId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[3]) == 0) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil;&quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;local counter = redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[3], -1); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;if (counter &gt; 0) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[2]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return 0; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;else &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;del&#x27;, KEYS[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;publish&#x27;, KEYS[2], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return 1; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil;&quot;</span>,</span><br><span class="line">                          Arrays.asList(getRawName(), getChannelName()), LockPubSub.UNLOCK_MESSAGE, internalLockLeaseTime, getLockName(threadId));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="RedissonLock有竞争的情况"><a href="#RedissonLock有竞争的情况" class="headerlink" title="RedissonLock有竞争的情况"></a>RedissonLock有竞争的情况</h1><p>有竞争的情况在redis端的lua脚本是相同的，只是不同的条件执行不同的redis命令。当通过tryAcquire发现锁被其它线程申请时，需要进入等待竞争逻辑中</p><ol><li><p>this.await返回false，说明等待时间已经超出获取锁最大等待时间，取消订阅并返回获取锁失败</p></li><li><p>this.await返回true，进入循环尝试获取锁。</p></li></ol><blockquote><p>继续看RedissonLock.tryLock后半部分代码如下：</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line"><span class="comment">//省略部分代码</span></span><br><span class="line">        time -= System.currentTimeMillis() - current;</span><br><span class="line">        <span class="keyword">if</span> (time &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">            acquireFailed(waitTime, unit, threadId);</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        current = System.currentTimeMillis();</span><br><span class="line">       <span class="comment">// 订阅监听redis消息，并且创建RedissonLockEntry</span></span><br><span class="line">        RFuture&lt;RedissonLockEntry&gt; subscribeFuture = subscribe(threadId);</span><br><span class="line">      <span class="comment">// 阻塞等待subscribe的future的结果对象，如果subscribe方法调用超过了time，说明已经超过了客户端设置的最大wait time，则直接返回false，取消订阅，不再继续申请锁了。</span></span><br><span class="line">        <span class="keyword">if</span> (!subscribeFuture.await(time, TimeUnit.MILLISECONDS)) &#123;</span><br><span class="line">            <span class="keyword">if</span> (!subscribeFuture.cancel(<span class="keyword">false</span>)) &#123; <span class="comment">//取消订阅</span></span><br><span class="line">                subscribeFuture.onComplete((res, e) -&gt; &#123;</span><br><span class="line">                    <span class="keyword">if</span> (e == <span class="keyword">null</span>) &#123;</span><br><span class="line">                        unsubscribe(subscribeFuture, threadId);</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">            &#125;</span><br><span class="line">            acquireFailed(waitTime, unit, threadId); <span class="comment">//表示抢占锁失败</span></span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>; <span class="comment">//返回false</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">//判断是否超时，如果等待超时，返回获的锁失败</span></span><br><span class="line">            time -= System.currentTimeMillis() - current;</span><br><span class="line">            <span class="keyword">if</span> (time &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                acquireFailed(waitTime, unit, threadId);</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//通过while循环再次尝试竞争锁</span></span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123; </span><br><span class="line">                <span class="keyword">long</span> currentTime = System.currentTimeMillis();</span><br><span class="line">                ttl = tryAcquire(waitTime, leaseTime, unit, threadId); <span class="comment">//竞争锁，返回锁超时时间</span></span><br><span class="line">                <span class="comment">// lock acquired</span></span><br><span class="line">                <span class="keyword">if</span> (ttl == <span class="keyword">null</span>) &#123; <span class="comment">//如果超时时间为null，说明获得锁成功</span></span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//判断是否超时，如果超时，表示获取锁失败</span></span><br><span class="line">                time -= System.currentTimeMillis() - currentTime;</span><br><span class="line">                <span class="keyword">if</span> (time &lt;= <span class="number">0</span>) &#123;</span><br><span class="line">                    acquireFailed(waitTime, unit, threadId);</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="comment">// 通过信号量(共享锁)阻塞,等待解锁消息.  (减少申请锁调用的频率)</span></span><br><span class="line"><span class="comment">// 如果剩余时间(ttl)小于wait time ,就在 ttl 时间内，从Entry的信号量获取一个许可(除非被中断或者一直没有可用的许可)。</span></span><br><span class="line"><span class="comment">// 否则就在wait time 时间范围内等待可以通过信号量</span></span><br><span class="line">                currentTime = System.currentTimeMillis();</span><br><span class="line">                <span class="keyword">if</span> (ttl &gt;= <span class="number">0</span> &amp;&amp; ttl &lt; time) &#123;</span><br><span class="line">                    subscribeFuture.getNow().getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS);</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    subscribeFuture.getNow().getLatch().tryAcquire(time, TimeUnit.MILLISECONDS);</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 更新等待时间(最大等待时间-已经消耗的阻塞时间)</span></span><br><span class="line">                time -= System.currentTimeMillis() - currentTime;</span><br><span class="line">                <span class="keyword">if</span> (time &lt;= <span class="number">0</span>) &#123; <span class="comment">//获取锁失败</span></span><br><span class="line">                    acquireFailed(waitTime, unit, threadId);</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">finally</span> &#123;</span><br><span class="line">            unsubscribe(subscribeFuture, threadId); <span class="comment">//取消订阅</span></span><br><span class="line">        &#125;</span><br><span class="line"><span class="comment">//        return get(tryLockAsync(waitTime, leaseTime, unit));</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h1 id="锁过期了怎么办？"><a href="#锁过期了怎么办？" class="headerlink" title="锁过期了怎么办？"></a>锁过期了怎么办？</h1><p>一般来说，我们去获得分布式锁时，为了避免死锁的情况，我们会对锁设置一个超时时间，但是有一种情况是，如果在指定时间内当前线程没有执行完，由于锁超时导致锁被释放，那么其他线程就会拿到这把锁，从而导致一些故障。</p><p>为了避免这种情况，Redisson引入了一个Watch Dog机制，这个机制是针对分布式锁来实现锁的自动续约，简单来说，如果当前获得锁的线程没有执行完，那么Redisson会自动给Redis中目标key延长超时时间。</p><blockquote><p>默认情况下，看门狗的续期时间是30s，也可以通过修改Config.lockWatchdogTimeout来另行指定。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">tryLock</span><span class="params">(<span class="keyword">long</span> waitTime, TimeUnit unit)</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> tryLock(waitTime, -<span class="number">1</span>, unit);  <span class="comment">//leaseTime=-1</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>实际上，当我们通过tryLock方法没有传递超时时间时，默认会设置一个30s的超时时间，避免出现死锁的问题。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> &lt;T&gt; <span class="function">RFuture&lt;Long&gt; <span class="title">tryAcquireAsync</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit, <span class="keyword">long</span> threadId)</span> </span>&#123;</span><br><span class="line">    RFuture&lt;Long&gt; ttlRemainingFuture;</span><br><span class="line">    <span class="keyword">if</span> (leaseTime != -<span class="number">1</span>) &#123; </span><br><span class="line">        ttlRemainingFuture = tryLockInnerAsync(waitTime, leaseTime, unit, threadId, RedisCommands.EVAL_LONG);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123; <span class="comment">//当leaseTime为-1时，leaseTime=internalLockLeaseTime，默认是30s，表示当前锁的过期时间。</span></span><br><span class="line">        </span><br><span class="line">        <span class="comment">//this.internalLockLeaseTime = commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout();</span></span><br><span class="line">        ttlRemainingFuture = tryLockInnerAsync(waitTime, internalLockLeaseTime,</span><br><span class="line">                                               TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG);</span><br><span class="line">    &#125;</span><br><span class="line">    ttlRemainingFuture.onComplete((ttlRemaining, e) -&gt; &#123;</span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123; <span class="comment">//说明出现异常，直接返回</span></span><br><span class="line">            <span class="keyword">return</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// lock acquired</span></span><br><span class="line">        <span class="keyword">if</span> (ttlRemaining == <span class="keyword">null</span>) &#123; <span class="comment">//表示第一次设置锁键</span></span><br><span class="line">            <span class="keyword">if</span> (leaseTime != -<span class="number">1</span>) &#123; <span class="comment">//表示设置过超时时间，更新internalLockLeaseTime，并返回</span></span><br><span class="line">                internalLockLeaseTime = unit.toMillis(leaseTime);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123; <span class="comment">//leaseTime=-1,启动Watch Dog</span></span><br><span class="line">                scheduleExpirationRenewal(threadId);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">    <span class="keyword">return</span> ttlRemainingFuture;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于默认设置了一个30s的过期时间，为了防止过期之后当前线程还未执行完，所以通过定时任务对过期时间进行续约。</p><ul><li>首先，会先判断在expirationRenewalMap中是否存在了entryName，这是个map结构，主要还是判断在这个服务实例中的加锁客户端的锁key是否存在，</li><li>如果已经存在了，就直接返回；主要是考虑到RedissonLock是可重入锁。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">scheduleExpirationRenewal</span><span class="params">(<span class="keyword">long</span> threadId)</span> </span>&#123;</span><br><span class="line">    ExpirationEntry entry = <span class="keyword">new</span> ExpirationEntry();</span><br><span class="line">    ExpirationEntry oldEntry = EXPIRATION_RENEWAL_MAP.putIfAbsent(getEntryName(), entry);</span><br><span class="line">    <span class="keyword">if</span> (oldEntry != <span class="keyword">null</span>) &#123;</span><br><span class="line">        oldEntry.addThreadId(threadId);</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;<span class="comment">// 第一次加锁的时候会调用，内部会启动WatchDog</span></span><br><span class="line">        entry.addThreadId(threadId);</span><br><span class="line">        renewExpiration();</span><br><span class="line">    </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>定义一个定时任务，该任务中调用<code>renewExpirationAsync</code>方法进行续约。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">renewExpiration</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ExpirationEntry ee = EXPIRATION_RENEWAL_MAP.get(getEntryName());</span><br><span class="line">    <span class="keyword">if</span> (ee == <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="keyword">return</span>;</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//用到了时间轮机制</span></span><br><span class="line">    Timeout task = commandExecutor.getConnectionManager().newTimeout(<span class="keyword">new</span> TimerTask() &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(Timeout timeout)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            ExpirationEntry ent = EXPIRATION_RENEWAL_MAP.get(getEntryName());</span><br><span class="line">            <span class="keyword">if</span> (ent == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            Long threadId = ent.getFirstThreadId();</span><br><span class="line">            <span class="keyword">if</span> (threadId == <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">return</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// renewExpirationAsync续约租期</span></span><br><span class="line">            RFuture&lt;Boolean&gt; future = renewExpirationAsync(threadId);</span><br><span class="line">            future.onComplete((res, e) -&gt; &#123;</span><br><span class="line">                <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    log.error(<span class="string">&quot;Can&#x27;t update lock &quot;</span> + getRawName() + <span class="string">&quot; expiration&quot;</span>, e);</span><br><span class="line">                    EXPIRATION_RENEWAL_MAP.remove(getEntryName());</span><br><span class="line">                    <span class="keyword">return</span>;</span><br><span class="line">                &#125;</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span> (res) &#123;</span><br><span class="line">                    <span class="comment">// reschedule itself</span></span><br><span class="line">                    renewExpiration();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;, internalLockLeaseTime / <span class="number">3</span>, TimeUnit.MILLISECONDS);<span class="comment">//每次间隔租期的1/3时间执行</span></span><br><span class="line"></span><br><span class="line">    ee.setTimeout(task);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>执行Lua脚本，对指定的key进行续约。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> RFuture&lt;Boolean&gt; <span class="title">renewExpirationAsync</span><span class="params">(<span class="keyword">long</span> threadId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return 1; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return 0;&quot;</span>,</span><br><span class="line">                          Collections.singletonList(getRawName()),</span><br><span class="line">                          internalLockLeaseTime, getLockName(threadId));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Lua脚本"><a href="#Lua脚本" class="headerlink" title="Lua脚本"></a>Lua脚本</h1><p>Lua是一个高效的轻量级脚本语言（和JavaScript类似），用标准C语言编写并以源代码形式开放， 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。Lua在葡萄牙语中是“月亮”的意思，它的logo形式卫星，寓意是Lua是一个“卫星语言”，能够方便地嵌入到其他语言中使用；其实在很多常见的框架中，都有嵌入Lua脚本的功能，比如OpenResty、Redis等。</p><p>使用Lua脚本的好处：</p><ol><li><p>减少网络开销，在Lua脚本中可以把多个命令放在同一个脚本中运行</p></li><li><p>原子操作，redis会将整个脚本作为一个整体执行，中间不会被其他命令插入。换句话说，编写脚本的过程中无需担心会出现竞态条件</p></li><li><p>复用性，客户端发送的脚本会永远存储在redis中，这意味着其他客户端可以复用这一脚本来完成同样的逻辑</p></li></ol><h2 id="Lua的下载和安装"><a href="#Lua的下载和安装" class="headerlink" title="Lua的下载和安装"></a>Lua的下载和安装</h2><p>Lua是一个独立的脚本语言，所以它有专门的编译执行工具，下面简单带大家安装一下。</p><ul><li><p>下载Lua源码包： <a href="https://www.lua.org/download.html">https://www.lua.org/download.html</a></p><p><a href="https://www.lua.org/ftp/lua-5.4.3.tar.gz">https://www.lua.org/ftp/lua-5.4.3.tar.gz</a></p></li><li><p>安装步骤如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">tar -zxvf lua-5.4.3.tar.gz</span><br><span class="line">cd lua-5.4.3</span><br><span class="line">make linux</span><br><span class="line">make install</span><br></pre></td></tr></table></figure></li></ul><p>如果报错，说找不到readline/readline.h, 可以通过yum命令安装</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">yum -y install readline-devel ncurses-devel</span><br></pre></td></tr></table></figure><p>最后，直接输入<code>lua</code>命令即可进入lua的控制台。Lua脚本有自己的语法、变量、逻辑运算符、函数等，这块我就不在这里做过多的说明，用过JavaScript的同学，应该只需要花几个小时就可以全部学完，简单演示两个案例如下。</p><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line">array = &#123;<span class="string">&quot;Lua&quot;</span>, <span class="string">&quot;mic&quot;</span>&#125;</span><br><span class="line"><span class="keyword">for</span> i= <span class="number">0</span>, <span class="number">2</span> <span class="keyword">do</span></span><br><span class="line">   <span class="built_in">print</span>(array[i])</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">array = &#123;&quot;mic&quot;, &quot;redis&quot;&#125;</span><br><span class="line"></span><br><span class="line">for key,value in ipairs(array)</span><br><span class="line">do</span><br><span class="line">   print(key, value)</span><br><span class="line">end</span><br></pre></td></tr></table></figure><h2 id="Redis与Lua"><a href="#Redis与Lua" class="headerlink" title="Redis与Lua"></a>Redis与Lua</h2><p>Redis中集成了Lua的编译和执行器，所以我们可以在Redis中定义Lua脚本去执行。同时，在Lua脚本中，可以直接调用Redis的命令，来操作Redis中的数据。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">redis.call(‘set’,&#x27;hello&#x27;,&#x27;world&#x27;)</span><br><span class="line"></span><br><span class="line">local value=redis.call(‘get’,’hello’) </span><br></pre></td></tr></table></figure><p>redis.call 函数的返回值就是redis命令的执行结果，前面我们介绍过redis的5中类型的数据返回的值的类型也都不一样，redis.call函数会将这5种类型的返回值转化对应的Lua的数据类型</p><p>在很多情况下我们都需要脚本可以有返回值，毕竟这个脚本也是一个我们所编写的命令集，我们可以像调用其他redis内置命令一样调用我们自己写的脚本，所以同样redis会自动将脚本返回值的Lua数据类型转化为Redis的返回值类型。 在脚本中可以使用return 语句将值返回给redis客户端，通过return语句来执行，如果没有执行return，默认返回为nil。</p><h2 id="Redis中执行Lua脚本相关的命令"><a href="#Redis中执行Lua脚本相关的命令" class="headerlink" title="Redis中执行Lua脚本相关的命令"></a>Redis中执行Lua脚本相关的命令</h2><p>编写完脚本后最重要的就是在程序中执行脚本。Redis提供了EVAL命令可以使开发者像调用其他Redis内置命令一样调用脚本。</p><h3 id="EVAL命令-执行脚本"><a href="#EVAL命令-执行脚本" class="headerlink" title="EVAL命令-执行脚本"></a>EVAL命令-执行脚本</h3><p><strong>[EVAL] [脚本内容] [key参数的数量] [key …] [arg …]</strong></p><p>可以通过key和arg这两个参数向脚本中传递数据，他们的值可以在脚本中分别使用<strong>KEYS</strong>和<strong>ARGV</strong> 这两个类型的全局变量访问。</p><p>比如我们通过脚本实现一个set命令，通过在redis客户端中调用，那么执行的语句是：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">eval &quot;return redis.call(&#x27;set&#x27;,KEYS[1],ARGV[1])&quot; 1 lua hello</span><br></pre></td></tr></table></figure><p>上述脚本相当于使用Lua脚本调用了Redis的<code>set</code>命令，存储了一个key=lua，value=hello到Redis中。</p><h3 id="EVALSHA命令"><a href="#EVALSHA命令" class="headerlink" title="EVALSHA命令"></a>EVALSHA命令</h3><p>考虑到我们通过eval执行lua脚本，脚本比较长的情况下，每次调用脚本都需要把整个脚本传给redis，比较占用带宽。为了解决这个问题，redis提供了EVALSHA命令允许开发者通过脚本内容的SHA1摘要来执行脚本。该命令的用法和EVAL一样，只不过是将脚本内容替换成脚本内容的SHA1摘要</p><ol><li><p>Redis在执行EVAL命令时会计算脚本的SHA1摘要并记录在脚本缓存中</p></li><li><p>执行EVALSHA命令时Redis会根据提供的摘要从脚本缓存中查找对应的脚本内容，如果找到了就执行脚本，否则返回“NOSCRIPT No matching script,Please use EVAL”</p></li></ol> <figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 将脚本加入缓存并生成sha1命令</span></span><br><span class="line">script load &quot;return redis.call(&#x27;get&#x27;,&#x27;lua&#x27;)&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash"> [<span class="string">&quot;13bd040587b891aedc00a72458cbf8588a27df90&quot;</span>]</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 传递sha1的值来执行该命令</span></span><br><span class="line">evalsha &quot;13bd040587b891aedc00a72458cbf8588a27df90&quot; 0</span><br></pre></td></tr></table></figure><h3 id="Redisson执行Lua脚本"><a href="#Redisson执行Lua脚本" class="headerlink" title="Redisson执行Lua脚本"></a>Redisson执行Lua脚本</h3><p>通过lua脚本来实现一个访问频率限制功能。</p><p>思路，定义一个key，key中包含ip地址。 value为指定时间内的访问次数，比如说是10秒内只能访问3次。</p><ul><li><p>定义Lua脚本。</p><figure class="highlight lua"><table><tr><td class="code"><pre><span class="line"><span class="keyword">local</span> times=redis.call(<span class="string">&#x27;incr&#x27;</span>,KEYS[<span class="number">1</span>])</span><br><span class="line"><span class="comment">-- 如果是第一次进来，设置一个过期时间</span></span><br><span class="line"><span class="keyword">if</span> times == <span class="number">1</span> <span class="keyword">then</span></span><br><span class="line">   redis.call(<span class="string">&#x27;expire&#x27;</span>,KEYS[<span class="number">1</span>],ARGV[<span class="number">1</span>])</span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">-- 如果在指定时间内访问次数大于指定次数，则返回0，表示访问被限制</span></span><br><span class="line"><span class="keyword">if</span> times &gt; <span class="built_in">tonumber</span>(ARGV[<span class="number">2</span>]) <span class="keyword">then</span></span><br><span class="line">   <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="keyword">end</span></span><br><span class="line"><span class="comment">-- 返回1，允许被访问</span></span><br><span class="line"><span class="keyword">return</span> <span class="number">1</span></span><br></pre></td></tr></table></figure></li><li><p>定义controller，提供访问测试方法</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedissonController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    RedissonClient redissonClient;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String LIMIT_LUA=</span><br><span class="line">        <span class="string">&quot;local times=redis.call(&#x27;incr&#x27;,KEYS[1])\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;if times == 1 then\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;   redis.call(&#x27;expire&#x27;,KEYS[1],ARGV[1])\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;end\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;if times &gt; tonumber(ARGV[2]) then\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;   return 0\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;end\n&quot;</span> +</span><br><span class="line">        <span class="string">&quot;return 1&quot;</span>;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/lua/&#123;id&#125;&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">lua</span><span class="params">(<span class="meta">@PathVariable(&quot;id&quot;)</span> Integer id)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException </span>&#123;</span><br><span class="line">        List&lt;Object&gt; keys= Arrays.asList(<span class="string">&quot;LIMIT:&quot;</span>+id);</span><br><span class="line">        RFuture&lt;Object&gt; future=redissonClient.getScript().</span><br><span class="line">            evalAsync(RScript.Mode.READ_WRITE,LIMIT_LUA, RScript.ReturnType.INTEGER,keys,<span class="number">10</span>,<span class="number">3</span>);</span><br><span class="line">        <span class="keyword">return</span> future.get().toString();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><p>需要注意，上述脚本执行的时候会有问题，因为redis默认的序列化方式导致value的值在传递到脚本中时，转成了对象类型，需要修改<code>redisson.yml</code>文件，增加codec的序列化方式。</p><ul><li><p><strong>application.yml</strong></p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">redisson:</span></span><br><span class="line">      <span class="attr">file:</span> <span class="string">classpath:redisson.yml</span></span><br></pre></td></tr></table></figure></li><li><p><strong>redisson.yml</strong></p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">singleServerConfig:</span></span><br><span class="line">  <span class="attr">address:</span> <span class="string">redis://192.168.221.128:6379</span></span><br><span class="line"></span><br><span class="line"><span class="attr">codec:</span> <span class="type">!&lt;org.redisson.codec.JsonJacksonCodec&gt;</span> &#123;&#125;</span><br></pre></td></tr></table></figure></li></ul><h2 id="Lua脚本的原子性"><a href="#Lua脚本的原子性" class="headerlink" title="Lua脚本的原子性"></a>Lua脚本的原子性</h2><p>redis的脚本执行是原子的，即脚本执行期间Redis不会执行其他命令。所有的命令必须等待脚本执行完以后才能执行。为了防止某个脚本执行时间过程导致Redis无法提供服务。Redis提供了lua-time-limit参数限制脚本的最长运行时间。默认是5秒钟。</p><h3 id="非事务性操作"><a href="#非事务性操作" class="headerlink" title="非事务性操作"></a>非事务性操作</h3><p>当脚本运行时间超过这个限制后，Redis将开始接受其他命令但不会执行（以确保脚本的原子性），而是返回BUSY的错误，下面演示一下这种情况。</p><p>打开两个客户端窗口，在第一个窗口中执行lua脚本的死循环</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">eval &quot;while true do end&quot; 0</span><br></pre></td></tr></table></figure><p>在第二个窗口中运行<code>get lua</code>，会得到如下的异常。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(error) BUSY Redis is busy running a script. You can only call SCRIPT KILL or SHUTDOWN NOSAVE.</span><br></pre></td></tr></table></figure><p>我们会发现执行结果是Busy， 接着我们通过<strong>script kill</strong> 的命令终止当前执行的脚本，第二个窗口的显示又恢复正常了。</p><h3 id="存在事务性操作"><a href="#存在事务性操作" class="headerlink" title="存在事务性操作"></a>存在事务性操作</h3><p>如果当前执行的Lua脚本对Redis的数据进行了修改（SET、DEL等），那么通过SCRIPT KILL 命令是不能终止脚本运行的，因为要保证脚本运行的原子性，如果脚本执行了一部分终止，那就违背了脚本原子性的要求。最终要保证脚本要么都执行，要么都不执行</p><p>同样打开两个窗口，第一个窗口运行如下命令</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">eval &quot;redis.call(&#x27;set&#x27;,&#x27;name&#x27;,&#x27;mic&#x27;) while true do end&quot; 0</span><br></pre></td></tr></table></figure><p>在第二个窗口运行</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">get lua</span><br></pre></td></tr></table></figure><p>结果一样，仍然是busy，但是这个时候通过script kill命令，会发现报错，没办法kill。</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(error) UNKILLABLE Sorry the script already executed write commands against the dataset. You can either wait the script termination or kill the server in a hard way using the SHUTDOWN NOSAVE command.</span><br></pre></td></tr></table></figure><p>遇到这种情况，只能通过<strong>shutdown nosave</strong>命令来强行终止redis。</p><p>shutdown nosave和shutdown的区别在于 shutdown nosave不会进行持久化操作，意味着发生在上一次快照后的数据库修改都会丢失。</p><h2 id="Redisson的Lua脚本"><a href="#Redisson的Lua脚本" class="headerlink" title="Redisson的Lua脚本"></a>Redisson的Lua脚本</h2><p>了解了lua之后，我们再回过头来看看Redisson的Lua脚本，就不难理解了。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">&lt;T&gt; <span class="function">RFuture&lt;T&gt; <span class="title">tryLockInnerAsync</span><span class="params">(<span class="keyword">long</span> waitTime, <span class="keyword">long</span> leaseTime, TimeUnit unit, <span class="keyword">long</span> threadId, RedisStrictCommand&lt;T&gt; command)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> evalWriteAsync(getRawName(), LongCodec.INSTANCE, command,</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;exists&#x27;, KEYS[1]) == 0) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[2]) == 1) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[2], 1); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return redis.call(&#x27;pttl&#x27;, KEYS[1]);&quot;</span>,</span><br><span class="line">                          Collections.singletonList(getRawName()), unit.toMillis(leaseTime), getLockName(threadId));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="Redis中的Pub-Sub机制"><a href="#Redis中的Pub-Sub机制" class="headerlink" title="Redis中的Pub/Sub机制"></a>Redis中的Pub/Sub机制</h1><p>下面是Redisson中释放锁的代码，在代码中我们发现一个publish的指令<code>redis.call(&#39;publish&#39;, KEYS[2], ARGV[1])</code>，这个指令是干啥的呢？</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">protected</span> RFuture&lt;Boolean&gt; <span class="title">unlockInnerAsync</span><span class="params">(<span class="keyword">long</span> threadId)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> evalWriteAsync(getRawName(), LongCodec.INSTANCE, RedisCommands.EVAL_BOOLEAN,</span><br><span class="line">                          <span class="string">&quot;if (redis.call(&#x27;hexists&#x27;, KEYS[1], ARGV[3]) == 0) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil;&quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;local counter = redis.call(&#x27;hincrby&#x27;, KEYS[1], ARGV[3], -1); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;if (counter &gt; 0) then &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;pexpire&#x27;, KEYS[1], ARGV[2]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return 0; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;else &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;del&#x27;, KEYS[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;redis.call(&#x27;publish&#x27;, KEYS[2], ARGV[1]); &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return 1; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;end; &quot;</span> +</span><br><span class="line">                          <span class="string">&quot;return nil;&quot;</span>,</span><br><span class="line">                          Arrays.asList(getRawName(), getChannelName()), LockPubSub.UNLOCK_MESSAGE, internalLockLeaseTime, getLockName(threadId));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Redis提供了一组命令可以让开发者实现“发布/订阅”模式(publish/subscribe) . 该模式同样可以实现进程间的消息传递，它的实现原理是：</p><ul><li><p>发布/订阅模式包含两种角色，分别是发布者和订阅者。订阅者可以订阅一个或多个频道，而发布者可以向指定的频道发送消息，所有订阅此频道的订阅者都会收到该消息</p></li><li><p>发布者发布消息的命令是PUBLISH， 用法是</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">PUBLISH channel message</span><br></pre></td></tr></table></figure><p>比如向channel.1发一条消息:hello</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">PUBLISH channel.1 “hello”</span><br></pre></td></tr></table></figure></li></ul><p>这样就实现了消息的发送，该命令的返回值表示接收到这条消息的订阅者数量。因为在执行这条命令的时候还没有订阅者订阅该频道，所以返回为0. 另外值得注意的是消息发送出去不会持久化，如果发送之前没有订阅者，那么后续再有订阅者订阅该频道，之前的消息就收不到了</p><p>订阅者订阅消息的命令是：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">SUBSCRIBE channel [channel …]</span><br></pre></td></tr></table></figure><p>该命令同时可以订阅多个频道，比如订阅channel.1的频道：<strong>SUBSCRIBE channel.1</strong>，执行SUBSCRIBE命令后客户端会进入订阅状态。</p><p>一般情况下，我们不会用pub/sub来做消息发送机制，毕竟有这么多MQ技术在。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Redisson </tag>
            
            <tag> 分布式锁 </tag>
            
            <tag> Redis应用实战 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Redis使用过程中有哪些注意事项？缓存雪崩？缓存一致性？</title>
      <link href="/posts/2137391109/"/>
      <url>/posts/2137391109/</url>
      
        <content type="html"><![CDATA[<p>Redis使用起来很简单，但是在实际应用过程中，一定会碰到一些比较麻烦的问题，常见的问题有</p><ul><li>redis和数据库数据的一致性</li><li>缓存雪崩</li><li>缓存穿透</li><li>热点数据发现</li></ul><p>下面逐一来分析这些问题的原理及解决方案。</p><h1 id="数据一致性"><a href="#数据一致性" class="headerlink" title="数据一致性"></a>数据一致性</h1><p>针对读多写少的高并发场景，我们可以使用缓存来提升查询速度。当我们使用Redis作为缓存的时候，一般流程如图3-4所示。</p><ul><li>如果数据在Redis存在，应用就可以直接从Redis拿到数据，不用访问数据库。</li><li>如果Redis里面没有，先到数据库查询，然后写入到Redis，再返回给应用。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320507.png" alt="image-20210705200053476"></p><center>图3-4</center><p>因为这些数据是很少修改的，所以在绝大部分的情况下可以命中缓存。但是，一旦被缓存的数据发生变化的时候，我们既要操作数据库的数据，也要操作Redis的数据，所以问题来了。现在我们有两种选择：</p><ul><li><p>先操作Redis的数据再操作数据库的数据</p></li><li><p>先操作数据库的数据再操作Redis的数据</p></li></ul><p>到底选哪一种？</p><p>首先需要明确的是，不管选择哪一种方案， 我们肯定是希望两个操作要么都成功，要么都一个都不成功。不然就会发生Redis跟数据库的数据不一致的问题。但是，Redis的数据和数据库的数据是不可能通过事务达到统一的，我们只能根据相应的场景和所需要付出的代价来采取一些措施降低数据不一致的问题出现的概率，在数据一致性和性能之间取得一个权衡。</p><p>对于数据库的实时性一致性要求不是特别高的场合，比如T+1的报表，可以采用定时任务查询数据库数据同步到Redis的方案。由于我们是以数据库的数据为准的，所以给缓存设置一个过期时间，是保证最终一致性的解决方案。</p><h2 id="Redis：删除还是更新？"><a href="#Redis：删除还是更新？" class="headerlink" title="Redis：删除还是更新？"></a>Redis：删除还是更新？</h2><p>这里我们先要补充一点，当存储的数据发生变化，Redis的数据也要更新的时候，我们有两种方案，一种就是直接更新，调用set；还有一种是直接删除缓存，让应用在下次查询的时候重新写入。</p><p>这两种方案怎么选择呢？这里我们主要考虑更新缓存的代价。</p><p>更新缓存之前，判断是不是要经过其他表的查询、接口调用、计算才能得到最新的数据，而不是直接从数据库拿到的值，如果是的话，建议直接删除缓存，这种方案更加简单，一般情况下也推荐删除缓存方案。</p><p>这一点明确之后，现在我们就剩一个问题：</p><ul><li><p>到底是先更新数据库，再删除缓存</p></li><li><p>还是先删除缓存，再更新数据库</p></li></ul><h2 id="先更新数据库，再删除缓存"><a href="#先更新数据库，再删除缓存" class="headerlink" title="先更新数据库，再删除缓存"></a>先更新数据库，再删除缓存</h2><p><strong>正常情况</strong>：更新数据库，成功。删除缓存，成功。</p><p><strong>异常情况</strong>：</p><p>1、更新数据库失败，程序捕获异常，不会走到下一步，所以数据不会出现不一致。</p><p>2、更新数据库成功，删除缓存失败。数据库是新数据，缓存是旧数据，发生了不一致的情况。</p><p>这种问题怎么解决呢？我们可以提供一个重试的机制。</p><p>比如：如果删除缓存失败，我们捕获这个异常，把需要删除的key发送到消息队列。然后自己创建一个消费者消费，尝试再次删除这个key，如图3-5所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320836.png" alt="image-20210705201740430"></p><center>图3-5</center><p>另外一种方案，<strong>异步更新缓存</strong>：</p><p>因为更新数据库时会往<strong>binlog</strong>写入日志，所以我们可以通过一个服务来监听<strong>binlog</strong>的变化（比如阿里的canal），然后在客户端完成删除key的操作。如果删除失败的话，再发送到消息队列。</p><p>总之，对于后删除缓存失败的情况，我们的做法是不断地重试删除，直到成功。无论是重试还是异步删除，都是最终一致性的思想，如图3-6所示。</p><blockquote><p>基于数据库增量日志解析，提供增量数据订阅&amp;消费，目前主要支持了mysql。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320962.png" alt="image-20210705202304171"></p><center>图3-6</center><h2 id="先删除缓存，再更新数据库"><a href="#先删除缓存，再更新数据库" class="headerlink" title="先删除缓存，再更新数据库"></a>先删除缓存，再更新数据库</h2><p>正常情况：删除缓存，成功。更新数据库，成功。</p><p>异常情况：</p><ul><li><p>删除缓存，程序捕获异常，不会走到下一步，所以数据不会出现不一致。</p></li><li><p>删除缓存成功，更新数据库失败。 因为以数据库的数据为准，所以不存在数据不一致的情况。</p></li></ul><p>看起来好像没问题，但是如果有程序并发操作的情况下：</p><ul><li><p>线程A需要更新数据，首先删除了Redis缓存</p></li><li><p>线程B查询数据，发现缓存不存在，到数据库查询旧值，写入Redis，返回</p></li><li><p>线程A更新了数据库</p></li></ul><p>这个时候，Redis是旧的值，数据库是新的值，发生了数据不一致的情况，如图3-7所示，这种情况就比较难处理了，只有针对同一条数据进行串行化访问，才能解决这个问题，但是这种实现起来对性能影响较大，因此一般情况下不会采用这种做法。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320709.png" alt="image-20210705204932980"></p><center>图3-7</center><h1 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h1><p>缓存雪崩就是Redis的大量热点数据同时过期（失效），因为设置了相同的过期时间，刚好这个时候Redis请求的并发量又很大，就会导致所有的请求落到数据库。</p><h2 id="关于缓存过期"><a href="#关于缓存过期" class="headerlink" title="关于缓存过期"></a>关于缓存过期</h2><p>在实际开发中，我们经常会，比如限时优惠、缓存、验证码有效期等。一旦过了指定的有效时间就需要自动删除这些数据，否则这些无效数据会一直占用内存但是缺没有任何价值，因此在Redis中提供了Expire命令设置一个键的过期时间，到期以后Redis会自动删除它。这个在我们实际使用过程中用得非常多。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">expire key seconds # 设置键在给定秒后过期</span><br><span class="line">pexpire key milliseconds # 设置键在给定毫秒后过期</span><br><span class="line"></span><br><span class="line">expireat key timestamp # 到达指定秒数时间戳之后键过期</span><br><span class="line">pexpireat key timestamp # 到达指定毫秒数时间戳之后键过期</span><br></pre></td></tr></table></figure><p>EXPIRE 返回值为1表示设置成功，0表示设置失败或者键不存在，如果向知道一个键还有多久时间被删除，可以使用TTL命令</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ttl key # 返回键多少秒后过期</span><br><span class="line">pttl key # 返回键多少毫秒后过期</span><br></pre></td></tr></table></figure><p>当键不存在时，TTL命令会返回-2，而对于没有给指定键设置过期时间的，通过TTL命令会返回-1。</p><p>除此之外，针对String类型的key的过期时间，我们还可以通过下面这个方法来设置，其中可选参数<code>ex</code>表示设置过期时间。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set key value [ex seconds]</span><br></pre></td></tr></table></figure><p>如果向取消键的过期时间设置（使该键恢复成为永久的），可以使用PERSIST命令，如果该命令执行成功或者成功清除了过期时间，则返回1 。 否则返回0（键不存在或者本身就是永久的）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">SET expire.demo 1 ex 20</span><br><span class="line">TTL expire.demo</span><br><span class="line">PERSIST expire.demo</span><br><span class="line">TTL expire</span><br></pre></td></tr></table></figure><p>除了PERSIST命令，使用set命令为键赋值的操作也会导致过期时间失效。</p><h2 id="关于key过期的实现原理"><a href="#关于key过期的实现原理" class="headerlink" title="关于key过期的实现原理"></a>关于key过期的实现原理</h2><p>Redis使用一个过期字典（Redis字典使用哈希表实现，可以将字典看作哈希表）存储键的过期时间，字典的键是指向数据库键的指针（使用指针可以避免浪费内存空间），字典的值是一个毫秒时间戳，所以在当前时间戳大于字典值的时候这个键就过期了，就可以对这个键进行删除（删除一个键不仅要删除数据库中的键，也要删除过期字典中的键）。</p><p>设置过期时间的命令都是使用<code>pexpireat</code>命令实现的，其他命令也会转换成<code>pexpireat</code>。给一个键设置过期时间，就是将这个键的指针以及给定的到期时间戳添加到过期字典中。比如，执行命令<code>pexpireat key 1608290696843</code>，那么过期字典结构将如图3-8所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320438.png" alt="image-20210705221859849"></p><center>图3-8</center><h2 id="过期键的删除"><a href="#过期键的删除" class="headerlink" title="过期键的删除"></a>过期键的删除</h2><p>过期键的删除有两种方法。</p><ul><li><p>被动方式删除</p><p>被动方式的核心原理是，当客户端尝试访问某个key时，发现当前key已经过期了，就直接删除这个key。</p><p>当然，有可能会存在一些key，一直没有客户端访问，就会导致这部分key一直占用内存，因此加了一个主动删除方式。</p></li><li><p>主动方式删除</p><p>主动删除就是Redis定期扫描国期间中的key进行删除，它的删除策略是：</p><ul><li>从过期键中随机获取20个key，删除这20个key中已经过期的key。</li><li>如果在这20个key中有超过25%的key过期，则重新执行当前步骤。实际上这是利用了一种概率算法。</li></ul></li></ul><p>Redis结合这两种设计很好的解决了过期key的处理问题。</p><h2 id="如何解决缓存雪崩"><a href="#如何解决缓存雪崩" class="headerlink" title="如何解决缓存雪崩"></a>如何解决缓存雪崩</h2><p>了解了过期key的删除后，再来分析缓存雪崩问题。缓存雪崩有几个方面的原因导致。</p><ul><li>Redis的大量热点数据同时过期（失效）</li><li>Redis服务器出现故障， 这种情况，我们需要考虑到redis的高可用集群，这块后面再说。</li></ul><p>我们来分析第一种情况，这种情况无非就是程序再去查一次数据库，再把数据库中的数据保存到缓存中就行，问题也不大。可是一旦涉及大数据量的需求，比如一些商品抢购的情景，或者是主页访问量瞬间较大的时候，单一使用数据库来保存数据的系统会因为面向磁盘，磁盘读/写速度比较慢的问题而存在严重的性能弊端，一瞬间成千上万的请求到来，需要系统在极短的时间内完成成千上万次的读/写操作，这个时候往往不是数据库能够承受的，极其容易造成数据库系统瘫痪，最终导致服务宕机的严重生产问题。</p><p>解决这类问题的方法有几个。</p><ul><li>对过期时间增加一个随机值，避免同一时刻大量key失效。</li><li>对于热点数据，不设置过期时间。</li><li>当从redis中获取数据为空时，去数据库查询数据的地方互斥锁，这种方式会造成性能下降。</li><li>增加二级缓存，以及缓存和二级缓存的过期时间不同，当一级缓存失效后，可以再通过二级缓存获取。</li></ul><h1 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h1><p>缓存穿透，一般是指当前访问的数据在redis和mysql中都不存在的情况，有可能是一次错误的查询，也可能是恶意攻击。</p><p>在这种情况下，因为数据库值不存在，所以肯定不会写入Redis，那么下一次查询相同的key的时候，肯定还是会再到数据库查一次。试想一下，如果有人恶意设置大量请求去访问一些不存在的key，这些请求同样最终会访问到数据库中，有可能导致数据库的压力过大而宕机。</p><p>这种情况一般有两种处理方法。</p><h2 id="缓存空值"><a href="#缓存空值" class="headerlink" title="缓存空值"></a>缓存空值</h2><p>我们可以在数据库缓存一个空字符串，或者缓存一个特殊的字符串，那么在应用里面拿到这个特殊字符串的时候，就知道数据库没有值了，也没有必要再到数据库查询了。</p><p>但是这里需要设置一个过期时间，不然的会数据库已经新增了这一条记录，应用也还是拿不到值。</p><p>这个是应用重复查询同一个不存在的值的情况，如果应用每一次查询的不存在的值是不一样的呢？即使你每次都缓存特殊字符串也没用，因为它的值不一样，比如我们的用户系统登录的场景，如果是恶意的请求，它每次都生成了一个符合ID规则的账号，但是这个账号在我们的数据库是不存在的，那Redis就完全失去了作用，因此我们有另外一种方法，布隆过滤器。</p><h2 id="布隆过滤器解决缓存穿透"><a href="#布隆过滤器解决缓存穿透" class="headerlink" title="布隆过滤器解决缓存穿透"></a>布隆过滤器解决缓存穿透</h2><p>先来了解一下布隆过滤器的原理，</p><ul><li>首先，项目在启动的时候，把所有的数据加载到布隆过滤器中。</li><li>然后，当客户端有请求过来时，先到布隆过滤器中查询一下当前访问的key是否存在，如果布隆过滤器中没有该key，则不需要去数据库查询直接反馈即可</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320226.png" alt="image-20210705232359445"></p><center>图3-9</center><p>下面我们通过一个案例来演示一下布隆过滤器的工作机制。</p><p>注意，该案例是在[springboot-redis-example]这个工程中进行演示。</p><ul><li><p>添加guava依赖，guava中提供了布隆过滤器的api</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.google.guava<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>guava<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>21.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>增加一个ApplicationRunner实现，当spring boot启动完成后执行初始化</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Slf4j</span></span><br><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BloomFilterDataLoadApplicationRunner</span> <span class="keyword">implements</span> <span class="title">ApplicationRunner</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    ICityService cityService;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(ApplicationArguments args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        List&lt;City&gt; cityList=cityService.list();</span><br><span class="line">        <span class="comment">// expectedInsertions: 预计添加的元素个数</span></span><br><span class="line">        <span class="comment">// fpp: 误判率（后续再讲）</span></span><br><span class="line">        BloomFilter&lt;String&gt; bloomFilter=BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8),<span class="number">10000000</span>,<span class="number">0.03</span>);</span><br><span class="line">        cityList.parallelStream().forEach(city -&gt; &#123;</span><br><span class="line">            bloomFilter.put(RedisKeyConstants.CITY_KEY+<span class="string">&quot;:&quot;</span>+city.getId());</span><br><span class="line">        &#125;);</span><br><span class="line">        BooleanFilterCache.bloomFilter=bloomFilter;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li><li><p>添加一个controller用来访问测试</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BloomFilterController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    RedisTemplate redisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/bloom/&#123;id&#125;&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">filter</span><span class="params">(<span class="meta">@PathVariable(&quot;id&quot;)</span>Integer id)</span></span>&#123;</span><br><span class="line">        String key=RedisKeyConstants.CITY_KEY+<span class="string">&quot;:&quot;</span>+id;</span><br><span class="line">        <span class="keyword">if</span>(BooleanFilterCache.bloomFilter.mightContain(key))&#123; <span class="comment">//判断当前数据在布隆过滤器中是否存在，如果存在则从缓存中加载</span></span><br><span class="line">            <span class="keyword">return</span> redisTemplate.opsForValue().get(key).toString();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;数据不存在&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>布隆过滤器存储空间大小计算： <a href="https://hur.st/bloomfilter/?n=1000000&amp;p=0.03&amp;m=&amp;k=">https://hur.st/bloomfilter/?n=1000000&amp;p=0.03&amp;m=&amp;k=</a></p></blockquote><h1 id="布隆过滤器原理分析"><a href="#布隆过滤器原理分析" class="headerlink" title="布隆过滤器原理分析"></a>布隆过滤器原理分析</h1><p>完成上述实验过程后，很多同学会产生疑问，</p><ul><li>老师，如果我的数据量有上千万，那不会很占内存啊？</li><li>老师，布隆过滤器的实现原理是什么呀？</li></ul><h2 id="什么是布隆过滤器"><a href="#什么是布隆过滤器" class="headerlink" title="什么是布隆过滤器"></a>什么是布隆过滤器</h2><p>布隆过滤器是Burton Howard Bloom在1970年提出来的，一种空间效率极高的概率型算法和数据结构，主要用来判断一个元素是否在集合中存在。因为他是一个概率型的算法，所以会存在一定的误差，如果传入一个值去布隆过滤器中检索，可能会出现检测存在的结果但是实际上可能是不存在的，但是肯定不会出现实际上不存在然后反馈存在的结果。因此，Bloom Filter不适合那些“零错误”的应用场合。而在能容忍低错误率的应用场合下，Bloom Filter通过极少的错误换取了存储空间的极大节省</p><h2 id="BitMap（位图）"><a href="#BitMap（位图）" class="headerlink" title="BitMap（位图）"></a>BitMap（位图）</h2><p>所谓的Bit-map就是用一个bit位来标记某个元素对应的Value，通过Bit为单位来存储数据，可以大大节省存储空间. </p><blockquote><p>ps:比特是一个二进制数的最小单元，就像我们现在金额的最小单位是分。只不过比特是二进制数而已，一个比特只能拥有一个值，不是0就是1，所以如果我给你一个值0，你可以说它就是一个比特，如果我给你两个（00），你就可以说它们是两个比特了。如果你将八个0或者1组合在一起，我们可以说说是8比特或者1个字节。在32位的机器上，一个int类型的数据会占用4个字节，也就是32个比特位。</p></blockquote><p>在java中，一个int类型占32个比特，我们用一个int数组来表示时未new int[32],总计占用内存32*32bit,现假如我们用int字节码的每一位表示一个数字的话，那么32个数字只需要一个int类型所占内存空间大小就够了，这样在大数据量的情况下会节省很多内存。</p><p>如果要存储n个数字，那么具体思路如下。</p><ul><li><p>1个int占4字节即4*8=32位，那么我们只需要申请一个int数组长度为 int tmp[1+N/32]即可存储完这些数据，其中N代表要进行查找的总数，tmp中的每个元素在内存在占32位可以对应表示十进制数0~31,所以可得到BitMap表:</p><ul><li>tmp[0]:可表示0~31</li><li>tmp[1]:可表示32~63</li><li>tmp[2]可表示64~95</li><li>…….</li></ul></li><li><p>接着，我们只需要把对应的数字存储到指定数组元素的bit中即可，如何判断int数字在tmp数组的哪个下标，这个其实可以通过直接除以32取整数部分，例如：整数8除以32取整等于0，那么8就在tmp[0]上。另外，我们如何知道了8在tmp[0]中的32个位中的哪个位，这种情况直接mod上32就ok，又如整数8，在tmp[0]中的<code>8 mod 32</code>等于8，那么整数8就在tmp[0]中的第八个bit位（从右边数起）</p></li></ul><p>比如我们要存储5**(101)<strong>、9</strong>(1001)<strong>、3</strong>(11)<strong>、1</strong>(1)**四个数字，那么我们申请int型的内存空间，会有32个比特位。这四个数字的二进制分别对应如下。</p><blockquote><p>从右往左开始数，比如第一个数字是5，对应的二进制数据是101, 那么从有往左数到第5位，把对应的二进制数据存储到32个比特位上。</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">第一个5就是     00000000000000000000000000101000 </span><br><span class="line"></span><br><span class="line">而输入9的时候   00000000000000000000001001000000 </span><br><span class="line"></span><br><span class="line">输入3时候      00000000000000000000000000001100 </span><br><span class="line"></span><br><span class="line">输入1的时候    00000000000000000000000000000010</span><br></pre></td></tr></table></figure><p>思想比较简单，关键是十进制和二进制bit位需要一个map映射表，把10进制映射到bit位上，这样的好处是内存占用少、效率很高（不需要比较和位移）。</p><h2 id="布隆过滤器原理"><a href="#布隆过滤器原理" class="headerlink" title="布隆过滤器原理"></a>布隆过滤器原理</h2><p>有了对位图的理解以后，我们对布隆过滤器的原理理解就会更容易了，基于前面的例子，我们把数据库中的一张表的数据全部先保存到布隆过滤器中，用来判断当前访问的key是否存在于数据库。</p><p>假设我们需要把id=1这个key保存到布隆过滤器中，并且该布隆过滤器中的hash函数个数为3｛x、y、z｝，它的具体实现原理如下：</p><ul><li>首先将位数组进行初始化，将里面每个位都设置位0。</li><li>对于集合里面的每一个元素，将元素依次通过3个哈希函数｛x、y、z｝进行映射，每次映射都会产生一个哈希值，这个值对应位数组上面的一个点，然后将位数组对应的位置标记为1。</li><li>查询<code>id=1</code>元素是否存在集合中的时候，同样的方法将W通过哈希映射到位数组上的3个点。<ul><li>如果3个点的其中有一个点不为1，则可以判断该元素一定不存在集合中。</li><li>反之，如果3个点都为1，则该元素可能存在集合中。</li></ul></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320560.png" alt="image-20210706210232859"></p><center>图3-10</center><p>接下来按照该方法处理所有的输入对象，每个对象都可能把bitMap中一些白位置涂黑，也可能会遇到已经涂黑的位置，遇到已经为黑的让他继续为黑即可。处理完所有的输入对象之后，在bitMap中可能已经有相当多的位置已经被涂黑。至此，一个布隆过滤器生成完成，这个布隆过滤器代表之前所有输入对象组成的集合。</p><p><strong>如何去判断一个元素是否存在bit array中呢？</strong> 原理是一样，根据k个哈希函数去得到的结果，如果所有的结果都是1，表示这个元素可能（<strong>假设某个元素通过映射对应下标为4，5，6这3个点。虽然这3个点都为1，但是很明显这3个点是不同元素经过哈希得到的位置，因此这种情况说明元素虽然不在集合中，也可能对应的都是1</strong>）存在。 如果一旦发现其中一个比特位的元素是0，表示这个元素一定不存在</p><p>至于k个哈希函数的取值为多少，能够最大化的降低错误率（因为哈希函数越多，映射冲突会越少），这个地方就会涉及到最优的哈希函数个数的一个算法逻辑。</p><ul><li><p>fpp表示允许的错误概率</p></li><li><p>expectedInsertions: 预期插入的数量</p></li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    BloomFilter&lt;String&gt; bloomFilter=BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8),<span class="number">10000000</span>,<span class="number">0.03</span>);</span><br><span class="line">    bloomFilter.put(<span class="string">&quot;Mic&quot;</span>);</span><br><span class="line">    System.out.println(bloomFilter.mightContain(<span class="string">&quot;Mic&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 布隆过滤器 </tag>
            
            <tag> 缓存穿透 </tag>
            
            <tag> 缓存一致性 </tag>
            
            <tag> 缓存雪崩 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>盘点一下Redis中常用的Java客户端,或者咱们手写一个？</title>
      <link href="/posts/1921857783/"/>
      <url>/posts/1921857783/</url>
      
        <content type="html"><![CDATA[<p>我们要在Java中操作Redis，怎么做呢？首先我们先来了解一下Redis Serialization Protocol(Redis序列化协议)，这个是Redis提供的一种，客户端和Redis服务端通信传输的编码协议，服务端收到罅隙ihou，会基于这个约定编码进行解码。</p><ul><li><p>打开Wireshark工具，对VMnet8这个网络进行抓包</p></li><li><p>增加过滤条件</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ip.dst_host==192.168.221.128 and tcp.port in &#123;6379&#125;</span><br></pre></td></tr></table></figure></li><li><p>使用RDM工具连接到Redis Server进行key-value操作，比如执行 set name mic</p></li><li><p>通过Wireshark工具监控数据包内容，如图3-3所示，可以看到实际发出的数据包是：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">*3\r\n$3\r\nSET\r\n$4\r\nname\r\n$3\r\nmic</span><br></pre></td></tr></table></figure><ul><li><p>其中<code>*3*</code>代表参数个数，set  name mic， 表示三个参数。</p></li><li><p><code>$3</code>表示属性长度，<code>$</code>表示包含3个字符。</p></li></ul><blockquote><p>客户端和服务器发送的命令或数据一律以 \r\n （CRLF回车+换行）结尾。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151320687.png" alt="image-20210703173900083"></p><center>图3-3</center></li></ul><p>基于这样一个特性，我们可以自己实现一个Java客户端。</p><h2 id="自定义Redis客户端"><a href="#自定义Redis客户端" class="headerlink" title="自定义Redis客户端"></a>自定义Redis客户端</h2><p>下面我们通过抓包相关的命令，了解Redis客户端的工作机制。</p><h3 id="定义常量池。"><a href="#定义常量池。" class="headerlink" title="定义常量池。"></a>定义常量池。</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CommandConstant</span> </span>&#123;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 开始符</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String START = <span class="string">&quot;*&quot;</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 指令长度符</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String LENGTH = <span class="string">&quot;$&quot;</span>;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 换行符</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> String LINE = <span class="string">&quot;\r\n&quot;</span>;</span><br><span class="line">    <span class="keyword">public</span> <span class="class"><span class="keyword">enum</span> <span class="title">CommandEnum</span> </span>&#123;</span><br><span class="line">        SET,</span><br><span class="line">        GET,</span><br><span class="line">        INCR</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="CustomClientSocket"><a href="#CustomClientSocket" class="headerlink" title="CustomClientSocket"></a>CustomClientSocket</h3><p>CustomClientSocket用来建立网络通信连接，并且发送数据指定到RedisServer。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomClientSocket</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Socket socket;</span><br><span class="line">    <span class="keyword">private</span> InputStream inputStream;</span><br><span class="line">    <span class="keyword">private</span> OutputStream outputStream;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CustomClientSocket</span><span class="params">(String ip,<span class="keyword">int</span> port)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            socket=<span class="keyword">new</span> Socket(ip,port);</span><br><span class="line">            inputStream=socket.getInputStream();</span><br><span class="line">            outputStream=socket.getOutputStream();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">send</span><span class="params">(String cmd)</span></span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            outputStream.write(cmd.getBytes());</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">read</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">byte</span>[] bytes = <span class="keyword">new</span> <span class="keyword">byte</span>[<span class="number">1024</span>];</span><br><span class="line">        <span class="keyword">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            count = inputStream.read(bytes);</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> String(bytes, <span class="number">0</span>, count);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="封装客户端"><a href="#封装客户端" class="headerlink" title="封装客户端"></a>封装客户端</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CustomRedisClient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> CustomClientSocket customClientSocket;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">CustomRedisClient</span><span class="params">(String host,<span class="keyword">int</span> port)</span> </span>&#123;</span><br><span class="line">        customClientSocket=<span class="keyword">new</span> CustomClientSocket(host,port);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">set</span><span class="params">(String key, String value)</span> </span>&#123;</span><br><span class="line">        customClientSocket.send(convertToCommand(CommandConstant.CommandEnum.SET, key.getBytes(), value.getBytes()));</span><br><span class="line">        <span class="keyword">return</span> customClientSocket.read();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">get</span><span class="params">(String key)</span> </span>&#123;</span><br><span class="line">        customClientSocket.send(convertToCommand(CommandConstant.CommandEnum.GET, key.getBytes()));</span><br><span class="line">        <span class="keyword">return</span> customClientSocket.read();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> String <span class="title">convertToCommand</span><span class="params">(CommandConstant.CommandEnum command, <span class="keyword">byte</span>[]... bytes)</span> </span>&#123;</span><br><span class="line">        StringBuilder stringBuilder = <span class="keyword">new</span> StringBuilder();</span><br><span class="line">        stringBuilder.append(CommandConstant.START).append(bytes.length + <span class="number">1</span>).append(CommandConstant.LINE);</span><br><span class="line">        stringBuilder.append(CommandConstant.LENGTH).append(command.toString().length()).append(CommandConstant.LINE);</span><br><span class="line">        stringBuilder.append(command.toString()).append(CommandConstant.LINE);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">byte</span>[] aByte : bytes) &#123;</span><br><span class="line">            stringBuilder.append(CommandConstant.LENGTH).append(aByte.length).append(CommandConstant.LINE);</span><br><span class="line">            stringBuilder.append(<span class="keyword">new</span> String(aByte)).append(CommandConstant.LINE);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> stringBuilder.toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="测试方法"><a href="#测试方法" class="headerlink" title="测试方法"></a>测试方法</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    CustomRedisClient redisClient=<span class="keyword">new</span> CustomRedisClient(<span class="string">&quot;192.168.221.128&quot;</span>,<span class="number">6379</span>);</span><br><span class="line">    System.out.println(redisClient.set(<span class="string">&quot;name&quot;</span>,<span class="string">&quot;mic&quot;</span>));</span><br><span class="line">    System.out.println(redisClient.get(<span class="string">&quot;name&quot;</span>));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>你看，理解了原理之后，自己去实现起来发现并不难。</p><p>但是实际开发过程中，我们难倒也需要开发自己开发客户端吗？当然不用，官方推荐了以下三种客户端</p><table><thead><tr><th><strong>配置</strong></th><th><strong>作用</strong></th></tr></thead><tbody><tr><td>Jedis</td><td>A blazingly small and sane redis java  client</td></tr><tr><td>lettuce</td><td>Advanced Redis client for thread-safe  sync, async, and reactive usage. Supports Cluster, Sentinel, Pipelining, and  codecs.</td></tr><tr><td>Redisson</td><td>distributed and scalable Java data  structures on top of Redis server</td></tr></tbody></table><h2 id="Jedis"><a href="#Jedis" class="headerlink" title="Jedis"></a>Jedis</h2><p>Jedis是我们最熟悉和最常用的客户端。轻量，简洁，便于集成和改造。</p><h3 id="简单使用方法"><a href="#简单使用方法" class="headerlink" title="简单使用方法"></a>简单使用方法</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>redis.clients<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>jedis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.6.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    Jedis jedis = <span class="keyword">new</span> Jedis(<span class="string">&quot;127.0.0.1&quot;</span>, <span class="number">6379</span>);</span><br><span class="line">    jedis.set(<span class="string">&quot;qingshan&quot;</span>, <span class="string">&quot;2673&quot;</span>);</span><br><span class="line">    System.out.println(jedis.get(<span class="string">&quot;qingshan&quot;</span>));</span><br><span class="line">    jedis.close();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>一般来说，我们不会使用单个Jedis连接，而是会使用连接池，Jedis提供了连接池的功能。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    JedisPool pool = <span class="keyword">new</span> JedisPool(ip, port);</span><br><span class="line">    Jedis jedis = jedisPool.getResource();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Luttece"><a href="#Luttece" class="headerlink" title="Luttece"></a>Luttece</h2><p><code>Lettuce</code>是一个<code>Redis</code>的<code>Java</code>驱动包，大家常用的spring-boot-starter-data-redis中默认就采用的Lettuce。<code>Lettuce</code>是一个高性能基于<code>Java</code>编写的<code>Redis</code>驱动框架，底层集成了<code>Project Reactor</code>提供天然的反应式编程，通信框架集成了<code>Netty</code>使用了非阻塞<code>IO</code>，<code>5.x</code>版本之后融合了<code>JDK1.8</code>的异步编程特性，在保证高性能的同时提供了十分丰富易用的<code>API</code>。</p><h3 id="简单使用方法-1"><a href="#简单使用方法-1" class="headerlink" title="简单使用方法"></a>简单使用方法</h3><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>io.lettuce<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>lettuce-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.1.8.RELEASE<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p><code>Lettuce</code>使用的时候依赖于四个主要组件：</p><ul><li><code>RedisURI</code>：连接信息。</li><li><code>RedisClient</code>：<code>Redis</code>客户端，特殊地，集群连接有一个定制的<code>RedisClusterClient</code>。</li><li><code>Connection</code>：<code>Redis</code>连接，主要是<code>StatefulConnection</code>或者<code>StatefulRedisConnection</code>的子类，连接的类型主要由连接的具体方式（单机、哨兵、集群、订阅发布等等）选定，比较重要。</li><li><code>RedisCommands</code>：<code>Redis</code>命令<code>API</code>接口，<strong>基本上覆盖了<code>Redis</code>发行版本的所有命令</strong>，提供了同步（<code>sync</code>）、异步（<code>async</code>）、反应式（<code>reative</code>）的调用方式，对于使用者而言，会经常跟<code>RedisCommands</code>系列接口打交道。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        RedisURI redisUri = RedisURI.builder()                    <span class="comment">// &lt;1&gt; 创建单机连接的连接信息</span></span><br><span class="line">                .withHost(<span class="string">&quot;192.168.221.128&quot;</span>)</span><br><span class="line">                .withPort(<span class="number">6379</span>)</span><br><span class="line">                .withTimeout(Duration.of(<span class="number">10</span>, ChronoUnit.SECONDS))</span><br><span class="line">                .build();</span><br><span class="line">        RedisClient redisClient = RedisClient.create(redisUri);   <span class="comment">// &lt;2&gt; 创建客户端</span></span><br><span class="line">        StatefulRedisConnection&lt;String, String&gt; connection = redisClient.connect();     <span class="comment">// &lt;3&gt; 创建线程安全的连接</span></span><br><span class="line">        RedisCommands&lt;String, String&gt; redisCommands = connection.sync();                <span class="comment">// &lt;4&gt; 创建同步命令</span></span><br><span class="line">        SetArgs setArgs = SetArgs.Builder.nx().ex(<span class="number">5</span>);</span><br><span class="line">        String result = redisCommands.set(<span class="string">&quot;name&quot;</span>, <span class="string">&quot;throwable&quot;</span>, setArgs);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">        result = redisCommands.get(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        System.out.println(result);</span><br><span class="line">        <span class="comment">// ... 其他操作</span></span><br><span class="line">        connection.close();   <span class="comment">// &lt;5&gt; 关闭连接</span></span><br><span class="line">        redisClient.shutdown();  <span class="comment">// &lt;6&gt; 关闭客户端</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h3 id="和Spring-Boot集成使用"><a href="#和Spring-Boot集成使用" class="headerlink" title="和Spring Boot集成使用"></a>和Spring Boot集成使用</h3><p>Lettuce是Spring Boot 2.x 默认的客户端，替换了Jedis。集成之后我们不需要单独使用它，直接调用Spring的RedisTemplate操作，连接和创建和关闭也不需要我们操心。</p><p>引入依赖jar包</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework.boot<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">   <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-boot-starter-data-redis<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>application.yml配置文件如下</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">redis:</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">6379</span></span><br><span class="line">    <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.221</span><span class="number">.128</span></span><br><span class="line">    <span class="attr">lettuce:</span></span><br><span class="line">      <span class="attr">pool:</span></span><br><span class="line">        <span class="attr">max-active:</span> <span class="number">-1</span></span><br><span class="line">        <span class="attr">max-idle:</span> <span class="number">2000</span></span><br><span class="line">        <span class="attr">max-wait:</span> <span class="number">-1</span></span><br><span class="line">        <span class="attr">min-idle:</span> <span class="number">1</span></span><br><span class="line">        <span class="attr">time-between-eviction-runs:</span> <span class="number">5000</span></span><br></pre></td></tr></table></figure><p>使用方法</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="meta">@RequestMapping(&quot;/&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LutteceController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    RedisTemplate redisTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> ResponseEntity <span class="title">get</span><span class="params">()</span></span>&#123;</span><br><span class="line">        String name=(String)redisTemplate.opsForValue().get(<span class="string">&quot;name&quot;</span>);</span><br><span class="line">        <span class="keyword">return</span> ResponseEntity.ok(name);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="Redisson"><a href="#Redisson" class="headerlink" title="Redisson"></a>Redisson</h2><blockquote><p><a href="https://redisson.org/">https://redisson.org/</a></p><p><a href="https://github.com/redisson/redisson/wiki/%E7%9B%AE%E5%BD%95">https://github.com/redisson/redisson/wiki/目录</a></p></blockquote><p>Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务。其中包括(<code>BitSet</code>, <code>Set</code>, <code>Multimap</code>, <code>SortedSet</code>, <code>Map</code>, <code>List</code>, <code>Queue</code>, <code>BlockingQueue</code>, <code>Deque</code>, <code>BlockingDeque</code>, <code>Semaphore</code>, <code>Lock</code>, <code>AtomicLong</code>, <code>CountDownLatch</code>, <code>Publish / Subscribe</code>, <code>Bloom filter</code>, <code>Remote service</code>, <code>Spring cache</code>, <code>Executor service</code>, <code>Live Object service</code>, <code>Scheduler service</code>) Redisson提供了使用Redis的最简单和最便捷的方法。Redisson的宗旨是促进使用者对Redis的关注分离（Separation of Concern），从而让使用者能够将精力更集中地放在处理业务逻辑上。</p><h3 id="简单使用方法-2"><a href="#简单使用方法-2" class="headerlink" title="简单使用方法"></a>简单使用方法</h3><ul><li><p>引入依赖Jar包</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.redisson<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>redisson<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.16.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li><p>时间单节点连接和操作</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">    Config config=<span class="keyword">new</span> Config();</span><br><span class="line">    config.useSingleServer().setAddress(<span class="string">&quot;redis://192.168.221.128:6379&quot;</span>);</span><br><span class="line">    RedissonClient redissonClient= Redisson.create(config);</span><br><span class="line">    redissonClient.getBucket(<span class="string">&quot;test&quot;</span>).set(<span class="string">&quot;mic&quot;</span>);</span><br><span class="line">    System.out.println(redissonClient.getBucket(<span class="string">&quot;test&quot;</span>).get());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li></ul><h3 id="和Spring-Boot集成"><a href="#和Spring-Boot集成" class="headerlink" title="和Spring Boot集成"></a>和Spring Boot集成</h3><p>Spring Boot的集成方式。</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.redisson<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>redisson-spring-boot-starter<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.16.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure><p>application.yml中的配置。</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">timeout:</span> <span class="number">2000</span></span><br><span class="line">    <span class="attr">host:</span> <span class="number">192.168</span><span class="number">.221</span><span class="number">.128</span></span><br><span class="line">    <span class="attr">port:</span> <span class="number">6379</span></span><br></pre></td></tr></table></figure><p>使用方法。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RedissonController</span> </span>&#123;</span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    RedissonClient redissonClient;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@GetMapping(&quot;/&quot;)</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">get</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> redissonClient.getBucket(<span class="string">&quot;test&quot;</span>).get().toString();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>另外一种配置方式如下</p></blockquote><ul><li><p>修改application.yml</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">redis:</span></span><br><span class="line">    <span class="attr">redisson:</span></span><br><span class="line">      <span class="attr">file:</span> <span class="string">classpath:redisson.yml</span></span><br></pre></td></tr></table></figure></li><li><p>创建一个redisson.yml文件，内容如下</p><figure class="highlight yml"><table><tr><td class="code"><pre><span class="line"><span class="attr">singleServerConfig:</span></span><br><span class="line">  <span class="attr">address:</span> <span class="string">redis://192.168.221.128:6379</span></span><br><span class="line">  <span class="comment">#---------------------------------------------</span></span><br><span class="line">  <span class="comment"># 连接空闲超时，单位：毫秒</span></span><br><span class="line">  <span class="attr">idleConnectionTimeout:</span> <span class="number">10000</span></span><br><span class="line">  <span class="comment"># 连接超时，单位：毫秒</span></span><br><span class="line">  <span class="attr">connectTimeout:</span> <span class="number">10000</span></span><br><span class="line">  <span class="comment"># 命令等待超时，单位：毫秒</span></span><br><span class="line">  <span class="attr">timeout:</span> <span class="number">3000</span></span><br><span class="line">  <span class="comment"># 命令失败重试次数,如果尝试达到 retryAttempts（命令失败重试次数） 仍然不能将命令发送至某个指定的节点时，将抛出错误。</span></span><br><span class="line">  <span class="comment"># 如果尝试在此限制之内发送成功，则开始启用 timeout（命令等待超时） 计时。</span></span><br><span class="line">  <span class="attr">retryAttempts:</span> <span class="number">3</span></span><br><span class="line">  <span class="comment"># 命令重试发送时间间隔，单位：毫秒</span></span><br><span class="line">  <span class="attr">retryInterval:</span> <span class="number">1500</span></span><br></pre></td></tr></table></figure></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> Redis Java </tag>
            
            <tag> 手写Redis客户端 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>图解Redis6中的9种数据结构，墙裂建议准备去面试的人先看（干货，建议收藏）</title>
      <link href="/posts/2848818622/"/>
      <url>/posts/2848818622/</url>
      
        <content type="html"><![CDATA[<p>如图所示，Redis中提供了9种不同的数据操作类型，他们分别代表了不同的数据存储结构。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110131450348.png" alt="image-20211013145055292"></p><center>图2-17 数据类型</center><h2 id="String类型"><a href="#String类型" class="headerlink" title="String类型"></a>String类型</h2><p>String类型是Redis用的较多的一个基本类型，也是最简单的一种类型，它和我们在Java中使用的字符类型什么太大区别，具体结构如图2-18所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451904.png" alt="image-20210630182903375"></p><center>图2-19</center><h3 id="String常用操作指令"><a href="#String常用操作指令" class="headerlink" title="String常用操作指令"></a>String常用操作指令</h3><p>常用炒作指令如图2-20所示，更多的指令查询：<a href="http://doc.redisfans.com/">http://doc.redisfans.com/</a></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451060.png" alt="image-20210630184919969"></p><center>图2-20</center><h3 id="String的实际存储结构"><a href="#String的实际存储结构" class="headerlink" title="String的实际存储结构"></a>String的实际存储结构</h3><p>学过C++的同学都知道，C++中没有String类型，而Redis又是基于C++来实现的，那么它是如何存储String类型的呢？</p><p>Redis并没有采用C语言的传统字符串表示方式（<code>char*</code>或者<code>char[]</code>），在Redis内部，String类型以<code>int/SDS(simple dynamic string)</code>作为结构存储，int用来存放整型数据，sds存放字节/字符串和浮点型数据。</p><p>在C的标准字符串结构下进行了封装，用来提升基本操作的性能，同时充分利用以后的C的标准库，简化实现。我们可以在redis的源码中【<strong>sds.h</strong>】中看到sds的结构如下；</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> __<span class="title">attribute__</span> ((__<span class="title">packed__</span>)) <span class="title">sdshdr8</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint8_t</span> len;<span class="comment">//表示当前sds的长度(单位是字节)</span></span><br><span class="line">    <span class="keyword">uint8_t</span> alloc; <span class="comment">//表示已为sds分配的内存大小(单位是字节)</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> flags; <span class="comment">//用一个字节表示当前sdshdr的类型，因为有sdshdr有五种类型，所以至少需要3位来表示000:sdshdr5，001:sdshdr8，010:sdshdr16，011:sdshdr32，100:sdshdr64。高5位用不到所以都为0。</span></span><br><span class="line">    <span class="keyword">char</span> buf[];<span class="comment">//sds实际存放的位置</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>也就是说实际上sds类型就是<code>char*</code>类型，那<code>sds</code>和<code>char*</code>有什么区别呢？</p><p><strong>主要区别就是：sds一定有一个所属的结构(sdshdr)，这个header结构在每次创建sds时被创建，用来存储sds以及sds的相关信息</strong></p><p>对sds结构有一个简单认识以后，我们如果通过set创建一个字符串，那么也就是会创建一个sds来存储这个字符串信息，那么这个过程是怎么样的呢？</p><ul><li>首先第一个要判断选择一个什么类型的sdshdr来存放信息？这就得根据要存储的sds的长度决定了，redis在创建一个sds之前会调用【<strong>sds.c文件</strong>】sdsReqType(size_t string_size)来判断用哪个sdshdr。该函数传递一个sds的长度作为参数，返回应该选用的sdshdr类型。</li><li>然后把数据保存到对应的sdshdr中。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451456.png" alt="image-20210628163803639"></p><center>图2-19</center><blockquote><p>Redis采用类似C的做法存储字符串，也就是以’\0’结尾，’\0’只作为字符串的定界符，不计入alloc或者len</p></blockquote><p><strong>key命名小技巧</strong></p><ul><li>a) redis并没有规定我们对key应该怎么命名，但是最好的实践是“对象类型:对象id:对象属性.子属性”</li><li>b) key不要设置得太长，太长的key不仅仅消耗内存，而且在数据中查找这类键值计算成本很高</li><li>c) key不要设置得太短，比如u:1000:pwd 来代替user:1000:password, 虽然没什么问题，但是后者的可读性更好</li><li>d) 为了更好的管理你的key，对key进行业务上的分类；同时建议有一个wiki统一管理所有的key，通过查询这个文档知道redis中的key的作用</li></ul><h3 id="String类型的应用场景"><a href="#String类型的应用场景" class="headerlink" title="String类型的应用场景"></a>String类型的应用场景</h3><p>String类型使用比较多，一般来说，不太了解Redis的人，几乎所有场景都是用String类型来存储数据。</p><p><strong>分布式缓存</strong></p><p>首先最基本的就是用来做业务数据的缓存，如图2-20，Redis中会缓存一些常用的热点数据，可以提升数据查询的性能。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451205.png" alt="image-20210630191730761"></p><center>如图2-20</center><p><strong>分布式全局ID</strong></p><p>使用String类型的incr命令，实现原子递增</p><p><strong>限流</strong></p><p>使用计数器实现手机验证码频率限流。</p><p><strong>分布式session</strong></p><p>基于登录场景中，保存token信息。</p><h2 id="List类型"><a href="#List类型" class="headerlink" title="List类型"></a>List类型</h2><p>列表类型(list)可以存储一个有序且可重复的字符串列表，常用的操作是向列表两端添加元素或者获得列表的某一个片段，List的存储结构如图2-20所示</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451403.png" alt="image-20210629133004615"></p><center>图2-20</center><h3 id="常用操作命令"><a href="#常用操作命令" class="headerlink" title="常用操作命令"></a>常用操作命令</h3><p>图2-21表示list类型的常用操作命令，具体命令的操作，可以参考： <a href="http://doc.redisfans.com/">http://doc.redisfans.com/</a></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451804.png" alt="image-20210630200506802"></p><center>图2-21</center><h3 id="数据存储结构"><a href="#数据存储结构" class="headerlink" title="数据存储结构"></a>数据存储结构</h3><p>如图2-22所示，在redis6.0中，List采用了QuickList这样一种结构来存储数据，QuickList是一个双向链表，链表的每个节点保存一个ziplist，所有的数据实际上是存储在ziplist中，ziplist是一个压缩列表，它可以节省内存空间。</p><p>ziplist详细说明：<a href="https://www.cnblogs.com/hunternet/p/11306690.html">https://www.cnblogs.com/hunternet/p/11306690.html</a></p><blockquote><p>听到“压缩”两个字，直观的反应就是节省内存。之所以说这种存储结构节省内存,是相较于数组的存储思路而言的。我们知道,数组要求每个元素的大小相同,如果我们要存储不同长度的字符串,那我们就需要用最大长度的字符串大小作为元素的大小(假设是5个字节)。存储小于5个字节长度的字符串的时候，便会浪费部分存储空间，比如下面这个图所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451079.png" alt="image-20210629162512711"></p><p>所以，ziplist就是根据每个节点的长度来决定占用内存大小，然后每个元素保存时同步记录当前数据的长度，这样每次添加元素是就可以计算下一个节点在内存中的存储位置，从而形成一个压缩列表。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451256.png" alt="image-20210629163022632"></p><p>另外，数据的方式存储数据有一个很好的优势，就是它存储的是在一个连续的内存空间，它可以很好的利用CPU的缓存来访问数据，从而提升访问性能。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451747.png" alt="image-20210629143845481"></p><center>图2-22</center><p>其中，QuickList中的每个节点称为QuickListNode，具体的定义在<strong>quicklist.h</strong>文件中。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> &#123;</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">prev</span>;</span>   <span class="comment">//链表的上一个node节点</span></span><br><span class="line">    <span class="class"><span class="keyword">struct</span> <span class="title">quicklistNode</span> *<span class="title">next</span>;</span>   <span class="comment">//链表的下一个node节点</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">char</span> *zl;            <span class="comment">//数据指针，如果当前节点数据没有压缩，它指向一个ziplist，否则，指向一个quicklistLZF</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> sz;             <span class="comment">/* 指向的ziplist的总大小 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> count : <span class="number">16</span>;     <span class="comment">/* ziplist中的元素个数 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> encoding : <span class="number">2</span>;   <span class="comment">/* 表示ziplist是否压缩了，1表示没压缩，2表示压缩 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> container : <span class="number">2</span>;  <span class="comment">/* 预留字段 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> recompress : <span class="number">1</span>; <span class="comment">/* 当使用类似lindex命令查看某一个本压缩的数据时，需要先解压，这个用来存储标记，等有机会再把数据重新压缩 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> attempted_compress : <span class="number">1</span>; <span class="comment">/* node can&#x27;t compress; too small */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> extra : <span class="number">10</span>; <span class="comment">/* more bits to steal for future usage */</span></span><br><span class="line">&#125; quicklistNode;</span><br></pre></td></tr></table></figure><p>quickList是list类型的存储结构，其定义如下。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">quicklist</span> &#123;</span></span><br><span class="line">    quicklistNode *head;    <span class="comment">//指向quicklistNode头节点</span></span><br><span class="line">    quicklistNode *tail;    <span class="comment">//指向quicklistNode的尾节点</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> count;        <span class="comment">/* 所有ziplist数据项的个数综合 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">long</span> len;          <span class="comment">/* quicklist节点个数*/</span></span><br><span class="line">    <span class="keyword">int</span> fill : QL_FILL_BITS;              <span class="comment">/* ziplist大小设置 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> compress : QL_COMP_BITS; <span class="comment">/* 节点压缩深度设置 */</span></span><br><span class="line">    <span class="keyword">unsigned</span> <span class="keyword">int</span> bookmark_count: QL_BM_BITS;</span><br><span class="line">    quicklistBookmark bookmarks[];</span><br><span class="line">&#125; quicklist;</span><br></pre></td></tr></table></figure><p>如图2-23所示，当向list中添加元素时，会直接保存到某个QuickListNode中的ziplist中，不过不管是从头部插入数据，还是从尾部插入数据，都包含两种情况</p><ul><li>如果头节点（尾部节点）上的ziplist大小没有超过限制，新数据会直接插入到ziplist中</li><li>如果头节点上的ziplist达到阈值，则创建一个新的quicklistNode节点，该节点中会创建一个ziplist，然后把这个新创建的节点插入到quicklist双向链表中。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451224.png" alt="image-20210629152807286"></p><center>图2-23</center><h3 id="实际使用场景"><a href="#实际使用场景" class="headerlink" title="实际使用场景"></a>实际使用场景</h3><p><strong>消息队列</strong></p><p>列表类型可以使用 rpush 实现先进先出的功能，同时又可以使用 lpop 轻松的弹出（查询并删除）第一个元素，所以列表类型可以用来实现消息队列，如图2-24所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451792.png" alt="image-20210630200839165"></p><center>图2-24</center><p><strong>发红包的场景</strong></p><p>在发红包的场景中，假设发一个10元，10个红包，需要保证抢红包的人不会多抢到，也不会少抢到，这种情况下，可以根据图2-25所示去实现。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451805.png" alt="image-20210630201807762"></p><center>图2-25</center><h2 id="Hash类型"><a href="#Hash类型" class="headerlink" title="Hash类型"></a>Hash类型</h2><p>Hash类型大家应该都不陌生，他就是一个键值对集合，如图2-26所示。Hash相当于一个 string 类型的 key和 value 的映射表，key 还是key，但是value是一个键值对（key-value），类比于 Java里面的 Map&lt;String,Map&lt;String,Object&gt;&gt; 集合。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451273.png" alt="image-20210629154429976"></p><center>图2-26</center><h3 id="Hash常用操作命令"><a href="#Hash常用操作命令" class="headerlink" title="Hash常用操作命令"></a>Hash常用操作命令</h3><p>Hash结构的常用操作命令如图2-27所示，其他的指令可以参考：<a href="http://doc.redisfans.com/">http://doc.redisfans.com/</a></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451067.png" alt="image-20210629155915069"></p><center>图2-27</center><h3 id="Hash实际存储结构"><a href="#Hash实际存储结构" class="headerlink" title="Hash实际存储结构"></a>Hash实际存储结构</h3><p>如图2-28所示，哈希类型的内部编码有两种：<strong>ziplist压缩列表</strong>,<strong>hashtable哈希表</strong>。只有当存储的数据量比较小的情况下，Redis 才使用压缩列表来实现字典类型。具体需要满足两个条件：</p><ul><li>当哈希类型元素个数小于<strong>hash-max-ziplist-entries</strong>配置（默认512个）</li><li>所有值都小于<strong>hash-max-ziplist-value</strong>配置（默认64字节）<br><code>ziplist</code>使用更加紧凑的结构实现多个元素的连续存储，所以在节省内存方面比<code>hashtable</code>更加优秀。当哈希类型无法满足<code>ziplist</code>的条件时，Redis会使用<code>hashtable</code>作为哈希的内部实现，因为此时<code>ziplist</code>的读写效率会下降，而<code>hashtable</code>的读写时间复杂度为O（1）。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451472.png" alt="image-20210629172553348"></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451263.png" alt="image-20210630202531223"></p><center>图2-28</center><h3 id="Hash实际应用场景"><a href="#Hash实际应用场景" class="headerlink" title="Hash实际应用场景"></a>Hash实际应用场景</h3><p>Hash表使用用来存储对象数据，比如用户信息，相对于通过将对象转化为json存储到String类型中，Hash结构的灵活性更大，它可以任何添加和删除对象中的某些字段。</p><p><strong>购物车功能</strong></p><ul><li><p>1.以用户ID作为key</p></li><li><p>2.以商品id作为field</p></li><li><p>3.以商品的数量作为value</p></li></ul><p><strong>对象类型数据</strong></p><p>比如优化之后的用户信息存储，减少数据库的关联查询导致的性能慢的问题。</p><ul><li>用户信息</li><li>商品信息</li><li>计数器</li></ul><h2 id="Set类型"><a href="#Set类型" class="headerlink" title="Set类型"></a>Set类型</h2><p>如图2-29所示，集合类型 (Set) 是一个无序并唯一的键值集合。它的存储顺序不会按照插入的先后顺序进行存储。</p><p>集合类型和列表类型的区别如下：</p><ul><li>列表可以存储重复元素，集合只能存储非重复元素；</li><li>列表是按照元素的先后顺序存储元素的，而集合则是无序方式存储元素的。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451453.png" alt="image-20210629181723110"></p><center>图2-29</center><h3 id="set类型的常用操作"><a href="#set类型的常用操作" class="headerlink" title="set类型的常用操作"></a>set类型的常用操作</h3><p>Set类型的常用操作指令如下。</p><table><thead><tr><th>命令</th><th>说明</th><th>时间复杂度</th></tr></thead><tbody><tr><td>SADD key member [member …]</td><td>添加一个或者多个元素到集合(set)里</td><td>O(N)</td></tr><tr><td>SCARD key</td><td>获取集合里面的元素数量</td><td>O(1)</td></tr><tr><td>SDIFF key [key …]</td><td>获得队列不存在的元素</td><td>O(N)</td></tr><tr><td>SDIFFSTORE destination key [key …]]</td><td>获得队列不存在的元素，并存储在一个关键的结果集</td><td>O(N)</td></tr><tr><td>SINTER key [key …]</td><td>获得两个集合的交集</td><td>O(N*M)</td></tr><tr><td>SINTERSTORE destination key [key …]</td><td>获得两个集合的交集，并存储在一个关键的结果集</td><td>O(N*M)</td></tr><tr><td>SISMEMBER key member</td><td>确定一个给定的值是一个集合的成员</td><td>O(1)</td></tr><tr><td>SMEMBERS key</td><td>获取集合里面的所有元素</td><td>O(N)</td></tr><tr><td>SMOVE source destination member</td><td>移动集合里面的一个元素到另一个集合</td><td>O(1)</td></tr><tr><td>SPOP key [count]</td><td>删除并获取一个集合里面的元素</td><td>O(1)</td></tr><tr><td>SRANDMEMBER key [count]</td><td>从集合里面随机获取一个元素</td><td></td></tr><tr><td>SREM key member [member …]]</td><td>从集合里删除一个或多个元素</td><td>O(N)</td></tr><tr><td>SUNION key [key …]]</td><td>添加多个set元素</td><td>O(N)</td></tr><tr><td>SUNIONSTORE destination key [key …]</td><td>合并set元素，并将结果存入新的set里面</td><td>O(N)</td></tr></tbody></table><h3 id="Set类型实际存储结构"><a href="#Set类型实际存储结构" class="headerlink" title="Set类型实际存储结构"></a>Set类型实际存储结构</h3><p>Set在的底层数据结构以intset或者hashtable来存储。当set中只包含整数型的元素时，采用intset来存储，否则，采用hashtable存储，但是对于set来说，该hashtable的value值用于为NULL，通过key来存储元素。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> <span class="title">intset</span> &#123;</span></span><br><span class="line">    <span class="keyword">uint32_t</span> encoding;</span><br><span class="line">    <span class="keyword">uint32_t</span> length;</span><br><span class="line">    <span class="keyword">int8_t</span> contents[];</span><br><span class="line">&#125; intset;</span><br></pre></td></tr></table></figure><p>intset将整数元素按顺序存储在数组里，并通过二分法降低查找元素的时间复杂度。数据量大时，</p><p>依赖于“查找”的命令（如SISMEMBER）就会由于O(logn)的时间复杂度而遇到一定的瓶颈，所以数据量大时会用dict来代替intset。</p><p>但是intset的优势就在于比dict更省内存，而且数据量小的时候O(logn)未必会慢于O(1)的hash function，这也是intset存在的原因。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451936.png" alt="image-20210629233537351"></p><center>图2-30</center><h3 id="set类型的实际应用场景"><a href="#set类型的实际应用场景" class="headerlink" title="set类型的实际应用场景"></a>set类型的实际应用场景</h3><p><strong>标签管理功能</strong></p><ol><li><p>给用户添加标签。</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">sadd user:<span class="number">1</span>:basketball game coding swing</span><br><span class="line">sadd user:<span class="number">2</span>:sing coding sleep basketball</span><br><span class="line">...</span><br><span class="line">sadd user:k:tags tag1 tag2 tag4</span><br><span class="line">...</span><br></pre></td></tr></table></figure></li><li><p>使用sinter命令，可以来计算用户共同感兴趣的标签</p><figure class="highlight c"><table><tr><td class="code"><pre><span class="line">sinter user:<span class="number">1</span> user:<span class="number">2</span></span><br></pre></td></tr></table></figure></li></ol><p>这种标签系统在电商系统、社交系统、视频网站，图书网站，旅游网站等都有着广泛的应用。例如一个用户可能对娱乐、体育比较感兴趣，另一个用户可能对历史、新闻比较感兴趣，</p><p>这些兴趣点就是标签。有了这些数据就可以得到喜欢同一个标签的人，以及用户的共同喜好的标签，这些数据对于用户体验以及增强用户黏度比较重要。</p><p>例如一个社交系统可以根据用户的标签进行好友的推荐，已经用户感兴趣的新闻的推荐等，一个电子商务的网站会对不同标签的用户做不同类型的推荐，比如对数码产品比较感兴趣的人，</p><p>在各个页面或者通过邮件的形式给他们推荐最新的数码产品，通常会为网站带来更多的利益</p><p><strong>相关商品信息展示</strong></p><p>比如在电商系统中，当用户查看某个商品时，可以推荐和这个商品标签有关的商品信息。</p><h2 id="ZSet类型"><a href="#ZSet类型" class="headerlink" title="ZSet类型"></a>ZSet类型</h2><p>有序集合类型，顾名思义，和前面讲的集合类型的区别就是多了有序的功能。</p><p>如图2-31所示，在集合类型的基础上，有序集合类型为集合中的每个元素都关联了一个分数（浮点型），这使得我们不仅可以完成插入、删除和判断元素是否存在等集合类型支持的操作，还能获得分数最高(或最低)的前N个元素、获得指定分数范围内的元素等与分数有关的操作。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451026.png" alt="image-20210630151900199"></p><center>图2-31</center><h3 id="ZSet常用操作命令"><a href="#ZSet常用操作命令" class="headerlink" title="ZSet常用操作命令"></a>ZSet常用操作命令</h3><p>ZSet的常用命令如图2-32所示，完整的操作命令，详见：<a href="http://doc.redisfans.com/">http://doc.redisfans.com/</a></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451774.png" alt="image-20210630154837864"></p><center>图2-32</center><h3 id="ZSet的数据存储结构"><a href="#ZSet的数据存储结构" class="headerlink" title="ZSet的数据存储结构"></a>ZSet的数据存储结构</h3><p>ZSet的底层数据结构采用了zipList（压缩表）和skiplist（跳跃表）组成，当同时满足以下两个条件时，有序集合采用的是ziplist存储。</p><ul><li>有序集合保存的元素个数要小于128个</li><li>有序集合保存的所有元素成员的长度必须小于64个字节</li></ul><p>如果不能满足以上任意一个条件，有序集合会采用skiplist（跳跃表）结构进行存储，如图2-33所示，zSet不只是用skiplist，实际上，它使用了dict（字典表）和zskiplist（跳跃表）同时进行数据存储。</p><ul><li>dict，字典类型， 其中key表示zset的成员数据，value表示zset的分值，<strong>用来支持O(1)复杂度的按照成员取分值的操作</strong></li><li>zskiplist，跳跃表，按分值排序成员，<strong>用来支持平均复杂度为O<del>(logn)</del>的按照分值定位成员的操作，以及范围查找操作</strong>。</li></ul><p>其中zskiplistNode中<code>*obj</code>和Dic中<code>*key</code>指向同一个具体元素，所以不会存在多余的内存消耗问题。另外，backward表示后退指针，方便进行回溯。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121451536.png" alt="image-20210630172259860"></p><center>图2-33</center><h3 id="关于跳跃表"><a href="#关于跳跃表" class="headerlink" title="关于跳跃表"></a>关于跳跃表</h3><p>跳表(skip list) 对标的是平衡树(AVL Tree)，是一种 插入/删除/搜索 都是 <code>O(log n)</code> 的数据结构。它最大的优势是原理简单、容易实现、方便扩展、效率更高。因此在一些热门的项目里用来替代平衡树，如 redis, leveldb 等。</p><p><strong>跳表的基本思想</strong></p><p>首先，跳表处理的是有序的链表（一般是双向链表，下图未表示双向），如下：</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211020105629079.png" alt="image-20211020105629079"></p><p>这个链表中，如果要搜索一个数，需要从头到尾比较每个元素是否匹配，直到找到匹配的数为止，即时间复杂度是 O(n)O(n)。同理，插入一个数并保持链表有序，需要先找到合适的插入位置，再执行插入，总计也是 O(n)O(n) 的时间。</p><p>那么如何提高搜索的速度呢？很简单，做个索引：</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211020105657884.png" alt="image-20211020105657884"></p><p>如上图，我们新创建一个链表，它包含的元素为前一个链表的偶数个元素。这样在搜索一个元素时，我们先在上层链表进行搜索，当元素未找到时再到下层链表中搜索。例如搜索数字 <code>19</code> 时的路径如下图：</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211020105730457.png" alt="image-20211020105730457"></p><p>先在上层中搜索，到达节点 <code>17</code> 时发现下一个节点为 <code>21</code>，已经大于 <code>19</code>，于是转到下一层搜索，找到的目标数字 <code>19</code>。</p><p>我们知道上层的节点数目为 n/2n/2，因此，有了这层索引，我们搜索的时间复杂度降为了：O(n/2)O(n/2)。同理，我们可以不断地增加层数，来减少搜索的时间：</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211020105757674.png" alt="image-20211020105757674"></p><p>在上面的 4 层链表中搜索 <code>25</code>，在最上层搜索时就可以直接跳过 <code>21</code> 之前的所有节点，因此十分高效。</p><p>更一般地，如果有 kk 层，我们需要的搜索次数会小于 ⌈n2k⌉+k⌈n2k⌉+k ，这样当层数 kk 增加到 ⌈log2n⌉⌈log2⁡n⌉ 时，搜索的时间复杂度就变成了 lognlog⁡n。其实这背后的原理和二叉搜索树或二分查找很类似，通过索引来跳过大量的节点，从而提高搜索效率。</p><p><strong>动态跳表</strong></p><p>上节的结构是“静态”的，即我们先拥有了一个链表，再在之上建了多层的索引。但是在实际使用中，我们的链表是通过多次插入/删除形成的，换句话说是“动态”的。上节的结构要求上层相邻节点与对应下层节点间的个数比是 <code>1:2</code>，随意插入/删除一个节点，这个要求就被被破坏了。</p><p>因此跳表（skip list）表示，我们就不强制要求 <code>1:2</code> 了，一个节点要不要被索引，建几层的索引，都在节点插入时由抛硬币决定。当然，虽然索引的节点、索引的层数是随机的，为了保证搜索的效率，要大致保证每层的节点数目与上节的结构相当。下面是一个随机生成的跳表：</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211020105929667.png" alt="image-20211020105929667"></p><p>可以看到它每层的节点数还和上节的结构差不多，但是上下层的节点的对应关系已经完全被打破了。</p><p>现在假设节点 <code>17</code> 是最后插入的，在插入之前，我们需要搜索得到插入的位置：</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/image-20211020110003178.png" alt="image-20211020110003178"></p><p>接着，抛硬币决定要建立几层的索引，伪代码如下：</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">randomLevel()</span><br><span class="line">    lvl := 1</span><br><span class="line">    -- random() that returns a random value in [0...1)</span><br><span class="line">    while random() &lt; p and lvl &lt; MaxLevel do</span><br><span class="line">        lvl := lvl + 1</span><br><span class="line">    return lvl</span><br></pre></td></tr></table></figure><p>上面的伪代码相当于抛硬币，如果是正面（<code>random() &lt; p</code>）则层数加一，直到抛出反面为止。其中的 <code>MaxLevel</code> 是防止如果运气太好，层数就会太高，而太高的层数往往并不会提供额外的性能，</p><p>一般 MaxLevel=log1/pnMaxLevel=log1/p⁡n。现在假设 <code>randomLevel</code> 返回的结果是 <code>2</code>，那么就得到下面的结果。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110131359558.png" alt="image-20211013135934802"></p><p>如果要删除节点，则把节点和对应的所有索引节点全部删除即可。当然，要删除节点时需要先搜索得到该节点，搜索过程中可以把路径记录下来，这样删除索引层节点的时候就不需要多次搜索了</p><h3 id="ZSet的使用场景"><a href="#ZSet的使用场景" class="headerlink" title="ZSet的使用场景"></a>ZSet的使用场景</h3><ul><li><p><strong>排行榜系统</strong></p><p>有序集合比较典型的使用场景就是排行榜系统。例如学生成绩的排名。某视频(博客等)网站的用户点赞、播放排名、电商系统中商品的销量排名等。我们以博客点赞为例。</p><ul><li><p>添加用户赞数</p><p>例如小编Tom发表了一篇博文，并且获得了10个赞。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zadd user:ranking article1 10</span><br></pre></td></tr></table></figure></li><li><p>取消用户赞数</p><p>这个时候有一个读者又觉得Tom写的不好，又取消了赞，此时需要将文章的赞数从榜单中减去1，可以使用zincrby。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zincrby user:ranking -1 article1 </span><br></pre></td></tr></table></figure></li><li><p>查看某篇文章的赞数</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ZSCORE user:ranking arcticle1 </span><br></pre></td></tr></table></figure></li><li><p>展示获取赞数最多的十篇文章</p><p>此功能使用zrevrange命令实现：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">zrevrange user:ranking 0 10  #0 到 10表示元素个数索引</span><br><span class="line">zrevrangebyscore user:ranking 99 0 #  按照分数从高到低排名，99，0表示score</span><br></pre></td></tr></table></figure></li></ul></li><li><p><strong>热点话题排名</strong></p><p>比如想微博的热搜，就可以使用ZSet来实现。</p></li></ul><h1 id="其他数据类型介绍"><a href="#其他数据类型介绍" class="headerlink" title="其他数据类型介绍"></a>其他数据类型介绍</h1><p>在Redis中，还有一些使用得非常少的数据类型，简单给大家普及一下。</p><h2 id="Geospatial"><a href="#Geospatial" class="headerlink" title="Geospatial"></a>Geospatial</h2><p>Geo是Redis3.2推出的一个类型，它提供了地理位置的计算功能，也就是可以计算出两个地理位置的距离。</p><blockquote><p>文档：<a href="https://www.redis.net.cn/order/3687.html">https://www.redis.net.cn/order/3687.html</a></p></blockquote><p>下面演示一下Geo的基本使用，其中需要用到经纬度信息，可以从 <a href="http://www.jsons.cn/lngcode/%E6%9F%A5%E8%AF%A2%E3%80%82">http://www.jsons.cn/lngcode/查询。</a></p><ol><li><p>添加模拟数据</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">geoadd china:city 116.40 39.90 beijing</span><br><span class="line">geoadd china:city 121.47 31.23 shanghai</span><br><span class="line">geoadd china:city 114.05 22.52 shengzhen</span><br><span class="line">geoadd china:city 113.28 23.12 guangzhou</span><br></pre></td></tr></table></figure></li><li><p>获取当前位置的坐标值</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">geopos china:city beijing</span><br><span class="line">geopos china:city shanghai</span><br></pre></td></tr></table></figure></li><li><p>获取两个位置之间的距离：<code>m-表示米/km-表示千米/mi-表示英里/ft表示英尺</code></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 查看北京到上海的直线距离</span></span><br><span class="line">geodist china:city beijing shanghai km</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看北京到深圳的直线距离</span></span><br><span class="line">geodist china:city beijing shenzhen km</span><br></pre></td></tr></table></figure></li><li><p>给定一个经纬度，找出该经纬度某一半径内的元素</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 以110 30这个点为中心，寻找方圆1000km的城市</span></span><br><span class="line">georadius china:city 110 30 1000 km</span><br></pre></td></tr></table></figure></li><li><p>找出指定位置周围的其他元素</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">georadiusbymember china:city shanghai 1000 km</span><br></pre></td></tr></table></figure></li></ol><p>比如现在比较火的直播业务，我们需要检索附近的主播，那么GEO就可以很好的实现这个功能。</p><ul><li>一是主播开播的时候写入主播<code>Id</code>的经纬度，</li><li>二是主播关播的时候删除主播<code>Id</code>元素，这样就维护了一个具有位置信息的在线主播集合提供给线上检索。</li></ul><h2 id="HyperLogLog"><a href="#HyperLogLog" class="headerlink" title="HyperLogLog"></a>HyperLogLog</h2><p>HyperLogLog是Redis2.8.9提供的一种数据结构，他提供了一种基数统计方法。什么是基数统计呢？简单来说就是一个集合中不重复元素的个数，比如有一个集合{1,2,3,1,2}，那么它的基数就是3。</p><p>HyperLogLog提供了三种指令。</p><ul><li>pfadd  ，Redis Pfadd 命令将所有元素参数添加到 HyperLogLog 数据结构中。</li><li>pfcount，Redis Pfcount 命令返回给定 HyperLogLog 的基数估算值。</li><li>pgmerge，Redis Pgmerge 命令将多个 HyperLogLog 合并为一个 HyperLogLog ，合并后的 HyperLogLog 的基数估算值是通过对所有 给定 HyperLogLog 进行并集计算得出的。</li></ul><p>使用方法如下。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">pfadd uv a b c a c d e f   # 创建一组元素</span><br><span class="line">pfcount uv                 # 统计基数</span><br></pre></td></tr></table></figure><p>有同学会问了，这个功能，我用String类型、或者Set类型都可以实现，为什么要用HyperLogLog呢？</p><p>最大的特性就是： HyperLogLog在数据量非常大的情况下，占用的存储空间非常小，每个 HyperLogLog 键只需要花费 12 KB 内存，就可以计算接近 2^64（2的64次方） 个不同元素的基数，这个是一个非常庞大的数字，为什么能够用这么小的空间来存储这么大的数据呢？</p><p>不知道大家是否注意到，HyperLogLog并没有提供数据查询的命令，只提供了数据添加和数据统计。这是因为HyperLogLog并没有存储每个元素的值，它使用的是概率算法，通过存储元素的hash值的第一个1的位置，来计算元素数量，这块在这里就不做过多展开。</p><p><strong>应用场景：</strong></p><ul><li><p>HyperLogLog更适合做一些统计类的工作，比如统计一个网站的UV。</p></li><li><p>计算日活、7日活、月活数据.</p><p>如果我们通过解析日志，把 ip 信息（或用户 id）放到集合中，例如：HashSet。如果数量不多则还好，但是假如每天访问的用户有几百万。无疑会占用大量的存储空间。且计算月活时，还需要将一个整月的数据放到一个 Set 中，这随时可能导致我们的程序 OOM。</p><p>有了 HyperLogLog，这件事就变得很简单了。因为存储日活数据所需要的内存只有 12K，例如。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 使用日来存储每天的ip地址</span></span><br><span class="line">pfadd ip_20190301 192.168.8.1</span><br><span class="line">pfadd ip_20190302 xxx</span><br><span class="line">pfadd ip_20190303 xxx</span><br><span class="line">...</span><br><span class="line">pfadd ip_20190331 xxx</span><br></pre></td></tr></table></figure><p>计算某一天的日活，只需要执行 PFCOUNT ip_201903XX 就可以了。每个月的第一天，执行 PFMERGE 将上一个月的所有数据合并成一个 HyperLogLog，例如：ip_201903。再去执行 PFCOUNT ip_201903，就得到了 3 月的月活。</p></li></ul><h2 id="Bit"><a href="#Bit" class="headerlink" title="Bit"></a>Bit</h2><p>Bit，其实是String类型中提供的一个功能，他可以设置key对应存储的值指定偏移量上的bit位的值，可能大家理解起来比较抽象，举个例子</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121452834.jpg" alt="img"></p><ul><li><p>使用string类型保存一个key</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set key m</span><br></pre></td></tr></table></figure></li><li><p>通过getbit命令获取 <code>key</code>的bit位的值</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">getbit key 0</span><br><span class="line">getbit key 1</span><br><span class="line">getbit key 2</span><br><span class="line">getbit key 3</span><br><span class="line">getbit key 4</span><br><span class="line">getbit key 5</span><br><span class="line">getbit key 6</span><br><span class="line">getbit key 7</span><br><span class="line">getbit key 8</span><br></pre></td></tr></table></figure><p>打印上面的所有输出，会发现得到一个<strong>0 1 1 0 1 1 0 1</strong>的二进制数据，这个二进制拼接得到的结果。 <code>m</code>的ascII码对应的是109， 109的二进制正好是0 1 1 0 1 1 0 1。</p><p>所以从这里可以看出来，bit其实就是针对一个String类型的value值的bit位进行操作。</p></li><li><p>对<code>key</code>进行修改，修改第6位的值变成1， 第7位的值编程0.</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">setbit key 6 1</span><br><span class="line">setbit key 7 0</span><br></pre></td></tr></table></figure><p>在此使用<code> get key</code>命令，会发现得到的结果是n。</p><p>因为n的二进制是1101110,(十进制是110)。把上面的指定位修改之后，自然就得到了这样的结果。</p></li></ul><p>bit操作在实际应用中，可以怎么使用呢？</p><p>比如学习打卡功能就可以使用setbit操作，比如记录一周的打卡记录。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 设置用户id 1001的打卡记录</span></span><br><span class="line">set sign:1001 0 1   # 已打卡</span><br><span class="line">set sign:1001 1 0   # 未打卡</span><br><span class="line">set sign:1001 2 1   </span><br><span class="line">set sign:1001 3 1</span><br><span class="line">set sign:1001 4 1</span><br></pre></td></tr></table></figure><blockquote><p>查看某天是否已打卡</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">getbit sign 3</span><br></pre></td></tr></table></figure><blockquote><p>统计当前用户总的打卡天数</p></blockquote><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bitcount sign:1001</span><br></pre></td></tr></table></figure><p>除了这个场景之外，还有很多类似的场景都可以使用，</p><ul><li>统计活跃用户</li><li>记录用户在线状态</li></ul><p>bit最大的好处在于，它通过bit位来存储0/1表示特定含义，我们知道一个int类型是8个字节，占32个bit位，意味着一个int类型的数字就可以存储32个有意义的场景，大大压缩了存储空间。</p><h1 id="阶段性总结"><a href="#阶段性总结" class="headerlink" title="阶段性总结"></a>阶段性总结</h1><h2 id="数据结构总结"><a href="#数据结构总结" class="headerlink" title="数据结构总结"></a>数据结构总结</h2><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121452115.png" alt="image-20210630235340028"></p><h2 id="应用场景总结"><a href="#应用场景总结" class="headerlink" title="应用场景总结"></a>应用场景总结</h2><p>实际上，所谓的应用场景，其实就是合理的利用Redis本身的数据结构的特性来完成相关业务功能，就像mysql，它可以用来做服务注册，也可以用来做分布式锁，但是mysql它本质是一个关系型数据库，只是用到了其他特性而已。</p><ul><li><p>缓存——提升热点数据的访问速度</p></li><li><p>共享数据——数据的存储和共享的问题</p></li><li><p>全局ID —— 分布式全局ID的生成方案（分库分表）</p></li><li><p>分布式锁——进程间共享数据的原子操作保证</p></li><li><p>在线用户统计和计数</p></li><li><p>队列、栈——跨进程的队列/栈</p></li><li><p>消息队列——异步解耦的消息机制</p></li><li><p>服务注册与发现 —— RPC通信机制的服务协调中心（Dubbo支持Redis）</p></li><li><p>购物车</p></li><li><p>新浪/Twitter 用户消息时间线</p></li><li><p>抽奖逻辑（礼物、转发）</p></li><li><p>点赞、签到、打卡</p></li><li><p>商品标签</p></li><li><p>用户（商品）关注（推荐）模型</p></li><li><p>电商产品筛选</p></li><li><p>排行榜</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 数据结构 </tag>
            
            <tag> Redis存储原理 </tag>
            
            <tag> Redis应用场景 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从网络通信的演进过程彻底搞懂Redis高性能通信的原理（全网最详细，建议收藏）</title>
      <link href="/posts/3231701875/"/>
      <url>/posts/3231701875/</url>
      
        <content type="html"><![CDATA[<p>我们一直说Redis的性能很快，那为什么快？Redis为了达到性能最大化，做了哪些方面的优化呢？<br>在<a href="https://mp.weixin.qq.com/s?__biz=MzI0MzI1Mjg5Nw==&mid=2247483929&idx=1&sn=9fc45f293738b7bc397c81dc27e6cc16&chksm=e96ea9d7de1920c1bf23962fe56d4a2f9308a21a21d2f815d4a1d425fb7b8dd313c879d36080&token=768967670&lang=zh_CN#rd">深度解析Redis的数据结构</a><br>这篇文章中，其实从数据结构上分析了Redis性能高的一方面原因。</p><p>在目前的k-v数据库的技术选型中，Redis几乎是首选的用来实现高性能缓存的方案，它的性能有多快呢？</p><p>根据官方的基准测试数据，一台普通硬件配置的Linux机器上运行单个Redis实例，处理简单命令（O(n)或者O（logn）），QPS可以达到8W，如果使用pipeline批处理功能，QPS最高可以达到10W。</p><h1 id="Redis-为什么那么快"><a href="#Redis-为什么那么快" class="headerlink" title="Redis 为什么那么快"></a>Redis 为什么那么快</h1><p>Redis的高性能主要依赖于几个方面。</p><ul><li>C语言实现，C语言在一定程度上还是比Java语言性能要高一些，因为C语言不需要经过JVM进行翻译。</li><li>纯内存I/O，内存I/O比磁盘I/O性能更快</li><li>I/O多路复用，基于epoll的I/O多路复用技术，实现高吞吐网络I/O</li><li>单线程模型，单线程无法利用到多核CPU，但是在Redis中，性能瓶颈并不是在计算上，而是在I/O能力，所以单线程能够满足高并发的要求。 从另一个层面来说，单线程可以避免多线程的频繁上下文切换以及同步锁机制带来的性能开销。</li></ul><p>下面我们分别从上述几个方面进行展开说明，先来看网络I/O的多路复用模型。</p><h1 id="从请求处理开始分析"><a href="#从请求处理开始分析" class="headerlink" title="从请求处理开始分析"></a>从请求处理开始分析</h1><p>当我们在客户端向Redis Server发送一条指令，并且得到Redis回复的整个过程中，Redis做了什么呢？</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354817.png" alt="image-20210707221959664"></p><center>图4-1</center><p>要处理命令，则redis必须完整地接收客户端的请求，并将命令解析出来，再将结果读出来，通过网络回写到客户端。整个工序分为以下几个部分：</p><ul><li>接收，通过TCP接收到命令，可能会历经多次TCP包、ack、IO操作</li><li>解析，将命令取出来</li><li>执行，到对应的地方将value读出来</li><li>返回，将value通过TCP返回给客户端，如果value较大，则IO负荷会更重</li></ul><p>其中<strong>解析</strong>和<strong>执行</strong>是纯cpu/内存操作，而接收和返回主要是IO操作，首先我们先来看通信的过程。</p><h2 id="网络IO的通信原理"><a href="#网络IO的通信原理" class="headerlink" title="网络IO的通信原理"></a>网络IO的通信原理</h2><p>同样，我也画了一幅图来描述网络数据的传输流程</p><p>首先，对于TCP通信来说，每个TCP Socket的内核中都有一个发送缓冲区和一个接收缓冲区</p><p>接收缓冲区把数据缓存到内核，若应用进程一直没有调用Socket的read方法进行读取，那么该数据会一直被缓存在接收缓冲区内。不管进程是否读取Socket，对端发来的数据都会经过内核接收并缓存到Socket的内核接收缓冲区。</p><p>read所要做的工作，就是把内核接收缓冲区中的数据复制到应用层用户的Buffer里。</p><p>进程调用Socket的send发送数据的时候，一般情况下是将数据从应用层用户的Buffer里复制到Socket的内核发送缓冲区，然后send就会在上层返回。换句话说，send返回时，数据不一定会被发送到对端。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354929.png" alt="1576066931883"></p><p>网卡中的缓冲区既不属于内核空间，也不属于用户空间。它属于硬件缓冲，允许网卡与操作系统之间有个缓冲；<br>内核缓冲区在内核空间，在内存中，用于内核程序，做为读自或写往硬件的数据缓冲区；<br>用户缓冲区在用户空间，在内存中，用于用户程序，做为读自或写往硬件的数据缓冲区</p><p>网卡芯片收到网络数据会以中断的方式通知CPU，我有数据了，存在我的硬件缓冲里了，来读我啊。<br>CPU收到这个中断信号后，会调用相应的驱动接口函数从网卡的硬件缓冲里把数据读到内核缓冲区，正常情况下会向上传递给TCP/IP模块一层一层的处理。</p><h2 id="NIO多路复用机制"><a href="#NIO多路复用机制" class="headerlink" title="NIO多路复用机制"></a>NIO多路复用机制</h2><p>Redis的通信采用的是多路复用机制，什么是多路复用机制呢？ </p><blockquote><p>由于Redis是C语言实现，为了简化大家的理解，我们采用Java语言来描述这个过程。</p></blockquote><p>在理解多路复用之前，我们先来了解一下BIO。</p><h2 id="BIO模型"><a href="#BIO模型" class="headerlink" title="BIO模型"></a>BIO模型</h2><p>在Java中，如果要实现网络通信，我们会采用Socket套接字来完成。</p><p>Socket这不是一个协议，而是一个通信模型。其实它最初是<strong>BSD</strong>发明的，主要用来一台电脑的两个进程间通信，然后把它用到了两台电脑的进程间通信。所以，可以把它简单理解为进程间通信，不是什么高级的东西。主要做的事情不就是：</p><ul><li><p>A发包：发请求包给某个已经绑定的端口（所以我们经常会访问这样的地址182.13.15.16:1235，1235就是端口）；收到B的允许；然后正式发送；发送完了，告诉B要断开链接；收到断开允许，马上断开，然后发送已经断开信息给B。</p></li><li><p>B收包：绑定端口和IP；然后在这个端口监听；接收到A的请求，发允许给A，并做好接收准备，主要就是清理缓存等待接收新数据；然后正式接收；接受到断开请求，允许断开；确认断开后，继续监听其它请求。</p></li></ul><p>可见，Socket其实就是I/O操作，Socket并不仅限于网络通信，在网络通信中，它涵盖了网络层、传输层、会话层、表示层、应用层——其实这都不需要记，因为Socket通信时候用到了IP和端口，仅这两个就表明了它用到了网络层和传输层；而且它无视多台电脑通信的系统差别，所以它涉及了表示层；一般Socket都是基于一个应用程序的，所以会涉及到会话层和应用层。</p><h3 id="构建基础的BIO通信模型"><a href="#构建基础的BIO通信模型" class="headerlink" title="构建基础的BIO通信模型"></a>构建基础的BIO通信模型</h3><p><strong>BIOServerSocket</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BIOServerSocket</span> </span>&#123;</span><br><span class="line">    <span class="comment">//先定义一个端口号，这个端口的值是可以自己调整的。</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_PORT=<span class="number">8080</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//先定义一个端口号，这个端口的值是可以自己调整的。</span></span><br><span class="line">        <span class="comment">//在服务器端，我们需要使用ServerSocket，所以我们先声明一个ServerSocket变量</span></span><br><span class="line">        ServerSocket serverSocket=<span class="keyword">null</span>;</span><br><span class="line">        <span class="comment">//接下来，我们需要绑定监听端口, 那我们怎么做呢？只需要创建使用serverSocket实例</span></span><br><span class="line">        <span class="comment">//ServerSocket有很多构造重载，在这里，我们把前边定义的端口传入，表示当前</span></span><br><span class="line">        <span class="comment">//ServerSocket监听的端口是8080</span></span><br><span class="line">        serverSocket=<span class="keyword">new</span> ServerSocket(DEFAULT_PORT);</span><br><span class="line">        System.out.println(<span class="string">&quot;启动服务，监听端口：&quot;</span>+DEFAULT_PORT);</span><br><span class="line">        <span class="comment">//回顾一下前面我们讲的内容，接下来我们就需要开始等待客户端的连接了。</span></span><br><span class="line">        <span class="comment">//所以我们要使用的是accept这个函数，并且当accept方法获得一个客户端请求时，会返回</span></span><br><span class="line">        <span class="comment">//一个socket对象， 这个socket对象让服务器可以用来和客户端通信的一个端点。</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">//开始等待客户端连接，如果没有客户端连接，就会一直阻塞在这个位置</span></span><br><span class="line">        Socket socket=serverSocket.accept();</span><br><span class="line">        <span class="comment">//很可能有多个客户端来发起连接，为了区分客户端，咱们可以输出客户端的端口号</span></span><br><span class="line">        System.out.println(<span class="string">&quot;客户端：&quot;</span>+socket.getPort()+<span class="string">&quot;已连接&quot;</span>);</span><br><span class="line">        <span class="comment">//一旦有客户端连接过来，我们就可以用到IO来获得客户端传过来的数据。</span></span><br><span class="line">        <span class="comment">//使用InputStream来获得客户端的输入数据</span></span><br><span class="line">        <span class="comment">//bufferedReader大家还记得吧，他维护了一个缓冲区可以减少数据源读取的频率</span></span><br><span class="line">        BufferedReader bufferedReader=<span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(socket.getInputStream()));</span><br><span class="line">        String clientStr=bufferedReader.readLine(); <span class="comment">//读取一行信息</span></span><br><span class="line">        System.out.println(<span class="string">&quot;客户端发了一段消息：&quot;</span>+clientStr);</span><br><span class="line">        <span class="comment">//服务端收到数据以后，可以给到客户端一个回复。这里咱们用到BufferedWriter</span></span><br><span class="line">        BufferedWriter bufferedWriter=<span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> OutputStreamWriter(socket.getOutputStream()));</span><br><span class="line">        bufferedWriter.write(<span class="string">&quot;我已经收到你的消息了\n&quot;</span>);</span><br><span class="line">        bufferedWriter.flush(); <span class="comment">//清空缓冲区触发消息发送</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>BIOClientSocket</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BIOClientSocket</span> </span>&#123;</span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_PORT=<span class="number">8080</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">//在客户端这边，咱们使用socket来连接到指定的ip和端口</span></span><br><span class="line">        Socket socket=<span class="keyword">new</span> Socket(<span class="string">&quot;localhost&quot;</span>,<span class="number">8080</span>);</span><br><span class="line">        <span class="comment">//使用BufferedWriter，像服务器端写入一个消息</span></span><br><span class="line">        BufferedWriter bufferedWriter=<span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> OutputStreamWriter(socket.getOutputStream()));</span><br><span class="line">        bufferedWriter.write(<span class="string">&quot;我是客户端Client-01\n&quot;</span>);</span><br><span class="line">        bufferedWriter.flush();</span><br><span class="line">        BufferedReader bufferedReader=<span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(socket.getInputStream()));</span><br><span class="line">        String serverStr=bufferedReader.readLine(); <span class="comment">//通过bufferedReader读取服务端返回的消息</span></span><br><span class="line">        System.out.println(<span class="string">&quot;服务端返回的消息：&quot;</span>+serverStr);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述代码构建了一个简单的BIO通信模型，也就是服务端建立一个监听，客户端向服务端发送一个消息，实现简单的网络通信，那BIO有什么弊端呢？</p><p>我们通过对BIOServerSocket进行改造，关注case1和case2部分。</p><ul><li>case1: 增加了while循环，实现重复监听</li><li>case2: 当服务端收到客户端的请求后，不直接返回，而是等待20s。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">BIOServerSocket</span> </span>&#123;</span><br><span class="line">    <span class="comment">//先定义一个端口号，这个端口的值是可以自己调整的。</span></span><br><span class="line">    <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_PORT=<span class="number">8080</span>;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">        ServerSocket serverSocket=<span class="keyword">null</span>;</span><br><span class="line">        serverSocket=<span class="keyword">new</span> ServerSocket(DEFAULT_PORT);</span><br><span class="line">        System.out.println(<span class="string">&quot;启动服务，监听端口：&quot;</span>+DEFAULT_PORT);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>) &#123; <span class="comment">//case1: 增加循环，允许循环接收请求</span></span><br><span class="line">            Socket socket = serverSocket.accept();</span><br><span class="line">            System.out.println(<span class="string">&quot;客户端：&quot;</span> + socket.getPort() + <span class="string">&quot;已连接&quot;</span>);</span><br><span class="line">            BufferedReader bufferedReader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(socket.getInputStream()));</span><br><span class="line">            String clientStr = bufferedReader.readLine(); <span class="comment">//读取一行信息</span></span><br><span class="line">            System.out.println(<span class="string">&quot;客户端发了一段消息：&quot;</span> + clientStr);</span><br><span class="line">            Thread.sleep(<span class="number">20000</span>); <span class="comment">//case2: 修改：增加等待时间</span></span><br><span class="line">            BufferedWriter bufferedWriter = <span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> OutputStreamWriter(socket.getOutputStream()));</span><br><span class="line">            bufferedWriter.write(<span class="string">&quot;我已经收到你的消息了\n&quot;</span>);</span><br><span class="line">            bufferedWriter.flush(); <span class="comment">//清空缓冲区触发消息发送</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>接着，把BIOClientSocket复制两份（client1、client2），同时向BIOServerSocket发起请求。</p><blockquote><p>运行后看到的现象应该是： client1先发送请求到Server端，由于Server端等待20s才返回，导致client2的请求一直被阻塞。</p></blockquote><p>这个情况会导致一个问题，如果服务端在同一个时刻只能处理一个客户端的连接，而如果一个网站同时有1000个用户访问，那么剩下的999个用户都需要等待，而这个等待的耗时取决于前面的请求的处理时长，如图4-2所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354443.png" alt="image-20210708152538953"></p><center>图4-2</center><h3 id="基于多线程优化BIO"><a href="#基于多线程优化BIO" class="headerlink" title="基于多线程优化BIO"></a>基于多线程优化BIO</h3><p>为了让服务端能够同时处理更多的客户端连接，避免因为某个客户端连接阻塞导致后续请求被阻塞，于是引入多线程技术，代码如下。</p><p><strong>ServerSocket</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_PORT=<span class="number">8080</span>;</span><br><span class="line">    ServerSocket serverSocket=<span class="keyword">null</span>;</span><br><span class="line">    serverSocket=<span class="keyword">new</span> ServerSocket(DEFAULT_PORT);</span><br><span class="line">    System.out.println(<span class="string">&quot;启动服务，监听端口：&quot;</span>+DEFAULT_PORT);</span><br><span class="line">    ExecutorService executorService= Executors.newFixedThreadPool(<span class="number">5</span>);</span><br><span class="line">    <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">        Socket socket = serverSocket.accept();</span><br><span class="line">        executorService.submit(<span class="keyword">new</span> SocketThread(socket));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>SocketThread</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">SocketThread</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    Socket socket;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">SocketThread</span><span class="params">(Socket socket)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.socket = socket;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;客户端：&quot;</span> + socket.getPort() + <span class="string">&quot;已连接&quot;</span>);</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            BufferedReader bufferedReader = <span class="keyword">new</span> BufferedReader(<span class="keyword">new</span> InputStreamReader(socket.getInputStream()));</span><br><span class="line">            String clientStr = <span class="keyword">null</span>; <span class="comment">//读取一行信息</span></span><br><span class="line">            clientStr = bufferedReader.readLine();</span><br><span class="line">            System.out.println(<span class="string">&quot;客户端发了一段消息：&quot;</span> + clientStr);</span><br><span class="line">            Thread.sleep(<span class="number">20000</span>);</span><br><span class="line">            BufferedWriter bufferedWriter = <span class="keyword">new</span> BufferedWriter(<span class="keyword">new</span> OutputStreamWriter(socket.getOutputStream()));</span><br><span class="line">            bufferedWriter.write(<span class="string">&quot;我已经收到你的消息了\n&quot;</span>);</span><br><span class="line">            bufferedWriter.flush(); <span class="comment">//清空缓冲区触发消息发送</span></span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>如图4-3所示，当引入了多线程之后，每个客户端的链接（Socket），我们可以直接给到线程池去执行，而由于这个过程是异步的，所以并不会同步阻塞影响后续链接的监听，因此在一定程度上可以提升服务端链接的处理数量。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354397.png" alt="image-20210708160026412"></p><center>图4-3</center><h2 id="NIO非阻塞IO"><a href="#NIO非阻塞IO" class="headerlink" title="NIO非阻塞IO"></a>NIO非阻塞IO</h2><p>使用多线程的方式来解决这个问题，仍然有一个缺点，线程的数量取决于硬件配置，所以线程数量是有限的，如果请求量比较大的时候，线程本身会收到限制从而并发量也不会太高。那怎么办呢，我们可以采用非阻塞IO。</p><p>NIO 从JDK1.4 提出的，本意是New IO，它的出现为了弥补原本IO的不足，提供了更高效的方式，提出一个通道（channel）的概念，在IO中它始终以流的形式对数据的传输和接受，下面我们演示一下NIO的使用。</p><p><strong>NioServerSocket</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NioServerSocket</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();</span><br><span class="line">            serverSocketChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            serverSocketChannel.socket().bind(<span class="keyword">new</span> InetSocketAddress(<span class="number">8080</span>));</span><br><span class="line">            <span class="keyword">while</span> (<span class="keyword">true</span>) &#123;</span><br><span class="line">                SocketChannel socketChannel = serverSocketChannel.accept();</span><br><span class="line">                <span class="keyword">if</span> (socketChannel != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="comment">//读取数据</span></span><br><span class="line">                    ByteBuffer buffer = ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">                    socketChannel.read(buffer);</span><br><span class="line">                    System.out.println(<span class="keyword">new</span> String(buffer.array()));</span><br><span class="line">                    <span class="comment">//写出数据</span></span><br><span class="line">                    Thread.sleep(<span class="number">10000</span>); <span class="comment">//阻塞一段时间</span></span><br><span class="line">                    <span class="comment">//当数据读取到缓冲区之后，接下来就需要把缓冲区的数据写出到通道，而在写出之前必须要调用flip方法，实际上就是重置一个有效字节范围，然后把这个数据接触到通道。</span></span><br><span class="line">                    buffer.flip();</span><br><span class="line">                    socketChannel.write(buffer);<span class="comment">//写出数据</span></span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                    System.out.println(<span class="string">&quot;连接未就绪&quot;</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><strong>NioClientSocket</strong></p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NioClientSocket</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            SocketChannel socketChannel= SocketChannel.open();</span><br><span class="line">            socketChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            socketChannel.connect(<span class="keyword">new</span> InetSocketAddress(<span class="string">&quot;localhost&quot;</span>,<span class="number">8080</span>));</span><br><span class="line">            <span class="keyword">if</span>(socketChannel.isConnectionPending())&#123;</span><br><span class="line">                socketChannel.finishConnect();</span><br><span class="line">            &#125;</span><br><span class="line">            ByteBuffer byteBuffer= ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">            byteBuffer.put(<span class="string">&quot;Hello I&#x27;M SocketChannel Client&quot;</span>.getBytes());</span><br><span class="line">            byteBuffer.flip();</span><br><span class="line">            socketChannel.write(byteBuffer);</span><br><span class="line">            <span class="comment">//读取服务端数据</span></span><br><span class="line">            byteBuffer.clear();</span><br><span class="line">            <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">                <span class="keyword">int</span> i = socketChannel.read(byteBuffer);</span><br><span class="line">                <span class="keyword">if</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;收到服务端的数据：&quot;</span> + <span class="keyword">new</span> String(byteBuffer.array()));</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    System.out.println(<span class="string">&quot;服务端数据未准备好&quot;</span>);</span><br><span class="line">                    Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException | InterruptedException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>所谓的NIO（非阻塞IO），其实就是取消了IO阻塞和连接阻塞，当服务端不存在阻塞的时候，就可以不断轮询处理客户端的请求，如图4-4所示，表示NIO下的运行流程。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354021.png" alt="image-20210708165359843"></p><center>图4-4</center><p>上述这种NIO的使用方式，仍然存在一个问题，就是客户端或者服务端需要通过一个线程不断轮询才能获得结果，而这个轮询过程中会浪费线程资源。</p><h2 id="多路复用IO"><a href="#多路复用IO" class="headerlink" title="多路复用IO"></a>多路复用IO</h2><p>大家站在全局的角度再思考一下整个过程，有哪些地方可以优化呢？</p><p>我们回到NIOClientSocket中下面这段代码，当客户端通过<code>read</code>方法去读取服务端返回的数据时，如果此时服务端数据未准备好，对于客户端来说就是一次无效的轮询。</p><p>我们能不能够设计成，当客户端调用<code>read</code>方法之后，不仅仅不阻塞，同时也不需要轮询。而是等到服务端的数据就绪之后， 告诉客户端。然后客户端再去读取服务端返回的数据呢？</p><blockquote><p>就像点外卖一样，我们在网上下单之后，继续做其他事情，等到外卖到了公司，外卖小哥主动打电话告诉你，你直接去前台取餐即可。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">    <span class="keyword">int</span> i = socketChannel.read(byteBuffer);</span><br><span class="line">    <span class="keyword">if</span> (i &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;收到服务端的数据：&quot;</span> + <span class="keyword">new</span> String(byteBuffer.array()));</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        System.out.println(<span class="string">&quot;服务端数据未准备好&quot;</span>);</span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>所以为了优化这个问题，引入了多路复用机制。</p></blockquote><p>I/O多路复用的本质是通过一种机制（系统内核缓冲I/O数据），让单个进程可以监视多个文件描述符，一旦某个描述符就绪（一般是读就绪或写就绪），能够通知程序进行相应的读写操作</p><blockquote><p><strong>什么是fd</strong>：在linux中，内核把所有的外部设备都当成是一个文件来操作，对一个文件的读写会调用内核提供的系统命令，返回一个fd(文件描述符)。而对于一个socket的读写也会有相应的文件描述符，成为socketfd。</p></blockquote><p>常见的IO多路复用方式有<strong>【select、poll、epoll】</strong>，都是Linux API提供的IO复用方式，那么接下来重点讲一下select、和epoll这两个模型</p><ul><li><p><strong>select：</strong>进程可以通过把一个或者多个fd传递给select系统调用，进程会阻塞在select操作上，这样select可以帮我们检测多个fd是否处于就绪状态，这个模式有两个缺点</p><ul><li>由于他能够同时监听多个文件描述符，假如说有1000个，这个时候如果其中一个fd 处于就绪状态了，那么当前进程需要线性轮询所有的fd，也就是监听的fd越多，性能开销越大。</li><li>同时，select在单个进程中能打开的fd是有限制的，默认是1024，对于那些需要支持单机上万的TCP连接来说确实有点少</li></ul></li><li><p><strong>epoll</strong>：linux还提供了epoll的系统调用，epoll是基于事件驱动方式来代替顺序扫描，因此性能相对来说更高，主要原理是，当被监听的fd中，有fd就绪时，会告知当前进程具体哪一个fd就绪，那么当前进程只需要去从指定的fd上读取数据即可，另外，epoll所能支持的fd上线是操作系统的最大文件句柄，这个数字要远远大于1024</p></li></ul><blockquote><p>【由于epoll能够通过事件告知应用进程哪个fd是可读的，所以我们也称这种IO为异步非阻塞IO，当然它是伪异步的，因为它还需要去把数据从内核同步复制到用户空间中，真正的异步非阻塞，应该是数据已经完全准备好了，我只需要从用户空间读就行】</p></blockquote><p>I/O多路复用的好处是可以通过把多个I/O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程的情况下可以同时处理多个客户端请求。它的最大优势是系统开销小，并且不需要创建新的进程或者线程，降低了系统的资源开销，它的整体实现思想如图4-5所示。</p><p>客户端请求到服务端后，此时客户端在传输数据过程中，为了避免Server端在read客户端数据过程中阻塞，服务端会把该请求注册到Selector复路器上，服务端此时不需要等待，只需要启动一个线程，通过selector.select()阻塞轮询复路器上就绪的channel即可，也就是说，如果某个客户端连接数据传输完成，那么select()方法会返回就绪的channel，然后执行相关的处理即可。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354428.png" alt="image-20210708203509498"></p><center>图4-5</center><p><strong>NIOServer的实现如下</strong></p><blockquote><p>测试访问的时候，直接在cmd中通过telnet连接NIOServer，便可发送信息。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">NIOServer</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    Selector selector;</span><br><span class="line">    ServerSocketChannel serverSocketChannel;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">NIOServer</span><span class="params">(<span class="keyword">int</span> port)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        selector=Selector.open(); <span class="comment">//多路复用器</span></span><br><span class="line">        serverSocketChannel=ServerSocketChannel.open();</span><br><span class="line">        <span class="comment">//绑定监听端口</span></span><br><span class="line">        serverSocketChannel.socket().bind(<span class="keyword">new</span> InetSocketAddress(port));</span><br><span class="line">        serverSocketChannel.configureBlocking(<span class="keyword">false</span>);<span class="comment">//非阻塞配置</span></span><br><span class="line">        <span class="comment">//针对serverSocketChannel注册一个ACCEPT连接监听事件</span></span><br><span class="line">        serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(!Thread.interrupted())&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                selector.select(); <span class="comment">//阻塞等待事件就绪</span></span><br><span class="line">                Set selected=selector.selectedKeys(); <span class="comment">//得到事件列表</span></span><br><span class="line">                Iterator it=selected.iterator();</span><br><span class="line">                <span class="keyword">while</span>(it.hasNext())&#123;</span><br><span class="line">                    dispatch((SelectionKey) it.next()); <span class="comment">//分发事件</span></span><br><span class="line">                    it.remove(); <span class="comment">//移除当前时间</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">dispatch</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(key.isAcceptable())&#123; <span class="comment">//如果是客户端的连接事件，则需要针对该连接注册读写事件</span></span><br><span class="line">            register(key);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(key.isReadable())&#123;</span><br><span class="line">            read(key);</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(key.isWritable())&#123;</span><br><span class="line">            write(key);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//得到事件对应的连接</span></span><br><span class="line">        ServerSocketChannel server=(ServerSocketChannel)key.channel();</span><br><span class="line">        SocketChannel channel=server.accept(); <span class="comment">//获得客户端的链接</span></span><br><span class="line">        channel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">        <span class="comment">//把当前客户端连接注册到selector上，注册事件为READ，</span></span><br><span class="line">        <span class="comment">// 也就是当前channel可读时，就会触发事件，然后读取客户端的数据</span></span><br><span class="line">        channel.register(<span class="keyword">this</span>.selector,SelectionKey.OP_READ);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">read</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        SocketChannel channel=(SocketChannel)key.channel();</span><br><span class="line">        ByteBuffer byteBuffer= ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">        channel.read(byteBuffer); <span class="comment">//把数据从channel读取到缓冲区</span></span><br><span class="line">        System.out.println(<span class="string">&quot;server receive msg:&quot;</span>+<span class="keyword">new</span> String(byteBuffer.array()));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        SocketChannel channel=(SocketChannel)key.channel();</span><br><span class="line">        <span class="comment">//写一个信息给到客户端</span></span><br><span class="line">        channel.write(ByteBuffer.wrap(<span class="string">&quot;hello Client,I&#x27;m NIO Server\r\n&quot;</span>.getBytes()));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        NIOServer server=<span class="keyword">new</span> NIOServer(<span class="number">8888</span>);</span><br><span class="line">        <span class="keyword">new</span> Thread(server).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>事实上NIO已经解决了上述BIO暴露的下面两个问题：</p><ol><li>同步阻塞IO，读写阻塞，线程等待时间过长。</li><li>在制定线程策略的时候，只能根据CPU的数目来限定可用线程资源，不能根据连接并发数目来制定，也就是连接有限制。否则很难保证对客户端请求的高效和公平。</li></ol><p>到这里为止，通过NIO的多路复用机制，解决了IO阻塞导致客户端连接处理受限的问题，服务端只需要一个线程就可以维护多个客户端，并且客户端的某个连接如果准备就绪时，会通过事件机制告诉应用程序某个channel可用，应用程序通过select方法选出就绪的channel进行处理。</p><h2 id="单线程Reactor-模型（高性能I-O设计模式）"><a href="#单线程Reactor-模型（高性能I-O设计模式）" class="headerlink" title="单线程Reactor 模型（高性能I/O设计模式）"></a>单线程Reactor 模型（高性能I/O设计模式）</h2><p>了解了NIO多路复用后，就有必要再和大家说一下Reactor多路复用高性能I/O设计模式，Reactor本质上就是基于NIO多路复用机制提出的一个高性能IO设计模式，它的核心思想是把响应IO事件和业务处理进行分离，通过一个或者多个线程来处理IO事件，然后将就绪得到事件分发到业务处理handlers线程去异步非阻塞处理，如图4-6所示。</p><p>Reactor模型有三个重要的组件：</p><ul><li><strong>Reactor ：</strong>将I/O事件发派给对应的Handler</li><li><strong>Acceptor ：</strong>处理客户端连接请求</li><li><strong>Handlers ：</strong>执行非阻塞读/写</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354642.png" alt="image-20210708212057895"></p><center>图4-6</center><blockquote><p>下面演示一个单线程的Reactor模型。</p></blockquote><h3 id="Reactor"><a href="#Reactor" class="headerlink" title="Reactor"></a>Reactor</h3><p>Reactor 负责响应IO事件，一旦发生，广播发送给相应的Handler去处理。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Reactor</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Selector selector;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ServerSocketChannel serverSocketChannel;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Reactor</span><span class="params">(<span class="keyword">int</span> port)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="comment">//创建选择器</span></span><br><span class="line">        selector= Selector.open();</span><br><span class="line">        <span class="comment">//创建NIO-Server</span></span><br><span class="line">        serverSocketChannel=ServerSocketChannel.open();</span><br><span class="line">        serverSocketChannel.bind(<span class="keyword">new</span> InetSocketAddress(port));</span><br><span class="line">        serverSocketChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">        SelectionKey key=serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);</span><br><span class="line">        <span class="comment">// 绑定一个附加对象</span></span><br><span class="line">        key.attach(<span class="keyword">new</span> Acceptor(selector,serverSocketChannel));</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">while</span>(!Thread.interrupted())&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                selector.select(); <span class="comment">//阻塞等待就绪事件</span></span><br><span class="line">                Set selectionKeys=selector.selectedKeys();</span><br><span class="line">                Iterator it=selectionKeys.iterator();</span><br><span class="line">                <span class="keyword">while</span>(it.hasNext())&#123;</span><br><span class="line">                    dispatch((SelectionKey) it.next());</span><br><span class="line">                    it.remove();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">dispatch</span><span class="params">(SelectionKey key)</span></span>&#123;</span><br><span class="line">        <span class="comment">//调用之前注册时附加的对象，也就是attach附加的acceptor</span></span><br><span class="line">        Runnable r=(Runnable)key.attachment();</span><br><span class="line">        <span class="keyword">if</span>(r!=<span class="keyword">null</span>)&#123;</span><br><span class="line">            r.run();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> Thread(<span class="keyword">new</span> Reactor(<span class="number">8888</span>)).start();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Acceptor"><a href="#Acceptor" class="headerlink" title="Acceptor"></a>Acceptor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Acceptor</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Selector selector;</span><br><span class="line">    <span class="keyword">private</span> ServerSocketChannel serverSocketChannel;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Acceptor</span><span class="params">(Selector selector, ServerSocketChannel serverSocketChannel)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.selector = selector;</span><br><span class="line">        <span class="keyword">this</span>.serverSocketChannel = serverSocketChannel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        SocketChannel channel;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            channel=serverSocketChannel.accept();</span><br><span class="line">            System.out.println(channel.getRemoteAddress()+<span class="string">&quot;: 收到一个客户端连接&quot;</span>);</span><br><span class="line">            channel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            <span class="comment">//当channel连接中数据就绪时，调用DispatchHandler来处理channel</span></span><br><span class="line">            <span class="comment">//巧妙使用了SocketChannel的attach功能，将Hanlder和可能会发生事件的channel链接在一起，当发生事件时，可以立即触发相应链接的Handler。</span></span><br><span class="line">            channel.register(selector, SelectionKey.OP_READ,<span class="keyword">new</span> DispatchHandler(channel));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Handler"><a href="#Handler" class="headerlink" title="Handler"></a>Handler</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">DispatchHandler</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> SocketChannel channel;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">DispatchHandler</span><span class="params">(SocketChannel channel)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.channel = channel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        System.out.println(Thread.currentThread().getName()+<span class="string">&quot;---handler&quot;</span>); <span class="comment">//case: 打印当前线程名称，证明I/O是同一个线程来处理。</span></span><br><span class="line">        ByteBuffer buffer=ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">        <span class="keyword">int</span> len=<span class="number">0</span>,total=<span class="number">0</span>;</span><br><span class="line">        String msg=<span class="string">&quot;&quot;</span>;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">do</span> &#123;</span><br><span class="line">                len = channel.read(buffer);</span><br><span class="line">                <span class="keyword">if</span> (len &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                    total += len;</span><br><span class="line">                    msg += <span class="keyword">new</span> String(buffer.array());</span><br><span class="line">                &#125;</span><br><span class="line">                buffer.clear();</span><br><span class="line">            &#125; <span class="keyword">while</span> (len &gt; buffer.capacity());</span><br><span class="line">            System.out.println(channel.getRemoteAddress()+<span class="string">&quot;:Server Receive msg:&quot;</span>+msg);</span><br><span class="line"></span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">            <span class="keyword">if</span>(channel!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                <span class="keyword">try</span> &#123;</span><br><span class="line">                    channel.close();</span><br><span class="line">                &#125; <span class="keyword">catch</span> (IOException ioException) &#123;</span><br><span class="line">                    ioException.printStackTrace();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><blockquote><p>演示方式，通过window的cmd窗口，使用telnet 192.168.1.102 8888 连接到Server端进行数据通信；也可以通过下面这样一个客户端程序来访问。</p></blockquote><h3 id="ReactorClient"><a href="#ReactorClient" class="headerlink" title="ReactorClient"></a>ReactorClient</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ReactorClient</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Selector selector;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        selector=Selector.open();</span><br><span class="line">        <span class="comment">//创建一个连接通道连接指定的server</span></span><br><span class="line">        SocketChannel socketChannel= SocketChannel.open();</span><br><span class="line">        socketChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">        socketChannel.connect(<span class="keyword">new</span> InetSocketAddress(<span class="string">&quot;192.168.1.102&quot;</span>,<span class="number">8888</span>));</span><br><span class="line">        socketChannel.register(selector, SelectionKey.OP_CONNECT);</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</span><br><span class="line">            selector.select();</span><br><span class="line">            Set&lt;SelectionKey&gt; selectionKeys=selector.selectedKeys();</span><br><span class="line">            Iterator&lt;SelectionKey&gt; iterator=selectionKeys.iterator();</span><br><span class="line">            <span class="keyword">while</span>(iterator.hasNext())&#123;</span><br><span class="line">                SelectionKey key=iterator.next();</span><br><span class="line">                iterator.remove();</span><br><span class="line">                <span class="keyword">if</span>(key.isConnectable())&#123;</span><br><span class="line">                    handleConnection(key);</span><br><span class="line">                &#125;<span class="keyword">else</span> <span class="keyword">if</span>(key.isReadable())&#123;</span><br><span class="line">                    handleRead(key);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">handleConnection</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        SocketChannel socketChannel=(SocketChannel)key.channel();</span><br><span class="line">        <span class="keyword">if</span>(socketChannel.isConnectionPending())&#123;</span><br><span class="line">            socketChannel.finishConnect();</span><br><span class="line">        &#125;</span><br><span class="line">        socketChannel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">        <span class="keyword">while</span>(<span class="keyword">true</span>) &#123;</span><br><span class="line">            Scanner in = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line">            String msg = in.nextLine();</span><br><span class="line">            socketChannel.write(ByteBuffer.wrap(msg.getBytes()));</span><br><span class="line">            socketChannel.register(selector,SelectionKey.OP_READ);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">handleRead</span><span class="params">(SelectionKey key)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        SocketChannel channel=(SocketChannel)key.channel();</span><br><span class="line">        ByteBuffer byteBuffer=ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">        channel.read(byteBuffer);</span><br><span class="line">        System.out.println(<span class="string">&quot;client receive msg:&quot;</span>+<span class="keyword">new</span> String(byteBuffer.array()));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这是最基本的单Reactor单线程模型<strong>（整体的I/O操作是由同一个线程完成的）</strong>。</p><p>其中Reactor线程，负责多路分离套接字，有新连接到来触发connect 事件之后，交由Acceptor进行处理，有IO读写事件之后交给hanlder 处理。</p><p>Acceptor主要任务就是构建handler ，在获取到和client相关的SocketChannel之后 ，绑定到相应的hanlder上，对应的SocketChannel有读写事件之后，基于racotor 分发,hanlder就可以处理了（所有的IO事件都绑定到selector上，有Reactor分发）</p><blockquote><p><strong>Reactor 模式本质上指的是使用 I/O 多路复用(I/O multiplexing) + 非阻塞 I/O(non-blocking I/O)的模式。</strong></p></blockquote><h2 id="多线程单Reactor模型"><a href="#多线程单Reactor模型" class="headerlink" title="多线程单Reactor模型"></a>多线程单Reactor模型</h2><p>单线程Reactor这种实现方式有存在着缺点，从实例代码中可以看出，handler的执行是串行的，如果其中一个handler处理线程阻塞将导致其他的业务处理阻塞。由于handler和reactor在同一个线程中的执行，这也将导致新的无法接收新的请求，我们做一个小实验：</p><ul><li>在上述Reactor代码的DispatchHandler的run方法中，增加一个Thread.sleep()。</li><li>打开多个客户端窗口连接到Reactor Server端，其中一个窗口发送一个信息后被阻塞，另外一个窗口再发信息时由于前面的请求阻塞导致后续请求无法被处理。</li></ul><p>为了解决这种问题，有人提出使用多线程的方式来处理业务，也就是在业务处理的地方加入线程池异步处理，将reactor和handler在不同的线程来执行，如图4-7所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354175.png" alt="image-20210709154534593"></p><center>图4-7</center><h3 id="多线程改造-MultiDispatchHandler"><a href="#多线程改造-MultiDispatchHandler" class="headerlink" title="多线程改造-MultiDispatchHandler"></a>多线程改造-MultiDispatchHandler</h3><p>我们直接将4.2.5小节中的Reactor单线程模型改成多线程，其实我们就是把IO阻塞的问题通过异步的方式做了优化，代码如下，</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiDispatchHandler</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> SocketChannel channel;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MultiDispatchHandler</span><span class="params">(SocketChannel channel)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.channel = channel;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Executor executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors() &lt;&lt; <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        processor();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">processor</span><span class="params">()</span></span>&#123;</span><br><span class="line">        executor.execute(<span class="keyword">new</span> ReaderHandler(channel));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">ReaderHandler</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">        <span class="keyword">private</span> SocketChannel channel;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="title">ReaderHandler</span><span class="params">(SocketChannel socketChannel)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">this</span>.channel = socketChannel;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            System.out.println(Thread.currentThread().getName()+<span class="string">&quot;---handler&quot;</span>); <span class="comment">//case: 打印当前线程名称，证明I/O是同一个线程来处理。</span></span><br><span class="line">            ByteBuffer buffer= ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">            <span class="keyword">int</span> len=<span class="number">0</span>;</span><br><span class="line">            String msg=<span class="string">&quot;&quot;</span>;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">do</span> &#123;</span><br><span class="line">                    len = channel.read(buffer);</span><br><span class="line">                    <span class="keyword">if</span> (len &gt; <span class="number">0</span>) &#123;</span><br><span class="line">                        msg += <span class="keyword">new</span> String(buffer.array());</span><br><span class="line">                    &#125;</span><br><span class="line">                    buffer.clear();</span><br><span class="line">                &#125; <span class="keyword">while</span> (len &gt; buffer.capacity());</span><br><span class="line"></span><br><span class="line">                <span class="keyword">if</span>(len&gt;<span class="number">0</span>) &#123;</span><br><span class="line">                    System.out.println(channel.getRemoteAddress() + <span class="string">&quot;:Server Receive msg:&quot;</span> + msg);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">                <span class="keyword">if</span>(channel!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                    <span class="keyword">try</span> &#123;</span><br><span class="line">                        channel.close();</span><br><span class="line">                    &#125; <span class="keyword">catch</span> (IOException ioException) &#123;</span><br><span class="line">                        ioException.printStackTrace();</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Acceptor-1"><a href="#Acceptor-1" class="headerlink" title="Acceptor"></a>Acceptor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Acceptor</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Selector selector;</span><br><span class="line">    <span class="keyword">private</span> ServerSocketChannel serverSocketChannel;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Acceptor</span><span class="params">(Selector selector, ServerSocketChannel serverSocketChannel)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.selector = selector;</span><br><span class="line">        <span class="keyword">this</span>.serverSocketChannel = serverSocketChannel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        SocketChannel channel;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            channel=serverSocketChannel.accept();</span><br><span class="line">            System.out.println(channel.getRemoteAddress()+<span class="string">&quot;: 收到一个客户端连接&quot;</span>);</span><br><span class="line">            channel.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">            <span class="comment">//当channel连接中数据就绪时，调用DispatchHandler来处理channel</span></span><br><span class="line">            <span class="comment">//巧妙使用了SocketChannel的attach功能，将Hanlder和可能会发生事件的channel链接在一起，当发生事件时，可以立即触发相应链接的Handler。</span></span><br><span class="line">            channel.register(selector, SelectionKey.OP_READ,<span class="keyword">new</span> MultiDispatchHandler(channel));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="多线程Reactor总结"><a href="#多线程Reactor总结" class="headerlink" title="多线程Reactor总结"></a>多线程Reactor总结</h3><p>在多线程Reactor模型中，添加了一个工作者线程池，并将非I/O操作从Reactor线程中移出转交给工作者线程池来执行。这样能够提高Reactor线程的I/O响应，不至于因为一些耗时的业务逻辑而延迟对后面I/O请求的处理。</p><h2 id="多Reactor多线程模式（主从多Reactor模型）"><a href="#多Reactor多线程模式（主从多Reactor模型）" class="headerlink" title="多Reactor多线程模式（主从多Reactor模型）"></a>多Reactor多线程模式（主从多Reactor模型）</h2><p>在多线程单Reactor模型中，我们发现所有的I/O操作是由一个Reactor来完成，而Reactor运行在单个线程中，它需要处理包括<code>Accept()</code>/<code>read()</code>/<code>write</code>/<code>connect</code>操作，对于小容量的场景，影响不大。但是对于高负载、大并发或大数据量的应用场景时，容易成为瓶颈，主要原因如下：</p><ul><li>一个NIO线程同时处理成百上千的链路，性能上无法支撑，即便NIO线程的CPU负荷达到100%，也无法满足海量消息的读取和发送；</li><li>当NIO线程负载过重之后，处理速度将变慢，这会导致大量客户端连接超时，超时之后往往会进行重发，这更加重了NIO线程的负载，最终会导致大量消息积压和处理超时，成为系统的性能瓶颈；</li></ul><p>所以，我们还可以更进一步优化，引入多Reactor多线程模式，如图4-8所示，Main Reactor负责接收客户端的连接请求，然后把接收到的请求传递给SubReactor（其中subReactor可以有多个），具体的业务IO处理由SubReactor完成。</p><blockquote><p>Multiple Reactors 模式通常也可以等同于 Master-Workers 模式，比如 Nginx 和 Memcached 等就是采用这种多线程模型，虽然不同的项目实现细节略有区别，但总体来说模式是一致的。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354593.png" alt="image-20210709162516832"></p><center>图4-8</center><ul><li><p><strong>Acceptor</strong>，请求接收者，在实践时其职责类似服务器，并不真正负责连接请求的建立，而只将其请求委托 Main Reactor 线程池来实现，起到一个转发的作用。</p></li><li><p><strong>Main Reactor</strong>，主 Reactor 线程组，主要<strong>负责连接事件</strong>，并将<strong>IO读写请求转发到 SubReactor 线程池</strong>。</p></li><li><p><strong>Sub Reactor</strong>，Main Reactor 通常监听客户端连接后会将通道的读写转发到 Sub Reactor 线程池中一个线程(负载均衡)，负责数据的读写。在 NIO 中 通常注册通道的读(OP_READ)、写事件(OP_WRITE)。</p></li></ul><h3 id="MultiplyReactor"><a href="#MultiplyReactor" class="headerlink" title="MultiplyReactor"></a>MultiplyReactor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">MultiplyReactor</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        MultiplyReactor mr = <span class="keyword">new</span> MultiplyReactor(<span class="number">8888</span>);</span><br><span class="line">        mr.start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> POOL_SIZE = Runtime.getRuntime().availableProcessors();</span><br><span class="line">    <span class="comment">// Reactor（Selector） 线程池，其中一个线程被 mainReactor 使用，剩余线程都被 subReactor 使用</span></span><br><span class="line">    <span class="keyword">static</span> Executor mainReactorExecutor = Executors.newFixedThreadPool(POOL_SIZE);</span><br><span class="line">    <span class="comment">// 主 Reactor，接收连接，把 SocketChannel 注册到从 Reactor 上</span></span><br><span class="line">    <span class="keyword">private</span> Reactor mainReactor;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> port;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">MultiplyReactor</span><span class="params">(<span class="keyword">int</span> port)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">this</span>.port = port;</span><br><span class="line">            mainReactor = <span class="keyword">new</span> Reactor();</span><br><span class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 启动主从 Reactor，初始化并注册 Acceptor 到主 Reactor</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">start</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">new</span> Acceptor(mainReactor.getSelector(), port); <span class="comment">// 将 ServerSocketChannel 注册到 mainReactor</span></span><br><span class="line">        mainReactorExecutor.execute(mainReactor); <span class="comment">//使用线程池来处理main Reactor的连接请求</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Reactor-1"><a href="#Reactor-1" class="headerlink" title="Reactor"></a>Reactor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Reactor</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> ConcurrentLinkedQueue&lt;AsyncHandler&gt; events=<span class="keyword">new</span> ConcurrentLinkedQueue&lt;&gt;();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> Selector selector;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Reactor</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.selector = Selector.open();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Selector <span class="title">getSelector</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> selector;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">while</span> (!Thread.interrupted()) &#123;</span><br><span class="line">                AsyncHandler handler;</span><br><span class="line">                <span class="keyword">while</span> ((handler = events.poll()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                    handler.getChannel().configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">                    SelectionKey sk=handler.getChannel().register(selector, SelectionKey.OP_READ);</span><br><span class="line">                    sk.attach(handler);</span><br><span class="line">                    handler.setSk(sk);</span><br><span class="line">                &#125;</span><br><span class="line">                selector.select(); <span class="comment">//阻塞</span></span><br><span class="line">                Set&lt;SelectionKey&gt; selectionKeys=selector.selectedKeys();</span><br><span class="line">                Iterator&lt;SelectionKey&gt; it=selectionKeys.iterator();</span><br><span class="line">                <span class="keyword">while</span>(it.hasNext())&#123;</span><br><span class="line">                    SelectionKey key=it.next();</span><br><span class="line">                    <span class="comment">//获取attach方法传入的附加对象</span></span><br><span class="line">                    Runnable runnable=(Runnable)key.attachment();</span><br><span class="line">                    <span class="keyword">if</span>(runnable!=<span class="keyword">null</span>)&#123;</span><br><span class="line">                        runnable.run();</span><br><span class="line">                    &#125;</span><br><span class="line">                    it.remove();</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">register</span><span class="params">(AsyncHandler asyncHandler)</span></span>&#123;</span><br><span class="line">        events.offer(asyncHandler);</span><br><span class="line">        selector.wakeup();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Acceptor-2"><a href="#Acceptor-2" class="headerlink" title="Acceptor"></a>Acceptor</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Acceptor</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">final</span> Selector sel;</span><br><span class="line">    <span class="keyword">final</span> ServerSocketChannel serverSocket;</span><br><span class="line">    <span class="keyword">int</span> handleNext = <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> POOL_SIZE=Runtime.getRuntime().availableProcessors();</span><br><span class="line">    <span class="keyword">private</span> Executor subReactorExecutor= Executors.newFixedThreadPool(POOL_SIZE);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Reactor[] subReactors=<span class="keyword">new</span> Reactor[POOL_SIZE-<span class="number">1</span>];</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Acceptor</span><span class="params">(Selector sel, <span class="keyword">int</span> port)</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sel = sel;</span><br><span class="line">        serverSocket = ServerSocketChannel.open();</span><br><span class="line">        serverSocket.socket().bind(<span class="keyword">new</span> InetSocketAddress(port)); <span class="comment">// 绑定端口</span></span><br><span class="line">        <span class="comment">// 设置成非阻塞模式</span></span><br><span class="line">        serverSocket.configureBlocking(<span class="keyword">false</span>);</span><br><span class="line">        <span class="comment">// 注册到 选择器 并设置处理 socket 连接事件</span></span><br><span class="line">        serverSocket.register(sel, SelectionKey.OP_ACCEPT,<span class="keyword">this</span>);</span><br><span class="line">        init();</span><br><span class="line">        System.out.println(<span class="string">&quot;mainReactor-&quot;</span> + <span class="string">&quot;Acceptor: Listening on port: &quot;</span> + port);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; subReactors.length; i++) &#123;</span><br><span class="line">            subReactors[i]=<span class="keyword">new</span> Reactor();</span><br><span class="line">            subReactorExecutor.execute(subReactors[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">synchronized</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="comment">// 接收连接，非阻塞模式下，没有连接直接返回 null</span></span><br><span class="line">            SocketChannel sc = serverSocket.accept();</span><br><span class="line">            <span class="keyword">if</span> (sc != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="comment">// 把提示发到界面</span></span><br><span class="line">                sc.write(ByteBuffer.wrap(<span class="string">&quot;Multiply Reactor Pattern Example\r\nreactor&gt; &quot;</span>.getBytes()));</span><br><span class="line">                System.out.println(Thread.currentThread().getName()+<span class="string">&quot;:Main-Reactor-Acceptor: &quot;</span> + sc.socket().getLocalSocketAddress() +<span class="string">&quot; 注册到 subReactor-&quot;</span> + handleNext);</span><br><span class="line">                <span class="comment">// 如何解决呢，直接调用 wakeup，有可能还没有注册成功又阻塞了。这是一个多线程同步的问题，可以借助队列进行处理</span></span><br><span class="line">                Reactor subReactor = subReactors[handleNext];</span><br><span class="line">                subReactor.register(<span class="keyword">new</span> AsyncHandler(sc));</span><br><span class="line">                <span class="keyword">if</span>(++handleNext == subReactors.length) &#123;</span><br><span class="line">                    handleNext = <span class="number">0</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; <span class="keyword">catch</span> (Exception ex) &#123;</span><br><span class="line">            ex.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="AsyncHandler"><a href="#AsyncHandler" class="headerlink" title="AsyncHandler"></a>AsyncHandler</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">AsyncHandler</span> <span class="keyword">implements</span> <span class="title">Runnable</span></span>&#123;</span><br><span class="line">    <span class="keyword">private</span> SocketChannel channel;</span><br><span class="line">    <span class="keyword">private</span> SelectionKey sk;</span><br><span class="line"></span><br><span class="line">    ByteBuffer inputBuffer=ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">    ByteBuffer outputBuffer=ByteBuffer.allocate(<span class="number">1024</span>);</span><br><span class="line">    StringBuilder builder=<span class="keyword">new</span> StringBuilder(); <span class="comment">//存储客户端的完整消息</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">AsyncHandler</span><span class="params">(SocketChannel channel)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.channel=channel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> SocketChannel <span class="title">getChannel</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> channel;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setSk</span><span class="params">(SelectionKey sk)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.sk = sk;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">            <span class="keyword">if</span> (sk.isReadable()) &#123;</span><br><span class="line">                read();</span><br><span class="line">            &#125; <span class="keyword">else</span> <span class="keyword">if</span> (sk.isWritable()) &#123;</span><br><span class="line">                write();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                <span class="keyword">this</span>.sk.channel().close();</span><br><span class="line">            &#125; <span class="keyword">catch</span> (IOException ioException) &#123;</span><br><span class="line">                ioException.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">read</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        inputBuffer.clear();</span><br><span class="line">        <span class="keyword">int</span> n=channel.read(inputBuffer);</span><br><span class="line">        <span class="keyword">if</span>(inputBufferComplete(n))&#123;</span><br><span class="line">            System.out.println(Thread.currentThread().getName()+<span class="string">&quot;:Server端收到客户端的请求消息：&quot;</span>+builder.toString());</span><br><span class="line">            outputBuffer.put(builder.toString().getBytes(StandardCharsets.UTF_8));</span><br><span class="line">            <span class="keyword">this</span>.sk.interestOps(SelectionKey.OP_WRITE); <span class="comment">//更改服务的逻辑状态以及处理的事件类型</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">boolean</span> <span class="title">inputBufferComplete</span><span class="params">(<span class="keyword">int</span> bytes)</span> <span class="keyword">throws</span> EOFException </span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(bytes&gt;<span class="number">0</span>)&#123;</span><br><span class="line">            inputBuffer.flip(); <span class="comment">//转化成读取模式</span></span><br><span class="line">            <span class="keyword">while</span>(inputBuffer.hasRemaining())&#123; <span class="comment">//判断缓冲区中是否还有元素</span></span><br><span class="line">                <span class="keyword">byte</span> ch=inputBuffer.get(); <span class="comment">//得到输入的字符</span></span><br><span class="line">                <span class="keyword">if</span>(ch==<span class="number">3</span>)&#123; <span class="comment">//表示Ctrl+c 关闭连接</span></span><br><span class="line">                    <span class="keyword">throw</span> <span class="keyword">new</span> EOFException();</span><br><span class="line">                &#125;<span class="keyword">else</span> <span class="keyword">if</span>(ch==<span class="string">&#x27;\r&#x27;</span>||ch==<span class="string">&#x27;\n&#x27;</span>)&#123; <span class="comment">//表示换行符</span></span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">                &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">                    builder.append((<span class="keyword">char</span>)ch); <span class="comment">//拼接读取到的数据</span></span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(bytes==-<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> EOFException(); <span class="comment">//客户端关闭了连接</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">write</span><span class="params">()</span> <span class="keyword">throws</span> IOException </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> written=-<span class="number">1</span>;</span><br><span class="line">        outputBuffer.flip(); <span class="comment">//转化为读模式，判断是否有数据需要发送</span></span><br><span class="line">        <span class="keyword">if</span>(outputBuffer.hasRemaining())&#123;</span><br><span class="line">            written=channel.write(outputBuffer); <span class="comment">//把数据写回客户端</span></span><br><span class="line">        &#125;</span><br><span class="line">        outputBuffer.clear();</span><br><span class="line">        builder.delete(<span class="number">0</span>,builder.length());</span><br><span class="line">        <span class="keyword">if</span>(written&lt;=<span class="number">0</span>)&#123; <span class="comment">//表示客户端没有输信息</span></span><br><span class="line">            <span class="keyword">this</span>.sk.channel().close();</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            channel.write(ByteBuffer.wrap(<span class="string">&quot;\r\nreactor&gt;&quot;</span>.getBytes()));</span><br><span class="line">            <span class="keyword">this</span>.sk.interestOps(SelectionKey.OP_READ);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
          <category> NIO多路复用 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> NIO </tag>
            
            <tag> 高性能网络通信 </tag>
            
            <tag> Redis多路复用 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>字节跳动二面！面试官直接问我生产环境下如何监控线程池？还好我看了这篇文章！</title>
      <link href="/posts/3554467934/"/>
      <url>/posts/3554467934/</url>
      
        <content type="html"><![CDATA[<p>线程池的监控很重要，对于前面章节讲的动态参数调整，其实还是得依赖于线程池监控的数据反馈之后才能做出调整的决策。还有就是线程池本身的运行过程对于我们来说像一个黑盒，我们没办法了解线程池中的运行状态时，出现问题没有办法及时判断和预警。</p><p>对于监控这类的场景，核心逻辑就是要拿到关键指标，然后进行上报，只要能实时拿到这些关键指标，就可以轻松实现监控以及预警功能。</p><p>ThreadPoolExecutor中提供了以下方法来获取线程池中的指标。</p><ul><li>getCorePoolSize()：获取核心线程数。</li><li>getMaximumPoolSize：获取最大线程数。</li><li>getQueue()：获取线程池中的阻塞队列，并通过阻塞队列中的方法获取队列长度、元素个数等。</li><li>getPoolSize()：获取线程池中的工作线程数（包括核心线程和非核心线程）。</li><li>getActiveCount()：获取活跃线程数，也就是正在执行任务的线程。</li><li>getLargestPoolSize()：获取线程池曾经到过的最大工作线程数。</li><li>getTaskCount()：获取历史已完成以及正在执行的总的任务数量。</li></ul><p>除此之外，ThreadPoolExecutor中还提供了一些未实现的钩子方法，我们可以通过重写这些方法来实现更多指标数据的获取。</p><ul><li>beforeExecute，在Worker线程执行任务之前会调用的方法。</li><li>afterExecute，在Worker线程执行任务之后会调用的方法。</li><li>terminated，当线程池从状态变更到TERMINATED状态之前调用的方法。</li></ul><p>比如我们可以在<code>beforeExecute</code>方法中记录当前任务开始执行的时间，再到<code>afterExecute</code>方法来计算任务执行的耗时、最大耗时、最小耗时、平均耗时等。</p><h1 id="线程池监控的基本原理"><a href="#线程池监控的基本原理" class="headerlink" title="线程池监控的基本原理"></a>线程池监控的基本原理</h1><p>我们可以通过Spring Boot提供的Actuator，自定义一个Endpoint来发布线程池的指标数据，实现线程池监控功能。当然，除了Endpoint以外，我们还可以通过JMX的方式来暴露线程池的指标信息，不管通过什么方法，核心思想都是要有一个地方看到这些数据。</p><p>了解对于Spring Boot应用监控得读者应该知道，通过Endpoint发布指标数据后，可以采用一些主流的开源监控工具来进行采集和展示。如图10-9所示，假设在Spring Boot应用中发布一个获取线程池指标信息的Endpoint，那么我们可以采用Prometheus定时去抓取目标服务器上的Metric数据，Prometheus会将采集到的数据通过Retrieval分发给TSDB进行存储。这些数据可以通过Prometheus自带的UI进行展示，也可以使用Grafana图表工具通过PromQL语句来查询Prometheus中采集的数据进行渲染。最后采用AlertManager这个组件来触发预警功能。</p><p><img src="https://img-blog.csdnimg.cn/575d9defea4e4ce1a4fd82dbaecd63c6.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBA6Lef552ATWlj5a2m5p625p6E,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center" alt="在这里插入图片描述"></p><center>图10-9 线程池指标监控</center><p>图10-9中所涉及到的工具都是比较程度的开源监控组件，大家可以自行根据官方教程配置即可，而在本章节中要重点讲解的就是如何自定义Endpoint发布线程池的Metric数据。</p><h1 id="在Spring-Boot应用中发布线程池信息"><a href="#在Spring-Boot应用中发布线程池信息" class="headerlink" title="在Spring Boot应用中发布线程池信息"></a>在Spring Boot应用中发布线程池信息</h1><p>对于线程池的监控实现，笔者开发了一个相对较为完整的小程序，主要涉及到几个功能：</p><ul><li>可以通过配置文件来构建线程池。</li><li>扩展了ThreadPoolExecutor的实现。</li><li>发布一个自定义的Endpoint。</li></ul><p>该小程序包含的类以及功能说明如下：</p><ul><li>ThreadPoolExecutorForMonitor：扩展ThreadPoolExecutor的实现类。</li><li>ThreadPoolConfigurationProperties：绑定application.properties的配置属性。</li><li>ThreadPoolForMonitorManager：线程池管理类，实现线程池的初始化。</li><li>ThreadPoolProperties：线程池基本属性。</li><li>ResizeLinkedBlockingQueue：这个类是直接复制了LinkedBlockingQueue，提供了<code>setCapacity</code>方法，在前面有讲解到，源码就不贴出来。</li><li>ThreadPoolEndpoint：自定义Endpoint。</li></ul><h1 id="ThreadPoolExecutorForMonitor"><a href="#ThreadPoolExecutorForMonitor" class="headerlink" title="ThreadPoolExecutorForMonitor"></a>ThreadPoolExecutorForMonitor</h1><p>继承了ThreadPoolExecutor，实现了<code>beforeExecute</code>和<code>afterExecute</code>，在原有线程池的基础上新增了最短执行时间、最长执行时间、平均执行耗时的属性。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolExecutorForMonitor</span> <span class="keyword">extends</span> <span class="title">ThreadPoolExecutor</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> RejectedExecutionHandler defaultHandler = <span class="keyword">new</span> AbortPolicy();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> String defaultPoolName=<span class="string">&quot;Default-Task&quot;</span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">static</span> ThreadFactory threadFactory=<span class="keyword">new</span> MonitorThreadFactory(defaultPoolName);</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutorForMonitor</span><span class="params">(<span class="keyword">int</span> corePoolSize, <span class="keyword">int</span> maximumPoolSize, <span class="keyword">long</span> keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,threadFactory,defaultHandler);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutorForMonitor</span><span class="params">(<span class="keyword">int</span> corePoolSize, <span class="keyword">int</span> maximumPoolSize, <span class="keyword">long</span> keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,String poolName)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,<span class="keyword">new</span> MonitorThreadFactory(poolName),defaultHandler);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="title">ThreadPoolExecutorForMonitor</span><span class="params">(<span class="keyword">int</span> corePoolSize, <span class="keyword">int</span> maximumPoolSize, <span class="keyword">long</span> keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue,ThreadFactory threadFactory,RejectedExecutionHandler handler,String poolName)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,threadFactory,handler);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//最短执行时间</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">long</span> minCostTime;</span><br><span class="line">  <span class="comment">//最长执行时间</span></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">long</span> maxCostTime;</span><br><span class="line">  <span class="comment">//总的耗时</span></span><br><span class="line">  <span class="keyword">private</span> AtomicLong totalCostTime=<span class="keyword">new</span> AtomicLong();</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> ThreadLocal&lt;Long&gt; startTimeThreadLocal=<span class="keyword">new</span> ThreadLocal&lt;&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">shutdown</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.shutdown();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">beforeExecute</span><span class="params">(Thread t, Runnable r)</span> </span>&#123;</span><br><span class="line">    startTimeThreadLocal.set(System.currentTimeMillis());</span><br><span class="line">    <span class="keyword">super</span>.beforeExecute(t, r);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">afterExecute</span><span class="params">(Runnable r, Throwable t)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">long</span> costTime=System.currentTimeMillis()-startTimeThreadLocal.get();</span><br><span class="line">    startTimeThreadLocal.remove();</span><br><span class="line">    maxCostTime=maxCostTime&gt;costTime?maxCostTime:costTime;</span><br><span class="line">    <span class="keyword">if</span>(getCompletedTaskCount()==<span class="number">0</span>)&#123;</span><br><span class="line">      minCostTime=costTime;</span><br><span class="line">    &#125;</span><br><span class="line">    minCostTime=minCostTime&lt;costTime?minCostTime:costTime;</span><br><span class="line">    totalCostTime.addAndGet(costTime);</span><br><span class="line">    <span class="keyword">super</span>.afterExecute(r, t);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getMinCostTime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> minCostTime;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getMaxCostTime</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> maxCostTime;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">getAverageCostTime</span><span class="params">()</span></span>&#123;<span class="comment">//平均耗时</span></span><br><span class="line">    <span class="keyword">if</span>(getCompletedTaskCount()==<span class="number">0</span>||totalCostTime.get()==<span class="number">0</span>)&#123;</span><br><span class="line">      <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> totalCostTime.get()/getCompletedTaskCount();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="function"><span class="keyword">protected</span> <span class="keyword">void</span> <span class="title">terminated</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">super</span>.terminated();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MonitorThreadFactory</span> <span class="keyword">implements</span> <span class="title">ThreadFactory</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> AtomicInteger poolNumber = <span class="keyword">new</span> AtomicInteger(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> ThreadGroup group;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> AtomicInteger threadNumber = <span class="keyword">new</span> AtomicInteger(<span class="number">1</span>);</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> String namePrefix;</span><br><span class="line"></span><br><span class="line">    MonitorThreadFactory(String poolName) &#123;</span><br><span class="line">      SecurityManager s = System.getSecurityManager();</span><br><span class="line">      group = (s != <span class="keyword">null</span>) ? s.getThreadGroup() :</span><br><span class="line">      Thread.currentThread().getThreadGroup();</span><br><span class="line">      namePrefix = poolName+<span class="string">&quot;-pool-&quot;</span> +</span><br><span class="line">        poolNumber.getAndIncrement() +</span><br><span class="line">        <span class="string">&quot;-thread-&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Thread <span class="title">newThread</span><span class="params">(Runnable r)</span> </span>&#123;</span><br><span class="line">      Thread t = <span class="keyword">new</span> Thread(group, r,</span><br><span class="line">                            namePrefix + threadNumber.getAndIncrement(),</span><br><span class="line">                            <span class="number">0</span>);</span><br><span class="line">      <span class="keyword">if</span> (t.isDaemon())</span><br><span class="line">        t.setDaemon(<span class="keyword">false</span>);</span><br><span class="line">      <span class="keyword">if</span> (t.getPriority() != Thread.NORM_PRIORITY)</span><br><span class="line">        t.setPriority(Thread.NORM_PRIORITY);</span><br><span class="line">      <span class="keyword">return</span> t;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="ThreadPoolConfigurationProperties"><a href="#ThreadPoolConfigurationProperties" class="headerlink" title="ThreadPoolConfigurationProperties"></a>ThreadPoolConfigurationProperties</h1><p>提供了获取application.properties配置文件属性的功能，</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@ConfigurationProperties(prefix = &quot;monitor.threadpool&quot;)</span></span><br><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolConfigurationProperties</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> List&lt;ThreadPoolProperties&gt;  executors=<span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>线程池的核心属性声明。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Data</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolProperties</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> String poolName;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> corePoolSize;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> maxmumPoolSize=Runtime.getRuntime().availableProcessors();</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">long</span> keepAliveTime=<span class="number">60</span>;</span><br><span class="line">    <span class="keyword">private</span> TimeUnit unit= TimeUnit.SECONDS;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> queueCapacity=Integer.MAX_VALUE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>上述配置类要生效，需要通过@EnableConfigurationProperties开启，我们可以在Main方法上开启，代码如下。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@EnableConfigurationProperties(ThreadPoolConfigurationProperties.class)</span></span><br><span class="line"><span class="meta">@SpringBootApplication</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolApplication</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        SpringApplication.run(ThreadPoolApplication.class, args);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="application-properties"><a href="#application-properties" class="headerlink" title="application.properties"></a>application.properties</h1><p>配置类创建好之后，我们就可以在application.properties中，通过如下方式来构建线程池。</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">monitor.threadpool.executors[0].pool-name</span>=<span class="string">first-monitor-thread-pool</span></span><br><span class="line"><span class="meta">monitor.threadpool.executors[0].core-pool-size</span>=<span class="string">4</span></span><br><span class="line"><span class="meta">monitor.threadpool.executors[0].maxmum-pool-size</span>=<span class="string">8</span></span><br><span class="line"><span class="meta">monitor.threadpool.executors[0].queue-capacity</span>=<span class="string">100</span></span><br><span class="line"></span><br><span class="line"><span class="meta">monitor.threadpool.executors[1].pool-name</span>=<span class="string">second-monitor-thread-pool</span></span><br><span class="line"><span class="meta">monitor.threadpool.executors[1].core-pool-size</span>=<span class="string">2</span></span><br><span class="line"><span class="meta">monitor.threadpool.executors[1].maxmum-pool-size</span>=<span class="string">4</span></span><br><span class="line"><span class="meta">monitor.threadpool.executors[1].queue-capacity</span>=<span class="string">40</span></span><br></pre></td></tr></table></figure><h1 id="ThreadPoolForMonitorManager"><a href="#ThreadPoolForMonitorManager" class="headerlink" title="ThreadPoolForMonitorManager"></a>ThreadPoolForMonitorManager</h1><p>用来实现线程池的管理和初始化，实现线程池的统一管理，初始化的逻辑是根据application.properties中配置的属性来实现的。</p><ul><li>从配置类中获得线程池的基本配置。</li><li>根据配置信息构建ThreadPoolExecutorForMonitor实例。</li><li>把实例信息保存到集合中。</li></ul><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolForMonitorManager</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@Autowired</span></span><br><span class="line">  ThreadPoolConfigurationProperties poolConfigurationProperties;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> ConcurrentMap&lt;String,ThreadPoolExecutorForMonitor&gt; threadPoolExecutorForMonitorConcurrentMap=<span class="keyword">new</span> ConcurrentHashMap&lt;&gt;();</span><br><span class="line"></span><br><span class="line">  <span class="meta">@PostConstruct</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">init</span><span class="params">()</span></span>&#123;</span><br><span class="line">    poolConfigurationProperties.getExecutors().forEach(threadPoolProperties -&gt; &#123;</span><br><span class="line">      <span class="keyword">if</span>(!threadPoolExecutorForMonitorConcurrentMap.containsKey(threadPoolProperties.getPoolName()))&#123;</span><br><span class="line">        ThreadPoolExecutorForMonitor executorForMonitor=<span class="keyword">new</span> ThreadPoolExecutorForMonitor(</span><br><span class="line">          threadPoolProperties.getCorePoolSize(),</span><br><span class="line">          threadPoolProperties.getMaxmumPoolSize(),</span><br><span class="line">          threadPoolProperties.getKeepAliveTime(),</span><br><span class="line">          threadPoolProperties.getUnit(),</span><br><span class="line">          <span class="keyword">new</span> ResizeLinkedBlockingQueue&lt;&gt;(threadPoolProperties.getQueueCapacity()),</span><br><span class="line">          threadPoolProperties.getPoolName());</span><br><span class="line">        threadPoolExecutorForMonitorConcurrentMap.put(threadPoolProperties.getPoolName(),executorForMonitor);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> ThreadPoolExecutorForMonitor <span class="title">getThreadPoolExecutor</span><span class="params">(String poolName)</span></span>&#123;</span><br><span class="line">    ThreadPoolExecutorForMonitor threadPoolExecutorForMonitor=threadPoolExecutorForMonitorConcurrentMap.get(poolName);</span><br><span class="line">    <span class="keyword">if</span>(threadPoolExecutorForMonitor==<span class="keyword">null</span>)&#123;</span><br><span class="line">      <span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">&quot;找不到名字为&quot;</span>+poolName+<span class="string">&quot;的线程池&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> threadPoolExecutorForMonitor;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">public</span> ConcurrentMap&lt;String,ThreadPoolExecutorForMonitor&gt; <span class="title">getThreadPoolExecutorForMonitorConcurrentMap</span><span class="params">()</span></span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">this</span>.threadPoolExecutorForMonitorConcurrentMap;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="ThreadPoolEndpoint"><a href="#ThreadPoolEndpoint" class="headerlink" title="ThreadPoolEndpoint"></a>ThreadPoolEndpoint</h1><p>使用Spring-Boot-Actuator发布Endpoint，用来暴露当前应用中所有线程池的Metric数据。</p><blockquote><p>读者如果不清楚在Spring Boot中自定义Endpoint，可以直接去Spring官方文档中配置，比较简单。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="meta">@Endpoint(id=&quot;thread-pool&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ThreadPoolEndpoint</span> </span>&#123;</span><br><span class="line">  <span class="meta">@Autowired</span></span><br><span class="line">  <span class="keyword">private</span> ThreadPoolForMonitorManager threadPoolForMonitorManager;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@ReadOperation</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> Map&lt;String,Object&gt; <span class="title">threadPoolsMetric</span><span class="params">()</span></span>&#123;</span><br><span class="line">    Map&lt;String,Object&gt; metricMap=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">    List&lt;Map&gt; threadPools=<span class="keyword">new</span> ArrayList&lt;&gt;();</span><br><span class="line">    threadPoolForMonitorManager.getThreadPoolExecutorForMonitorConcurrentMap().forEach((k,v)-&gt;&#123;</span><br><span class="line">      ThreadPoolExecutorForMonitor tpe=(ThreadPoolExecutorForMonitor) v;</span><br><span class="line">      Map&lt;String,Object&gt; poolInfo=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.name&quot;</span>,k);</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.core.size&quot;</span>,tpe.getCorePoolSize());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.largest.size&quot;</span>,tpe.getLargestPoolSize());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.max.size&quot;</span>,tpe.getMaximumPoolSize());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.thread.count&quot;</span>,tpe.getPoolSize());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.max.costTime&quot;</span>,tpe.getMaxCostTime());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.average.costTime&quot;</span>,tpe.getAverageCostTime());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.min.costTime&quot;</span>,tpe.getMinCostTime());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.active.count&quot;</span>,tpe.getActiveCount());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.completed.taskCount&quot;</span>,tpe.getCompletedTaskCount());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.queue.name&quot;</span>,tpe.getQueue().getClass().getName());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.rejected.name&quot;</span>,tpe.getRejectedExecutionHandler().getClass().getName());</span><br><span class="line">      poolInfo.put(<span class="string">&quot;thread.pool.task.count&quot;</span>,tpe.getTaskCount());</span><br><span class="line">      threadPools.add(poolInfo);</span><br><span class="line">    &#125;);</span><br><span class="line">    metricMap.put(<span class="string">&quot;threadPools&quot;</span>,threadPools);</span><br><span class="line">    <span class="keyword">return</span> metricMap;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果需要上述自定义的Endpoint可以被访问，还需要在application.properties文件中配置如下代码，意味着thread-pool Endpoint允许被访问。</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="meta">management.endpoints.web.exposure.include</span>=<span class="string">thread-pool</span></span><br></pre></td></tr></table></figure><h1 id="TestController"><a href="#TestController" class="headerlink" title="TestController"></a>TestController</h1><p>提供使用线程池的方法，用来实现在调用之前和调用之后，通过Endpoint获取到Metric数据的变化。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@RestController</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">TestController</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span> <span class="keyword">final</span> String poolName=<span class="string">&quot;first-monitor-thread-pool&quot;</span>;</span><br><span class="line">  <span class="meta">@Autowired</span></span><br><span class="line">  ThreadPoolForMonitorManager threadPoolForMonitorManager;</span><br><span class="line"></span><br><span class="line">  <span class="meta">@GetMapping(&quot;/execute&quot;)</span></span><br><span class="line">  <span class="function"><span class="keyword">public</span> String <span class="title">doExecute</span><span class="params">()</span></span>&#123;</span><br><span class="line">    ThreadPoolExecutorForMonitor tpe=threadPoolForMonitorManager.getThreadPoolExecutor(poolName);</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; <span class="number">100</span>; i++) &#123;</span><br><span class="line">      tpe.execute(()-&gt;&#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          Thread.sleep(<span class="keyword">new</span> Random().nextInt(<span class="number">4000</span>));</span><br><span class="line">        &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">          e.printStackTrace();</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;success&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="效果演示"><a href="#效果演示" class="headerlink" title="效果演示"></a>效果演示</h1><p>访问自定义Endpoint： <a href="http://ip:8080/actuator/thread-pool%EF%BC%8C%E5%B0%B1%E5%8F%AF%E4%BB%A5%E7%9C%8B%E5%88%B0%E5%A6%82%E4%B8%8B%E6%95%B0%E6%8D%AE%E3%80%82%E6%88%91%E4%BB%AC%E5%8F%AF%E4%BB%A5%E6%8A%8A%E8%BF%99%E4%B8%AAEndpoint%E9%85%8D%E7%BD%AE%E5%88%B0Prometheus%E4%B8%AD%EF%BC%8CPrometheus%E4%BC%9A%E5%AE%9A%E6%97%B6%E6%8A%93%E5%8F%96%E8%BF%99%E4%BA%9B%E6%8C%87%E6%A0%87%E5%AD%98%E5%82%A8%E5%B9%B6%E5%B1%95%E7%A4%BA%EF%BC%8C%E4%BB%8E%E8%80%8C%E5%AE%8C%E6%88%90%E7%BA%BF%E7%A8%8B%E6%B1%A0%E7%9A%84%E6%95%B4%E4%BD%93%E7%9B%91%E6%8E%A7%E3%80%82">http://ip:8080/actuator/thread-pool，就可以看到如下数据。我们可以把这个Endpoint配置到Prometheus中，Prometheus会定时抓取这些指标存储并展示，从而完成线程池的整体监控。</a></p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;threadPools&quot;</span>:[</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;thread.pool.queue.name&quot;</span>:<span class="string">&quot;com.concurrent.demo.ResizeLinkedBlockingQueue&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.core.size&quot;</span>:<span class="number">2</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.min.costTime&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.completed.taskCount&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.max.costTime&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.task.count&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.name&quot;</span>:<span class="string">&quot;second-monitor-thread-pool&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.largest.size&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.rejected.name&quot;</span>:<span class="string">&quot;java.util.concurrent.ThreadPoolExecutor$AbortPolicy&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.active.count&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.thread.count&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.average.costTime&quot;</span>:<span class="number">0</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.max.size&quot;</span>:<span class="number">4</span></span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">&quot;thread.pool.queue.name&quot;</span>:<span class="string">&quot;com.concurrent.demo.ResizeLinkedBlockingQueue&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.core.size&quot;</span>:<span class="number">4</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.min.costTime&quot;</span>:<span class="number">65</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.completed.taskCount&quot;</span>:<span class="number">115</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.max.costTime&quot;</span>:<span class="number">3964</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.task.count&quot;</span>:<span class="number">200</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.name&quot;</span>:<span class="string">&quot;first-monitor-thread-pool&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.largest.size&quot;</span>:<span class="number">4</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.rejected.name&quot;</span>:<span class="string">&quot;java.util.concurrent.ThreadPoolExecutor$AbortPolicy&quot;</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.active.count&quot;</span>:<span class="number">4</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.thread.count&quot;</span>:<span class="number">4</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.average.costTime&quot;</span>:<span class="number">1955</span>,</span><br><span class="line">            <span class="attr">&quot;thread.pool.max.size&quot;</span>:<span class="number">8</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>线程池的整体实现并不算太复杂，但是里面涉及到的一些思想和理论是可以值得我们去学习和借鉴，如基于阻塞队列的生产者消费者模型的实现、动态扩容的思想、如何通过AQS来实现安全关闭线程池、降级方案（拒绝策略）、位运算等。实际上越底层的实现，越包含更多技术层面的思想和理论。</p><p>线程池在实际使用中，如果是新手，不建议直接用Executors中提供的工厂方法，因为线程池中的参数会影响到内存以及CPU资源的占用，我们可以自己集成ThreadPoolExecutor这个类，扩展一个自己的实现，也可以自己构造ThreadPoolExecutor实例，这样能够更好的了解线程池中核心参数的意义避免不必要的生产问题。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 线程池 </tag>
            
            <tag> Spring Boot </tag>
            
            <tag> 监控 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>1万字长文高速你千万级并发架构下如何提高数据库存储性能</title>
      <link href="/posts/4032676932/"/>
      <url>/posts/4032676932/</url>
      
        <content type="html"><![CDATA[<p>如图所示，表示发起一个请求时，涉及到数据库的相关操作，在前面的文章中我们说过，如果服务端要提升整体的吞吐量，就必须要减少每一次请求的处理时长，那么在当前这个场景中，数据库层面哪些因素会影响到性能呢？</p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121455814.png" alt="image-20210624225017321" style="zoom:50%;" /><center>图2-1</center><h2 id="池化技术，减少频繁创建数据库连接"><a href="#池化技术，减少频繁创建数据库连接" class="headerlink" title="池化技术，减少频繁创建数据库连接"></a>池化技术，减少频繁创建数据库连接</h2><p>遇到这样的问题，解决办法就是顺着当前整体的逻辑去思考，首先，应用要和数据库打交道，必然会设计到数据库链接的建立。然后在当前连接中完成数据库的相关操作，最后再关闭连接。</p><p>在这种场景下，客户端每次发起请求，都需要重新建立连接，如果频繁的创建连接是否会影响到性能呢？答案是一定的，我们通过下面这样一个方式来验证一下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> -i指定网卡名称</span></span><br><span class="line">tcpdump -i eth0 -nn -tttt port 3306</span><br></pre></td></tr></table></figure><p>当我们向数据库发起一次连接时，上述抓包命令会打印连接的相关信息如下。（通过Navicat 的链接测试工具测试）</p><blockquote><p>关注前面8行数据即可。</p></blockquote><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.130812</span> IP <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span> &gt; <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span>: Flags [S], seq <span class="number">759743325</span>, win <span class="number">64240</span>, options [mss <span class="number">1448</span>,nop,wscale <span class="number">8</span>,nop,nop,sackOK], length <span class="number">0</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.130901</span> IP <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span> &gt; <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span>: Flags [S.], seq <span class="number">3058334924</span>, ack <span class="number">759743326</span>, win <span class="number">29200</span>, options [mss <span class="number">1460</span>,nop,nop,sackOK,nop,wscale <span class="number">7</span>], length <span class="number">0</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.160730</span> IP <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span> &gt; <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span>: Flags [.], ack <span class="number">1</span>, win <span class="number">260</span>, length <span class="number">0</span></span><br><span class="line">    </span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.161037</span> IP <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span> &gt; <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span>: Flags [P.], seq <span class="number">1</span>:<span class="number">79</span>, ack <span class="number">1</span>, win <span class="number">229</span>, length <span class="number">78</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.190126</span> IP <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span> &gt; <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span>: Flags [P.], seq <span class="number">1</span>:<span class="number">63</span>, ack <span class="number">79</span>, win <span class="number">259</span>, length <span class="number">62</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.190193</span> IP <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span> &gt; <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span>: Flags [.], ack <span class="number">63</span>, win <span class="number">229</span>, length <span class="number">0</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.190306</span> IP <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span> &gt; <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span>: Flags [P.], seq <span class="number">79</span>:<span class="number">90</span>, ack <span class="number">63</span>, win <span class="number">229</span>, length <span class="number">11</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.219256</span> IP <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span> &gt; <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span>: Flags [P.], seq <span class="number">63</span>:<span class="number">82</span>, ack <span class="number">90</span>, win <span class="number">259</span>, length <span class="number">19</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.219412</span> IP <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span> &gt; <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span>: Flags [P.], seq <span class="number">90</span>:<span class="number">101</span>, ack <span class="number">82</span>, win <span class="number">229</span>, length <span class="number">11</span></span><br><span class="line"><span class="number">2021</span>-<span class="number">06</span>-<span class="number">24</span> <span class="number">23</span>:<span class="number">15</span>:<span class="number">50.288721</span> IP <span class="number">218.76</span><span class="number">.8</span><span class="number">.219</span><span class="number">.57423</span> &gt; <span class="number">172.17</span><span class="number">.136</span><span class="number">.216</span><span class="number">.3306</span>: Flags [.], ack <span class="number">101</span>, win <span class="number">259</span>, length <span class="number">0</span></span><br></pre></td></tr></table></figure><ul><li><p>第一部分是TCP三次握手建立连接的数据包</p><ul><li>第一个数据包是客户端向服务区段发送一个SYN包</li><li>第二个数据包是服务端返回给客户端的ACK包以及一个SYN包</li><li>第三个数据包是客户端返回给服务端的ACK包</li></ul></li><li><p>第二个部分是Mysql服务端校验客户端密码的过程</p></li></ul><p>从开始建立连接的时间130812到最终完成连接288721， 总共耗时157909，接近158ms时间，这个时间看起来很小，而且在请求量较小的情况下，对系统的影响不是很大。但是请求量上来之后，这个请求耗时的影响就非常大了。</p><p>而对于这个问题的解决办法大家都已经知道，就是利用池化技术，预先建立好数据库连接，当应用需要使用连接时，直接从预先建立好的连接中来获取进行调用，如图2-2所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450806.png" alt="image-20210625134607312"></p><center>图2-2</center><p>数据库连接池的工作原理和线程池类似，数据库连接池有两个最重要的配置： <strong>最小连接数和最大连接数，</strong> 它们控制着从连接池中获取连接的流程：</p><ul><li>如果当前连接数小于最小连接数，则创建新的连接处理数据库请求；</li><li>如果连接池中有空闲连接则复用空闲连接；</li><li>如果空闲池中没有连接并且当前连接数小于最大连接数，则创建新的连接处理请求；</li><li>如果当前连接数已经大于等于最大连接数，则按照配置中设定的时间（maxWait）等待旧的连接可用；</li><li>如果等待超过了这个设定时间则向用户抛出错误。</li></ul><p>总的来说，连接池核心思想是空间换时间，期望使用预先创建好的对象来减少频繁创建对象的性能开销，同时还可以对对象进行统一的管理，降低了对象的使用的成本。</p><h2 id="数据库本身的性能优化"><a href="#数据库本身的性能优化" class="headerlink" title="数据库本身的性能优化"></a>数据库本身的性能优化</h2><p>数据库本身的性能优化也很重要，常见的优化手段</p><ul><li>创建并正确使用索引，尽量只通过索引访问数据</li><li>优化SQL执行计划，SQL执行计划是关系型数据库最核心的技术之一，它表示SQL执行时的数据访问算法，优化执行计划也就能够提升sql查询的性能</li><li>每次数据交互时，尽可能返回更少的数据，因为更大的数据意味着会增大网络通信延迟。常见的方式是通过分页来查询数据、只返回当前场景需要的字段</li><li>减少和数据库的交互次数，比如批量提交、批量查询</li><li>…</li></ul><h2 id="数据库读写操作的性能问题"><a href="#数据库读写操作的性能问题" class="headerlink" title="数据库读写操作的性能问题"></a>数据库读写操作的性能问题</h2><p>如果老板说公司准备在下个月搞一场运营活动，用户数量会快速增加，导致对数据库的读压力增加，假设在4 核 8G 的机器上运 MySQL 5.7 时，大概可以支撑 500 的 TPS 和 10000 的 QPS，而实际的QPS可能是10W，那怎么解决呢？</p><p>首先分析一下这个问题，在绝大部分面向用户的系统中，都是读多写少的模型，比如电商，大部分的时候是在搜索和浏览，比如抖音，大部分是在加载短视频，所以我们需要考虑的问题是，数据库如何扛住查询请求。一般的解决方法是读写分离，</p><p>所谓读写分离，就是把同一个数据库分离成两份，一份专门用来做事务操作，另一份专门用来做读操作，如图2-3所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450506.png" alt="image-20210625142110740"></p><center>图2-3</center><p>做了主从复制之后，我们就可以在写入时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响到读请求的执行。同时呢，在读流量比较大的情况下，我们可以部署多个从库共同承担读流量，这就是所说的 <strong>一主多从</strong> 部署方式，在你的垂直电商项目中就可以通过这种方式来抵御较高的并发读流量。另外，从库也可以当成一个备库来使用，以避免主库故障导致数据丢失。</p><p><strong>那么你可能会说，是不是我无限制地增加从库的数量就可以抵抗大量的并发呢？</strong> 实际上并不是的。因为随着从库数量增加，从库连接上来的 IO 线程比较多，<strong>主库也需要创建同样多的 log dump 线程来处理复制的请求</strong>，对于主库资源消耗比较高，同时受限于主库的网络带宽，所以在实际使用中，<strong>一般一个主库最多挂 3～5 个从库</strong>。</p><p><strong>当然，主从复制也有一些缺陷，</strong> 除了带来了部署上的复杂度，还有就是会带来一定的主从同步的延迟，这种延迟有时候会对业务产生一定的影响</p><h2 id="数据量增加带来的性能问题"><a href="#数据量增加带来的性能问题" class="headerlink" title="数据量增加带来的性能问题"></a>数据量增加带来的性能问题</h2><p>随着业务的增长，数据库中的数据量也会随着增加，由于最早开发时主要是为了赶进度，数据都是单表存储，因此单表数据量增加之后，导致数据库的查询和写入都造成非常大的性能开销，具体体现在。</p><ul><li>单表数据量过大，千万级别到上亿级别，这时即使你使用了索引，索引占用的空间也随着数据量的增长而增大，数据库就无法缓存全量的索引信息，那么就需要从磁盘上读取索引数据，就会影响到查询的性能。</li><li>数据量的增加也占据了磁盘的空间，数据库在备份和恢复的时间变长</li><li>不同模块的数据，比如用户数据和用户关系数据，全都存储在一个主库中，一旦主库发生故障，所有的模块儿都会受到影响</li><li>在 4 核 8G 的云服务器上对 MySQL5.7 做 Benchmark，大概可以支撑 500TPS 和 10000QPS，你可以看到数据库对于写入性能要弱于数据查询的能力，那么随着系统写入请求量的增长，对于写请求的耗时也会增加（更新数据操作需要同步更新索引，数据量较大的情况下更新索引耗时较长）</li></ul><p>在这类场景中，解决方案就是对数据进行分片，也就是分库分表的机制，如图2-4所示。数据拆分的核心降低单表和单库的数据IO压力，从而提升对数据库相关操作的性能。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450667.png" alt="image-20210625144502558"></p><center>图2-4</center><h1 id="不同存储设备带来的性能提升"><a href="#不同存储设备带来的性能提升" class="headerlink" title="不同存储设备带来的性能提升"></a>不同存储设备带来的性能提升</h1><p>前面我们了解了对于传统关系型数据库的一些优化思路，整体来说，通过优化之后能够提升程序访问数据库的计算性能。但是还是有一些情况，即便是优化之后，使用传统关系型数据库无法解决的，比如。</p><ul><li>当数据量达到TB级别时，传统关系型数据库基本做了分库分表，单表数据量也是非常大的。</li><li>对于一些不适合用关系型数据库存储的数据，传统数据库无法做到，所以数据库本身的特性限制了多样性数据的管理。</li></ul><p>所以nosql出现了，大家对nosql这个概念已经不陌生了，它是指不同于传统关系型数据库的其他数据库系统的一个统称，它不使用SQL作为查询语言，并且相对于传统关系型数据库来说，</p><p>它提供了更高的性能以及横向扩展能力，非常适合互联网项目中高并发且数据量较大的场景中，如图25所示，表示目前比较主流的不同类型的nosql数据库。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450770.png" alt="image-20210625164052410"></p><center>图2-5 不同的NoSql数据库</center><blockquote><p>这个网站上记录了所有的Nosql框架</p><p><a href="https://hostingdata.co.uk/nosql-database/">https://hostingdata.co.uk/nosql-database/</a></p></blockquote><h2 id="Key-Value数据库"><a href="#Key-Value数据库" class="headerlink" title="Key-Value数据库"></a>Key-Value数据库</h2><p>key-value数据库，典型的代表就是Redis、Memcached，也是目前业内非常主流的Nosq数据库。</p><p>之所以在IO性能方面比传统关系型数据库高，有两个点</p><ul><li>数据基于内存，读写效率高</li><li>KV型数据，时间复杂度为O(1)，查询速度快</li></ul><p>KV型NoSql最大的优点就是<strong>高性能</strong>，利用Redis自带的BenchMark做基准测试，TPS可达达到接近10W的级别，性能非常强劲。同样的Redis也有所有KV型NoSql都有的比较明显的缺点：</p><ul><li>查询方式单一，只有KV的方式，不支持条件查询，多条件查询唯一的做法就是数据冗余，但这会极大的浪费存储空间</li><li>内存是有限的，无法支持海量数据存储</li><li>同样的，由于KV型NoSql的存储是基于内存的，会有丢失数据的风险</li></ul><p>基于Key-Value数据库的特性，这类数据库比较适用于缓存的场景。</p><ul><li>读多写少</li><li>读取能力强</li><li>可以接受数据丢失</li></ul><p>这类存储相比于传统的数据库的优势是极高的读写性能，一般对性能有比较高的要求的场景会使用，主要使用场景。</p><ul><li>用来做分布式缓存，提升程序处理效率。</li><li>用来做会话数据存储</li><li>其他功能性特性，比如消息通信、分布式锁、布隆过滤器</li><li>微博的feed流，早期就是用了redis实现。（持续更新并呈现给用户内容的信息流。每个人的朋友圈，微博关注页等等都是一个 Feed 流）</li></ul><h2 id="列式数据库"><a href="#列式数据库" class="headerlink" title="列式数据库"></a>列式数据库</h2><p>我们最早学习数据库，都是基于以二维表形式存储，每一行代表一条完整的数据。大部分传统的关系型数据库中，都是以行来存储数据。不过最近几年，列式存储也逐步被广泛运用在大数据框架中。</p><p>行存储和列存储，是数据库底层数据组织的形式的区别，如图2-6所示，数据库表中所有列一次排成一行，以行位单位存储，再配合B+树或者SS-Table作为索引，就能快速通过主键找到相应的行数据。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450630.png" alt="image-20210625202700946"></p><center>图2-6</center><p>在实际应用中，大部分的操作都是以实体（Entity）为单位，也就是大部分CRUD操作都是针对一整行记录，如果需要保存一行数据，只需要在原来的数据后追加一行数据即可，所以数据的写入非常快。</p><p>但是对于查询来说，一个典型的查询操作需要遍历整个表，分组、排序、聚合等，对于行存储来说，这样的操作的优势就不存在了，更惨的是，分析型SQL可能不需要用到所有的列，仅仅只需要对某些列进行运算即可，但是那一行中和本次操作无关的列也必须要参与到数据扫描中。</p><p>比如，如图2-7所示，现在我想统计所有文章的总的点赞数量，作为行存储的系统，数据库会怎么操作呢？</p><ul><li>首先需要把所有行的数据加载到内存</li><li>然后对like_num列做sum操作</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450318.png" alt="image-20210625204523910"></p><center>图2-7</center><p>行式存储对于OLAP场景而言，优势就不存在了，所以就引入了列式存储。</p><blockquote><p>OLTP（on-line transaction processing）翻译为联机事务处理， OLAP（On-Line Analytical Processing）翻译为联机分析处理，从字面上来看OLTP是做事务处理，OLAP是做分析处理。从对数据库操作来看，OLTP主要是对数据的增删改，OLAP是对数据的查询</p></blockquote><p>如图2-8所示，列式存储是将每一列数据组织在一起，它方便对于列的操作，比如前面说的统计like_num之和，按列存储之后只需要一次磁盘操作就可以完成三个数据的汇总，所以非常适合OLAP的场景。</p><ul><li>当查询语句只涉及部分列时，只需要扫描相关列</li><li>每一列数据都是相同类型，彼此间的关联性更大，对列数据压缩的效率较高。</li></ul><p>但是对于OLTP来说不是很友好，因为一行数据的写入需要修改多个列。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450057.png" alt="image-20210625221307500"></p><center>图2-8</center><p>列式存储在大数据分析中使用非常多，比如推荐画像（蚂蚁金服的风控）、是空数据（滴滴打车的归集数据）、消息/订单（电信领域、银行领域）不少订单查询底层的存储。 Feeds流（朋友圈类似的应用）等等。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450491.png" alt="image-20210625220018008"></p><center>图2-9</center><h2 id="文档型数据库"><a href="#文档型数据库" class="headerlink" title="文档型数据库"></a>文档型数据库</h2><p>传统的数据库，所有信息会被分割成离散的数据字段，保存在关系型数据库中，甚至对于一些复杂的场景，还会分散在不同的表结构中。</p><p>举个例子，在一个技术论坛中，假设对于用户、文章、文章评论表的关系图如图2-10所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450374.png" alt="image-20210625225801200"></p><center>图2-10</center><p>那用户点一篇文章，里面要显示该文章的创建者、文章详情、文章的评论，那么服务端要做什么呢？</p><ul><li>查找文章详情</li><li>根据文章中的uid查找用户信息</li><li>查询该文章的所有评论列表</li><li>查询每个评论的创建者名字</li></ul><p>这个过程要么就是多次数据库查询，要么就是使用一个复杂关联查询来检索，不管怎么做，都不是很方便。而文档数据库就可以解决这样的问题。</p><p>文档数据库是以文档单位，具体的文档形式有很多种，比如（XML、YAML、JSON、BSON）等，文档中存储具体的字段和值，应用可以使用这些字段进行查询和数据筛选。</p><p>一般情况下，文档中包含了实体中的全部数据，比如图2-10的结构，我们可以直接把一篇文章的基本要素信息构建成一个完整的文档保存到文档数据库中，应用程序只需要发起一次请求就可以获取所有数据。b</p><figure class="highlight json"><table><tr><td class="code"><pre><span class="line">Article：&#123;</span><br><span class="line">    Creator:&#123;</span><br><span class="line">        uid: &#x27;&#x27;,</span><br><span class="line">        username: &#x27;&#x27;</span><br><span class="line">    &#125;,</span><br><span class="line">    Topic: &#123;</span><br><span class="line">        title: &#x27;&#x27;,</span><br><span class="line">        content: &#x27;&#x27;</span><br><span class="line">    &#125;,</span><br><span class="line">    Reply: [</span><br><span class="line">        &#123;</span><br><span class="line">            replyId:,</span><br><span class="line">            content:&#x27;&#x27;</span><br><span class="line">        &#125;,</span><br><span class="line">        &#123;</span><br><span class="line">            replyId:,</span><br><span class="line">            content:&#x27;&#x27;</span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>MongoDB是目前最流行的Nosql数据库，它是一种面向集合、与模式（Schema Free）无关的文档型数据库。它的数据是以“集合”的方式进行分组，每个集合都有单独的名称并可以包含无线数量的文档，这种集合与关系型数据库中的表类似，唯一的区别就是它并没有任何明确的schema。</p><blockquote><p>在数据库中，schema（发音 “skee-muh” 或者“skee-mah”，中文叫模式）是数据库的组织和结构，<em>schemas</em> 和<em>schemata</em>都可以作为复数形式。模式中包含了schema对象，可以是<strong>表</strong>(table)、<strong>列</strong>(column)、<strong>数据类型</strong>(data type)、<strong>视图</strong>(view)、<strong>存储过程</strong>(stored procedures)、<strong>关系</strong>(relationships)、<strong>主键</strong>(primary key)、**外键(**foreign key)等。数据库模式可以用一个可视化的图来表示，它显示了数据库对象及其相互之间的关系</p></blockquote><p>如图2-11所示， 将数据存储在类似 JSON 的灵活文档中，这意味着字段可能因具体文档而异，并且数据结构可能随着时间的推移而变化。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450288.png" alt="img"></p><center>图2-11</center><p>MongoDB没有“数据一致性检查”、“事务”等，不适合存储对数据事务要求较高的场景，只适合放一些非关键性数据，常见应用场景如下：</p><ul><li>使用Mongodb对应用日志进行记录</li><li>存储监控数据，比如应用的埋点信息，可以直接上报存储到mongoDB中</li><li>MongoDB可以用来实现O2O快递应用，比如快递骑手、快递商家的信息存储在MongoDB，然后通过MongoDB的地理位置查询，方便用来查询附近的商家、骑手等功能。</li></ul><h2 id="图形数据库"><a href="#图形数据库" class="headerlink" title="图形数据库"></a>图形数据库</h2><p>图形数据库，表示以数据结构“图”作为存储的数据库。<br>图形数据存储管理两类信息：节点信息和边缘信息。 节点表示实体，边缘表示这些实体之间的关系。 节点和边缘都可以包含一些属性用于提供有关该节点或边缘的信息（类似于表中的列）。 </p><p>边缘还可以包含一个方向用于指示关系的性质。</p><p>图形数据存储的用途是让应用程序有效执行需遍历节点和边缘网络的查询，以及分析实体之间的关系。 如图2-12所示，显示了已结构化为图形的组织人员数据。 </p><p>实体为员工和部门，边缘指示隶属关系以及员工所在的部门。 在此图中，边缘上的箭头表示关系的方向。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450756.png" alt="image-20210625180249817"></p><center>图2-12</center><p>使用此结构可以简单直接地执行类似于“查找 Sarah 的直接或间接下属”或“谁与 John 在同一个部门工作？”的查询。 对于包含大量实体和关系的大型图形，可以快速执行复杂的分析。 多个图形数据库提供一种可用于高效遍历关系网络的查询语言。比如：关系、地图、网络拓扑、交通路线等场景。</p><h2 id="NewSql"><a href="#NewSql" class="headerlink" title="NewSql"></a>NewSql</h2><p>NewSql也是最近几年出来的概念，想必大家或多或少都有听过，NewSql是Nosql发展之后的下一代数据存储方案。</p><p>前面我们了解了Nosql的优势。</p><ul><li>高可用性和可扩展性，自动分区，轻松扩展</li><li>不保证强一致性，性能大幅提升</li><li>没有关系模型的限制，极其灵活</li></ul><p>但是有些优势在某些场景下不是很适合，比如不保证强一致性，对于普通应用来说没有问题，但是对于一些金融级的企业应用来说，</p><p>强一致的需求会比较高。另外，Nosql不支持SQL语句，不同的Nosql数据库都是有自己独立的API来进行数据操作，相对来说比较麻烦和复杂。</p><p>所以NewSql出现了，简单来说，newSQL 就是在传统关系型数据库上集成了 noSQL 强大的可扩展性，传统的SQL架构设计基因中是没有分布式的，而 newSQL 生于云时代，天生就是分布式架构。</p><p>NewSQL 的主要特性：</p><ul><li>SQL 支持，支持复杂查询和大数据分析。</li><li>支持 ACID 事务，支持隔离级别。</li><li>弹性伸缩，扩容缩容对于业务层完全透明。</li><li>高可用，自动容灾</li></ul><blockquote><p>商用NewSql</p></blockquote><ul><li><p>Spanner、F1：谷歌</p></li><li><p>OceanBase：阿里</p></li><li><p>TDSQL：腾讯</p></li><li><p>UDDB：UCloud</p></li></ul><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在 NoSQL 数据库刚刚被应用时，它被认为是可以替代关系型数据库的银弹，在我看来，也许因为以下几个方面的原因：</p><ul><li>弥补了传统数据库在性能方面的不足；</li><li>数据库变更方便，不需要更改原先的数据结构；</li><li>适合互联网项目常见的大数据量的场景；</li></ul><p>不过，这种看法是个误区，因为慢慢地我们发现在业务开发的场景下还是需要利用 SQL 语句的强大的查询功能以及传统数据库事务和灵活的索引等功能，NoSQL 只能作为一些场景的补充。</p><h1 id="使用Redis优化性能问题"><a href="#使用Redis优化性能问题" class="headerlink" title="使用Redis优化性能问题"></a>使用Redis优化性能问题</h1><p>Redis是目前用得非常多的一种Key-Vlaue数据库，我们先来通过一个压测数据了解一下redis和mysql的性能差距。</p><p>演示项目： springboot-redis-example</p><p>通过jmeter工具分别压测这个项目中的两个url。</p><ul><li><a href="http://localhost:8080/city/%7Bid%7D">http://localhost:8080/city/{id}</a></li><li><a href="http://localhost:8080/city/redis/%7Bid%7D">http://localhost:8080/city/redis/{id}</a></li></ul><p>其中，基于mysql访问的接口，吞吐量数据如下，qps=4735/s。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450620.png" alt="image-20210628143407508"></p><center>图2-13</center><p>基于redis的压测数据，如图2-14所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450108.png" alt="image-20210628143634472"></p><center>图2-14</center><p>可以很明显的看到，在同样的程序中，Redis的QPS要比Mysql的多了1000。</p><h2 id="了解Redis"><a href="#了解Redis" class="headerlink" title="了解Redis"></a>了解Redis</h2><p>08年的时候有一个意大利西西里岛的小伙子，笔名antirez（<a href="http://invece.org/%EF%BC%89%EF%BC%8C%E5%88%9B%E5%BB%BA%E4%BA%86%E4%B8%80%E4%B8%AA%E8%AE%BF%E5%AE%A2%E4%BF%A1%E6%81%AF%E7%BD%91%E7%AB%99LLOOGG.COM%E3%80%82%E5%A6%82%E6%9E%9C%E6%9C%89%E8%87%AA%E5%B7%B1%E5%81%9A%E8%BF%87%E7%BD%91%E7%AB%99%E7%9A%84%E5%90%8C%E5%AD%A6%E5%BA%94%E8%AF%A5%E7%9F%A5%E9%81%93%EF%BC%8C">http://invece.org/），创建了一个访客信息网站LLOOGG.COM。如果有自己做过网站的同学应该知道，</a></p><p>有的时候我们需要知道网站的访问情况，比如访客的IP、操作系统、浏览器、使用的搜索关键词、所在地区、访问的网页地址等等。在国内，有很多网站提供了这个功能，比如CNZZ，百度统计，国外也有谷歌的Google Analytics。</p><p>也就是说，我们不用自己写代码去实现这个功能，只需要在全局的footer里面嵌入一段JS代码就行了，当页面被访问的时候，就会自动把访客的信息发送到这些网站统计的服务器，然后我们登录后台就可以查看数据了。</p><p>LLOOGG.COM提供的就是这种功能，它可以查看最多10000条的最新浏览记录。这样的话，它需要为每一个网站创建一个列表（List），不同网站的访问记录进入到不同的列表。如果列表的长度超过了用户指定的长度，它需要把最早的记录删除（先进先出）。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450677.jpg" alt="img"></p><center>图2-15</center><p>当LLOOGG.COM的用户越来越多的时候，它需要维护的列表数量也越来越多，这种记录最新的请求和删除最早的请求的操作也越来越多。LLOOGG.COM最初使用的数据库是MySQL，可想而知，因为每一次记录和删除都要读写磁盘，因为数据量和并发量太大，在这种情况下无论怎么去优化数据库都不管用了。</p><p>考虑到最终限制数据库性能的瓶颈在于磁盘，所以antirez打算放弃磁盘，自己去实现一个具有列表结构的数据库的原型，把数据放在内存而不是磁盘，这样可以大大地提升列表的push和pop的效率。antirez发现这种思路确实能解决这个问题，所以用C语言重写了这个内存数据库，并且加上了持久化的功能，09年，Redis横空出世了。从最开始只支持列表的数据库，到现在支持多种数据类型，并且提供了一系列的高级特性，Redis已经成为一个在全世界被广泛使用的开源项目。</p><p>为什么叫REDIS呢？它的全称是Remote Dictionary Service，直接翻译过来是远程字典服务。</p><h2 id="key-value数据库使用排名"><a href="#key-value数据库使用排名" class="headerlink" title="key-value数据库使用排名"></a>key-value数据库使用排名</h2><p>对于Redis，我们大部分时候的认识是一个缓存的组件，当然从它的发展历史我们也可以看到，它最开始并不是作为缓存使用的。只是在很多的互联网应用里面，它作为缓存发挥了最大的作用。所以下面我们来聊一下，Redis的主要特性有哪些，我们为什么要使用它作为数据库的缓存。 </p><p>大家对于缓存应该不陌生，比如我们有硬件层面的CPU的缓存，浏览器的缓存，手机的应用也有缓存。我们把数据缓存起来的原因就是从原始位置取数据的代价太大了，放在一个临时存储起来，取回就可以快一些。</p><p>如果要了解Redis的特性，我们必须回答几个问题：</p><p><strong>1、为什么要把数据放在内存中？</strong></p><ol><li><p>内存的速度更快，10w QPS</p></li><li><p>减少计算的时间</p></li></ol><p><strong>2、如果是用内存的数据结构作为缓存，为什么不用HashMap或者Memcache？</strong></p><ol><li><p>更丰富的数据类型</p></li><li><p>进程内与跨进程；单机与分布式</p></li><li><p>功能丰富：持久化机制、过期策略</p></li><li><p>支持多种编程语言</p></li><li><p>高可用，集群</p></li></ol><blockquote><p><a href="https://db-engines.com/en/ranking/key-value+store">https://db-engines.com/en/ranking/key-value+store</a></p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110121450702.png" alt="image-20210626202902337"></p><center>图2-16</center>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 架构 </tag>
            
            <tag> 高性能 </tag>
            
            <tag> 并发 </tag>
            
            <tag> 数据库优化 </tag>
            
            <tag> 性能调优 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>工作3年的Java程序员，轻松拿到阿里P6Offer，只因为他搞明白了Redis这几个问题！！</title>
      <link href="/posts/2781994300/"/>
      <url>/posts/2781994300/</url>
      
        <content type="html"><![CDATA[<h1 id="Redis中的多路复用模型"><a href="#Redis中的多路复用模型" class="headerlink" title="Redis中的多路复用模型"></a>Redis中的多路复用模型</h1><p>Redis6用到了多线程？那多线程应用在哪些地方，引入多线程后，又改如何保证线程安全性呢？<br>同时，如何在性能和线程安全性方面做好平衡？</p><h2 id="关于Redis的单线程模型"><a href="#关于Redis的单线程模型" class="headerlink" title="关于Redis的单线程模型"></a>关于Redis的单线程模型</h2><p>在Redis6.0之前，我们一直说Redis是单线程，所以并不会存在线程安全问题，而这个单线程，实际上就是在做数据IO处理中，是用的主线程来串行执行，如图4-7所示。</p><p>Redis基于Reactor模式设计开发了自己的一套高效事件处理模型，这个事件处理模型对应的就是Redis中的文件事件处理器，这个文件事件处理器是单线程运行的，这也是为什么我们一直强调Redis是线程安全的。</p><p>既然Redis是基于Reactor模型实现，那它必然用了I/O多路复用机制来监听多个客户端连接，然后把感兴趣的事件（READ/ACCEPT/CLOSE/WRITE）注册到多路复用器中。</p><p>文件事件处理器中使用I/O多路复用模型同时监听多个客户端连接，并且根据当前连接执行的任务类型关联不同的事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）来处理这些事件。</p><p>这样设计的好处：</p><ul><li>文件事件处理器实现了高性能的网络IO通信模型</li><li>通过单线程的方式执行指令，避免同步机制的性能开销、避免过多的上下文切换、整体实现比较简单，不需要考虑多线程场景中的各种数据结构的线程安全问题。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354544.png" alt="image-20210708232804607"></p><center>图4-7</center><p>其实严格意义上来说，在Redis4.x版本就支持了多线程，只是，<strong>负责客户端请求的IO处理使用的是单线程</strong>。但是针对那些非常耗时的命令，Redis4.x提供了异步化的指令来处理，避免因为IO时间过长影响到客户端请求IO处理的线程。比如在 Redis v4.0 之后增加了一些的非阻塞命令如 <code>UNLINK</code>（del命令的异步版本）、<code>FLUSHALL ASYNC</code>、<code>FLUSHDB ASYNC</code>。</p><h2 id="Redis6-0之后的多线程？"><a href="#Redis6-0之后的多线程？" class="headerlink" title="Redis6.0之后的多线程？"></a>Redis6.0之后的多线程？</h2><p>在Redis6.0中引入了多线程，可能很多同学会误以为redis原本的单线程数据IO变成了多线程IO，那作者不就是在打自己的脸吗？</p><blockquote><p>对于Redis来说，CPU通常不是瓶颈，因为大多数请求不是属于CPU密集型，而是I/O密集型。而在Redis中除了数据的持久化方案之外，它是完全的纯内存操作，因此执行速度是非常快的，所以数据的IO并不是Redis的性能瓶颈，Redis真正的性能瓶颈是在网络I/O，也就是客户端和服务端之间的网络传输延迟，所以Redis选择了单线程的IO多路复用来实现它的核心网络模型。</p></blockquote><p>前面我们说过，单线程设计对于Redis来说有很多好处。</p><ul><li>避免过多的上上下文切换开销</li><li>避免同步机制的开销，涉及到数据同步和事务操作时，避免多线程影响所以必然需要加同步机制保证线程安全性。但是加锁同时也会影响到程序的执行性能。 </li><li>维护简单，引入多线程之后，不管是对数据结构的设计，还是在程序代码的维护上，都会变得很复杂。</li></ul><p>所以既然Redis的数据I/O不是瓶颈，同时单线程又有这么多好处，那Redis自然就采用单线程了。既然是这样，那么Redis 6.0引入多线程，一定不是优化数据IO性能，那么我们先来分析一下Redis性能瓶颈主要体现在哪些方面，无非就是三个方面。</p><ul><li>网络IO</li><li>CPU核心数</li><li>内存</li></ul><p>由于CPU核心数并不是redis的瓶颈，所以影响Redis性能的因素只有网络IO和内存，而内存属于硬件范畴，比如采用容量更大、吞吐量更高的内存进行优化就行，因此也不是属于Redis可优化的空间，所以最终我们发现Redis的性能瓶颈还是在网络IO上。</p><p>而在Redis6.0之前，使用的是单线程Reactor模型，单线程模型是指对于客户端的请求，主线程需要负责对这个请求的完整IO过程进行处理，如图4-8所示，从socket中读取数据和往socket中写数据都是比较耗时的网络IO操作，解析请求和内存交互耗时可能远小于这个网络IO操作。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354708.png" alt="image-20210710153215329"></p><center>图4-8</center><p>按照前面我们对多Reactor多线程的理解，那我们能不能改成主从多Reactor多线程模型呢？主Reactor负责接收客户端连接，然后分发给多个Reactor进行网络IO操作。很显然，这样做就会导致Redis编程了一个多线程模型，这对Redis的影响较大，因为多线程带来的线程安全问题和底层复杂的数据结构的操作都非常棘手，所以Redis 6.0并没有这么做。</p><p>Redis 6.0中将处理过程中最耗时的Socket读取、请求解析、单独用一个线程来处理，剩下的命令执行操作仍然由单线程来完成和内存的数据交互，这样一来，网络IO操作就变成了多线程了，但是核心部分仍然是线程安全的，如图4-9所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354391.png" alt="image-20210710154600353"></p><center>图4-9</center><p>为什么说Redis6.0是一个特殊的多线程，原因就在这里，Redis主要针对网络IO这块引入了多线程的方式来提升了网络IO性能，但是真正执行命令的操作仍然是由主线程来完成。因此，总的来说，我们仍然可以说Redis是单线程模型。</p><h2 id="Redis-6-0如何开启多线程"><a href="#Redis-6-0如何开启多线程" class="headerlink" title="Redis 6.0如何开启多线程"></a>Redis 6.0如何开启多线程</h2><p>Redis 6.0默认多线程是禁止的，也就是仍然只是使用主线程来完成网络IO，如果需要开启，则修改redis.conf配置文件中的如下属性</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 默认是关闭，设置为yes打开</span></span><br><span class="line"><span class="meta">io-threads-do-reads</span> <span class="string">no</span></span><br><span class="line"><span class="comment">#默认线程数量是4，官方建议是4核机器上设置为2~3个，8核机器上设置6个</span></span><br><span class="line"><span class="meta">io-threads</span> <span class="string">4</span></span><br></pre></td></tr></table></figure><h2 id="引入多线程之后的性能提升"><a href="#引入多线程之后的性能提升" class="headerlink" title="引入多线程之后的性能提升"></a>引入多线程之后的性能提升</h2><p>图4-20是美团技术团队使用阿里云服务器压测GET/SET命令在4个线程IO时性能上的对比结果，可以明显的看到，Redis 在使用多线程模式之后性能大幅提升，达到了一倍。</p><ul><li>Redis Server 阿里云 Ubuntu 18.04  ，  8CPU 2.5GHZ，8G内存，主机型号： ecs.ic5.2xlarge</li><li>Redis Benchmark client: 阿里云 Unbuntu 18.04 , 8CPU  2.5GHZ，8G内存，主机型号：ecs.ic5.2xlarge</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354177.png" alt="preview"></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354660.png" alt="preview"></p><center>图4-20</center><h1 id="内存回收策略"><a href="#内存回收策略" class="headerlink" title="内存回收策略"></a>内存回收策略</h1><p>很多同学了解了Redis的好处之后，于是把任何数据都往Redis中放，如果使用不合理很容易导致数据超过Redis的内存，这种情况会出现什么问题呢？</p><ul><li>Redis中有很多无效的缓存，这些缓存数据会降低数据IO的性能，因为不同的数据类型时间复杂度算法不同，数据越多可能会造成性能下降</li><li>随着系统的运行，redis的数据越来越多，会导致物理内存不足。通过使用虚拟内存（VM），将很少访问的数据交换到磁盘上，腾出内存空间的方法来解决物理内存不足的情况。虽然能够解决物理内存不足导致的问题，但是由于这部分数据是存储在磁盘上，如果在高并发场景中，频繁访问虚拟内存空间会严重降低系统性能。</li></ul><p>所以遇到这类问题的时候，我们一般有几种方法。</p><ul><li>对每个存储到redis中的key设置过期时间，这个根据实际业务场景来决定。否则，再大的内存都会虽则系统运行被消耗完。</li><li>增加内存</li><li>使用内存淘汰策略。</li></ul><h2 id="设置Redis能够使用的最大内存"><a href="#设置Redis能够使用的最大内存" class="headerlink" title="设置Redis能够使用的最大内存"></a>设置Redis能够使用的最大内存</h2><p>在实际生产环境中，服务器不仅仅只有Redis，为了避免Redis内存使用过多对其他程序造成影响，我们一般会设置最大内存。</p><p>Redis默认的最大内存<code>maxmemory=0</code>，表示不限制Redis内存的使用。我们可以修改<code>redis.conf</code>文件，设置Redis最大使用的内存。</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 单位为byte</span></span><br><span class="line"><span class="attr">maxmemory</span> <span class="string">&lt;bytes&gt;  2147483648（2G）</span></span><br></pre></td></tr></table></figure><p>如何查看当前Redis最大内存设置呢，进入到Redis-Cli控制台，输入下面这个命令。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">config get maxmemory</span><br></pre></td></tr></table></figure><p>当Redis中存储的内存超过maxmemory时，会怎么样呢？下面我们做一个实验</p><ul><li><p>在redis-cli控制台输入下面这个命令，把最大内存设置为1个字节。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">config set maxmemory 1</span><br></pre></td></tr></table></figure></li><li><p>通过下面的命令存储一个string类型的数据</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">set name mic</span><br></pre></td></tr></table></figure></li><li><p>此时，控制台会得到下面这个错误信息</p></li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">(error) OOM command not allowed when used memory &gt; &#x27;maxmemory&#x27;.</span><br></pre></td></tr></table></figure><h2 id="使用内存淘汰策略释放内存"><a href="#使用内存淘汰策略释放内存" class="headerlink" title="使用内存淘汰策略释放内存"></a>使用内存淘汰策略释放内存</h2><p>设置了maxmemory的选项，redis内存使用达到上限。可以通过设置LRU算法来删除部分key，释放空间。默认是按照过期时间的，如果set时候没有加上过期时间就会导致数据写满maxmemory。</p><p>Redis中提供了一种内存淘汰策略，当内存不足时，Redis会根据相应的淘汰规则对key数据进行淘汰。 Redis一共提供了8种淘汰策略，默认的策略为<strong>noeviction</strong>，当内存使用达到阈值的时候，</p><p>所有引起申请内存的命令会报错。</p><ul><li><strong>volatile-lru</strong>，针对设置了过期时间的key，使用lru算法进行淘汰。</li><li><strong>allkeys-lru</strong>，针对所有key使用lru算法进行淘汰。</li><li><strong>volatile-lfu</strong>，针对设置了过期时间的key，使用lfu算法进行淘汰。</li><li><strong>allkeys-lfu</strong>，针对所有key使用lfu算法进行淘汰。</li><li><strong>volatile-random</strong>，从所有设置了过期时间的key中使用随机淘汰的方式进行淘汰。</li><li><strong>allkeys-random</strong>，针对所有的key使用随机淘汰机制进行淘汰。</li><li><strong>volatile-ttl</strong>，删除生存时间最近的一个键。</li><li><strong>noeviction</strong>，不删除键，值返回错误。</li></ul><p>前缀为volatile-和allkeys-的区别在于二者选择要清除的键时的字典不同，volatile-前缀的策略代表从redisDb中的expire字典中选择键进行清除；allkeys-开头的策略代表从dict字典中选择键进行清除。</p><p>内存淘汰算法的具体工作原理是：</p><ul><li>客户端执行一条新命令，导致数据库需要增加数据（比如set key value）</li><li>Redis会检查内存使用，如果内存使用超过 maxmemory，就会按照置换策略删除一些 key</li><li>新的命令执行成功</li></ul><h3 id="了解并手写LRU算法"><a href="#了解并手写LRU算法" class="headerlink" title="了解并手写LRU算法"></a>了解并手写LRU算法</h3><p>LRU是Least Recently Used的缩写，也就是表示最近很少使用，也可以理解成最久没有使用。也就是说当内存不够的时候，每次添加一条数据，都需要抛弃一条最久时间没有使用的旧数据。</p><p>标准的LRU算法为了降低查找和删除元素的时间复杂度，一般采用Hash表和双向链表结合的数据结构，hash表可以赋予链表快速查找到某个key是否存在链表中，同时可以快速删除、添加节点，如图4-21所示。</p><blockquote><p>双向链表的查找时间复杂度是O(n)，删除和插入是O(1)，借助HashMap结构，可以使得查找的时间复杂度变成O(1)</p></blockquote><p>Hash表用来查询在链表中的数据位置，链表负责数据的插入，当新数据插入到链表头部时有两种情况。</p><ul><li>链表满了，把链表尾部的数据丢弃掉，新加入的缓存直接加入到链表头中。</li><li>当链表中的某个缓存被命中时，直接把数据移到链表头部，原本在头节点的缓存就向链表尾部移动</li></ul><p>这样，经过多次Cache操作之后，最近被命中的缓存，都会存在链表头部的方向，没有命中的，都会在链表尾部方向，当需要替换内容时，由于链表尾部是最少被命中的，我们只需要淘汰链表尾部的数据即可。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354493.png" alt="image-20210710205446429"></p><center>图4-21</center><p>下面我们通过一段代码实现一个简单的LRU算法，加深大家对于LRU算法的理解。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LRUCache</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> Node head;</span><br><span class="line">    <span class="keyword">private</span> Node tail;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">final</span> HashMap&lt;String,Node&gt; nodeHashMap;</span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">int</span> capacity;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">LRUCache</span><span class="params">(<span class="keyword">int</span> capacity)</span></span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.capacity=capacity;</span><br><span class="line">        nodeHashMap=<span class="keyword">new</span> HashMap&lt;&gt;();</span><br><span class="line">        head=<span class="keyword">new</span> Node();</span><br><span class="line">        tail=<span class="keyword">new</span> Node();</span><br><span class="line">        head.next=tail;</span><br><span class="line">        tail.prev=head;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">removeNode</span><span class="params">(Node node)</span></span>&#123;</span><br><span class="line">        <span class="keyword">if</span>(node==tail)&#123;</span><br><span class="line">            tail=tail.prev;</span><br><span class="line">            tail.next=<span class="keyword">null</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span>(node==head)&#123;</span><br><span class="line">            head=head.next;</span><br><span class="line">            head.prev=<span class="keyword">null</span>;</span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;</span><br><span class="line">            node.prev.next=node.next;</span><br><span class="line">            node.next.prev=node.prev;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addNodeToHead</span><span class="params">(Node node)</span></span>&#123;</span><br><span class="line">        node.next=head.next;</span><br><span class="line">        head.next.prev=node;</span><br><span class="line">        node.prev=head;</span><br><span class="line">        head.next=node;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">void</span> <span class="title">addNodeToTail</span><span class="params">(Node node)</span></span>&#123;</span><br><span class="line">        node.prev=tail.prev;</span><br><span class="line">        node.prev.next=node;</span><br><span class="line">        node.next=tail;</span><br><span class="line">        tail.prev=node;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//当链表中的某个缓存被命中时，直接把数据移到链表头部，原本在头节点的缓存就向链表尾部移动</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">moveNodeToHead</span><span class="params">(Node node)</span></span>&#123;</span><br><span class="line"></span><br><span class="line">        removeNode(node);</span><br><span class="line">        addNodeToHead(node);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> String <span class="title">get</span><span class="params">(String key)</span></span>&#123;</span><br><span class="line">        Node node=nodeHashMap.get(key);</span><br><span class="line">        <span class="keyword">if</span>(node==<span class="keyword">null</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//刷新当前节点的位置</span></span><br><span class="line">        moveNodeToHead(node);</span><br><span class="line">        <span class="comment">//返回value值</span></span><br><span class="line">        <span class="keyword">return</span> node.value;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(String key,String value)</span></span>&#123;</span><br><span class="line">        Node node=nodeHashMap.get(key);</span><br><span class="line">        <span class="keyword">if</span>(node==<span class="keyword">null</span>)&#123; <span class="comment">//不存在</span></span><br><span class="line">            <span class="comment">//如果当前存储的数据量达到了阈值，则需要淘汰掉访问较少的数据</span></span><br><span class="line">            <span class="keyword">if</span>(nodeHashMap.size()&gt;=capacity)&#123;</span><br><span class="line">                removeNode(tail); <span class="comment">//移除尾部节点</span></span><br><span class="line">                nodeHashMap.remove(tail.key);</span><br><span class="line">            &#125;</span><br><span class="line">            node=<span class="keyword">new</span> Node(key,value);</span><br><span class="line">            nodeHashMap.put(key,node);</span><br><span class="line">            addNodeToTail(node);</span><br><span class="line">        &#125;<span class="keyword">else</span>&#123;</span><br><span class="line">            node.value=value;</span><br><span class="line">            <span class="comment">//刷新当前节点的位置</span></span><br><span class="line">            moveNodeToHead(node);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">        LRUCache lruCache=<span class="keyword">new</span> LRUCache(<span class="number">3</span>);</span><br><span class="line">        lruCache.put(<span class="string">&quot;1&quot;</span>,<span class="string">&quot;1&quot;</span>);</span><br><span class="line">        lruCache.put(<span class="string">&quot;2&quot;</span>,<span class="string">&quot;2&quot;</span>);</span><br><span class="line">        lruCache.put(<span class="string">&quot;3&quot;</span>,<span class="string">&quot;3&quot;</span>);</span><br><span class="line"><span class="comment">//        lruCache.get(&quot;3&quot;); // 增加一个访问次数之后，被清理的元素就会发生变化</span></span><br><span class="line">        System.out.println(lruCache.nodeHashMap);</span><br><span class="line">        lruCache.put(<span class="string">&quot;4&quot;</span>,<span class="string">&quot;4&quot;</span>);</span><br><span class="line">        System.out.println(lruCache.nodeHashMap);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span></span>&#123;</span><br><span class="line">    <span class="comment">//双向链表中的节点类，存储key是因为我们在双向链表删除表尾的值时，只是返回了一个节点，</span></span><br><span class="line">    <span class="comment">//所以这个节点要包括key值，这样我们的哈希表才可以删除对应key值的映射</span></span><br><span class="line">    <span class="keyword">public</span> String key;</span><br><span class="line">    <span class="keyword">public</span> String value;</span><br><span class="line">    Node prev;</span><br><span class="line">    Node next;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Node</span><span class="params">()</span></span>&#123;&#125;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="title">Node</span><span class="params">(String key, String value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.key = key;</span><br><span class="line">        <span class="keyword">this</span>.value = value;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="Redis中的LRU算法"><a href="#Redis中的LRU算法" class="headerlink" title="Redis中的LRU算法"></a>Redis中的LRU算法</h3><p>实际上，Redis使用的LRU算法其实是一种不可靠的LRU算法，它实际淘汰的键并不一定是真正最少使用的数据，它的工作机制是：</p><ul><li>随机采集淘汰的key，每次随机选出5个key</li><li>然后淘汰这5个key中最少使用的key</li></ul><p>这5个key是默认的个数，具体的数值可以在redis.conf中配置</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">maxmemory-samples 5</span><br></pre></td></tr></table></figure><p>当近似LRU算法取值越大的时候就会越接近真实的LRU算法，因为取值越大获取的数据越完整，淘汰中的数据就更加接近最少使用的数据。这里其实涉及一个权衡问题，</p><p>如果需要在所有的数据中搜索最符合条件的数据，那么一定会增加系统的开销，Redis是单线程的，所以耗时的操作会谨慎一些。</p><p>为了在一定成本内实现相对的LRU，早期的Redis版本是基于采样的LRU，也就是放弃了从所有数据中搜索解改为采样空间搜索最优解。Redis3.0版本之后，Redis作者对于基于采样的LRU进行了一些优化：</p><ul><li>Redis中维护一个大小为16的候选池，当第一次随机选取采用数据时，会把数据放入到候选池中，并且候选池中的数据会更具时间进行排序。</li><li>当第二次以后选取数据时，只有小于候选池内最小时间的才会被放进候选池。</li><li>当候选池的数据满了之后，那么时间最大的key就会被挤出候选池。当执行淘汰时，直接从候选池中选取最近访问时间小的key进行淘汰。</li></ul><p>如图4-22所示，首先从目标字典中采集出maxmemory-samples个键，缓存在一个samples数组中，然后从samples数组中一个个取出来，和回收池中以后的键进行键的空闲时间，从而更新回收池。</p><p>在更新过程中，首先利用遍历找到的每个键的实际插入位置x，然后根据不同情况进行处理。</p><ul><li>回收池满了，并且当前插入的key的空闲时间最小（也就是回收池中的所有key都比当前插入的key的空闲时间都要大），则不作任何操作。</li><li>回收池未满，并且插入的位置x没有键，则直接插入即可</li><li>回收池未满，且插入的位置x原本已经存在要淘汰的键，则把第x个以后的元素都往后挪一个位置，然后再执行插入操作。</li><li>回收池满了，将当前第x个以前的元素往前挪一个位置（实际就是淘汰了），然后执行插入操作。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354542.png" alt="image-20210710203108453"></p><center>图4-22</center><p>这样做的目的是能够选出最真实的最少被访问的key，能够正确不常使用的key。因为在Redis3.0之前是随机选取样本，这样的方式很有可能不是真正意义上的最少访问的key。</p><p>LRU算法有一个弊端，加入一个key值访问频率很低，但是最近一次被访问到了，那LRU会认为它是热点数据，不会被淘汰。同样，</p><p>经常被访问的数据，最近一段时间没有被访问，这样会导致这些数据被淘汰掉，导致误判而淘汰掉热点数据，于是在Redis 4.0中，新加了一种LFU算法。</p><h3 id="LFU算法"><a href="#LFU算法" class="headerlink" title="LFU算法"></a>LFU算法</h3><p>LFU（Least Frequently Used），表示最近最少使用，它和key的使用次数有关，其思想是：根据key最近被访问的频率进行淘汰，比较少访问的key优先淘汰，反之则保留。</p><p>LRU的原理是使用计数器来对key进行排序，每次key被访问时，计数器会增大，当计数器越大，意味着当前key的访问越频繁，也就是意味着它是热点数据。 它很好的解决了LRU算法的缺陷：<strong>一个很久没有被访问的key，偶尔被访问一次，导致被误认为是热点数据的问题。</strong></p><p>LFU的实现原理如图4-23所示，LFU维护了两个链表，横向组成的链表用来存储访问频率，每个访问频率的节点下存储另外一个具有相同访问频率的缓存数据。具体的工作原理是：</p><ul><li>当添加元素时，找到相同访问频次的节点，然后添加到该节点的数据链表的头部。如果该数据链表满了，则移除链表尾部的节点</li><li>当获取元素或者修改元素是，都会增加对应key的访问频次，并把当前节点移动到下一个频次节点。</li></ul><blockquote><p>添加元素时，访问频率默认为1，随着访问次数的增加，频率不断递增。而当前被访问的元素也会随着频率增加进行移动。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151354188.png" alt="image-20210710213258901"></p><center>图4-23</center><h1 id="持久化机制的实现及原理"><a href="#持久化机制的实现及原理" class="headerlink" title="持久化机制的实现及原理"></a>持久化机制的实现及原理</h1><p>Redis的强劲性能很大程度上是由于它所有的数据都存储在内存中，当然如果redis重启或者服务器故障导致redis重启，所有存储在内存中的数据就会丢失。但是在某些情况下，我们希望Redis在重启后能够保证数据不会丢失。</p><ol><li><p>将redis作为nosql数据库使用。</p></li><li><p>将Redis作为高效缓存服务器，缓存被击穿后对后端数据库层面的瞬时压力是特别大的，所有缓存同时失效可能会导致雪崩。</p></li></ol><p>这时我们希望Redis能将数据从内存中以某种形式同步到硬盘上，使得重启后可以根据硬盘中的记录来恢复数据。</p><p>Redis支持两种方式的持久化，一种是RDB方式、另一种是AOF（append-only-file）方式，两种持久化方式可以单独使用其中一种，也可以将这两种方式结合使用。</p><ul><li><strong>RDB</strong>：根据指定的规则“<strong>定时</strong>”将内存中的数据存储在硬盘上，</li><li><strong>AOF</strong>：每次执行命令后将命令本身记录下来。</li></ul><h3 id="4-3-1-RDB模式"><a href="#4-3-1-RDB模式" class="headerlink" title="4.3.1 RDB模式"></a>4.3.1 RDB模式</h3><p>RDB的持久化方式是通过快照（snapshotting）完成的，它是Redis默认的持久化方式，配置如下。</p><figure class="highlight properties"><table><tr><td class="code"><pre><span class="line"><span class="comment"># save 3600 1</span></span><br><span class="line"><span class="comment"># save 300 100</span></span><br><span class="line"><span class="comment"># save 60 10000</span></span><br></pre></td></tr></table></figure><p>Redis允许用户自定义快照条件，当符合快照条件时，Redis会自动执行快照操作。快照的条件可以由用户在配置文件中配置。配置格式如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">save &lt;seconds&gt; &lt;changes&gt;</span><br></pre></td></tr></table></figure><p>第一个参数是时间窗口，第二个是键的个数，也就是说，在第一个时间参数配置范围内被更改的键的个数大于后面的changes时，即符合快照条件。当触发条件时，Redis会自动将内存中的数据生成一份副本并存储在磁盘上，这个过程称之为“快照”，除了上述规则之外，还有以下几种方式生成快照。</p><ol><li>根据配置规则进行自动快照</li><li>用户执行SAVE或者GBSAVE命令</li><li>执行FLUSHALL命令</li><li>执行复制(replication)时</li></ol><h3 id="根据配置规则进行自动快照"><a href="#根据配置规则进行自动快照" class="headerlink" title="根据配置规则进行自动快照"></a>根据配置规则进行自动快照</h3><ul><li>修改redis.conf文件，表示5秒内，有一个key发生变化，就会生成rdb文件。</li></ul><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">save 5 1                # 表示3600s以内至少发生1个key变化（新增、修改、删除），则重写rdb文件</span><br><span class="line">save 300 100</span><br><span class="line">save 60 10000</span><br></pre></td></tr></table></figure><ul><li><p>修改文件存储路径</p><figure class="highlight plaintext"><table><tr><td class="code"><pre><span class="line">dir /data/program/redis/bin</span><br></pre></td></tr></table></figure></li><li><p>其他参数配置说明</p><table><thead><tr><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>dir</td><td>rdb文件默认在启动目录下（相对路径） <code>config get dir</code> 获取</td></tr><tr><td>dbfilename</td><td>文件名称</td></tr><tr><td>rdbcompression</td><td>开启压缩可以节省存储空间，但是会消耗一些CPU的计算时间，默认开启</td></tr><tr><td>rdbchecksum</td><td>使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，如果希望获取到最大的性能提升，可以关闭此功能。</td></tr></tbody></table></li></ul><p><strong>如果需要关闭RDB的持久化机制，可以参考如下配置，开启<code>save</code>，并注释其他规则即可</strong></p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">save &quot;&quot;</span><br><span class="line"><span class="meta">#</span><span class="bash">save 900 1</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 300 10</span></span><br><span class="line"><span class="meta">#</span><span class="bash">save 60 10000</span></span><br></pre></td></tr></table></figure><h3 id="用户执行SAVE或者GBSAVE命令"><a href="#用户执行SAVE或者GBSAVE命令" class="headerlink" title="用户执行SAVE或者GBSAVE命令"></a>用户执行SAVE或者GBSAVE命令</h3><p>除了让Redis自动进行快照以外，当我们对服务进行重启或者服务器迁移我们需要人工去干预备份。redis提供了两条命令来完成这个任务</p><ol><li><p><strong>save命令</strong></p><p>如图4-24所示，当执行save命令时，Redis同步做快照操作，在快照执行过程中会阻塞所有来自客户端的请求。当redis内存中的数据较多时，通过该命令将导致Redis较长时间的不响应。所以不建议在生产环境上使用这个命令，而是推荐使用bgsave命令</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151355068.png" alt="image-20210712184050955"></p><center>图4-24</center></li><li><p><strong>bgsave命令</strong></p><p>如图4-25所示，bgsave命令可以在后台异步地进行快照操作，快照的同时服务器还可以继续响应来自客户端的请求。执行BGSAVE后，Redis会立即返回ok表示开始执行快照操作，在redis-cli终端，通过下面这个命令可以获取最近一次成功执行快照的时间（以 UNIX 时间戳格式表示）。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">LASTSAVE</span><br></pre></td></tr></table></figure></li></ol><p>1：redis使用fork函数复制一份当前进程的副本(子进程)</p><p>2：父进程继续接收并处理客户端发来的命令，而子进程开始将内存中的数据写入硬盘中的临时文件</p><p>3：当子进程写入完所有数据后会用该临时文件替换旧的RDB文件，至此，一次快照操作完成。 </p><blockquote><p>注意：redis在进行快照的过程中不会修改RDB文件，只有快照结束后才会将旧的文件替换成新的，也就是说任何时候RDB文件都是完整的。 这就使得我们可以通过定时备份RDB文件来实现redis数据库的备份， RDB文件是经过压缩的二进制文件，占用的空间会小于内存中的数据，更加利于传输。</p><p><strong>bgsave是异步执行快照的，bgsave写入的数据就是for进程时redis的数据状态，一旦完成fork，后续执行的新的客户端命令对数据产生的变更都不会反应到本次快照</strong></p></blockquote><p>Redis启动后会读取RDB快照文件，并将数据从硬盘载入到内存。根据数据量大小以及服务器性能不同，这个载入的时间也不同。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151355770.png" alt="image-20210712183559812"></p><center>图4-25</center><h3 id="执行FLUSHALL命令"><a href="#执行FLUSHALL命令" class="headerlink" title="执行FLUSHALL命令"></a>执行FLUSHALL命令</h3><p>该命令在前面讲过，会清除redis在内存中的所有数据。执行该命令后，只要redis中配置的快照规则不为空，也就是save 的规则存在。redis就会执行一次快照操作。不管规则是什么样的都会执行。如果没有定义快照规则，就不会执行快照操作。</p><h3 id="执行复制-replication-时"><a href="#执行复制-replication-时" class="headerlink" title="执行复制(replication)时"></a>执行复制(replication)时</h3><p>该操作主要是在主从模式下，redis会在复制初始化时进行自动快照。这个会在后面讲到；</p><p>这里只需要了解当执行复制操作时，即时没有定义自动快照规则，并且没有手动执行过快照操作，它仍然会生成RDB快照文件。</p><h3 id="RDB数据恢复演示"><a href="#RDB数据恢复演示" class="headerlink" title="RDB数据恢复演示"></a>RDB数据恢复演示</h3><ul><li>准备初始数据</li></ul><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k1 1</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k2 2</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k3 3</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k4 4</span></span><br><span class="line"><span class="meta">redis&gt;</span><span class="bash"> <span class="built_in">set</span> k5 5</span></span><br></pre></td></tr></table></figure><ul><li><p>通过shutdown命令关闭触发save</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> shutdown</span></span><br></pre></td></tr></table></figure></li><li><p>备份dump.rdb文件(用来后续恢复)</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cp dump.rdb dump.rdb.bak</span><br></pre></td></tr></table></figure></li><li><p>接着再启动redis-server(systemctl restart redis_6379)，通过keys命令查看，发现数据还在</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">keys *</span><br></pre></td></tr></table></figure></li></ul><blockquote><p>模拟数据丢失</p></blockquote><ul><li><p>执行flushall</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> flushall</span></span><br></pre></td></tr></table></figure></li><li><p>shutdown(重新生成没有数据的快照，用来模拟后续的数据恢复)</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> shutdown</span></span><br></pre></td></tr></table></figure></li><li><p>再次启动redis, 通过keys 命令查看，此时rdb中没有任何数据。</p></li><li><p>恢复之前备份的rdb文件（之前保存了数据的rdb快照）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">mv dump.rdb.bak dump.rdb</span><br></pre></td></tr></table></figure></li><li><p>再次重启redis，可以看到之前快照保存的数据</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">keys *</span><br></pre></td></tr></table></figure></li></ul><h3 id="RDB文件的优势和劣势"><a href="#RDB文件的优势和劣势" class="headerlink" title="RDB文件的优势和劣势"></a>RDB文件的优势和劣势</h3><p><strong>一、优势</strong></p><p>　　1.RDB是一个非常紧凑(compact)的文件，它保存了redis 在某个时间点上的数据集，这种文件非常适合用于进行备份和灾难恢复。</p><p>　　2.生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。</p><p>　　3.RDB 在恢复大数据集时的速度比AOF的恢复速度要快。</p><p><strong>二、劣势</strong></p><ul><li><p>1、RDB方式数据没办法做到实时持久化/秒级持久化。因为bgsave每次运行都要执行fork操作创建子进程，频繁执行成本过高</p></li><li><p>2、在一定间隔时间做一次备份，所以如果redis意外down掉的话，就会丢失最后一次快照之后的所有修改（数据有丢失）。</p></li></ul><p><strong>如果数据相对来说比较重要，希望将损失降到最小，则可以使用AOF方式进行持久化。</strong></p><h3 id="4-3-2-AOF模式"><a href="#4-3-2-AOF模式" class="headerlink" title="4.3.2 AOF模式"></a>4.3.2 AOF模式</h3><p>AOF(Append Only File)：Redis 默认不开启。AOF采用日志的形式来记录每个写操作，并<strong>追加</strong>到文件中。开启后，执行更改Redis数据的命令时，就会把命令写入到AOF文件中。</p><p>Redis 重启时会根据日志文件的内容把写指令从前到后执行一次以完成数据的恢复工作。</p><h3 id="AOF配置开关"><a href="#AOF配置开关" class="headerlink" title="AOF配置开关"></a>AOF配置开关</h3><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 开关</span></span><br><span class="line">appendonly no  /yes</span><br><span class="line"><span class="meta">#</span><span class="bash"> 文件名</span></span><br><span class="line">appendfilename &quot;appendonly.aof&quot;</span><br></pre></td></tr></table></figure><p>通过修改redis.conf重启redis之后：systemctl restart redis_6379。</p><p>再次运行redis的相关操作命令，会发现在指定的<code>dir</code>目录下生成appendonly.aof文件，通过vim查看该文件内容如下</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">*2</span><br><span class="line"><span class="meta">$</span><span class="bash">6</span></span><br><span class="line">SELECT</span><br><span class="line"><span class="meta">$</span><span class="bash">1</span></span><br><span class="line">0</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">name</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">mic</span><br><span class="line">*3</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">set</span><br><span class="line"><span class="meta">$</span><span class="bash">4</span></span><br><span class="line">name</span><br><span class="line"><span class="meta">$</span><span class="bash">3</span></span><br><span class="line">123</span><br></pre></td></tr></table></figure><h3 id="AOF配置相关问题解答"><a href="#AOF配置相关问题解答" class="headerlink" title="AOF配置相关问题解答"></a>AOF配置相关问题解答</h3><p><strong>问题1：数据都是实时持久化到磁盘吗？</strong></p><p>虽然每次执行更改Redis数据库内容的操作时，AOF都会将命令记录在AOF文件中，但是事实上，由于操作系统的缓存机制，数据并没有真正地写入硬盘，而是进入了系统的硬盘缓存。在默认情况下系统每30秒会执行一次同步操作。以便将硬盘缓存中的内容真正地写入硬盘。</p><p>在这30秒的过程中如果系统异常退出则会导致硬盘缓存中的数据丢失。一般来说能够启用AOF的前提是业务场景不能容忍这样的数据损失，这个时候就需要Redis在写入AOF文件后主动要求系统将缓存内容同步到硬盘中。在redis.conf中通过如下配置来设置同步机制。</p><table><thead><tr><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>appendfsync everysec</td><td>AOF持久化策略（硬盘缓存到磁盘），默认<strong>everysec</strong> <br /> 1 no  表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快，但是不太安全；  <br /> 2 always  表示每次写入都执行fsync，以保证数据同步到磁盘，效率很低；<br /> 3 everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。通常选择 everysec ，兼顾安全性和效率。</td></tr></tbody></table><p><strong>问题2：文件越来越大，怎么办？</strong></p><p>由于AOF持久化是Redis不断将写命令记录到 AOF 文件中，随着Redis不断的运行，AOF 的文件会越来越大，文件越大，占用服务器内存越大以及 AOF 恢复要求时间越长。</p><p><strong>例如set gupao 666，执行1000次，结果都是gupao=666。</strong></p><p>为了解决这个问题，Redis新增了重写机制，当AOF文件的大小超过所设定的阈值时，Redis就会启动AOF文件的内容压缩，只保留可以恢复数据的最小指令集。</p><p>可以使用命令下面这个命令主动触发重写</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line"><span class="meta">redis&gt;</span><span class="bash"> bgrewriteaof</span></span><br></pre></td></tr></table></figure><p>AOF 文件重写并不是对原文件进行重新整理，而是直接读取服务器现有的键值对，然后用一条命令去代替之前记录这个键值对的多条命令，生成一个新的文件后去替换原来的 AOF 文件。</p><p><strong>重写触发机制如下</strong></p><table><thead><tr><th><strong>参数</strong></th><th><strong>说明</strong></th></tr></thead><tbody><tr><td>auto-aof-rewrite-percentage</td><td>默认值为100。表示的是当目前的AOF文件大小超过上一次重写时的AOF文件大小的百分之多少时会再次进行重写，如果之前没有重写过，则以启动时AOF文件大小为依据</td></tr><tr><td>auto-aof-rewrite-min-size</td><td>默认64M。表示限制了允许重写的最小AOF文件大小，通常在AOF文件很小的情况下即使其中有很多冗余的命令我们也并不太关心</td></tr></tbody></table><p>在启动时，Redis会逐个执行AOF文件中的命令来将硬盘中的数据载入到内存中，载入的速度相对于RDB会慢一些</p><p><strong>问题：重写过程中，AOF文件被更改了怎么办？</strong></p><p>Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 </p><p>重写的流程是这样，</p><ul><li>主进程会fork一个子进程出来进行AOF重写，这个重写过程并不是基于原有的aof文件来做的，而是有点类似于快照的方式，全量遍历内存中的数据，然后逐个序列到aof文件中。</li><li>在fork子进程这个过程中，服务端仍然可以对外提供服务，<strong>那这个时候重写的aof文件的数据和redis内存数据不一致了怎么办？</strong>不用担心，这个过程中，主进程的数据更新操作，会缓存到<strong>aof_rewrite_buf</strong>中，也就是单独开辟一块缓存来存储重写期间收到的命令，当子进程重写完以后再把缓存中的数据追加到新的aof文件。</li><li>当所有的数据全部追加到新的aof文件中后，把新的aof文件重命名正式的文件名字，此后所有的操作都会被写入新的aof文件。</li><li>如果在rewrite过程中出现故障，不会影响原来aof文件的正常工作，只有当rewrite完成后才会切换文件。因此这个rewrite过程是比较可靠的。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110151355374.png" alt="img"></p><center>图4-26</center><p>Redis允许同时开启AOF和RDB，既保证了数据安全又使得进行备份等操作十分容易。如果同时开启后，Redis重启会使用AOF文件来恢复数据，因为AOF方式的持久化可能丢失的数据更少。</p><h3 id="AOF的优劣势"><a href="#AOF的优劣势" class="headerlink" title="AOF的优劣势"></a>AOF的优劣势</h3><p><strong>优点：</strong></p><p>1、AOF 持久化的方法提供了多种的同步频率，即使使用默认的同步频率每秒同步一次，Redis 最多也就丢失 1 秒的数据而已。</p><p><strong>缺点：</strong></p><p>1、对于具有相同数据的的Redis，AOF 文件通常会比 RDB 文件体积更大（RDB存的是数据快照）。</p><p>2、虽然 AOF 提供了多种同步的频率，默认情况下，每秒同步一次的频率也具有较高的性能。在高并发的情况下，RDB 比 AOF 具好更好的性能保证。</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 面试题 </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阿里P8面试官：如何设计一个扛住千万级并发的架构（超级详细）-续</title>
      <link href="/posts/2734400627/"/>
      <url>/posts/2734400627/</url>
      
        <content type="html"><![CDATA[<p>在上一篇文章中，详细分析了设计一个千万级并发架构所需要思考的问题，以及解决方案。<br>在这一片文章中，我们主要分析如何在职场足够用户数量的情况下，同步提升架构的性能降低平均响应时间。</p><h1 id="如何降低RT的值"><a href="#如何降低RT的值" class="headerlink" title="如何降低RT的值"></a>如何降低RT的值</h1><p>继续看上面这个图，一个请求只有等到tomcat容器中的应用执行完成才能返回，而请求在执行过程中会做什么事情呢？</p><ul><li>查询数据库</li><li>访问磁盘数据</li><li>进行内存运算</li><li>调用远程服务</li></ul><p>这些操作每一个步骤都会消耗时间，当前客户端的请求只有等到这些操作都完成之后才能返回，所以降低RT的方法，就是优化业务逻辑的处理。</p><h2 id="数据库瓶颈的优化"><a href="#数据库瓶颈的优化" class="headerlink" title="数据库瓶颈的优化"></a>数据库瓶颈的优化</h2><p>当18000个请求进入到服务端并且被接收后，开始执行业务逻辑处理，那么必然会查询数据库。</p><p>每个请求至少都有一次查询数据库的操作，多的需要查询3~5次以上，我们假设按照3次来计算，那么每秒会对数据库形成54000个请求，假设一台数据库服务器每秒支撑10000个请求（影响数据库的请求数量有很多因素，比如数据库表的数据量、数据库服务器本身的系统性能、查询语句的复杂度），那么需要6台数据库服务器才能支撑每秒10000个请求。</p><p>除此之外，数据库层面还有涉及到其他的优化方案。</p><ul><li><p>首先是Mysql的最大连接数设置，大家可能遇到过<code>MySQL: ERROR 1040: Too many connections</code>这样的问题，原因就是访问量过高，连接数耗尽了。</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line"><span class="keyword">show</span> variables <span class="keyword">like</span> <span class="string">&#x27;%max_connections%&#x27;</span>;</span><br></pre></td></tr></table></figure><p>如果服务器的并发连接请求量比较大，建议调高此值，以增加并行连接数量，当然这建立在机器能支撑的情况下，因为如果连接数越多，介于MySQL会为每个连接提供连接缓冲区，就会开销越多的内存，所以要适当调整该值，不能盲目提高设值。</p></li><li><p>数据表数据量过大，比如达到几千万甚至上亿，这种情况下sql的优化已经毫无意义了，因为这么大的数据量查询必然会涉及到运算。</p><ul><li><p>可以缓存来解决读请求并发过高的问题，一般来说对于数据库的读写请求也都遵循2/8法则，在每秒54000个请求中，大概有43200左右是读请求，这些读请求中基本上90%都是可以通过缓存来解决。</p></li><li><p>分库分表，减少单表数据量，单表数据量少了，那么查询性能就自然得到了有效的提升</p></li><li><p>读写分离，避免事务操作对查询操作带来的性能影响</p><blockquote><ul><li><p>写操作本身耗费资源</p><p>数据库写操作为IO写入，写入过程中通常会涉及唯一性校验、建索引、索引排序等操作，对资源消耗比较大。一次写操作的响应时间往往是读操作的几倍甚至几十倍。</p></li><li><p>锁争用</p><p>写操作很多时候需要加锁，包括表级锁、行级锁等，这类锁都是排他锁，一个会话占据排它锁之后，其他会话是不能读取数据的，这会会极大影响数据读取性能。</p><p>所以MYSQL部署往往会采用读写分离方式，主库用来写入数据及部分时效性要求很高的读操作，从库用来承接大部分读操作，这样数据库整体性能能够得到大幅提升。</p></li></ul></blockquote></li></ul></li><li><p>不同类型的数据采用不同的存储库，</p><ul><li>MongoDB  nosql 文档化存储</li><li>Redis  nosql  key-value存储</li><li>HBase nosql， 列式存储，其实本质上有点类似于key-value数据库。</li><li>cassandra，Cassandra 是一个来自 Apache 的分布式数据库，具有高度可扩展性，可用于管理大量的结构化数据</li><li>TIDB，是PingCAP公司自主设计、研发的开源分布式关系型数据库，是一款同时支持在线事务处理与在线分析处理 (Hybrid Transactional and Analytical Processing, HTAP) 的融合型分布式数据库产品</li></ul></li></ul><blockquote><p>为什么把mysql数据库中的数据放redis缓存中能提升性能？</p><ol><li>Redis存储的是k-v格式的数据。时间复杂度是O(1),常数阶,而mysql引擎的底层实现是B+TREE，时间复杂度是O(logn）是对数阶的。Redis会比Mysql快一点点。</li><li>Mysql数据存储是存储在表中，查找数据时要先对表进行全局扫描或根据索引查找，这涉及到磁盘的查找，磁盘查找如果是单点查找可能会快点，但是顺序查找就比较慢。而redis不用这么麻烦，本身就是存储在内存中，会根据数据在内存的位置直接取出。</li><li>Redis是单线程的多路复用IO,单线程避免了线程切换的开销，而多路复用IO避免了IO等待的开销，在多核处理器下提高处理器的使用效率可以对数据进行分区，然后每个处理器处理不同的数据。</li></ol></blockquote><ul><li><p>池化技术，减少频繁创建数据库连接的性能损耗。</p><p>每次进行数据库操作之前，先建立连接然后再进行数据库操作，最后释放连接。这个过程涉及到网络通信的延时，频繁创建连接对象和销毁对象的性能开销等，当请求量较大时，这块带来的性能影响非常大。</p></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350704.png" alt="数据存储"></p><h2 id="磁盘数据访问优化"><a href="#磁盘数据访问优化" class="headerlink" title="磁盘数据访问优化"></a>磁盘数据访问优化</h2><p>对于磁盘的操作，无非就是读和写。</p><p>比如对于做交易系统的场景来说，一般会设计到对账文件的解析和写入。而对于磁盘的操作，优化方式无非就是</p><ul><li><p>磁盘的页缓存，可以借助缓存 I/O ，充分利用系统缓存，降低实际 I/O 的次数。</p></li><li><p>顺序读写，可以用追加写代替随机写，减少寻址开销，加快 I/O 写的速度。</p></li><li><p>SSD代替HDD，固态硬盘的I/O效率远远高于机械硬盘。</p></li><li><p>在需要频繁读写同一块磁盘空间时，可以用 mmap （内存映射，）代替 read/write，减少内存的拷贝次数</p></li><li><p>在需要同步写的场景中，尽量将写请求合并，而不是让每个请求都同步写入磁盘，即可以用 fsync() 取代 O_SYNC</p></li></ul><h2 id="合理利用内存"><a href="#合理利用内存" class="headerlink" title="合理利用内存"></a>合理利用内存</h2><p>充分利用内存缓存，把一些经常访问的数据和对象保存在内存中，这样可以避免重复加载或者避免数据库访问带来的性能损耗。</p><h2 id="调用远程服务"><a href="#调用远程服务" class="headerlink" title="调用远程服务"></a>调用远程服务</h2><p>远程服务调用，影响到IO性能的因素有。</p><ul><li>远程调用等待返回结果的阻塞<ul><li>异步通信</li></ul></li><li>网络通信的耗时<ul><li>内网通信</li><li>增加网络带宽</li></ul></li><li>远程服务通信的稳定性</li></ul><h2 id="异步化架构"><a href="#异步化架构" class="headerlink" title="异步化架构"></a>异步化架构</h2><p>微服务中的逻辑复杂处理时间长的情况，在高并发量下，导致服务线程消耗尽，不能再创建线程处理请求。对这种情况的优化，除了在程序上不断调优(数据库调优，算法调优，缓存等等)，可以考虑在架构上做些调整，先返回结果给客户端，让用户可以继续使用客户端的其他操作，再把服务端的复杂逻辑处理模块做异步化处理。这种异步化处理的方式适合于客户端对处理结果不敏感不要求实时的情况，比如群发邮件、群发消息等。</p><p>异步化设计的解决方案： 多线程、MQ。</p><h1 id="应用服务的拆分"><a href="#应用服务的拆分" class="headerlink" title="应用服务的拆分"></a>应用服务的拆分</h1><p>除了上述的手段之外，业务系统往微服务化拆分也非常有必要，原因是：</p><ul><li>随着业务的发展，应用程序本身的复杂度会不断增加，同样会产生熵增现象。</li><li>业务系统的功能越来越多，参与开发迭代的人员也越多，多个人维护一个非常庞大的项目，很容易出现问题。</li><li>单个应用系统很难实现横向扩容，并且由于服务器资源有限，导致所有的请求都集中请求到某个服务器节点，造成资源消耗过大，使得系统不稳定</li><li>测试、部署成本越来越高</li><li>…..</li></ul><p>其实，最终要的是，单个应用在性能上的瓶颈很难突破，也就是说如果我们要支持18000QPS，单个服务节点肯定无法支撑，所以服务拆分的好处，就是可以利用多个计算机阶段组成一个大规模的分布式计算网络，通过网络通信的方式完成一整套业务逻辑。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350400.png" alt="img"></p><h2 id="如何拆分服务"><a href="#如何拆分服务" class="headerlink" title="如何拆分服务"></a>如何拆分服务</h2><p>如何拆分服务，这个问题看起来简单，很多同学会说，直接按照业务拆分啊。</p><p>但是实际在实施的时候，会发现拆分存在一些边界性问题，比如有些数据模型可以存在A模块，也可以存在B模块，这个时候怎么划分呢？另外，服务拆分的粒度应该怎么划分？</p><p>一般来说，服务的拆分是按照业务来实现的，然后基于DDD来指导微服务的边界划分。<strong>领域驱动就是一套方法论，通过领域驱动设计方法论来定义领域模型，从而确定业务边界和应用边界，保证业务模型和代码模型的一致性。</strong>不管是DDD还是微服务，都要遵循软件设计的基本原则：<strong>高内聚低耦合</strong>。服务内部高内聚，服务之间低耦合，实际上一个领域服务对应了一个功能集合，这些功能一定是有一些共性的。比如，订单服务，那么创建订单、修改订单、查询订单列表，领域的边界越清晰，功能也就越内聚，服务之间的耦合性也就越低。</p><p>服务拆分还需要根据当前技术团队和公司所处的状态来进行。</p><p>如果是初创团队，不需要过分的追求微服务，否则会导致业务逻辑过于分散，技术架构太过负载，再加上团队的基础设施还不够完善，导致整个交付的时间拉长，对公司的发展来说会造成较大的影响。所以在做服务拆分的时候还需要考虑几个因素。</p><ul><li>当前公司业务所处领域的市场性质，如果是市场较为敏感的项目，前期应该是先出来东西，然后再去迭代和优化。</li><li>开发团队的成熟度，团队技术能否能够承接。</li><li>基础能力是否足够，比如Devops、运维、测试自动化等基础能力。 团队是否有能力来支撑大量服务实例运行带来的运维复杂度，是否可以做好服务的监控。</li><li>测试团队的执行效率，如果测试团队不能支持自动化测试、自动回归、压力测试等手段来提高测试效率，那必然会带来测试工作量的大幅度提升从而导致项目上线周期延期</li></ul><p>如果是针对一个老的系统进行改造，那可能涉及到的风险和问题更多，所以要开始着手改动之前，需要考虑几个步骤：拆分前准备阶段，设计拆分改造方案，实施拆分计划</p><ul><li><p>拆分之前，先梳理好当前的整个架构，以及各个模块的依赖关系，还有接口</p><p>准备阶段主要是梳理清楚了依赖关系和接口，就可以思考如何来拆，第一刀切在哪儿里，即能达到快速把一个复杂单体系统变成两个更小系统的目标，又能对系统的现有业务影响最小。要尽量避免构建出一个分布式的单体应用，一个包含了一大堆互相之间紧耦合的服务，却又必须部署在一起的所谓分布式系统。没分析清楚就强行拆，可能就一不小心剪断了大动脉，立马搞出来一个 A 类大故障，后患无穷。</p></li><li><p>不同阶段拆分要点不同，每个阶段的关注点要聚焦</p><p>拆分本身可以分成三个阶段，核心业务和非业务部分的拆分、核心业务的调整设计、核心业务内部的拆分。</p><ul><li><p>第一阶段将核心业务瘦身，把非核心的部分切开，减少需要处理的系统大小；</p></li><li><p>第二阶段。重新按照微服务设计核心业务部分；</p></li><li><p>第三阶段把核心业务部分重构设计落地。</p></li></ul><p>拆分的方式也有三个：代码拆分、部署拆分、数据拆分。</p></li></ul><p>另外，每个阶段需要聚焦到一两个具体的目标，否则目标太多反而很难把一件事儿做通透。例如某个系统的微服务拆分，制定了如下的几个目标：</p><ol><li>性能指标（吞吐和延迟）：核心交易吞吐提升一倍以上（TPS：1000-&gt;10000），A 业务延迟降低一半（Latency：250ms-&gt;125ms），B 业务延迟降低一半（Latency：70ms-&gt;35ms）。</li><li>稳定性指标（可用性，故障恢复时间）：可用性&gt;=99.99%，A 类故障恢复时间&lt;=15 分钟，季度次数&lt;=1 次。</li><li>质量指标：编写完善的产品需求文档、设计文档、部署运维文档，核心交易部分代码 90%以上单测覆盖率和 100%的自动化测试用例和场景覆盖，实现可持续的性能测试基准环境和长期持续性能优化机制。</li><li>扩展性指标：完成代码、部署、运行时和数据多个维度的合理拆分，对于核心系统重构后的各块业务和交易模块、以及对应的各个数据存储，都可以随时通过增加机器资源实现伸缩扩展。</li><li>可维护性指标：建立全面完善的监控指标、特别是全链路的实时性能指标数据，覆盖所有关键业务和状态，缩短监控报警响应处置时间，配合运维团队实现容量规划和管理，出现问题时可以在一分钟内拉起系统或者回滚到上一个可用版本（启动时间&lt;=1 分钟）。</li><li>易用性指标，通过重构实现新的 API 接口既合理又简单，极大的满足各个层面用户的使用和需要，客户满意度持续上升。</li><li>业务支持指标：对于新的业务需求功能开发，在保障质量的前提下，开发效率提升一倍，开发资源和周期降低一半。</li></ol><p>当然，不要期望一次性完成所有目标，每一个阶段可以选择一个两个优先级高的目标进行执行。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350615.png" alt="img"></p><h2 id="微服务化架构带来的问题"><a href="#微服务化架构带来的问题" class="headerlink" title="微服务化架构带来的问题"></a>微服务化架构带来的问题</h2><p>微服务架构首先是一个分布式的架构，其次我们要暴露和提供业务服务能力，然后我们需要考虑围绕这些业务能力的各种非功能性的能力。这些分散在各处的服务本身需要被管理起来，并且对服务的调用方透明，这样就有了服务的注册发现的功能需求。</p><p>同样地，每个服务可能部署了多台机器多个实例，所以，我们需要有路由和寻址的能力，做负载均衡，提升系统的扩展能力。有了这么多对外提供的不同服务接口，我们一样需要有一种机制对他们进行统一的接入控制，并把一些非业务的策略做到这个接入层，比如权限相关的，这就是服务网关。同时我们发现随着业务的发展和一些特定的运营活动，比如秒杀大促，流量会出现十倍以上的激增，这时候我们就需要考虑系统容量，服务间的强弱依赖关系，做服务降级、熔断，系统过载保护等措施。</p><p>以上这些由于微服务带来的复杂性，导致了应用配置、业务配置，都被散落到各处，所以分布式配置中心的需求也出现了。最后，系统分散部署以后，所有的调用都跨了进程，我们还需要有能在线上做链路跟踪，性能监控的一套技术，来协助我们时刻了解系统内部的状态和指标，让我们能够随时对系统进行分析和干预。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171351673.png" alt="image-20210624133950124"></p><h2 id="整体架构图"><a href="#整体架构图" class="headerlink" title="整体架构图"></a>整体架构图</h2><p>基于上述从微观到宏观的整体分析，我们基本上能够设计出一个整体的架构图。</p><ul><li><p>接入层，外部请求到内部系统之间的关口，所有请求都必须经过api 网关。</p></li><li><p>应用层，也叫聚合层，为相关业务提供聚合接口，它会调用中台服务进行组装。</p></li><li><p>中台服务，也是业务服务层，以业务为纬度提供业务相关的接口。中台的本质是为整个架构提供复用的能力，比如评论系统，在咕泡云课堂和Gper社区都需要，那么这个时候评论系统为了设计得更加可复用性，就不能耦合云课堂或者Gper社区定制化的需求，那么作为设计评论中台的人，就不需要做非常深度的思考，如何提供一种针对不同场景都能复用的能力。</p><p>你会发现，当这个服务做到机制的时候，就变成了一个baas服务。</p><blockquote><p><strong>服务商</strong>为<strong>客户</strong>(开发者)提供整合云后端的服务，如提供文件存储、数据存储、推送服务、身份验证服务等功能，以帮助开发者快速开发应用。</p></blockquote></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110091513908.png" alt="image-20210624152616146"></p><h1 id="了解什么是高并发"><a href="#了解什么是高并发" class="headerlink" title="了解什么是高并发"></a>了解什么是高并发</h1><p>总结一下什么是高并发。</p><p>高并发并没有一个具体的定义，高并发主要是形容突发流量较高的场景。</p><p>如果面试的过程中，或者在实际工作中，你们领导或者面试官问你一个如何设计承接千万级流量的系统时，你应该要按照我说的方法去进行逐一分析。</p><ul><li>一定要形成可以量化的数据指标，比如QPS、DAU、总用户数、TPS、访问峰值</li><li>针对这些数据情况，开始去设计整个架构方案</li><li>接着落地执行</li></ul><h2 id="高并发中的宏观指标"><a href="#高并发中的宏观指标" class="headerlink" title="高并发中的宏观指标"></a>高并发中的宏观指标</h2><p>一个满足高并发系统，不是一味追求高性能，至少需要满足三个宏观层面的目标：</p><ul><li>高性能，性能体现了系统的并行处理能力，在有限的硬件投入下，提高性能意味着节省成本。同时，性能也反映了用户体验，响应时间分别是 100 毫秒和 1 秒，给用户的感受是完全不同的。</li><li>高可用，表示系统可以正常服务的时间。一个全年不停机、无故障；另一个隔三差五出现上事故、宕机，用户肯定选择前者。另外，如果系统只能做到 90%可用，也会大大拖累业务。</li><li>高扩展，表示系统的扩展能力，流量高峰时能否在短时间内完成扩容，更平稳地承接峰值流量，比如双 11 活动、明星离婚等热点事件。</li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110091513525.png" alt="image-20210624211728937"></p><h2 id="微观指标"><a href="#微观指标" class="headerlink" title="微观指标"></a>微观指标</h2><p><strong>性能指标</strong></p><p>通过性能指标可以度量目前存在的性能问题，同时作为性能优化的评估依据。一般来说，会采用一段时间内的接口响应时间作为指标。</p><p>1、平均响应时间：最常用，但是缺陷很明显，对于慢请求不敏感。比如 1 万次请求，其中 9900 次是 1ms，100 次是 100ms，则平均响应时间为 1.99ms，虽然平均耗时仅增加了 0.99ms，但是 1%请求的响应时间已经增加了 100 倍。</p><p>2、TP90、TP99 等分位值：将响应时间按照从小到大排序，TP90 表示排在第 90 分位的响应时间， 分位值越大，对慢请求越敏感。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110091513882.jpeg" alt="img"></p><p><strong>可用性指标</strong></p><p>高可用性是指系统具有较高的无故障运行能力，可用性 = 平均故障时间 / 系统总运行时间，一般使用几个 9 来描述系统的可用性。</p><p>对于高并发系统来说，最基本的要求是：保证 3 个 9 或者 4 个 9。原因很简单，如果你只能做到 2 个 9，意味着有 1%的故障时间，像一些大公司每年动辄千亿以上的 GMV 或者收入，1%就是 10 亿级别的业务影响。</p><p><strong>可扩展性指标</strong></p><p>面对突发流量，不可能临时改造架构，最快的方式就是增加机器来线性提高系统的处理能力。</p><p>对于业务集群或者基础组件来说，扩展性 = 性能提升比例 / 机器增加比例，理想的扩展能力是：资源增加几倍，性能提升几倍。通常来说，扩展能力要维持在 70%以上。</p><p>但是从高并发系统的整体架构角度来看，扩展的目标不仅仅是把服务设计成无状态就行了，因为当流量增加 10 倍，业务服务可以快速扩容 10 倍，但是数据库可能就成为了新的瓶颈。</p><p>像 MySQL 这种有状态的存储服务通常是扩展的技术难点，如果架构上没提前做好规划（垂直和水平拆分），就会涉及到大量数据的迁移。</p><p>因此，高扩展性需要考虑：服务集群、数据库、缓存和消息队列等中间件、负载均衡、带宽、依赖的第三方等，当并发达到某一个量级后，上述每个因素都可能成为扩展的瓶颈点。</p><h2 id="实践方案"><a href="#实践方案" class="headerlink" title="实践方案"></a>实践方案</h2><p>通用设计方法</p><p><strong>纵向扩展（scale-up）</strong></p><p>它的目标是提升单机的处理能力，方案又包括：</p><p>1、提升单机的硬件性能：通过增加内存、CPU 核数、存储容量、或者将磁盘升级成 SSD 等堆硬件的方式来提升。</p><p>2、提升单机的软件性能：使用缓存减少 IO 次数，使用并发或者异步的方式增加吞吐量。</p><p><strong>横向扩展（scale-out）</strong></p><p>因为单机性能总会存在极限，所以最终还需要引入横向扩展，通过集群部署以进一步提高并发处理能力，又包括以下 2 个方向：</p><p>1、做好分层架构：这是横向扩展的提前，因为高并发系统往往业务复杂，通过分层处理可以简化复杂问题，更容易做到横向扩展。</p><p>2、各层进行水平扩展：无状态水平扩容，有状态做分片路由。业务集群通常能设计成无状态的，而数据库和缓存往往是有状态的，因此需要设计分区键做好存储分片，当然也可以通过主从同步、读写分离的方案提升读性能。</p><h3 id="高性能实践方案"><a href="#高性能实践方案" class="headerlink" title="高性能实践方案"></a>高性能实践方案</h3><p>1、集群部署，通过负载均衡减轻单机压力。</p><p>2、多级缓存，包括静态数据使用 CDN、本地缓存、分布式缓存等，以及对缓存场景中的热点 key、缓存穿透、缓存并发、数据一致性等问题的处理。</p><p>3、分库分表和索引优化，以及借助搜索引擎解决复杂查询问题。</p><p>4、考虑 NoSQL 数据库的使用，比如 HBase、TiDB 等，但是团队必须熟悉这些组件，且有较强的运维能力。</p><p>5、异步化，将次要流程通过多线程、MQ、甚至延时任务进行异步处理。</p><p>6、限流，需要先考虑业务是否允许限流（比如秒杀场景是允许的），包括前端限流、Nginx 接入层的限流、服务端的限流。</p><p>7、对流量进行削峰填谷，通过 MQ 承接流量。</p><p>8、并发处理，通过多线程将串行逻辑并行化。</p><p>9、预计算，比如抢红包场景，可以提前计算好红包金额缓存起来，发红包时直接使用即可。</p><p>10、缓存预热，通过异步任务提前预热数据到本地缓存或者分布式缓存中。</p><p>11、减少 IO 次数，比如数据库和缓存的批量读写、RPC 的批量接口支持、或者通过冗余数据的方式干掉 RPC 调用。</p><p>12、减少 IO 时的数据包大小，包括采用轻量级的通信协议、合适的数据结构、去掉接口中的多余字段、减少缓存 key 的大小、压缩缓存 value 等。</p><p>13、程序逻辑优化，比如将大概率阻断执行流程的判断逻辑前置、For 循环的计算逻辑优化，或者采用更高效的算法。</p><p>14、各种池化技术的使用和池大小的设置，包括 HTTP 请求池、线程池（考虑 CPU 密集型还是 IO 密集型设置核心参数）、数据库和 Redis 连接池等。</p><p>15、JVM 优化，包括新生代和老年代的大小、GC 算法的选择等，尽可能减少 GC 频率和耗时。</p><p>16、锁选择，读多写少的场景用乐观锁，或者考虑通过分段锁的方式减少锁冲突。</p><h3 id="高可用实践方案"><a href="#高可用实践方案" class="headerlink" title="高可用实践方案"></a>高可用实践方案</h3><p>1、对等节点的故障转移，Nginx 和服务治理框架均支持一个节点失败后访问另一个节点。</p><p>2、非对等节点的故障转移，通过心跳检测并实施主备切换（比如 redis 的哨兵模式或者集群模式、MySQL 的主从切换等）。</p><p>3、接口层面的超时设置、重试策略和幂等设计。</p><p>4、降级处理：保证核心服务，牺牲非核心服务，必要时进行熔断；或者核心链路出问题时，有备选链路。</p><p>5、限流处理：对超过系统处理能力的请求直接拒绝或者返回错误码。</p><p>6、MQ 场景的消息可靠性保证，包括 producer 端的重试机制、broker 侧的持久化、consumer 端的 ack 机制等。</p><p>7、灰度发布，能支持按机器维度进行小流量部署，观察系统日志和业务指标，等运行平稳后再推全量。</p><p>8、监控报警：全方位的监控体系，包括最基础的 CPU、内存、磁盘、网络的监控，以及 Web 服务器、JVM、数据库、各类中间件的监控和业务指标的监控。</p><p>9、灾备演练：类似当前的“混沌工程”，对系统进行一些破坏性手段，观察局部故障是否会引起可用性问题。</p><p>高可用的方案主要从冗余、取舍、系统运维 3 个方向考虑，同时需要有配套的值班机制和故障处理流程，当出现线上问题时，可及时跟进处理。</p><h3 id="高扩展的实践方案"><a href="#高扩展的实践方案" class="headerlink" title="高扩展的实践方案"></a>高扩展的实践方案</h3><p>1、合理的分层架构：比如上面谈到的互联网最常见的分层架构，另外还能进一步按照数据访问层、业务逻辑层对微服务做更细粒度的分层（但是需要评估性能，会存在网络多一跳的情况）。</p><p>2、存储层的拆分：按照业务维度做垂直拆分、按照数据特征维度进一步做水平拆分（分库分表）。</p><p>3、业务层的拆分：最常见的是按照业务维度拆（比如电商场景的商品服务、订单服务等），也可以按照核心接口和非核心接口拆，还可以按照请求去拆（比如 To C 和 To B，APP 和 H5）。</p>]]></content>
      
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 架构设计 </tag>
            
            <tag> 面试题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>阿里P8面试官：如何设计一个扛住千万级并发的架构？</title>
      <link href="/posts/1568521894/"/>
      <url>/posts/1568521894/</url>
      
        <content type="html"><![CDATA[<p>大家先思考一个问题，这也是在面试过程中经常遇到的问题。</p><blockquote><p>如果你们公司现在的产品能够支持10W用户访问，你们老板突然和你说，融到钱了，会大量投放广告，预计在1个月后用户量会达到1000W，如果这个任务交给你，你应该怎么做？</p></blockquote><h1 id="1000W用户的问题分解"><a href="#1000W用户的问题分解" class="headerlink" title="1000W用户的问题分解"></a>1000W用户的问题分解</h1><p>如何支撑1000W用户其实是一个非常抽象的问题，对于技术开发来说，我们需要一个非常明确的对于执行关键业务上的性能指标数据，比如，高峰时段下对于事务的响应时间、并发用户数、QPS、成功率、以及基本指标要求等，这些都 必须要非常明确，只有这样才能够指导整个架构的改造和优化。所以，如果大家接到这样一个问题，首先需要去定位到问题的本质，也就是首先得知道一些可量化的数据指标。</p><ul><li><p>如果有过往的相似业务交易历史数据经验，你需要尽量参考，处理这些收集到的原始数据（日志），从而分析出高峰时段，以及该时段下的交易行为，交易规模等，得到你想要看清楚的需求细节</p></li><li><p>另外一种情况，就是没有相关的数据指标作为参考，这个时候就需要经验来分析。比如可以参考一些类似行业的比较成熟的业务交易模型（比如银行业的日常交易活动或交通行业售检票交易活动）或者干脆遵循“2/8”原则和“2/5/8”原则来直接下手实践。</p><blockquote><ul><li>当用户能够在2秒以内得到响应时，会感觉系统的响应很快；</li><li>当用户在2-5秒之间得到响应时，会感觉系统的响应速度还可以；</li><li>当用户在5-8秒以内得到响应时，会感觉系统的响应速度很慢，但是还可以接受；</li><li>而当用户在超过8秒后仍然无法得到响应时，会感觉系统糟透了，或者认为系统已经失去响应，而选择离开这个Web站点，或者发起第二次请求。</li></ul></blockquote></li></ul><p>在估算响应时间、并发用户数、TPS、成功率这些关键指标的同时，你仍需要关心具体的业务功能维度上的需求，每个业务功能都有各自的特点，比如有些场景可以不需要同步返回明确执行结果，有些业务场景可以接受返回“系统忙，请等待！”这样暴力的消息，以避免过大的处理流量所导致的大规模瘫痪，因此，学会平衡这些指标之间的关系是必要的，大多数情况下最好为这些指标做一个优先级排序，并且尽量只考察几个优先级高的指标要求。(SLA服务等级)</p><blockquote><p><strong>SLA</strong>：Service-Level Agreement的缩写，意思是服务等级协议。服务的SLA是服务提供者对服务消费者的正式承诺，是衡量服务能力等级的关键项。服务SLA中定义的项必须是可测量的，有明确的测量方法。</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350947.png" alt="image-20210623165109183"></p><h2 id="并发中相关概念的解释"><a href="#并发中相关概念的解释" class="headerlink" title="并发中相关概念的解释"></a>并发中相关概念的解释</h2><p>在分析上述问题之前，先给大家普及一下，系统相关的一些关键衡量指标。</p><h3 id="TPS"><a href="#TPS" class="headerlink" title="TPS"></a>TPS</h3><p>TPS（Transaction Per Second）每秒处理的事务数。</p><p>站在宏观角度来说，一个事务是指客户端向服务端发起一个请求，并且等到请求返回之后的整个过程。从客户端发起请求开始计时，等到收到服务器端响应结果后结束计时，在计算这个时间段内总共完成的事务个数，我们称为TPS。</p><p>站在微观角度来说，一个数据库的事务操作，从开始事务到事务提交完成，表示一个完整事务，这个是数据库层面的TPS。</p><h3 id="QPS"><a href="#QPS" class="headerlink" title="QPS"></a>QPS</h3><p>QPS（Queries Per Second）每秒查询数，表示服务器端每秒能够响应的查询次数。这里的查询是指用户发出请求到服务器做出响应成功的次数，可以简单认为每秒钟的Request数量。</p><p>针对单个接口而言，TPS和QPS是相等的。如果从宏观层面来说，用户打开一个页面到页面渲染结束代表一个TPS，那这个页面中会调用服务器很多次，比如加载静态资源、查询服务器端的渲染数据等，就会产生两个QPS，因此，一个TPS中可能会包含多个QPS。</p><blockquote><p><strong>QPS=并发数/平均响应时间</strong></p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350727.png" alt="image-20210622180649041"></p><h3 id="RT"><a href="#RT" class="headerlink" title="RT"></a>RT</h3><p>RT（Response Time），表示客户端发起请求到服务端返回的时间间隔，一般表示平均响应时间。</p><h3 id="并发数"><a href="#并发数" class="headerlink" title="并发数"></a>并发数</h3><p>并发数是指系统同时能处理的请求数量。</p><p>需要注意，并发数和QPS不要搞混了，QPS表示每秒的请求数量，而并发数是系统同时处理的请求数量，并发数量会大于QPS，因为服务端的一个连接需要有一个处理时长，在这个请求处理结束之前，这个连接一直占用。</p><p>举个例子，如果QPS=1000，表示每秒钟客户端会发起1000个请求到服务端，而如果一个请求的处理耗时是3s，那么意味着总的并发=1000*3=3000，也就是服务端会同时有3000个并发。</p><h3 id="计算方法"><a href="#计算方法" class="headerlink" title="计算方法"></a>计算方法</h3><p>上面说的这些指标，怎么计算呢？举个例子。</p><p>假设在10点到11点这一个小时内，有200W个用户访问我们的系统，假设平均每个用户请求的耗时是3秒，那么计算的结果如下：</p><ul><li>QPS=2000000/60*60 = 556 （表示每秒钟会有556个请求发送到服务端）</li><li>RT=3s（每个请求的平均响应时间是3秒）</li><li>并发数=556*3=1668</li></ul><p>从这个计算过程中发现，随着RT的值越大，那么并发数就越多，而并发数代表着服务器端同时处理的连接请求数量，也就意味服务端占用的连接数越多，这些链接会消耗内存资源以及CPU资源等。所以RT值越大系统资源占用越大，同时也意味着服务端的请求处理耗时较长。</p><p>但实际情况是，RT值越小越好，比如在游戏中，至少做到100ms左右的响应才能达到最好的体验，对于电商系统来说，3s左右的时间是能接受的，那么如何缩短RT的值呢？</p><h2 id="按照2-8法则来推算1000w用户的访问量"><a href="#按照2-8法则来推算1000w用户的访问量" class="headerlink" title="按照2/8法则来推算1000w用户的访问量"></a>按照2/8法则来推算1000w用户的访问量</h2><p>继续回到最开始的问题，假设没有历史数据供我们参考，我们可以使用2/8法则来进行预估。</p><ul><li><p>1000W用户，每天来访问这个网站的用户占到20%，也就是每天有200W用户来访问。</p></li><li><p>假设平均每个用户过来点击50次，那么总共的PV=1亿。</p></li><li><p>一天是24小时，根据2/8法则，每天大部分用户活跃的时间点集中在(24*0.2) 约等于5个小时以内，而大部分用户指的是（1亿点击 * 80%）约等于8000W（PV）， 意味着在5个小时以内，大概会有8000W点击进来，也就是每秒大约有4500(8000W/5小时)个请求。</p></li><li><p>4500只是一个平均数字。在这5个小时中，不可能请求是非常平均的，有可能会存在大量的用户集中访问（比如像淘宝这样的网站，日访问峰值的时间点集中在下午14：00、以及晚上21：00，其中21：00是一天中活跃的峰值），一般情况下访问峰值是平均访问请求的3倍到4倍左右（这个是经验值），我们按照4倍来计算。那么在这5个小时内有可能会出现每秒18000个请求的情况。也就是说，问题由原本的支撑1000W用户，变成了一个具体的问题，<strong>就是服务器端需要能够支撑每秒18000个请求</strong>（QPS=18000）</p></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350543.png" alt="image-20210622160313561"></p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350921.png" alt="image-20210622160320454"></p><h2 id="服务器压力预估"><a href="#服务器压力预估" class="headerlink" title="服务器压力预估"></a>服务器压力预估</h2><p>大概预估出了后端服务器需要支撑的最高并发的峰值之后，就需要从整个系统架构层面进行压力预估，然后配置合理的服务器数量和架构。既然是这样，那么首先需要知道一台服务器能够扛做多少的并发，那这个问题怎么去分析呢？我们的应用是部署在Tomcat上，所以需要从Tomcat本身的性能下手。</p><p>下面这个图表示Tomcat的工作原理，该图的说明如下。</p><ul><li><p>LimitLatch是连接控制器，它负责控制Tomcat能够同时处理的最大连接数，在NIO/NIO2的模式中，默认是10000，如果是APR/native，默认是8192</p></li><li><p>Acceptor是一个独立的线程，在run方法中，在while循环中调用socket.accept方法中接收客户端的连接请求，一旦有新的请求过来，accept会返回一个Channel对象，接着把这个Channel对象交给Poller去处理。</p><blockquote><p>Poller 的本质是一个 Selector ，它同样也实现了线程，Poller 在内部维护一个 Channel 数组，它在一个死循环里不断检测 Channel 的数据就绪状态，一旦有 Channel 可读，就生成一个 SocketProcessor 任务对象扔给 Executor 去处理</p></blockquote></li><li><p>SocketProcessor 实现了 Runnable 接口，当线程池在执行SocketProcessor这个任务时，会通过Http11Processor去处理当前这个请求，Http11Processor 读取 Channel 的数据来生成 ServletRequest 对象。</p></li><li><p>Executor 就是线程池，负责运行 SocketProcessor 任务类， SocketProcessor 的 run 方法会调用 Http11Processor 来读取和解析请求数据。我们知道， Http11Processor 是应用层协议的封装，它会调用容器获得响应，再把响应通过 Channel 写出。</p></li></ul><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350538.png" alt="image-20210622154519229"></p><p>从这个图中可以得出，限制Tomcat请求数量的因素四个方面。</p><h3 id="当前服务器系统资源"><a href="#当前服务器系统资源" class="headerlink" title="当前服务器系统资源"></a>当前服务器系统资源</h3><p>我想可能大家遇到过类似“Socket/File：Can’t open so many files”的异常，这个就是表示Linux系统中的文件句柄限制。</p><p>在Linux中，每一个TCP连接会占用一个文件描述符（fd），一旦文件描述符超过Linux系统当前的限制，就会提示这个错误。</p><p>我们可以通过下面这条命令来查看一个进程可以打开的文件数量</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">ulimit -a 或者 ulimit -n</span><br></pre></td></tr></table></figure><p>open files （-n） 1024 是linux操作系统对一个进程打开的文件句柄数量的限制（也包含打开的套接字数量）</p><p>这里只是对用户级别的限制，其实还有个是对系统的总限制，查看系统总线制：</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">cat /proc/sys/fs/file-max</span><br></pre></td></tr></table></figure><p>file-max是设置系统所有进程一共可以打开的文件数量 。同时一些程序可以通过<code>setrlimit</code>调用，设置每个进程的限制。如果得到大量使用完文件句柄的错误信息，是应该增加这个值。</p><p>当出现上述异常时，我们可以通过下面的方式来进行修改（针对单个进程的打开数量限制）</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /etc/security/limits.conf</span><br><span class="line">  root soft nofile 65535</span><br><span class="line">  root hard nofile 65535</span><br><span class="line">  * soft nofile 65535</span><br><span class="line">  * hard nofile 65535</span><br></pre></td></tr></table></figure><ul><li><code>*</code>代表所有用户、<code>root</code>表示root用户。</li><li>noproc 表示最大进程数量</li><li>nofile代表最大文件打开数量。</li><li>soft/hard，前者当达到阈值时，制作警告，后者会报错。</li></ul><p>另外还要注意，要确保针对进程级别的文件打开数量反问是小于或者等于系统的总限制，否则，我们需要修改系统的总限制。</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">vi /proc/sys/fs/file-max</span><br></pre></td></tr></table></figure><p>TCP连接对于系统资源最大的开销就是内存。</p><p>因为tcp连接归根结底需要双方接收和发送数据，那么就需要一个读缓冲区和写缓冲区，这两个buffer在linux下最小为4096字节，可通过cat /proc/sys/net/ipv4/tcp_rmem和cat /proc/sys/net/ipv4/tcp_wmem来查看。</p><p>所以，一个tcp连接最小占用内存为4096+4096 = 8k，那么对于一个8G内存的机器，在不考虑其他限制下，最多支持的并发量为：8<em>1024</em>1024/8 约等于100万。此数字为纯理论上限数值，在实际中，由于linux kernel对一些资源的限制，加上程序的业务处理，所以，8G内存是很难达到100万连接的，当然，我们也可以通过增加内存的方式增加并发量。</p><h3 id="Tomcat依赖的JVM的配置"><a href="#Tomcat依赖的JVM的配置" class="headerlink" title="Tomcat依赖的JVM的配置"></a>Tomcat依赖的JVM的配置</h3><p>我们知道Tomcat是Java程序，运行在JVM上，因此我们还需要对JVM做优化，才能更好的提升Tomcat的性能，简单带大家了解一下JVM，如下图所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350493.png" alt="image-20210623204411021"></p><p>在JVM中，内存划分为堆、程序计数器、本地方发栈、方法区（元空间）、虚拟机栈。</p><h4 id="堆空间说明"><a href="#堆空间说明" class="headerlink" title="堆空间说明"></a>堆空间说明</h4><p>其中，堆内存是JVM内存中最大的一块区域，几乎所有的对象和数组都会被分配到堆内存中，它被所有线程共享。 堆空间被划分为新生代和老年代，新生代进一步划分为Eden和Surivor区，如下图所示。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350001.png" alt="image-20210623205840226"></p><p>新生代和老年代的比例是1：2，也就是新生代会占1/3的堆空间，老年代会占2/3的堆空间。 另外，在新生代中，空间占比为Eden:Surivor0:Surivor1=8:1:1 。 举个例子来说，如果eden区内存大小是40M，那么两个Survivor区分别是占5M，整个新生代就是50M，然后计算出老年代的内存大小是100M，也就是说堆空间的总内存大小是150M。</p><blockquote><p>可以通过 java -XX:PrintFlagsFinal -version查看默认参数</p><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">uintx InitialSurvivorRatio                      = 8</span><br><span class="line">uintx NewRatio                                  = 2</span><br></pre></td></tr></table></figure><p>InitialSurvivorRatio:  新生代Eden/Survivor空间的初始比例</p><p>NewRatio ： Old区/Young区的内存比例</p></blockquote><p>堆内存的具体工作原理是：</p><ul><li>绝大部分的对象被创建之后，会保存在Eden区，当Eden区满了的时候，就会触发YGC（Young GC），大部分对象会被回收掉，如果还有活着的对象，就拷贝到Survivor0，这时Eden区被清空。</li><li>如果后续再次触发YGC，活着的对象Eden+Survivor0中的对象拷贝到Survivor1区， 这时Eden和Survivor0都会被清空</li><li>接着再触发YGC，Eden+Survivor1中的对象会被拷贝到Survivor0区，一直这么循环，直到对象的年龄达到阈值，则放入到老年代。（之所以这么设计，是因为Eden区的大部分对象会被回收）</li><li>Survivor区装不下的对象会直接进入到老年代</li><li>老年代满了，会触发Full GC。</li></ul><blockquote><p>GC标记-清除算法 在执行过程中暂停其他线程??</p></blockquote><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350497.png" alt="image-20210623214030533"></p><h4 id="程序计数器"><a href="#程序计数器" class="headerlink" title="程序计数器"></a>程序计数器</h4><p>程序计数器是用来记录各个线程执行的字节码地址等，当线程发生上下文切换时，需要依靠这个来记住当前执行的位置，当下次恢复执行后要沿着上一次执行的位置继续执行。</p><h4 id="方法区"><a href="#方法区" class="headerlink" title="方法区"></a>方法区</h4><p>方法区是逻辑上的概念，在HotSpot虚拟机的1.8版本中，它的具体实现就是元空间。</p><p>方法区主要用来存放已经被虚拟机加载的类相关信息，包括类元信息、运行时常量池、字符串常量池，类信息又包括类的版本、字段、方法、接口和父类信息等。</p><p>方法区和堆空间类似，它是一个共享内存区域，所以方法区是属于线程共享的。</p><h4 id="本地方发栈和虚拟机栈"><a href="#本地方发栈和虚拟机栈" class="headerlink" title="本地方发栈和虚拟机栈"></a>本地方发栈和虚拟机栈</h4><p>Java虚拟机栈是线程私有的内存空间，当创建一个线程时，会在虚拟机中申请一个线程栈，用来保存方法的局部变量、操作数栈、动态链接方法等信息。每一个方法的调用都伴随这栈帧的入栈操作，当一个方法返回之后，就是栈帧的出栈操作。</p><p>本地方法栈和虚拟机栈类似，本地方法栈是用来管理本地方法的调用，也就是native方法。</p><h4 id="JVM内存应该怎么设置"><a href="#JVM内存应该怎么设置" class="headerlink" title="JVM内存应该怎么设置"></a>JVM内存应该怎么设置</h4><p>了解了上述基本信息之后，那么JVM中内存应该如何设置呢？有哪些参数来设置？</p><p>而在JVM中，要配置的几个核心参数无非是。</p><ul><li><p><code>-Xms</code>，Java堆内存大小</p></li><li><p><code>-Xmx</code>，Java最大堆内存大小</p></li><li><p><code>-Xmn</code>，Java堆内存中的新生代大小，扣除新生代剩下的就是老年代内存</p><p>新生代内存设置过小会频繁触发Minor GC，频繁触发GC会影响系统的稳定性</p></li><li><p><code>-XX:MetaspaceSize</code>，元空间大小， 128M</p></li><li><p><code>-XX:MaxMetaspaceSize</code>，最大云空间大小 （如果没有指定这两个参数，元空间会在运行时根据需要动态调整。）  256M</p><blockquote><p>一个新系统的元空间，基本上没办法有一个测算的方法，一般设置几百兆就够用，因为这里面主要存放一些类信息。</p></blockquote></li><li><p><code>-Xss</code>，线程栈内存大小，这个基本上不需要预估，设置512KB到1M就行，因为值越小，能够分配的线程数越多。</p></li></ul><p>JVM内存的大小，取决于机器的配置，比如一个2核4G的服务器，能够分配给JVM进程也就2G左右，因为机器本身也需要内存，而且机器上还运行了其他的进程也需要占内存。而这2G还得分配给栈内存、堆内存、元空间，那堆内存能够得到的也就1G左右，然后堆内存还要分新生代、老年代。</p><h3 id="Tomcat本身的配置"><a href="#Tomcat本身的配置" class="headerlink" title="Tomcat本身的配置"></a>Tomcat本身的配置</h3><blockquote><p><a href="http://tomcat.apache.org/tomcat-8.0-doc/config/http.html">http://tomcat.apache.org/tomcat-8.0-doc/config/http.html</a></p></blockquote><blockquote><p>The maximum number of request processing threads to be created by this <strong>Connector</strong>, which therefore determines the maximum number of simultaneous requests that can be handled. If not specified, this attribute is set to 200. If an executor is associated with this connector, this attribute is ignored as the connector will execute tasks using the executor rather than an internal thread pool. Note that if an executor is configured any value set for this attribute will be recorded correctly but it will be reported (e.g. via JMX) as <code>-1</code> to make clear that it is not used.</p></blockquote><figure class="highlight yaml"><table><tr><td class="code"><pre><span class="line"><span class="attr">server:</span></span><br><span class="line">  <span class="attr">tomcat:</span></span><br><span class="line">    <span class="attr">uri-encoding:</span> <span class="string">UTF-8</span></span><br><span class="line">    <span class="comment">#最大工作线程数，默认200, 4核8g内存，线程数经验值800</span></span><br><span class="line">    <span class="comment">#操作系统做线程之间的切换调度是有系统开销的，所以不是越多越好。</span></span><br><span class="line">    <span class="attr">max-threads:</span> <span class="number">1000</span></span><br><span class="line">    <span class="comment"># 等待队列长度，默认100，</span></span><br><span class="line">    <span class="attr">accept-count:</span> <span class="number">1000</span></span><br><span class="line">    <span class="attr">max-connections:</span> <span class="number">20000</span></span><br><span class="line">    <span class="comment"># 最小工作空闲线程数，默认10, 适当增大一些，以便应对突然增长的访问量</span></span><br><span class="line">    <span class="attr">min-spare-threads:</span> <span class="number">100</span></span><br></pre></td></tr></table></figure><ul><li><p><strong>accept-count:</strong> 最大等待数，当调用HTTP请求数达到tomcat的最大线程数时，还有新的HTTP请求到来，这时tomcat会将该请求放在等待队列中，这个acceptCount就是指能够接受的最大等待数，默认100。如果等待队列也被放满了，这个时候再来新的请求就会被tomcat拒绝（connection refused）</p></li><li><p><strong>maxThreads：</strong>最大线程数，每一次HTTP请求到达Web服务，tomcat都会创建一个线程来处理该请求，那么最大线程数决定了Web服务容器可以同时处理多少个请求。maxThreads默认200，肯定建议增加。但是，增加线程是有成本的，更多的线程，不仅仅会带来更多的线程上下文切换成本，而且意味着带来更多的内存消耗。JVM中默认情况下在创建新线程时会分配大小为1M的线程栈，所以，更多的线程异味着需要更多的内存。线程数的经验值为：1核2g内存为200，线程数经验值200；4核8g内存，线程数经验值800。</p></li><li><p><strong>maxConnections</strong>，最大连接数，这个参数是指在同一时间，tomcat能够接受的最大连接数。对于Java的阻塞式BIO，默认值是maxthreads的值；如果在BIO模式使用定制的Executor执行器，默认值将是执行器中maxthreads的值。对于Java 新的NIO模式，maxConnections 默认值是10000。对于windows上APR/native IO模式，maxConnections默认值为8192</p><p>如果设置为-1，则禁用maxconnections功能，表示不限制tomcat容器的连接数。<br><strong>maxConnections和accept-count的关系为：当连接数达到最大值maxConnections后，系统会继续接收连接，但不会超过acceptCount的值。</strong></p></li></ul><h3 id="1-3-4-应用带来的压力"><a href="#1-3-4-应用带来的压力" class="headerlink" title="1.3.4 应用带来的压力"></a>1.3.4 应用带来的压力</h3><p>前面我们分析过，NIOEndPoint接收到客户端请求连接后，会生成一个SocketProcessor任务给到线程池去处理，SocketProcessor中的run方法会调用HttpProcessor组件去解析应用层的协议，并生成Request对象。最后调用Adapter的Service方法，将请求传递到容器中。</p><p>容器主要负责内部的处理工作，也就是当前置的连接器通过Socket获取到信息之后，得到一个Servlet请求，而容器就是负责处理Servlet请求。</p><p>Tomcat使用Mapper组件将用户请求的URL定位到一个具体的Serlvet，然后Spring中的DispatcherServlet拦截到该Servlet请求后，基于Spring本身的Mapper映射定位到我们具体的Controller中。</p><p>到了Controller之后，对于我们的业务来说，才是一个请求真正的开始，Controller调用Service、Service调用dao，完成数据库操作之后，讲请求原路返回给到客户端，完成一次整体的会话。也就是说，Controller中的业务逻辑处理耗时，对于整个容器的并发来说也会受到影响。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350088.png" alt="image-20210622151107514"></p><h2 id="服务器数量评估"><a href="#服务器数量评估" class="headerlink" title="服务器数量评估"></a>服务器数量评估</h2><p>通过上述分析，我们假设一个tomcat节点的QPS=500，如果要支撑到高峰时期的QPS=18000，那么需要40台服务器，这四台服务器需要通过Nginx软件负载均衡，进行请求分发，Nginx的性能很好，官方给的说明是Nginx处理静态文件的并发能够达到5W/s。另外Nginx由于不能单点，我们可以采用LVS对Nginx做负载均衡，LVS（Linux VirtualServer），它是采用IP负载均衡技术实现负载均衡。</p><p><img src="https://mic-blob-bucket.oss-cn-beijing.aliyuncs.com/202110171350886.png" alt="image-20210622220213652"></p><p>通过这样的一组架构，我们当前服务端是能够同时承接QPS=18000，但是还不够，再回到前面我们说的两个公式。</p><ul><li><p>QPS=并发量/平均响应时间</p></li><li><p>并发量=QPS*平均响应时间</p></li></ul><p>假设我们的RT是3s，那么意味着服务器端的并发数=18000*3=54000，也就是同时有54000个连接打到服务器端，所以服务端需要同时支持的连接数为54000，这个我们在前文说过如何进行配置。如果RT越大，那么意味着堆积的链接越多，而这些连接会占用内存资源/CPU资源等，容易造成系统崩溃的现象。同时，当链接数超过阈值时，后续的请求无法进来，用户会得到一个请求超时的结果，这显然不是我们所希望看到的，所以我们必须要缩短RT的值。</p>]]></content>
      
      
      <categories>
          
          <category> 架构设计 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 高并发 </tag>
            
            <tag> 架构设计 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/posts/1243066710/"/>
      <url>/posts/1243066710/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
